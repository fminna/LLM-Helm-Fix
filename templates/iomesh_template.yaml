---
# Source: iomesh/charts/csi-driver/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name:  iomesh-csi-driver-controller-account
  labels:
    helm.sh/chart: csi-driver-2.6.0
    app.kubernetes.io/name: csi-driver
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "v2.6.0"
    app.kubernetes.io/managed-by: Helm
  namespace: default
---
# Source: iomesh/charts/csi-driver/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name:  iomesh-csi-driver-node-account
  labels:
    helm.sh/chart: csi-driver-2.6.0
    app.kubernetes.io/name: csi-driver
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "v2.6.0"
    app.kubernetes.io/managed-by: Helm
  namespace: default
---
# Source: iomesh/charts/csi-driver/templates/snapshotter-controller.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  annotations:
    helm.sh/resource-policy: keep
  name: snapshot-controller
  namespace: kube-system
---
# Source: iomesh/charts/hostpath-provisioner/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: release-name-hostpath-provisioner
  labels:
    helm.sh/chart: hostpath-provisioner-0.5.3
    app.kubernetes.io/name: hostpath-provisioner
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.5.3"
    app.kubernetes.io/managed-by: Helm
---
# Source: iomesh/charts/iomesh-localpv-manager/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name:  iomesh-localpv-manager
  labels:
    app.kubernetes.io/name: iomesh-localpv-manager
  namespace: default
---
# Source: iomesh/charts/openebs-ndm/templates/rbac.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: openebs-ndm
  annotations:
    helm.sh/resource-policy: keep
---
# Source: iomesh/charts/zookeeper-operator/templates/service_account.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: zookeeper-operator
  namespace: default
  annotations:
    helm.sh/resource-policy: keep
  labels:
    app.kubernetes.io/name: zookeeper-operator
    app.kubernetes.io/version: "0.2.15"
    app.kubernetes.io/managed-by: Helm
    helm.sh/chart: "zookeeper-operator-0.2.15"
---
# Source: iomesh/templates/prepare-iomesh.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: prepare-csi
  namespace: default
---
# Source: iomesh/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: release-name-operator
  namespace: default
  labels:
    helm.sh/chart: iomesh-v1.0.1
    app.kubernetes.io/name: operator
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "v5.3.0-rc13"
    app.kubernetes.io/managed-by: Helm
  annotations:
    helm.sh/resource-policy: keep
---
# Source: iomesh/templates/webhook.yaml
kind: Secret
apiVersion: v1
metadata:
  name: iomesh-webhook-cert
  namespace: "default"
  labels:
      app.kubernetes.io/name: operator
      app.kubernetes.io/instance: release-name
type: Opaque
data:
  ca.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURJekNDQWd1Z0F3SUJBZ0lRSDJrU2FFSStPMGcxTkc3TWJKOER5akFOQmdrcWhraUc5dzBCQVFzRkFEQWMKTVJvd0dBWURWUVFERXhGcGIyMWxjMmd0ZDJWaWFHOXZheTFqWVRBZUZ3MHlOREExTVRVeE1ETXdORGxhRncwegpOREExTVRNeE1ETXdORGxhTUJ3eEdqQVlCZ05WQkFNVEVXbHZiV1Z6YUMxM1pXSm9iMjlyTFdOaE1JSUJJakFOCkJna3Foa2lHOXcwQkFRRUZBQU9DQVE4QU1JSUJDZ0tDQVFFQW9haExoZDVaLys5Wm9uWUI0MnhOZitRMHVsTW0KTS9sN2ZIc2R0R1hZUk1yblhTRXV3SnFFbnRTOUVBZFJhNHd6bnQ4KzRsRkR3SDlteXNLUVEzUWJlL2YwS0w4NApQM1c3T3hhanVsaXIzcHVsVEZKR05UUDJQd2N4aVAvdUxDVGgvK0ltZFpSMGJtL3VxbER6Y1FZeHdPY0xKNEQwCkoxVUtFV0VkZFZvQ1pPRkpQVVpucUJ0YURhMTJad21OOGFzaG1QSjBoOG5pZDQ5R3E3NUVEdDk3dDA4Y3NrUVEKa2RTMHl2Q244SnFBTkVDeFhOZHBDdU1WVzllVmxheWVzZVZrck1QaWFacHV5N2dvSEkySlFjK2hYS1NKaEFKQgp0ZEZrRlZEMHpjRWo3Yjg4emVrRlR5VFNtNE45S1E4ZjA3NHJwSFZLVnBRcVIvbzl5RWZEY0ZtYmt3SURBUUFCCm8yRXdYekFPQmdOVkhROEJBZjhFQkFNQ0FxUXdIUVlEVlIwbEJCWXdGQVlJS3dZQkJRVUhBd0VHQ0NzR0FRVUYKQndNQ01BOEdBMVVkRXdFQi93UUZNQU1CQWY4d0hRWURWUjBPQkJZRUZERmR3dkxZRURwRnpMSkRIUE1SRlNRWAoxQ0JETUEwR0NTcUdTSWIzRFFFQkN3VUFBNElCQVFCWkxjc1BQdnRnb1E4U21SQ3NJdXQya1NrTzNqQVhobGNHCi9Id3EzMkJXNTNIVmlqdlNzM1NhbzRJdjRCbEFrL09STWJGYnFwK2xrNWxxQmN2TWhkeElISHdmeEw3bFMzTksKdXF3eURPMUplRTFrRytaSTN6d2lrc2tDbHY5VEZjdUltYno4bmVBNVRqdUlkSnp3WFJZMXY4cHg0WnZCZkdwdQo2VXNya052ajMyQ0Mwc3lXS3hISS92L252WWp0dlQ2alcxYkFtVXNQenhlT1A3dE91Mmd6ZmplVHFSOHpRMHdoCmtscG1BZCt6VEJjR3pFK2FjUmRWU2ZES0pMZ3J4VHpUZnIwMjZ3Nm1nUGdreHVJUm5QNnhQemJRVGRXdmJaSHkKWTQ5alMyNHl3ZFozc0xlVFVRaDQ4bWxpclBNV1REMm1VZWlGd05zVjJwazhmZ0NJZTRyOAotLS0tLUVORCBDRVJUSUZJQ0FURS0tLS0tCg==
  tls.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURWVENDQWoyZ0F3SUJBZ0lSQU14UEJVcXRUTEFIUTd4cW5RV0hHNjR3RFFZSktvWklodmNOQVFFTEJRQXcKSERFYU1CZ0dBMVVFQXhNUmFXOXRaWE5vTFhkbFltaHZiMnN0WTJFd0hoY05NalF3TlRFMU1UQXpNRFE1V2hjTgpNelF3TlRFek1UQXpNRFE1V2pBbE1TTXdJUVlEVlFRREV4cHBiMjFsYzJndGQyVmlhRzl2YXk1a1pXWmhkV3gwCkxuTjJZekNDQVNJd0RRWUpLb1pJaHZjTkFRRUJCUUFEZ2dFUEFEQ0NBUW9DZ2dFQkFNc0NhbTJBcjI3QVVGMXoKQUVRQ0E2ZHdZVTdPeFRmcU9yVFVMMGp3cWtNN1hNdkxlTXNTRmV2THhHakdtMytxNW93VWlOd3pCUGN5RHQ5awpRT1ZxbTh0ektBZWIxZWtqV3o4dWplcHJxZk1HYm52SCtzS0RyaDI2dm5MUzR5ajVoN3l4RTV3VFZtWDVPN0pnClRCSlY5ZGhMc0cxdDU2c3dKSkxNc3E4ZHBuK0pTOFdWWjBYSUk5RU9LcWFVQytXWUloMG8zazJYYmZHdHQweVYKZWhHeEtnZ0RWOWdLQjBEeVAxRGlCQk9mVURJM203SHl0dE1rM1pSbHprSW9SWTNvdytYME02UktVTDdWbEtjego3ODNjaE82UDF1RkVkai9wU2JTbGhVOHN1dldBTy9zTW1KbGdUbXRkZG8wUzJya202Q29yR1J0WHp3LzBCSjhsCnRUMFBUVTBDQXdFQUFhT0JpRENCaFRBT0JnTlZIUThCQWY4RUJBTUNCYUF3SFFZRFZSMGxCQll3RkFZSUt3WUIKQlFVSEF3RUdDQ3NHQVFVRkJ3TUNNQXdHQTFVZEV3RUIvd1FDTUFBd0h3WURWUjBqQkJnd0ZvQVVNVjNDOHRnUQpPa1hNc2tNYzh4RVZKQmZVSUVNd0pRWURWUjBSQkI0d0hJSWFhVzl0WlhOb0xYZGxZbWh2YjJzdVpHVm1ZWFZzCmRDNXpkbU13RFFZSktvWklodmNOQVFFTEJRQURnZ0VCQUVLUERnMFJ4Wmt4NzZNSy94V3lhOW5CN3BmdWwrTTUKNE1hN1BDdnAyZWN4aElrczNJeGlMdU1RcE1XOHprZjd4NTcwOEEzSDFOaTE0c2x6Rk1uYmthdVR4Y0hhU1RNdgpKdEl0MytGWE1keDJOSUZYdkZRZ05xUU5aRWhBWldiN2k5ZGJCQUFEM2FtYVhzdVBCditBdlU5SERxK1Nab1kwCisvYTlPclB1Zk95Vk1KdFp3ZTRETDR2VkZFZTBWK04yRDZ6T0RBOWVzcWJ1OE84U2FGckhtV3NUdGNzNENjRGQKVU1DWGlXRE5RZERnZXJDb2tjZ0ZlNVZhWFgyNFFNR2FnRUlsQmFZZjZKYnVYM0dvRzdXbDNQWDdWVnZESVpGRgpXc05aZjQzZFl0OFRuNXNZdnhrLzZuM0tLS3d0aThXcGUrc2JTaFNaSmJydHBZWnB3OGYyekR3PQotLS0tLUVORCBDRVJUSUZJQ0FURS0tLS0tCg==
  tls.key: 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
---
# Source: iomesh/charts/csi-driver/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: iomesh-csi-driver-node-map
  labels:
    helm.sh/chart: csi-driver-2.6.0
    app.kubernetes.io/name: csi-driver
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "v2.6.0"
    app.kubernetes.io/managed-by: Helm
  namespace: default
---
# Source: iomesh/charts/csi-driver/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: iomesh-csi-driver-iscsi-config
  labels:
    helm.sh/chart: csi-driver-2.6.0
    app.kubernetes.io/name: csi-driver
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "v2.6.0"
    app.kubernetes.io/managed-by: Helm
  namespace: default
data:
  iscsi: |
---
# Source: iomesh/charts/openebs-ndm/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-openebs-ndm-config
  annotations:
    helm.sh/resource-policy: keep
data:
  # node-disk-manager-config contains config of available probes and filters.
  # Probes and Filters will initialize with default values if config for that
  # filter or probe are not present in configmap

  # udev-probe is default or primary probe it should be enabled to run ndm
  # filterconfigs contains configs of filters. To provide a group of include
  # and exclude values add it as , separated string
  node-disk-manager.config: |
    probeconfigs:
      - key: udev-probe
        name: udev probe
        state: true
      - key: seachest-probe
        name: seachest probe
        state: true
      - key: smart-probe
        name: smart probe
        state: true
    filterconfigs:
      - key: os-disk-exclude-filter
        name: os disk exclude filter
        state: true
        exclude: "/,/etc/hosts,/boot"
      - key: vendor-filter
        name: vendor filter
        state: true
        include: ""
        exclude: "ZBS"
      - key: path-filter
        name: path filter
        state: true
        include: ""
        exclude: "/dev/fd0,/dev/sr0,/dev/ram,/dev/dm-,/dev/md,loop"
    metaconfigs:
      - key: node-labels
        name: node labels
        pattern: ""
      - key: device-labels
        name: device labels
        type: ""
---
# Source: iomesh/charts/csi-driver/templates/storgeclass.yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: iomesh-csi-driver
provisioner: com.iomesh.csi-driver
parameters:
  csi.storage.k8s.io/fstype: ext4
  replicaFactor: "2"
  thinProvision: "true"
reclaimPolicy: Delete
allowVolumeExpansion: true
volumeBindingMode: Immediate
---
# Source: iomesh/charts/hostpath-provisioner/templates/storageclass.yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: hostpath
provisioner: kubevirt.io/hostpath-provisioner
reclaimPolicy: Delete
volumeBindingMode: WaitForFirstConsumer
---
# Source: iomesh/charts/iomesh-localpv-manager/templates/storgeclass.yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: iomesh-localpv-manager-hostpath
provisioner: com.iomesh.iomesh-localpv-manager
parameters:
  volumeType: hostpath
  basePath: /var/iomesh/local
  enableQuota: "false"
reclaimPolicy: Delete
volumeBindingMode: WaitForFirstConsumer
---
# Source: iomesh/charts/iomesh-localpv-manager/templates/storgeclass.yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: iomesh-localpv-manager-device
provisioner: com.iomesh.iomesh-localpv-manager
parameters:
  volumeType: device
  csi.storage.k8s.io/fstype: ext4
  deviceSelector: ""
reclaimPolicy: Delete
volumeBindingMode: WaitForFirstConsumer
---
# Source: iomesh/charts/csi-driver/templates/snapshotter-controller.yaml
apiVersion: apiextensions.k8s.io/v1
kind: CustomResourceDefinition
metadata:
  annotations:
    controller-gen.kubebuilder.io/version: v0.4.0
    api-approved.kubernetes.io: "https://github.com/kubernetes-csi/external-snapshotter/pull/419"
    helm.sh/resource-policy: keep
  creationTimestamp: null
  name: volumesnapshotclasses.snapshot.storage.k8s.io
spec:
  group: snapshot.storage.k8s.io
  names:
    kind: VolumeSnapshotClass
    listKind: VolumeSnapshotClassList
    plural: volumesnapshotclasses
    singular: volumesnapshotclass
  scope: Cluster
  versions:
  - additionalPrinterColumns:
    - jsonPath: .driver
      name: Driver
      type: string
    - description: Determines whether a VolumeSnapshotContent created through the VolumeSnapshotClass should be deleted when its bound VolumeSnapshot is deleted.
      jsonPath: .deletionPolicy
      name: DeletionPolicy
      type: string
    - jsonPath: .metadata.creationTimestamp
      name: Age
      type: date
    name: v1
    schema:
      openAPIV3Schema:
        description: VolumeSnapshotClass specifies parameters that a underlying storage system uses when creating a volume snapshot. A specific VolumeSnapshotClass is used by specifying its name in a VolumeSnapshot object. VolumeSnapshotClasses are non-namespaced
        properties:
          apiVersion:
            description: 'APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources'
            type: string
          deletionPolicy:
            description: deletionPolicy determines whether a VolumeSnapshotContent created through the VolumeSnapshotClass should be deleted when its bound VolumeSnapshot is deleted. Supported values are "Retain" and "Delete". "Retain" means that the VolumeSnapshotContent and its physical snapshot on underlying storage system are kept. "Delete" means that the VolumeSnapshotContent and its physical snapshot on underlying storage system are deleted. Required.
            enum:
            - Delete
            - Retain
            type: string
          driver:
            description: driver is the name of the storage driver that handles this VolumeSnapshotClass. Required.
            type: string
          kind:
            description: 'Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds'
            type: string
          parameters:
            additionalProperties:
              type: string
            description: parameters is a key-value map with storage driver specific parameters for creating snapshots. These values are opaque to Kubernetes.
            type: object
        required:
        - deletionPolicy
        - driver
        type: object
    served: true
    storage: true
    subresources: {}
  - additionalPrinterColumns:
    - jsonPath: .driver
      name: Driver
      type: string
    - description: Determines whether a VolumeSnapshotContent created through the VolumeSnapshotClass should be deleted when its bound VolumeSnapshot is deleted.
      jsonPath: .deletionPolicy
      name: DeletionPolicy
      type: string
    - jsonPath: .metadata.creationTimestamp
      name: Age
      type: date
    name: v1beta1
    # This indicates the v1beta1 version of the custom resource is deprecated.
    # API requests to this version receive a warning in the server response.
    deprecated: true
    # This overrides the default warning returned to clients making v1beta1 API requests.
    deprecationWarning: "snapshot.storage.k8s.io/v1beta1 VolumeSnapshotClass is deprecated; use snapshot.storage.k8s.io/v1 VolumeSnapshotClass"
    schema:
      openAPIV3Schema:
        description: VolumeSnapshotClass specifies parameters that a underlying storage system uses when creating a volume snapshot. A specific VolumeSnapshotClass is used by specifying its name in a VolumeSnapshot object. VolumeSnapshotClasses are non-namespaced
        properties:
          apiVersion:
            description: 'APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources'
            type: string
          deletionPolicy:
            description: deletionPolicy determines whether a VolumeSnapshotContent created through the VolumeSnapshotClass should be deleted when its bound VolumeSnapshot is deleted. Supported values are "Retain" and "Delete". "Retain" means that the VolumeSnapshotContent and its physical snapshot on underlying storage system are kept. "Delete" means that the VolumeSnapshotContent and its physical snapshot on underlying storage system are deleted. Required.
            enum:
            - Delete
            - Retain
            type: string
          driver:
            description: driver is the name of the storage driver that handles this VolumeSnapshotClass. Required.
            type: string
          kind:
            description: 'Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds'
            type: string
          parameters:
            additionalProperties:
              type: string
            description: parameters is a key-value map with storage driver specific parameters for creating snapshots. These values are opaque to Kubernetes.
            type: object
        required:
        - deletionPolicy
        - driver
        type: object
    served: true
    storage: false
    subresources: {}
status:
  acceptedNames:
    kind: ""
    plural: ""
  conditions: []
  storedVersions: []
---
# Source: iomesh/charts/csi-driver/templates/snapshotter-controller.yaml
apiVersion: apiextensions.k8s.io/v1
kind: CustomResourceDefinition
metadata:
  annotations:
    controller-gen.kubebuilder.io/version: v0.4.0
    api-approved.kubernetes.io: "https://github.com/kubernetes-csi/external-snapshotter/pull/419"
    helm.sh/resource-policy: keep
  creationTimestamp: null
  name: volumesnapshotcontents.snapshot.storage.k8s.io
spec:
  group: snapshot.storage.k8s.io
  names:
    kind: VolumeSnapshotContent
    listKind: VolumeSnapshotContentList
    plural: volumesnapshotcontents
    singular: volumesnapshotcontent
  scope: Cluster
  versions:
  - additionalPrinterColumns:
    - description: Indicates if the snapshot is ready to be used to restore a volume.
      jsonPath: .status.readyToUse
      name: ReadyToUse
      type: boolean
    - description: Represents the complete size of the snapshot in bytes
      jsonPath: .status.restoreSize
      name: RestoreSize
      type: integer
    - description: Determines whether this VolumeSnapshotContent and its physical snapshot on the underlying storage system should be deleted when its bound VolumeSnapshot is deleted.
      jsonPath: .spec.deletionPolicy
      name: DeletionPolicy
      type: string
    - description: Name of the CSI driver used to create the physical snapshot on the underlying storage system.
      jsonPath: .spec.driver
      name: Driver
      type: string
    - description: Name of the VolumeSnapshotClass to which this snapshot belongs.
      jsonPath: .spec.volumeSnapshotClassName
      name: VolumeSnapshotClass
      type: string
    - description: Name of the VolumeSnapshot object to which this VolumeSnapshotContent object is bound.
      jsonPath: .spec.volumeSnapshotRef.name
      name: VolumeSnapshot
      type: string
    - description: Namespace of the VolumeSnapshot object to which this VolumeSnapshotContent object is bound.
      jsonPath: .spec.volumeSnapshotRef.namespace
      name: VolumeSnapshotNamespace
      type: string
    - jsonPath: .metadata.creationTimestamp
      name: Age
      type: date
    name: v1
    schema:
      openAPIV3Schema:
        description: VolumeSnapshotContent represents the actual "on-disk" snapshot object in the underlying storage system
        properties:
          apiVersion:
            description: 'APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources'
            type: string
          kind:
            description: 'Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds'
            type: string
          spec:
            description: spec defines properties of a VolumeSnapshotContent created by the underlying storage system. Required.
            properties:
              deletionPolicy:
                description: deletionPolicy determines whether this VolumeSnapshotContent and its physical snapshot on the underlying storage system should be deleted when its bound VolumeSnapshot is deleted. Supported values are "Retain" and "Delete". "Retain" means that the VolumeSnapshotContent and its physical snapshot on underlying storage system are kept. "Delete" means that the VolumeSnapshotContent and its physical snapshot on underlying storage system are deleted. For dynamically provisioned snapshots, this field will automatically be filled in by the CSI snapshotter sidecar with the "DeletionPolicy" field defined in the corresponding VolumeSnapshotClass. For pre-existing snapshots, users MUST specify this field when creating the  VolumeSnapshotContent object. Required.
                enum:
                - Delete
                - Retain
                type: string
              driver:
                description: driver is the name of the CSI driver used to create the physical snapshot on the underlying storage system. This MUST be the same as the name returned by the CSI GetPluginName() call for that driver. Required.
                type: string
              source:
                description: source specifies whether the snapshot is (or should be) dynamically provisioned or already exists, and just requires a Kubernetes object representation. This field is immutable after creation. Required.
                properties:
                  snapshotHandle:
                    description: snapshotHandle specifies the CSI "snapshot_id" of a pre-existing snapshot on the underlying storage system for which a Kubernetes object representation was (or should be) created. This field is immutable.
                    type: string
                  volumeHandle:
                    description: volumeHandle specifies the CSI "volume_id" of the volume from which a snapshot should be dynamically taken from. This field is immutable.
                    type: string
                type: object
                oneOf:
                - required: ["snapshotHandle"]
                - required: ["volumeHandle"]
              volumeSnapshotClassName:
                description: name of the VolumeSnapshotClass from which this snapshot was (or will be) created. Note that after provisioning, the VolumeSnapshotClass may be deleted or recreated with different set of values, and as such, should not be referenced post-snapshot creation.
                type: string
              volumeSnapshotRef:
                description: volumeSnapshotRef specifies the VolumeSnapshot object to which this VolumeSnapshotContent object is bound. VolumeSnapshot.Spec.VolumeSnapshotContentName field must reference to this VolumeSnapshotContent's name for the bidirectional binding to be valid. For a pre-existing VolumeSnapshotContent object, name and namespace of the VolumeSnapshot object MUST be provided for binding to happen. This field is immutable after creation. Required.
                properties:
                  apiVersion:
                    description: API version of the referent.
                    type: string
                  fieldPath:
                    description: 'If referring to a piece of an object instead of an entire object, this string should contain a valid JSON/Go field access statement, such as desiredState.manifest.containers[2]. For example, if the object reference is to a container within a pod, this would take on a value like: "spec.containers{name}" (where "name" refers to the name of the container that triggered the event) or if no container name is specified "spec.containers[2]" (container with index 2 in this pod). This syntax is chosen only to have some well-defined way of referencing a part of an object. TODO: this design is not final and this field is subject to change in the future.'
                    type: string
                  kind:
                    description: 'Kind of the referent. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds'
                    type: string
                  name:
                    description: 'Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names'
                    type: string
                  namespace:
                    description: 'Namespace of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/'
                    type: string
                  resourceVersion:
                    description: 'Specific resourceVersion to which this reference is made, if any. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency'
                    type: string
                  uid:
                    description: 'UID of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#uids'
                    type: string
                type: object
            required:
            - deletionPolicy
            - driver
            - source
            - volumeSnapshotRef
            type: object
          status:
            description: status represents the current information of a snapshot.
            properties:
              creationTime:
                description: creationTime is the timestamp when the point-in-time snapshot is taken by the underlying storage system. In dynamic snapshot creation case, this field will be filled in by the CSI snapshotter sidecar with the "creation_time" value returned from CSI "CreateSnapshot" gRPC call. For a pre-existing snapshot, this field will be filled with the "creation_time" value returned from the CSI "ListSnapshots" gRPC call if the driver supports it. If not specified, it indicates the creation time is unknown. The format of this field is a Unix nanoseconds time encoded as an int64. On Unix, the command `date +%s%N` returns the current time in nanoseconds since 1970-01-01 00:00:00 UTC.
                format: int64
                type: integer
              error:
                description: error is the last observed error during snapshot creation, if any. Upon success after retry, this error field will be cleared.
                properties:
                  message:
                    description: 'message is a string detailing the encountered error during snapshot creation if specified. NOTE: message may be logged, and it should not contain sensitive information.'
                    type: string
                  time:
                    description: time is the timestamp when the error was encountered.
                    format: date-time
                    type: string
                type: object
              readyToUse:
                description: readyToUse indicates if a snapshot is ready to be used to restore a volume. In dynamic snapshot creation case, this field will be filled in by the CSI snapshotter sidecar with the "ready_to_use" value returned from CSI "CreateSnapshot" gRPC call. For a pre-existing snapshot, this field will be filled with the "ready_to_use" value returned from the CSI "ListSnapshots" gRPC call if the driver supports it, otherwise, this field will be set to "True". If not specified, it means the readiness of a snapshot is unknown.
                type: boolean
              restoreSize:
                description: restoreSize represents the complete size of the snapshot in bytes. In dynamic snapshot creation case, this field will be filled in by the CSI snapshotter sidecar with the "size_bytes" value returned from CSI "CreateSnapshot" gRPC call. For a pre-existing snapshot, this field will be filled with the "size_bytes" value returned from the CSI "ListSnapshots" gRPC call if the driver supports it. When restoring a volume from this snapshot, the size of the volume MUST NOT be smaller than the restoreSize if it is specified, otherwise the restoration will fail. If not specified, it indicates that the size is unknown.
                format: int64
                minimum: 0
                type: integer
              snapshotHandle:
                description: snapshotHandle is the CSI "snapshot_id" of a snapshot on the underlying storage system. If not specified, it indicates that dynamic snapshot creation has either failed or it is still in progress.
                type: string
            type: object
        required:
        - spec
        type: object
    served: true
    storage: true
    subresources:
      status: {}
  - additionalPrinterColumns:
    - description: Indicates if the snapshot is ready to be used to restore a volume.
      jsonPath: .status.readyToUse
      name: ReadyToUse
      type: boolean
    - description: Represents the complete size of the snapshot in bytes
      jsonPath: .status.restoreSize
      name: RestoreSize
      type: integer
    - description: Determines whether this VolumeSnapshotContent and its physical snapshot on the underlying storage system should be deleted when its bound VolumeSnapshot is deleted.
      jsonPath: .spec.deletionPolicy
      name: DeletionPolicy
      type: string
    - description: Name of the CSI driver used to create the physical snapshot on the underlying storage system.
      jsonPath: .spec.driver
      name: Driver
      type: string
    - description: Name of the VolumeSnapshotClass to which this snapshot belongs.
      jsonPath: .spec.volumeSnapshotClassName
      name: VolumeSnapshotClass
      type: string
    - description: Name of the VolumeSnapshot object to which this VolumeSnapshotContent object is bound.
      jsonPath: .spec.volumeSnapshotRef.name
      name: VolumeSnapshot
      type: string
    - description: Namespace of the VolumeSnapshot object to which this VolumeSnapshotContent object is bound.
      jsonPath: .spec.volumeSnapshotRef.namespace
      name: VolumeSnapshotNamespace
      type: string
    - jsonPath: .metadata.creationTimestamp
      name: Age
      type: date
    name: v1beta1
    # This indicates the v1beta1 version of the custom resource is deprecated.
    # API requests to this version receive a warning in the server response.
    deprecated: true
    # This overrides the default warning returned to clients making v1beta1 API requests.
    deprecationWarning: "snapshot.storage.k8s.io/v1beta1 VolumeSnapshotContent is deprecated; use snapshot.storage.k8s.io/v1 VolumeSnapshotContent"
    schema:
      openAPIV3Schema:
        description: VolumeSnapshotContent represents the actual "on-disk" snapshot object in the underlying storage system
        properties:
          apiVersion:
            description: 'APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources'
            type: string
          kind:
            description: 'Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds'
            type: string
          spec:
            description: spec defines properties of a VolumeSnapshotContent created by the underlying storage system. Required.
            properties:
              deletionPolicy:
                description: deletionPolicy determines whether this VolumeSnapshotContent and its physical snapshot on the underlying storage system should be deleted when its bound VolumeSnapshot is deleted. Supported values are "Retain" and "Delete". "Retain" means that the VolumeSnapshotContent and its physical snapshot on underlying storage system are kept. "Delete" means that the VolumeSnapshotContent and its physical snapshot on underlying storage system are deleted. For dynamically provisioned snapshots, this field will automatically be filled in by the CSI snapshotter sidecar with the "DeletionPolicy" field defined in the corresponding VolumeSnapshotClass. For pre-existing snapshots, users MUST specify this field when creating the  VolumeSnapshotContent object. Required.
                enum:
                - Delete
                - Retain
                type: string
              driver:
                description: driver is the name of the CSI driver used to create the physical snapshot on the underlying storage system. This MUST be the same as the name returned by the CSI GetPluginName() call for that driver. Required.
                type: string
              source:
                description: source specifies whether the snapshot is (or should be) dynamically provisioned or already exists, and just requires a Kubernetes object representation. This field is immutable after creation. Required.
                properties:
                  snapshotHandle:
                    description: snapshotHandle specifies the CSI "snapshot_id" of a pre-existing snapshot on the underlying storage system for which a Kubernetes object representation was (or should be) created. This field is immutable.
                    type: string
                  volumeHandle:
                    description: volumeHandle specifies the CSI "volume_id" of the volume from which a snapshot should be dynamically taken from. This field is immutable.
                    type: string
                type: object
              volumeSnapshotClassName:
                description: name of the VolumeSnapshotClass from which this snapshot was (or will be) created. Note that after provisioning, the VolumeSnapshotClass may be deleted or recreated with different set of values, and as such, should not be referenced post-snapshot creation.
                type: string
              volumeSnapshotRef:
                description: volumeSnapshotRef specifies the VolumeSnapshot object to which this VolumeSnapshotContent object is bound. VolumeSnapshot.Spec.VolumeSnapshotContentName field must reference to this VolumeSnapshotContent's name for the bidirectional binding to be valid. For a pre-existing VolumeSnapshotContent object, name and namespace of the VolumeSnapshot object MUST be provided for binding to happen. This field is immutable after creation. Required.
                properties:
                  apiVersion:
                    description: API version of the referent.
                    type: string
                  fieldPath:
                    description: 'If referring to a piece of an object instead of an entire object, this string should contain a valid JSON/Go field access statement, such as desiredState.manifest.containers[2]. For example, if the object reference is to a container within a pod, this would take on a value like: "spec.containers{name}" (where "name" refers to the name of the container that triggered the event) or if no container name is specified "spec.containers[2]" (container with index 2 in this pod). This syntax is chosen only to have some well-defined way of referencing a part of an object. TODO: this design is not final and this field is subject to change in the future.'
                    type: string
                  kind:
                    description: 'Kind of the referent. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds'
                    type: string
                  name:
                    description: 'Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names'
                    type: string
                  namespace:
                    description: 'Namespace of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/'
                    type: string
                  resourceVersion:
                    description: 'Specific resourceVersion to which this reference is made, if any. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency'
                    type: string
                  uid:
                    description: 'UID of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#uids'
                    type: string
                type: object
            required:
            - deletionPolicy
            - driver
            - source
            - volumeSnapshotRef
            type: object
          status:
            description: status represents the current information of a snapshot.
            properties:
              creationTime:
                description: creationTime is the timestamp when the point-in-time snapshot is taken by the underlying storage system. In dynamic snapshot creation case, this field will be filled in by the CSI snapshotter sidecar with the "creation_time" value returned from CSI "CreateSnapshot" gRPC call. For a pre-existing snapshot, this field will be filled with the "creation_time" value returned from the CSI "ListSnapshots" gRPC call if the driver supports it. If not specified, it indicates the creation time is unknown. The format of this field is a Unix nanoseconds time encoded as an int64. On Unix, the command `date +%s%N` returns the current time in nanoseconds since 1970-01-01 00:00:00 UTC.
                format: int64
                type: integer
              error:
                description: error is the last observed error during snapshot creation, if any. Upon success after retry, this error field will be cleared.
                properties:
                  message:
                    description: 'message is a string detailing the encountered error during snapshot creation if specified. NOTE: message may be logged, and it should not contain sensitive information.'
                    type: string
                  time:
                    description: time is the timestamp when the error was encountered.
                    format: date-time
                    type: string
                type: object
              readyToUse:
                description: readyToUse indicates if a snapshot is ready to be used to restore a volume. In dynamic snapshot creation case, this field will be filled in by the CSI snapshotter sidecar with the "ready_to_use" value returned from CSI "CreateSnapshot" gRPC call. For a pre-existing snapshot, this field will be filled with the "ready_to_use" value returned from the CSI "ListSnapshots" gRPC call if the driver supports it, otherwise, this field will be set to "True". If not specified, it means the readiness of a snapshot is unknown.
                type: boolean
              restoreSize:
                description: restoreSize represents the complete size of the snapshot in bytes. In dynamic snapshot creation case, this field will be filled in by the CSI snapshotter sidecar with the "size_bytes" value returned from CSI "CreateSnapshot" gRPC call. For a pre-existing snapshot, this field will be filled with the "size_bytes" value returned from the CSI "ListSnapshots" gRPC call if the driver supports it. When restoring a volume from this snapshot, the size of the volume MUST NOT be smaller than the restoreSize if it is specified, otherwise the restoration will fail. If not specified, it indicates that the size is unknown.
                format: int64
                minimum: 0
                type: integer
              snapshotHandle:
                description: snapshotHandle is the CSI "snapshot_id" of a snapshot on the underlying storage system. If not specified, it indicates that dynamic snapshot creation has either failed or it is still in progress.
                type: string
            type: object
        required:
        - spec
        type: object
    served: true
    storage: false
    subresources:
      status: {}
status:
  acceptedNames:
    kind: ""
    plural: ""
  conditions: []
  storedVersions: []
---
# Source: iomesh/charts/csi-driver/templates/snapshotter-controller.yaml
apiVersion: apiextensions.k8s.io/v1
kind: CustomResourceDefinition
metadata:
  annotations:
    helm.sh/resource-policy: keep
    controller-gen.kubebuilder.io/version: v0.4.0
    api-approved.kubernetes.io: "https://github.com/kubernetes-csi/external-snapshotter/pull/419"
  creationTimestamp: null
  name: volumesnapshots.snapshot.storage.k8s.io
spec:
  group: snapshot.storage.k8s.io
  names:
    kind: VolumeSnapshot
    listKind: VolumeSnapshotList
    plural: volumesnapshots
    singular: volumesnapshot
  scope: Namespaced
  versions:
  - additionalPrinterColumns:
    - description: Indicates if the snapshot is ready to be used to restore a volume.
      jsonPath: .status.readyToUse
      name: ReadyToUse
      type: boolean
    - description: If a new snapshot needs to be created, this contains the name of the source PVC from which this snapshot was (or will be) created.
      jsonPath: .spec.source.persistentVolumeClaimName
      name: SourcePVC
      type: string
    - description: If a snapshot already exists, this contains the name of the existing VolumeSnapshotContent object representing the existing snapshot.
      jsonPath: .spec.source.volumeSnapshotContentName
      name: SourceSnapshotContent
      type: string
    - description: Represents the minimum size of volume required to rehydrate from this snapshot.
      jsonPath: .status.restoreSize
      name: RestoreSize
      type: string
    - description: The name of the VolumeSnapshotClass requested by the VolumeSnapshot.
      jsonPath: .spec.volumeSnapshotClassName
      name: SnapshotClass
      type: string
    - description: Name of the VolumeSnapshotContent object to which the VolumeSnapshot object intends to bind to. Please note that verification of binding actually requires checking both VolumeSnapshot and VolumeSnapshotContent to ensure both are pointing at each other. Binding MUST be verified prior to usage of this object.
      jsonPath: .status.boundVolumeSnapshotContentName
      name: SnapshotContent
      type: string
    - description: Timestamp when the point-in-time snapshot was taken by the underlying storage system.
      jsonPath: .status.creationTime
      name: CreationTime
      type: date
    - jsonPath: .metadata.creationTimestamp
      name: Age
      type: date
    name: v1
    schema:
      openAPIV3Schema:
        description: VolumeSnapshot is a user's request for either creating a point-in-time snapshot of a persistent volume, or binding to a pre-existing snapshot.
        properties:
          apiVersion:
            description: 'APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources'
            type: string
          kind:
            description: 'Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds'
            type: string
          spec:
            description: 'spec defines the desired characteristics of a snapshot requested by a user. More info: https://kubernetes.io/docs/concepts/storage/volume-snapshots#volumesnapshots Required.'
            properties:
              source:
                description: source specifies where a snapshot will be created from. This field is immutable after creation. Required.
                properties:
                  persistentVolumeClaimName:
                    description: persistentVolumeClaimName specifies the name of the PersistentVolumeClaim object representing the volume from which a snapshot should be created. This PVC is assumed to be in the same namespace as the VolumeSnapshot object. This field should be set if the snapshot does not exists, and needs to be created. This field is immutable.
                    type: string
                  volumeSnapshotContentName:
                    description: volumeSnapshotContentName specifies the name of a pre-existing VolumeSnapshotContent object representing an existing volume snapshot. This field should be set if the snapshot already exists and only needs a representation in Kubernetes. This field is immutable.
                    type: string
                type: object
                oneOf:
                - required: ["persistentVolumeClaimName"]
                - required: ["volumeSnapshotContentName"]
              volumeSnapshotClassName:
                description: 'VolumeSnapshotClassName is the name of the VolumeSnapshotClass requested by the VolumeSnapshot. VolumeSnapshotClassName may be left nil to indicate that the default SnapshotClass should be used. A given cluster may have multiple default Volume SnapshotClasses: one default per CSI Driver. If a VolumeSnapshot does not specify a SnapshotClass, VolumeSnapshotSource will be checked to figure out what the associated CSI Driver is, and the default VolumeSnapshotClass associated with that CSI Driver will be used. If more than one VolumeSnapshotClass exist for a given CSI Driver and more than one have been marked as default, CreateSnapshot will fail and generate an event. Empty string is not allowed for this field.'
                type: string
            required:
            - source
            type: object
          status:
            description: status represents the current information of a snapshot. Consumers must verify binding between VolumeSnapshot and VolumeSnapshotContent objects is successful (by validating that both VolumeSnapshot and VolumeSnapshotContent point at each other) before using this object.
            properties:
              boundVolumeSnapshotContentName:
                description: 'boundVolumeSnapshotContentName is the name of the VolumeSnapshotContent object to which this VolumeSnapshot object intends to bind to. If not specified, it indicates that the VolumeSnapshot object has not been successfully bound to a VolumeSnapshotContent object yet. NOTE: To avoid possible security issues, consumers must verify binding between VolumeSnapshot and VolumeSnapshotContent objects is successful (by validating that both VolumeSnapshot and VolumeSnapshotContent point at each other) before using this object.'
                type: string
              creationTime:
                description: creationTime is the timestamp when the point-in-time snapshot is taken by the underlying storage system. In dynamic snapshot creation case, this field will be filled in by the snapshot controller with the "creation_time" value returned from CSI "CreateSnapshot" gRPC call. For a pre-existing snapshot, this field will be filled with the "creation_time" value returned from the CSI "ListSnapshots" gRPC call if the driver supports it. If not specified, it may indicate that the creation time of the snapshot is unknown.
                format: date-time
                type: string
              error:
                description: error is the last observed error during snapshot creation, if any. This field could be helpful to upper level controllers(i.e., application controller) to decide whether they should continue on waiting for the snapshot to be created based on the type of error reported. The snapshot controller will keep retrying when an error occurrs during the snapshot creation. Upon success, this error field will be cleared.
                properties:
                  message:
                    description: 'message is a string detailing the encountered error during snapshot creation if specified. NOTE: message may be logged, and it should not contain sensitive information.'
                    type: string
                  time:
                    description: time is the timestamp when the error was encountered.
                    format: date-time
                    type: string
                type: object
              readyToUse:
                description: readyToUse indicates if the snapshot is ready to be used to restore a volume. In dynamic snapshot creation case, this field will be filled in by the snapshot controller with the "ready_to_use" value returned from CSI "CreateSnapshot" gRPC call. For a pre-existing snapshot, this field will be filled with the "ready_to_use" value returned from the CSI "ListSnapshots" gRPC call if the driver supports it, otherwise, this field will be set to "True". If not specified, it means the readiness of a snapshot is unknown.
                type: boolean
              restoreSize:
                type: string
                description: restoreSize represents the minimum size of volume required to create a volume from this snapshot. In dynamic snapshot creation case, this field will be filled in by the snapshot controller with the "size_bytes" value returned from CSI "CreateSnapshot" gRPC call. For a pre-existing snapshot, this field will be filled with the "size_bytes" value returned from the CSI "ListSnapshots" gRPC call if the driver supports it. When restoring a volume from this snapshot, the size of the volume MUST NOT be smaller than the restoreSize if it is specified, otherwise the restoration will fail. If not specified, it indicates that the size is unknown.
                pattern: ^(\+|-)?(([0-9]+(\.[0-9]*)?)|(\.[0-9]+))(([KMGTPE]i)|[numkMGTPE]|([eE](\+|-)?(([0-9]+(\.[0-9]*)?)|(\.[0-9]+))))?$
                x-kubernetes-int-or-string: true
            type: object
        required:
        - spec
        type: object
    served: true
    storage: true
    subresources:
      status: {}
  - additionalPrinterColumns:
    - description: Indicates if the snapshot is ready to be used to restore a volume.
      jsonPath: .status.readyToUse
      name: ReadyToUse
      type: boolean
    - description: If a new snapshot needs to be created, this contains the name of the source PVC from which this snapshot was (or will be) created.
      jsonPath: .spec.source.persistentVolumeClaimName
      name: SourcePVC
      type: string
    - description: If a snapshot already exists, this contains the name of the existing VolumeSnapshotContent object representing the existing snapshot.
      jsonPath: .spec.source.volumeSnapshotContentName
      name: SourceSnapshotContent
      type: string
    - description: Represents the minimum size of volume required to rehydrate from this snapshot.
      jsonPath: .status.restoreSize
      name: RestoreSize
      type: string
    - description: The name of the VolumeSnapshotClass requested by the VolumeSnapshot.
      jsonPath: .spec.volumeSnapshotClassName
      name: SnapshotClass
      type: string
    - description: Name of the VolumeSnapshotContent object to which the VolumeSnapshot object intends to bind to. Please note that verification of binding actually requires checking both VolumeSnapshot and VolumeSnapshotContent to ensure both are pointing at each other. Binding MUST be verified prior to usage of this object.
      jsonPath: .status.boundVolumeSnapshotContentName
      name: SnapshotContent
      type: string
    - description: Timestamp when the point-in-time snapshot was taken by the underlying storage system.
      jsonPath: .status.creationTime
      name: CreationTime
      type: date
    - jsonPath: .metadata.creationTimestamp
      name: Age
      type: date
    name: v1beta1
    # This indicates the v1beta1 version of the custom resource is deprecated.
    # API requests to this version receive a warning in the server response.
    deprecated: true
    # This overrides the default warning returned to clients making v1beta1 API requests.
    deprecationWarning: "snapshot.storage.k8s.io/v1beta1 VolumeSnapshot is deprecated; use snapshot.storage.k8s.io/v1 VolumeSnapshot"
    schema:
      openAPIV3Schema:
        description: VolumeSnapshot is a user's request for either creating a point-in-time snapshot of a persistent volume, or binding to a pre-existing snapshot.
        properties:
          apiVersion:
            description: 'APIVersion defines the versioned schema of this representation of an object. Servers should convert recognized schemas to the latest internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources'
            type: string
          kind:
            description: 'Kind is a string value representing the REST resource this object represents. Servers may infer this from the endpoint the client submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds'
            type: string
          spec:
            description: 'spec defines the desired characteristics of a snapshot requested by a user. More info: https://kubernetes.io/docs/concepts/storage/volume-snapshots#volumesnapshots Required.'
            properties:
              source:
                description: source specifies where a snapshot will be created from. This field is immutable after creation. Required.
                properties:
                  persistentVolumeClaimName:
                    description: persistentVolumeClaimName specifies the name of the PersistentVolumeClaim object representing the volume from which a snapshot should be created. This PVC is assumed to be in the same namespace as the VolumeSnapshot object. This field should be set if the snapshot does not exists, and needs to be created. This field is immutable.
                    type: string
                  volumeSnapshotContentName:
                    description: volumeSnapshotContentName specifies the name of a pre-existing VolumeSnapshotContent object representing an existing volume snapshot. This field should be set if the snapshot already exists and only needs a representation in Kubernetes. This field is immutable.
                    type: string
                type: object
              volumeSnapshotClassName:
                description: 'VolumeSnapshotClassName is the name of the VolumeSnapshotClass requested by the VolumeSnapshot. VolumeSnapshotClassName may be left nil to indicate that the default SnapshotClass should be used. A given cluster may have multiple default Volume SnapshotClasses: one default per CSI Driver. If a VolumeSnapshot does not specify a SnapshotClass, VolumeSnapshotSource will be checked to figure out what the associated CSI Driver is, and the default VolumeSnapshotClass associated with that CSI Driver will be used. If more than one VolumeSnapshotClass exist for a given CSI Driver and more than one have been marked as default, CreateSnapshot will fail and generate an event. Empty string is not allowed for this field.'
                type: string
            required:
            - source
            type: object
          status:
            description: status represents the current information of a snapshot. Consumers must verify binding between VolumeSnapshot and VolumeSnapshotContent objects is successful (by validating that both VolumeSnapshot and VolumeSnapshotContent point at each other) before using this object.
            properties:
              boundVolumeSnapshotContentName:
                description: 'boundVolumeSnapshotContentName is the name of the VolumeSnapshotContent object to which this VolumeSnapshot object intends to bind to. If not specified, it indicates that the VolumeSnapshot object has not been successfully bound to a VolumeSnapshotContent object yet. NOTE: To avoid possible security issues, consumers must verify binding between VolumeSnapshot and VolumeSnapshotContent objects is successful (by validating that both VolumeSnapshot and VolumeSnapshotContent point at each other) before using this object.'
                type: string
              creationTime:
                description: creationTime is the timestamp when the point-in-time snapshot is taken by the underlying storage system. In dynamic snapshot creation case, this field will be filled in by the snapshot controller with the "creation_time" value returned from CSI "CreateSnapshot" gRPC call. For a pre-existing snapshot, this field will be filled with the "creation_time" value returned from the CSI "ListSnapshots" gRPC call if the driver supports it. If not specified, it may indicate that the creation time of the snapshot is unknown.
                format: date-time
                type: string
              error:
                description: error is the last observed error during snapshot creation, if any. This field could be helpful to upper level controllers(i.e., application controller) to decide whether they should continue on waiting for the snapshot to be created based on the type of error reported. The snapshot controller will keep retrying when an error occurrs during the snapshot creation. Upon success, this error field will be cleared.
                properties:
                  message:
                    description: 'message is a string detailing the encountered error during snapshot creation if specified. NOTE: message may be logged, and it should not contain sensitive information.'
                    type: string
                  time:
                    description: time is the timestamp when the error was encountered.
                    format: date-time
                    type: string
                type: object
              readyToUse:
                description: readyToUse indicates if the snapshot is ready to be used to restore a volume. In dynamic snapshot creation case, this field will be filled in by the snapshot controller with the "ready_to_use" value returned from CSI "CreateSnapshot" gRPC call. For a pre-existing snapshot, this field will be filled with the "ready_to_use" value returned from the CSI "ListSnapshots" gRPC call if the driver supports it, otherwise, this field will be set to "True". If not specified, it means the readiness of a snapshot is unknown.
                type: boolean
              restoreSize:
                type: string
                description: restoreSize represents the minimum size of volume required to create a volume from this snapshot. In dynamic snapshot creation case, this field will be filled in by the snapshot controller with the "size_bytes" value returned from CSI "CreateSnapshot" gRPC call. For a pre-existing snapshot, this field will be filled with the "size_bytes" value returned from the CSI "ListSnapshots" gRPC call if the driver supports it. When restoring a volume from this snapshot, the size of the volume MUST NOT be smaller than the restoreSize if it is specified, otherwise the restoration will fail. If not specified, it indicates that the size is unknown.
                pattern: ^(\+|-)?(([0-9]+(\.[0-9]*)?)|(\.[0-9]+))(([KMGTPE]i)|[numkMGTPE]|([eE](\+|-)?(([0-9]+(\.[0-9]*)?)|(\.[0-9]+))))?$
                x-kubernetes-int-or-string: true
            type: object
        required:
        - spec
        type: object
    served: true
    storage: false
    subresources:
      status: {}
status:
  acceptedNames:
    kind: ""
    plural: ""
  conditions: []
  storedVersions: []
---
# Source: iomesh/charts/blockdevice-monitor/templates/role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: blockdevice-monitor-all
rules:
- apiGroups:
  - iomesh.com
  resources:
  - blockdevicemonitors
  verbs:
  - create
  - delete
  - get
  - list
  - patch
  - update
  - watch
- apiGroups:
  - iomesh.com
  resources:
  - blockdevicemonitors/status
  verbs:
  - get
  - patch
  - update
- apiGroups:
  - openebs.io
  resources:
  - blockdevices
  verbs: [list,watch]
---
# Source: iomesh/charts/csi-driver/templates/clusterrole.yaml
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name:  iomesh-csi-driver-provisioner
  labels:
    helm.sh/chart: csi-driver-2.6.0
    app.kubernetes.io/name: csi-driver
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "v2.6.0"
    app.kubernetes.io/managed-by: Helm
rules:
  - apiGroups: [""]
    resources: ["secrets"]
    verbs: ["get", "list"]
  - apiGroups: [""]
    resources: ["persistentvolumes"]
    verbs: ["get", "list", "watch", "create", "delete"]
  - apiGroups: [""]
    resources: ["persistentvolumeclaims"]
    verbs: ["get", "list", "watch", "update"]
  - apiGroups: ["storage.k8s.io"]
    resources: ["storageclasses"]
    verbs: ["get", "list", "watch"]
  - apiGroups: [""]
    resources: ["events"]
    verbs: ["list", "watch", "create", "update", "patch"]
  - apiGroups: ["snapshot.storage.k8s.io"]
    resources: ["volumesnapshots"]
    verbs: ["get", "list"]
  - apiGroups: ["snapshot.storage.k8s.io"]
    resources: ["volumesnapshotcontents"]
    verbs: ["get", "list"]
  - apiGroups: ["storage.k8s.io"]
    resources: ["csinodes"]
    verbs: ["get", "list", "watch"]
  - apiGroups: [""]
    resources: ["nodes"]
    verbs: ["get", "list", "watch"]
  - apiGroups: ["coordination.k8s.io"]
    resources: ["leases"]
    verbs: ["get", "watch", "list", "delete", "update", "create"]
  - apiGroups: [""]
    resources: ["endpoints"]
    verbs: ["get", "watch", "list", "delete", "update", "create"]
---
# Source: iomesh/charts/csi-driver/templates/clusterrole.yaml
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name:  iomesh-csi-driver-attacher
  labels:
    helm.sh/chart: csi-driver-2.6.0
    app.kubernetes.io/name: csi-driver
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "v2.6.0"
    app.kubernetes.io/managed-by: Helm
rules:
  - apiGroups: [""]
    resources: ["persistentvolumes"]
    verbs: ["get", "list", "watch", "update"]
  - apiGroups: [""]
    resources: ["nodes"]
    verbs: ["get", "list", "watch"]
  - apiGroups: ["storage.k8s.io"]
    resources: ["csinodes"]
    verbs: ["get", "list", "watch"]
  - apiGroups: ["csi.storage.k8s.io"]
    resources: ["csinodeinfos"]
    verbs: ["get", "list", "watch"]
  - apiGroups: ["storage.k8s.io"]
    resources: ["*"]
    verbs: ["get", "list", "watch", "update", "patch"]
  - apiGroups: ["coordination.k8s.io"]
    resources: ["leases"]
    verbs: ["get", "watch", "list", "delete", "update", "create"]
---
# Source: iomesh/charts/csi-driver/templates/clusterrole.yaml
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name:  iomesh-csi-driver-snapshotter
  labels:
    helm.sh/chart: csi-driver-2.6.0
    app.kubernetes.io/name: csi-driver
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "v2.6.0"
    app.kubernetes.io/managed-by: Helm
rules:
  - apiGroups: [""]
    resources: ["events"]
    verbs: ["list", "watch", "create", "update", "patch"]
  - apiGroups: ["snapshot.storage.k8s.io"]
    resources: ["volumesnapshotclasses"]
    verbs: ["get", "list", "watch"]
  - apiGroups: ["snapshot.storage.k8s.io"]
    resources: ["volumesnapshotcontents"]
    verbs: ["create", "get", "list", "watch", "update", "delete"]
  - apiGroups: ["snapshot.storage.k8s.io"]
    resources: ["volumesnapshotcontents/status"]
    verbs: ["update"]
  - apiGroups: ["snapshot.storage.k8s.io"]
    resources: ["volumesnapshots"]
    verbs: ["create", "get", "list", "watch", "update", "delete"]
  - apiGroups: ["snapshot.storage.k8s.io"]
    resources: ["volumesnapshots/status"]
    verbs: ["update"]
  - apiGroups: ["coordination.k8s.io"]
    resources: ["leases"]
    verbs: ["get", "watch", "list", "delete", "update", "create"]
  - apiGroups: ["apiextensions.k8s.io"]
    resources: ["customresourcedefinitions"]
    verbs: ["create", "list", "watch", "delete", "get", "update"]
---
# Source: iomesh/charts/csi-driver/templates/clusterrole.yaml
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name:  iomesh-csi-driver-resizer
  labels:
    helm.sh/chart: csi-driver-2.6.0
    app.kubernetes.io/name: csi-driver
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "v2.6.0"
    app.kubernetes.io/managed-by: Helm
rules:
  - apiGroups: [""]
    resources: ["persistentvolumes"]
    verbs: ["get", "list", "watch", "patch"]
  - apiGroups: [""]
    resources: ["persistentvolumeclaims"]
    verbs: ["get", "list", "watch"]
  - apiGroups: [""]
    resources: ["pods"]
    verbs: ["get", "list", "watch"]
  - apiGroups: [""]
    resources: ["persistentvolumeclaims/status"]
    verbs: ["patch"]
  - apiGroups: [""]
    resources: ["events"]
    verbs: ["list", "watch", "create", "update", "patch"]
  - apiGroups: ["coordination.k8s.io"]
    resources: ["leases"]
    verbs: ["get", "watch", "list", "delete", "update", "create"]
---
# Source: iomesh/charts/csi-driver/templates/clusterrole.yaml
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name:  iomesh-csi-driver
  labels:
    helm.sh/chart: csi-driver-2.6.0
    app.kubernetes.io/name: csi-driver
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "v2.6.0"
    app.kubernetes.io/managed-by: Helm
rules:
  - apiGroups: [""]
    resources: ["nodes", "persistentvolumes"]
    verbs: ["list", "get", "update"]
  - apiGroups: [""]
    resources: ["pods"]
    verbs: ["list", "get", "delete"]
  - apiGroups: ["apps"]
    resources: ["daemonsets"]
    verbs: ["list", "get"]
  - apiGroups: [""]
    resources: ["configmaps"]
    verbs: ["create", "update", "list", "get"]
  - apiGroups: ["snapshot.storage.k8s.io"]
    resources: ["volumesnapshotcontents"]
    verbs: ["get", "list"]
  - apiGroups: ["snapshot.storage.k8s.io"]
    resources: ["volumesnapshotcontents/status"]
    verbs: ["get"]
---
# Source: iomesh/charts/csi-driver/templates/snapshotter-controller.yaml
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  annotations:
    helm.sh/resource-policy: keep
  name: snapshot-controller-runner
rules:
  - apiGroups: [""]
    resources: ["persistentvolumes"]
    verbs: ["get", "list", "watch"]
  - apiGroups: [""]
    resources: ["persistentvolumeclaims"]
    verbs: ["get", "list", "watch", "update"]
  - apiGroups: ["storage.k8s.io"]
    resources: ["storageclasses"]
    verbs: ["get", "list", "watch"]
  - apiGroups: [""]
    resources: ["events"]
    verbs: ["list", "watch", "create", "update", "patch"]
  - apiGroups: ["snapshot.storage.k8s.io"]
    resources: ["volumesnapshotclasses"]
    verbs: ["get", "list", "watch"]
  - apiGroups: ["snapshot.storage.k8s.io"]
    resources: ["volumesnapshotcontents"]
    verbs: ["create", "get", "list", "watch", "update", "delete"]
  - apiGroups: ["snapshot.storage.k8s.io"]
    resources: ["volumesnapshots"]
    verbs: ["get", "list", "watch", "update"]
  - apiGroups: ["snapshot.storage.k8s.io"]
    resources: ["volumesnapshots/status"]
    verbs: ["update"]
---
# Source: iomesh/charts/hostpath-provisioner/templates/clusterrole.yaml
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: release-name-hostpath-provisioner
  labels: 
    helm.sh/chart: hostpath-provisioner-0.5.3
    app.kubernetes.io/name: hostpath-provisioner
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.5.3"
    app.kubernetes.io/managed-by: Helm
  annotations:
    helm.sh/resource-policy: keep
rules:
  - apiGroups: [""]
    resources: ["nodes"]
    verbs: ["get"]
  - apiGroups: [""]
    resources: ["persistentvolumes"]
    verbs: ["get", "list", "watch", "create", "delete"]
  - apiGroups: [""]
    resources: ["persistentvolumeclaims"]
    verbs: ["get", "list", "watch", "update"]
  - apiGroups: ["storage.k8s.io"]
    resources: ["storageclasses"]
    verbs: ["get", "list", "watch"]
  - apiGroups: [""]
    resources: ["events"]
    verbs: ["list", "watch", "create", "update", "patch"]
---
# Source: iomesh/charts/iomesh-localpv-manager/templates/clusterrole.yaml
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name:  iomesh-localpv-manager-provisioner
  labels:
    app.kubernetes.io/name: iomesh-localpv-manager
rules:
  - apiGroups: [""]
    resources: ["secrets"]
    verbs: ["get", "list"]
  - apiGroups: [""]
    resources: ["persistentvolumes"]
    verbs: ["get", "list", "watch", "create", "delete"]
  - apiGroups: [""]
    resources: ["persistentvolumeclaims"]
    verbs: ["get", "list", "watch", "update"]
  - apiGroups: ["storage.k8s.io"]
    resources: ["storageclasses"]
    verbs: ["get", "list", "watch"]
  - apiGroups: [""]
    resources: ["events"]
    verbs: ["list", "watch", "create", "update", "patch"]
  - apiGroups: ["snapshot.storage.k8s.io"]
    resources: ["volumesnapshots"]
    verbs: ["get", "list"]
  - apiGroups: ["snapshot.storage.k8s.io"]
    resources: ["volumesnapshotcontents"]
    verbs: ["get", "list"]
  - apiGroups: ["storage.k8s.io"]
    resources: ["csinodes"]
    verbs: ["get", "list", "watch"]
  - apiGroups: [""]
    resources: ["nodes"]
    verbs: ["get", "list", "watch"]
  - apiGroups: ["coordination.k8s.io"]
    resources: ["leases"]
    verbs: ["get", "watch", "list", "delete", "update", "create"]
  - apiGroups: [""]
    resources: ["endpoints"]
    verbs: ["get", "watch", "list", "delete", "update", "create"]
  - apiGroups: ["storage.k8s.io"]
    resources: ["volumeattachments"]
    verbs: ["get", "list", "watch"]
  - apiGroups: ["storage.k8s.io"]
    resources: ["csistoragecapacities"]
    verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]
  - apiGroups: [""]
    resources: ["pods"]
    verbs: ["get"]
  - apiGroups: ["apps"]
    resources: ["replicasets"]
    verbs: ["get"]
---
# Source: iomesh/charts/iomesh-localpv-manager/templates/clusterrole.yaml
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name:  iomesh-localpv-manager
  labels:
    app.kubernetes.io/name: iomesh-localpv-manager
rules:
  - apiGroups: [""]
    resources: ["nodes", "persistentvolumes"]
    verbs: ["list", "get"]
  - apiGroups: [""]
    resources: ["configmaps"]
    verbs: ["create", "update", "list", "get"]
  - apiGroups: ["snapshot.storage.k8s.io"]
    resources: ["volumesnapshotcontents"]
    verbs: ["get", "list"]
  - apiGroups: ["snapshot.storage.k8s.io"]
    resources: ["volumesnapshotcontents/status"]
    verbs: ["get"]
  - apiGroups: ["openebs.io"]
    resources: ["*"]
    verbs: ["*"]
---
# Source: iomesh/charts/openebs-ndm/templates/rbac.yaml
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: release-name-openebs-ndm
  annotations:
    helm.sh/resource-policy: keep
rules:
  - apiGroups: ["*"]
    resources: ["nodes", "pods", "events", "configmaps", "jobs"]
    verbs:
      - '*'
  - apiGroups: ["apiextensions.k8s.io"]
    resources: ["customresourcedefinitions"]
    verbs:
      - '*'
  - apiGroups:
      - openebs.io
    resources:
      - blockdevices
      - blockdeviceclaims
    verbs:
      - '*'
---
# Source: iomesh/charts/zookeeper-operator/templates/clusterrole.yaml
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: release-name-zookeeper-operator
  namespace: default
  annotations:
    helm.sh/resource-policy: keep
  labels:
    app.kubernetes.io/name: zookeeper-operator
    app.kubernetes.io/version: "0.2.15"
    app.kubernetes.io/managed-by: Helm
    helm.sh/chart: "zookeeper-operator-0.2.15"
rules:
- apiGroups:
  - zookeeper.pravega.io
  resources:
  - "*"
  verbs:
  - "*"
- apiGroups:
  - ""
  resources:
  - pods
  - services
  - endpoints
  - persistentvolumeclaims
  - events
  - configmaps
  - secrets
  - serviceaccounts
  verbs:
  - "*"
- apiGroups:
  - apps
  resources:
  - deployments
  - daemonsets
  - replicasets
  - statefulsets
  verbs:
  - "*"
- apiGroups:
  - policy
  resources:
  - poddisruptionbudgets
  verbs:
  - "*"
---
# Source: iomesh/templates/clusterrole.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: iomesh:blockdevice:editor
rules:
- apiGroups:
  - openebs.io
  resources:
  - "*"
  verbs: ["*"]
---
# Source: iomesh/templates/clusterrole.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: iomesh:manager
  annotations:
    helm.sh/resource-policy: keep
rules:
- apiGroups:
  - ""
  resources:
  - configmaps
  - endpoints
  - events
  - pods
  - services
  - serviceaccounts
  - persistentvolumeclaims
  - secrets
  verbs: ["*"]
- apiGroups:
  - ""
  resources:
  - nodes
  verbs: ["get", "list", "watch"]
- apiGroups:
  - apps
  resources:
  - daemonsets
  - statefulsets
  verbs: ["*"]
- apiGroups:
  - rbac.authorization.k8s.io
  resources:
  - clusterroles
  - clusterrolebindings
  verbs: ["*"]
- apiGroups:
  - openebs.io
  resources:
  - "*"
  verbs: ["*"]
- apiGroups:
  - iomesh.com
  resources:
  - "*"
  verbs: ["*"]
- apiGroups:
  - zookeeper.pravega.io
  resources:
  - "*"
  verbs:
  - "*"
---
# Source: iomesh/templates/clusterrole.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: iomesh:chunk
rules:
- apiGroups: [""]
  resources: ["configmaps"]
  verbs:     ["get", "list", "watch"]
- apiGroups: [""]
  resources: ["pods"]
  verbs:     ["get", "list", "watch"]
- apiGroups: ["openebs.io"]
  resources: ["*"]
  verbs:     ["*"]
- apiGroups: ["iomesh.com"]
  resources: ["*"]
  verbs:     ["*"]
---
# Source: iomesh/templates/prepare-iomesh.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: prepare-csi
rules:
- apiGroups: [""]
  resources: ["nodes"]
  verbs: ["get", "patch"]
---
# Source: iomesh/charts/blockdevice-monitor/templates/role_binding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: blockdevice-monitor-rolebinding
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: blockdevice-monitor-all
subjects:
- kind: ServiceAccount
  name: default
  namespace: default
---
# Source: iomesh/charts/csi-driver/templates/clusterrolebinding.yaml
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: iomesh-csi-driver-provisioner-binding
  labels:
    helm.sh/chart: csi-driver-2.6.0
    app.kubernetes.io/name: csi-driver
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "v2.6.0"
    app.kubernetes.io/managed-by: Helm
subjects:
  - kind: ServiceAccount
    name: iomesh-csi-driver-controller-account
    namespace: default
roleRef:
  kind: ClusterRole
  name: iomesh-csi-driver-provisioner
  apiGroup: rbac.authorization.k8s.io
---
# Source: iomesh/charts/csi-driver/templates/clusterrolebinding.yaml
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: iomesh-csi-driver-attacher-binding
subjects:
  - kind: ServiceAccount
    name: iomesh-csi-driver-controller-account
    namespace: default
roleRef:
  kind: ClusterRole
  name: iomesh-csi-driver-attacher
  apiGroup: rbac.authorization.k8s.io
---
# Source: iomesh/charts/csi-driver/templates/clusterrolebinding.yaml
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: iomesh-csi-driver-snapshotter-binding
subjects:
  - kind: ServiceAccount
    name: iomesh-csi-driver-controller-account
    namespace: default
roleRef:
  kind: ClusterRole
  name: iomesh-csi-driver-snapshotter
  apiGroup: rbac.authorization.k8s.io
---
# Source: iomesh/charts/csi-driver/templates/clusterrolebinding.yaml
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: iomesh-csi-driver-resizer-binding
subjects:
  - kind: ServiceAccount
    name: iomesh-csi-driver-controller-account
    namespace: default
roleRef:
  kind: ClusterRole
  name: iomesh-csi-driver-resizer
  apiGroup: rbac.authorization.k8s.io
---
# Source: iomesh/charts/csi-driver/templates/clusterrolebinding.yaml
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: iomesh-csi-driver-controller-binding
subjects:
  - kind: ServiceAccount
    name: iomesh-csi-driver-controller-account
    namespace: default
roleRef:
  kind: ClusterRole
  name: iomesh-csi-driver
  apiGroup: rbac.authorization.k8s.io
---
# Source: iomesh/charts/csi-driver/templates/clusterrolebinding.yaml
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: iomesh-csi-driver-node-binding
subjects:
  - kind: ServiceAccount
    name: iomesh-csi-driver-node-account
    namespace: default
roleRef:
  kind: ClusterRole
  name: iomesh-csi-driver
  apiGroup: rbac.authorization.k8s.io
---
# Source: iomesh/charts/csi-driver/templates/snapshotter-controller.yaml
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  annotations:
    helm.sh/resource-policy: keep
  name: snapshot-controller-role
subjects:
  - kind: ServiceAccount
    name: snapshot-controller
    namespace: kube-system
roleRef:
  kind: ClusterRole
  name: snapshot-controller-runner
  apiGroup: rbac.authorization.k8s.io
---
# Source: iomesh/charts/hostpath-provisioner/templates/clusterrolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: release-name-hostpath-provisioner
  labels:
    app.kubernetes.io/name: hostpath-provisioner
    helm.sh/chart: hostpath-provisioner-0.5.3
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
  annotations:
    helm.sh/resource-policy: keep
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: release-name-hostpath-provisioner
subjects:
  - kind: ServiceAccount
    name: release-name-hostpath-provisioner
    namespace: default
---
# Source: iomesh/charts/iomesh-localpv-manager/templates/clusterrolebinding.yaml
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: iomesh-localpv-manager-provisioner-binding
  labels:
    app.kubernetes.io/name: iomesh-localpv-manager
subjects:
  - kind: ServiceAccount
    name: iomesh-localpv-manager
    namespace: default
roleRef:
  kind: ClusterRole
  name: iomesh-localpv-manager-provisioner
  apiGroup: rbac.authorization.k8s.io
---
# Source: iomesh/charts/iomesh-localpv-manager/templates/clusterrolebinding.yaml
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: iomesh-localpv-manager-binding
subjects:
  - kind: ServiceAccount
    name: iomesh-localpv-manager
    namespace: default
roleRef:
  kind: ClusterRole
  name: iomesh-localpv-manager
  apiGroup: rbac.authorization.k8s.io
---
# Source: iomesh/charts/openebs-ndm/templates/rbac.yaml
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: release-name-openebs-ndm
  annotations:
    helm.sh/resource-policy: keep
subjects:
  - kind: ServiceAccount
    name: openebs-ndm
    namespace: default
  - kind: User
    name: system:serviceaccount:default:default
    apiGroup: rbac.authorization.k8s.io
roleRef:
  kind: ClusterRole
  name: release-name-openebs-ndm
  apiGroup: rbac.authorization.k8s.io
---
# Source: iomesh/charts/zookeeper-operator/templates/clusterrolebinding.yaml
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: release-name-zookeeper-operator
  namespace: default
  annotations:
    helm.sh/resource-policy: keep
  labels:
    app.kubernetes.io/name: zookeeper-operator
    app.kubernetes.io/version: "0.2.15"
    app.kubernetes.io/managed-by: Helm
    helm.sh/chart: "zookeeper-operator-0.2.15"
subjects:
- kind: ServiceAccount
  name: zookeeper-operator
  namespace: default
roleRef:
  kind: ClusterRole
  name: release-name-zookeeper-operator
  apiGroup: rbac.authorization.k8s.io
---
# Source: iomesh/templates/clusterrolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: iomesh:blockdevice:editor
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: iomesh:blockdevice:editor
subjects:
  - kind: ServiceAccount
    name: release-name-operator
    namespace: default
---
# Source: iomesh/templates/clusterrolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: iomesh:manager
  annotations:
    helm.sh/resource-policy: keep
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: iomesh:manager
subjects:
  - kind: ServiceAccount
    name: release-name-operator
    namespace: default
---
# Source: iomesh/templates/clusterrolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: iomesh:chunk
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: iomesh:chunk
subjects: []
---
# Source: iomesh/templates/prepare-iomesh.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: prepare-csi
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: prepare-csi
subjects:
- kind: ServiceAccount
  name: prepare-csi
  namespace: default
---
# Source: iomesh/charts/csi-driver/templates/snapshotter-controller.yaml
kind: Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  annotations:
    helm.sh/resource-policy: keep
  name: snapshot-controller-leaderelection
  namespace: kube-system
rules:
- apiGroups: ["coordination.k8s.io"]
  resources: ["leases"]
  verbs: ["get", "watch", "list", "delete", "update", "create"]
---
# Source: iomesh/charts/zookeeper-operator/templates/role.yaml
kind: Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: release-name-zookeeper-operator
  namespace: default
  annotations:
    helm.sh/resource-policy: keep
  labels:
    app.kubernetes.io/name: zookeeper-operator
    app.kubernetes.io/version: "0.2.15"
    app.kubernetes.io/managed-by: Helm
    helm.sh/chart: "zookeeper-operator-0.2.15"
rules:
- apiGroups:
  - zookeeper.pravega.io
  resources:
  - "*"
  verbs:
  - "*"
- apiGroups:
  - ""
  resources:
  - pods
  - services
  - endpoints
  - persistentvolumeclaims
  - events
  - configmaps
  - secrets
  verbs:
  - "*"
- apiGroups:
  - apps
  resources:
  - deployments
  - daemonsets
  - replicasets
  - statefulsets
  verbs:
  - "*"
- apiGroups:
  - policy
  resources:
  - poddisruptionbudgets
  verbs:
  - "*"
---
# Source: iomesh/templates/operator-leader-election.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: iomesh:leader-election
  namespace: default
  annotations:
    helm.sh/resource-policy: keep
rules:
- apiGroups: [""]
  resources: ["configmaps"]
  verbs: ["create", "delete", "get","list","patch","update","watch"]
- apiGroups: [""]
  resources: ["configmaps/status"]
  verbs: ["get", "update", "patch"]
- apiGroups: [""]
  resources: ["events"]
  verbs: ["create"]
---
# Source: iomesh/charts/csi-driver/templates/snapshotter-controller.yaml
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  annotations:
    helm.sh/resource-policy: keep
  name: snapshot-controller-leaderelection
  namespace: kube-system
subjects:
  - kind: ServiceAccount
    name: snapshot-controller
roleRef:
  kind: Role
  name: snapshot-controller-leaderelection
  apiGroup: rbac.authorization.k8s.io
---
# Source: iomesh/charts/zookeeper-operator/templates/rolebinding.yaml
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: release-name-zookeeper-operator
  namespace: default
  annotations:
    helm.sh/resource-policy: keep
  labels:
    app.kubernetes.io/name: zookeeper-operator
    app.kubernetes.io/version: "0.2.15"
    app.kubernetes.io/managed-by: Helm
    helm.sh/chart: "zookeeper-operator-0.2.15"
subjects:
- kind: ServiceAccount
  name: zookeeper-operator
roleRef:
  kind: Role
  name: release-name-zookeeper-operator
  apiGroup: rbac.authorization.k8s.io
---
# Source: iomesh/templates/operator-leader-election.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: iomesh:leader-election
  namespace: default
  annotations:
    helm.sh/resource-policy: keep
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: iomesh:leader-election
subjects:
  - kind: ServiceAccount
    name: release-name-operator
    namespace: default
---
# Source: iomesh/charts/openebs-ndm/templates/cluster-exporter-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-openebs-ndm-cluster-exporter-service
  labels:
    chart: openebs-ndm-1.8.0
    heritage: Helm
    openebs.io/version: "1.8.0"
    app: openebs-ndm-exporter
    release: release-name
    component: openebs-ndm-cluster-exporter
    openebs.io/component-name: openebs-ndm-cluster-exporter
spec:
  clusterIP: None
  ports:
    - name: metrics
      port: 9100
      targetPort: 9100
  selector:
    name: openebs-ndm-cluster-exporter
---
# Source: iomesh/charts/openebs-ndm/templates/node-exporter-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-openebs-ndm-node-exporter-service
  labels:
    chart: openebs-ndm-1.8.0
    heritage: Helm
    openebs.io/version: "1.8.0"
    app: openebs-ndm-exporter
    release: release-name
    component: openebs-ndm-node-exporter
    openebs.io/component-name: openebs-ndm-node-exporter
spec:
  clusterIP: None
  ports:
    - name: metrics
      port: 9101
      targetPort: 9101
  selector:
    name: openebs-ndm-node-exporter
---
# Source: iomesh/templates/operator.yaml
apiVersion: v1
kind: Service
metadata:
  name: operator
  namespace: default
  labels:
    operator.iomesh.com/role: operator
    helm.sh/chart: iomesh-v1.0.1
    app.kubernetes.io/name: operator
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "v5.3.0-rc13"
    app.kubernetes.io/managed-by: Helm
    prometheus.io/scrape: "true"
spec:
  selector:
      app.kubernetes.io/name: operator
      app.kubernetes.io/instance: release-name
  ports:
  - name: iomesh-exporter
    targetPort: 8080
    port: 8080
    protocol: TCP
---
# Source: iomesh/templates/webhook-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: iomesh-webhook
spec:
  ports:
  - port: 443
    targetPort: 9443
  selector:
      app.kubernetes.io/name: operator
      app.kubernetes.io/instance: release-name
---
# Source: iomesh/charts/blockdevice-monitor/templates/prober_daemonset.yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: release-name-blockdevice-monitor-prober
  namespace: default
  labels:
    app: blockdevice-monitor-prober
spec:
  selector:
    matchLabels:
      app: blockdevice-monitor-prober
  template:
    metadata:
      labels:
        app: blockdevice-monitor-prober
    spec:
      containers:
      - name: prober
        command:
        - /opt/blockdevice-monitor/bin/prober
        - --enable-prober-iostat=true
        - --iostat-loop-interval-sec=15
        - --sampling-win-size=6
        - --threshold-ssd-latency-ms=500
        - --threshold-ssd-iops=5000
        - --threshold-ssd-total-bandwidth=314572800
        - --threshold-hdd-latency-ms=3000
        - --threshold-hdd-iops=50
        - --threshold-hdd-total-bandwidth=104857600
        - --enable-prober-smart=true
        - --smart-loop-interval-sec=21600
        - --enable-prober-zbs-device-health=true
        - --chunk-rpc-ip=127.0.0.1
        - --chunk-rpc-port=10200
        - --zbs-device-health-loop-interval-sec=10
        - --metrics-port=8443
        - --metrics-path=/metrics
        image: docker.io/iomesh/blockdevice-monitor-prober:v0.1.0
        imagePullPolicy: IfNotPresent
        env:
        - name: NODE_NAME
          valueFrom:
            fieldRef:
              fieldPath: spec.nodeName
        resources:
          limits:
            memory: 500Mi
        securityContext:
          allowPrivilegeEscalation: true
          capabilities:
            add:
            - SYS_ADMIN
          privileged: true
        ports:
        - name: http-metrics
          containerPort: 8443  
      hostNetwork: true
---
# Source: iomesh/charts/csi-driver/templates/node.yaml
kind: DaemonSet
apiVersion: apps/v1
metadata:
  name: iomesh-csi-driver-node-plugin
  namespace: default
spec:
  selector:
    matchLabels:
      app: iomesh-csi-driver-node-plugin
  template:
    metadata:
      labels:
        app: iomesh-csi-driver-node-plugin
    spec:
      serviceAccountName: iomesh-csi-driver-node-account
      dnsPolicy: ClusterFirstWithHostNet
      hostNetwork: true
      containers:        
        - name: driver-registrar
          securityContext:
            privileged: true
          image: docker.io/iomesh/csi-node-driver-registrar:v2.5.0
          args:
            - --v=5
            - --csi-address=/csi/csi.sock
            - --kubelet-registration-path=/var/lib/kubelet/plugins/com.iomesh.csi-driver/csi.sock
          lifecycle:
            preStop:
              exec:
               command:
                  [  
                     "/bin/sh",
                     "-c",
                      "rm -rf /registration/com.iomesh.csi-driver /registration/com.iomesh.csi-driver-reg.sock",
                  ]
          volumeMounts:
            - name: socket-dir
              mountPath: /csi
            - name: registration-dir
              mountPath: /registration
        - name: liveness-probe
          image: docker.io/iomesh/livenessprobe:v2.8.0
          args:
            - --csi-address=/csi/csi.sock
            - --health-port=9811
          volumeMounts:
            - mountPath: /csi
              name: socket-dir
        - name: csi-driver
          image: docker.io/iomesh/csi-driver:v2.6.0
          imagePullPolicy: IfNotPresent
          securityContext:
            privileged: true
            capabilities:
              add: ["SYS_ADMIN"]
            allowPrivilegeEscalation: true
          ports:
            - containerPort: 9811
              name: health
              protocol: TCP
            - containerPort: 9812
              name: liveness
              protocol: TCP
          resources: 
            limits:
              cpu: 100m
              memory: 150Mi
            requests:
              cpu: 100m
              memory: 150Mi
          livenessProbe:
            failureThreshold: 5
            initialDelaySeconds: 10
            timeoutSeconds: 3
            periodSeconds: 2
            httpGet:
              path: /healthz
              port: health
          command:
          - /usr/bin/bash          
          args:
            - /usr/sbin/csi-entrypoint.sh
            - --csi_addr=unix:///csi/csi.sock
            - --role=node
            - --driver_name=com.iomesh.csi-driver
            - --namespace=$(NAMESPACE)
            - --iscsi_portal=127.0.0.1:3260
            # iomesh-cluster-vip:10206
            - --meta_proxy=iomesh-access.$(NAMESPACE).svc:10206
            # unique cluster id
            - --cluster_id=iomesh
            # HCI / EXTERNAL
            - --deployment_mode=HCI
            - --node_map=iomesh-csi-driver-node-map
            - --iscsi_config_path=/etc/iomesh/iscsi.yaml
            - --liveness_port=9812
            - --v=1
          env:
            - name: NODE_NAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
            - name: NODE_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.hostIP
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
          volumeMounts:
          - name: iscsi-config
            mountPath: /etc/iomesh
            readOnly: true
          - name: socket-dir
            mountPath: /csi
          - name: pods-mount-dir
            mountPath: /var/lib/kubelet
            mountPropagation: Bidirectional
          - name: device-dir
            mountPath: /dev
          - name: iscsi-dir
            mountPath: /host/etc/iscsi
          - name: iscsiadm
            mountPath: /host/sbin/iscsiadm
          - name: iscsi-lib
            mountPath: /host/var/lib/iscsi
          - name: lib
            mountPath: /host/lib
          - name: lib64
            mountPath: /host/lib64
          - name: usr-lib64
            mountPath: /host/usr/lib64
          - name: sys
            mountPath: /host/sys
          - name: iscsi-run-lock
            mountPath: /host/run/lock/iscsi
          - name: iscsi-var-lock
            mountPath: /host/var/lock/iscsi
      volumes:
      - name: iscsi-config
        configMap:
          name: iomesh-csi-driver-iscsi-config
          items:
          - key: iscsi
            path: iscsi.yaml
      - name: socket-dir
        hostPath:
          path: /var/lib/kubelet/plugins/com.iomesh.csi-driver
          type: DirectoryOrCreate
      - name: pods-mount-dir
        hostPath:
          path: /var/lib/kubelet
          type: Directory
      - name: device-dir
        hostPath:
          path: /dev
          type: Directory
      - name: registration-dir
        hostPath:
          path: /var/lib/kubelet/plugins_registry/
          type: DirectoryOrCreate
      - name: iscsi-dir
        hostPath:
          path: /etc/iscsi
          type: Directory
      - name: iscsi-lib
        hostPath:
          path: /var/lib/iscsi
          type: DirectoryOrCreate
      - name: iscsiadm
        hostPath:
          path: /sbin/iscsiadm
          type: File
      - name: lib
        hostPath:
          path: /lib
          type: DirectoryOrCreate
      - name: lib64
        hostPath:
          path: /lib64
          type: DirectoryOrCreate
      - name: usr-lib64
        hostPath:
          path: /usr/lib64
          type: DirectoryOrCreate
      - name: sys
        hostPath:
          path: /sys
          type: Directory
      - name: iscsi-run-lock
        hostPath:
          path: /run/lock/iscsi
          type: DirectoryOrCreate
      - name: iscsi-var-lock
        hostPath:
          path: /var/lock/iscsi
          type: DirectoryOrCreate
---
# Source: iomesh/charts/hostpath-provisioner/templates/deployment.yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: release-name-hostpath-provisioner
  labels:
    helm.sh/chart: hostpath-provisioner-0.5.3
    app.kubernetes.io/name: hostpath-provisioner
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.5.3"
    app.kubernetes.io/managed-by: Helm
  annotations:
    helm.sh/resource-policy: keep
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: hostpath-provisioner
      app.kubernetes.io/instance: release-name
  template:
    metadata:
      labels:
        app.kubernetes.io/name: hostpath-provisioner
        app.kubernetes.io/instance: release-name
    spec:
      serviceAccountName: release-name-hostpath-provisioner
      securityContext:
        {}
      containers:
        - name: hostpath-provisioner
          securityContext:
            {}
          image: "iomesh/hostpath-provisioner:v0.5.1"
          imagePullPolicy: IfNotPresent
          resources:
            {}
          env:
            - name: USE_NAMING_PREFIX
              value: "true"
            - name: NODE_NAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
            - name: PV_DIR
              value: /opt/iomesh/hostpath
          volumeMounts:
            - name: pv-volume
              mountPath: /opt/iomesh/hostpath
      volumes:
        - name: pv-volume
          hostPath:
            path: /opt/iomesh/hostpath
---
# Source: iomesh/charts/iomesh-localpv-manager/templates/daemonset.yaml
kind: DaemonSet
apiVersion: apps/v1
metadata:
  name: iomesh-localpv-manager
  namespace: default
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: iomesh-localpv-manager
  template:
    metadata:
      labels:
        app.kubernetes.io/name: iomesh-localpv-manager
    spec:
      serviceAccountName: iomesh-localpv-manager
      dnsPolicy: ClusterFirstWithHostNet
      hostNetwork: false
      containers:
        - name: localpv-manager
          image: iomesh/localpv-manager:v0.1.0
          imagePullPolicy: IfNotPresent
          securityContext:
            privileged: true
            capabilities:
              add: ["SYS_ADMIN"]
            allowPrivilegeEscalation: true
          ports:
            - containerPort: 9810
              name: health
              protocol: TCP
            - containerPort: 9611
              name: liveness
              protocol: TCP
          resources: 
            limits:
              cpu: 200m
              memory: 200Mi
          livenessProbe:
            failureThreshold: 5
            initialDelaySeconds: 10
            timeoutSeconds: 3
            periodSeconds: 2
            httpGet:
              path: /healthz
              port: health
          command:
          - /localpv-manager
          args:
            - --csi_addr=unix:///csi/csi.sock
            - --driver_name=com.iomesh.iomesh-localpv-manager
            - --v=1
          env:
            - name: NODE_NAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
            - name: NODE_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.hostIP
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
          volumeMounts:
          - name: socket-dir
            mountPath: /csi
          - name: pods-mount-dir
            mountPath: /var/lib/kubelet
            mountPropagation: Bidirectional
          - name: device-dir
            mountPath: /dev
          - name: host-root
            mountPath: /host
            mountPropagation: HostToContainer        
        - name: csi-provisioner
          image: iomesh/csi-provisioner:v3.0.0
          args:
            - "--csi-address=$(ADDRESS)"
            - "--extra-create-metadata"
            - --feature-gates=Topology=true
            - --extra-create-metadata=true
            - --immediate-topology=false
            - --strict-topology=true
            - "--v=5"
          env:
            - name: ADDRESS
              value: /csi/csi.sock
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.name
            - name: NODE_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: spec.nodeName
          volumeMounts:
            - name: socket-dir
              mountPath: /csi
        - name: liveness-probe
          image: iomesh/livenessprobe:v2.8.0
          args:
            - --csi-address=/csi/csi.sock
            - --health-port=9810
          env:
            - name: ADDRESS
              value: /csi/csi.sock
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.name
            - name: NODE_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: spec.nodeName
          volumeMounts:
            - name: socket-dir
              mountPath: /csi
        - name: driver-registrar
          securityContext:
            privileged: true
          image: iomesh/csi-node-driver-registrar:v2.5.0
          args:
            - --v=5
            - --csi-address=/csi/csi.sock
            - --kubelet-registration-path=/var/lib/kubelet/plugins/com.iomesh.iomesh-localpv-manager/csi.sock
          lifecycle:
            preStop:
              exec:
               command:
                  [  
                     "/bin/sh",
                     "-c",
                      "rm -rf /registration/com.iomesh.iomesh-localpv-manager/registration/com.iomesh.iomesh-localpv-manager-reg.sock",
                  ]
          env:
            - name: ADDRESS
              value: /csi/csi.sock
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.name
            - name: NODE_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: spec.nodeName
          volumeMounts:
            - name: socket-dir
              mountPath: /csi
            - name: registration-dir
              mountPath: /registration
      volumes:
      - name: registration-dir
        hostPath:
          path: /var/lib/kubelet/plugins_registry/
          type: DirectoryOrCreate
      - name: socket-dir
        hostPath:
          path: /var/lib/kubelet/plugins/com.iomesh.iomesh-localpv-manager
          type: DirectoryOrCreate
      - name: pods-mount-dir
        hostPath:
          path: /var/lib/kubelet
          type: Directory
      - name: device-dir
        hostPath:
          path: /dev
          type: Directory
      - name: host-root
        hostPath:
          path: /
          type: Directory
---
# Source: iomesh/charts/openebs-ndm/templates/daemonset.yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: release-name-openebs-ndm
  labels:
    chart: openebs-ndm-1.8.0
    heritage: Helm
    openebs.io/version: "1.8.0"
    app: openebs-ndm
    release: release-name
    component: "ndm"
    openebs.io/component-name: "ndm"
  annotations:
    helm.sh/resource-policy: keep
spec:
  updateStrategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app: openebs-ndm
      release: release-name
      component: "ndm"
  template:
    metadata:
      labels:
        chart: openebs-ndm-1.8.0
        heritage: Helm
        openebs.io/version: "1.8.0"
        app: openebs-ndm
        release: release-name
        component: "ndm"
        openebs.io/component-name: "ndm"
        name: openebs-ndm
    spec:
      serviceAccountName: openebs-ndm
      hostPID: true
      containers:
      - name: openebs-ndm
        image: "openebs/node-disk-manager:1.8.0"
        args:
          - -v=4
          - --feature-gates=GPTBasedUUID
          - --feature-gates=APIService
          - --api-service-address=0.0.0.0:9115
          - --feature-gates=PartitionTableUUID
        imagePullPolicy: IfNotPresent
        resources:
            {}
        securityContext:
          privileged: true
        env:
        # namespace in which NDM is installed will be passed to NDM Daemonset
        # as environment variable
        - name: NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        # pass hostname as env variable using downward API to the NDM container
        - name: NODE_NAME
          valueFrom:
            fieldRef:
              fieldPath: spec.nodeName
        # specify the directory where the sparse files need to be created.
        # if not specified, then sparse files will not be created.
        - name: SPARSE_FILE_DIR
          value: "/var/openebs/sparse"
        # Size(bytes) of the sparse file to be created.
        - name: SPARSE_FILE_SIZE
          value: "10737418240"
        # Specify the number of sparse files to be created
        - name: SPARSE_FILE_COUNT
          value: "0"
        # Process name used for matching is limited to the 15 characters
        # present in the pgrep output.
        # So fullname can be used here with pgrep (cmd is < 15 chars).
        livenessProbe:
          exec:
            command:
            - pgrep
            - "ndm"
          initialDelaySeconds: 30
          periodSeconds: 60
        volumeMounts:
        - name: config
          mountPath: /host/node-disk-manager.config
          subPath: node-disk-manager.config
          readOnly: true
        - name: udev
          mountPath: /run/udev
        - name: procmount
          mountPath: /host/proc
          readOnly: true
        - name: devmount
          mountPath: /dev
        - name: basepath
          mountPath: /var/openebs/ndm
        - name: sparsepath
          mountPath: /var/openebs/sparse
      volumes:
      - name: config
        configMap:
          name: release-name-openebs-ndm-config
      - name: udev
        hostPath:
          path: /run/udev
          type: Directory
      # mount /proc (to access mount file of process 1 of host) inside container
      # to read mount-point of disks and partitions
      - name: procmount
        hostPath:
          path: /proc
          type: Directory
      - name: devmount
      # the /dev directory is mounted so that we have access to the devices that
      # are connected at runtime of the pod.
        hostPath:
          path: /dev
          type: Directory
      - name: basepath
        hostPath:
          path: "/var/openebs/ndm"
          type: DirectoryOrCreate
      - name: sparsepath
        hostPath:
          path: /var/openebs/sparse
      # By default the node-disk-manager will be run on all kubernetes nodes
      # If you would like to limit this to only some nodes, say the nodes
      # that have storage attached, you could label those node and use
      # nodeSelector.
      #
      # e.g. label the storage nodes with - "openebs.io/nodegroup"="storage-node"
      # kubectl label node <node-name> "openebs.io/nodegroup"="storage-node"
      #nodeSelector:
      #  "openebs.io/nodegroup": "storage-node"
      hostNetwork: true
---
# Source: iomesh/charts/openebs-ndm/templates/node-exporter.yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: release-name-openebs-ndm-node-exporter
  labels:
    chart: openebs-ndm-1.8.0
    heritage: Helm
    openebs.io/version: "1.8.0"
    app: openebs-ndm-exporter
    release: release-name
    component: openebs-ndm-node-exporter
    openebs.io/component-name: openebs-ndm-node-exporter
spec:
  updateStrategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app: openebs-ndm-exporter
      release: release-name
      component: openebs-ndm-node-exporter
  template:
    metadata:
      labels:
        chart: openebs-ndm-1.8.0
        heritage: Helm
        openebs.io/version: "1.8.0"
        app: openebs-ndm-exporter
        release: release-name
        component: openebs-ndm-node-exporter
        openebs.io/component-name: openebs-ndm-node-exporter
        name: openebs-ndm-node-exporter
    spec:
      serviceAccountName: openebs-ndm
      containers:
        - name: release-name-openebs-ndm-node-exporter
          image: "openebs/node-disk-exporter:1.8.0"
          command:
            - /usr/local/bin/exporter
          args:
            - "start"
            - "--mode=node"
            - "--port=$(METRICS_LISTEN_PORT)"
            - "--metrics=/metrics"
          ports:
            - containerPort: 9101
              protocol: TCP
              name: metrics
          imagePullPolicy: IfNotPresent
          securityContext:
            privileged: true
          env:
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: METRICS_LISTEN_PORT
              value: :9101
---
# Source: iomesh/templates/prepare-iomesh.yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: prepare-csi
  namespace: default
  labels:
    app.kubernetes.io/name: prepare-csi
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: prepare-csi
  template:
    metadata:
      name: prepare-csi
      labels:
        app.kubernetes.io/name: prepare-csi
    spec:
      hostNetwork: true
      hostPID: true
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: iomesh.com/iscsi-installed
                operator: DoesNotExist
      serviceAccountName: prepare-csi
      containers:
      - name: prepare-csi
        image: iomesh/prepare-csi:v1.0.1
        imagePullPolicy: IfNotPresent
        env:
        - name: MY_NODE_NAME
          valueFrom:
            fieldRef:
              fieldPath: spec.nodeName
        securityContext:
          runAsUser: 0
          privileged: true
        volumeMounts:
        - mountPath: /host
          mountPropagation: HostToContainer
          name: host-root
      volumes:
      - hostPath:
          path: /
          type: Directory
        name: host-root
---
# Source: iomesh/charts/blockdevice-monitor/templates/blockdevicemonitor_deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-blockdevice-monitor
  namespace: default
  labels:
    app: blockdevice-monitor
spec:
  selector:
    matchLabels:
      app: blockdevice-monitor
  replicas: 1
  template:
    metadata:
      labels:
        app: blockdevice-monitor
    spec:
      containers:
      - name: blockdevicemonitor
        command:
        - /blockdevicemonitor
        - --blockdevicemonitor-metrics-port=8443
        image: docker.io/iomesh/blockdevice-monitor:v0.1.0
        imagePullPolicy: IfNotPresent
        resources:
          limits:
            memory: 500Mi
        env:
        - name: BLOCK_DEVICE_NAMESPACE
          value: default
        ports:
        - name: http-metrics
          containerPort: 8443
---
# Source: iomesh/charts/csi-driver/templates/controller.yaml
kind: Deployment
apiVersion: apps/v1
metadata:
  name: iomesh-csi-driver-controller-plugin
  namespace: default
spec:
  replicas: 3
  selector:
    matchLabels:
      app: iomesh-csi-driver-controller-plugin
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 0
      maxUnavailable: 1
  template:
    metadata:
      labels:
        app: iomesh-csi-driver-controller-plugin
    spec:
      dnsPolicy: ClusterFirstWithHostNet
      hostNetwork: true
      serviceAccountName: iomesh-csi-driver-controller-account
      containers:        
        - name: csi-provisioner
          image: docker.io/iomesh/csi-provisioner:v3.0.0
          args:
            - "--csi-address=$(ADDRESS)"
            - "--extra-create-metadata"
            - "--leader-election"
            - "--feature-gates=Topology=true"
            - "--v=5"
          env:
            - name: ADDRESS
              value: /csi/csi.sock
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
          volumeMounts:
            - name: socket-dir
              mountPath: /csi
        - name: csi-snapshotter
          image: docker.io/iomesh/csi-snapshotter:v4.2.1
          args:
          - "--csi-address=$(ADDRESS)"
          - "--leader-election"
          - "--v=5"
          env:
            - name: ADDRESS
              value: /csi/csi.sock
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
          volumeMounts:
            - name: socket-dir
              mountPath: /csi
        - name: csi-attacher
          image: docker.io/iomesh/csi-attacher:v3.3.0
          args:
            - "--csi-address=$(ADDRESS)"
            - "--leader-election"
            - "--v=5"
          env:
            - name: ADDRESS
              value: /csi/csi.sock
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
          volumeMounts:
            - name: socket-dir
              mountPath: /csi
        - name: csi-resizer
          image: docker.io/iomesh/csi-resizer:v1.3.0
          args:
            - "--csi-address=$(ADDRESS)"
            - "--leader-election"
            - "--v=5"
          env:
            - name: ADDRESS
              value: /csi/csi.sock
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
          volumeMounts:
            - name: socket-dir
              mountPath: /csi
        - name: liveness-probe
          image: docker.io/iomesh/livenessprobe:v2.8.0
          args:
            - --csi-address=/csi/csi.sock
            - --health-port=9810
          volumeMounts:
            - mountPath: /csi
              name: socket-dir
        - name: csi-driver
          image: docker.io/iomesh/csi-driver:v2.6.0
          imagePullPolicy: IfNotPresent
          ports:
            - containerPort: 9810
              name: health
              protocol: TCP
          resources: 
            limits:
              cpu: 100m
              memory: 150Mi
            requests:
              cpu: 100m
              memory: 150Mi
          livenessProbe:
            failureThreshold: 5
            initialDelaySeconds: 10
            timeoutSeconds: 3
            periodSeconds: 2
            httpGet:
              path: /healthz
              port: health
          command:
          - /usr/bin/bash          
          args:
            - /usr/sbin/csi-entrypoint.sh
            - --csi_addr=unix:///csi/csi.sock
            - --driver_name=com.iomesh.csi-driver
            - --role=controller
            # iomesh-cluster-vip:10206
            - --meta_proxy=iomesh-access.$(NAMESPACE).svc:10206
            # unique cluster id
            - --cluster_id=iomesh
            # HCI / EXTERNAL
            - --deployment_mode=HCI
            - --namespace=$(NAMESPACE)
            - --node_map=iomesh-csi-driver-node-map
            - --pod_delete_policy=no-delete-pod
            - --pod_delete_latency=90s
            - --v=1
          volumeMounts:
            - name: socket-dir
              mountPath: /csi
          env:
            - name: NODE_NAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
            - name: NODE_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.hostIP
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
      volumes:
        - name: socket-dir
          emptyDir: {}
---
# Source: iomesh/charts/csi-driver/templates/snapshotter-controller.yaml
kind: Deployment
apiVersion: apps/v1
metadata:
  annotations:
    helm.sh/resource-policy: keep
  name: snapshot-controller
  namespace: kube-system
spec:
  replicas: 2
  selector:
    matchLabels:
      app: snapshot-controller
  # the snapshot controller won't be marked as ready if the v1 CRDs are unavailable
  # in #504 the snapshot-controller will exit after around 7.5 seconds if it
  # can't find the v1 CRDs so this value should be greater than that
  minReadySeconds: 15
  strategy:
    rollingUpdate:
      maxSurge: 0
      maxUnavailable: 1
    type: RollingUpdate
  template:
    metadata:
      labels:
        app: snapshot-controller
    spec:
      serviceAccount: snapshot-controller
      containers:
        - name: snapshot-controller
          image: docker.io/iomesh/snapshot-controller:v4.2.1
          args:
            - "--v=5"
            - "--leader-election=true"
          imagePullPolicy: IfNotPresent
---
# Source: iomesh/charts/openebs-ndm/templates/cluster-exporter.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-openebs-ndm-cluster-exporter
  labels:
    chart: openebs-ndm-1.8.0
    heritage: Helm
    openebs.io/version: "1.8.0"
    app: openebs-ndm-exporter
    release: release-name
    component: openebs-ndm-cluster-exporter
    openebs.io/component-name: openebs-ndm-cluster-exporter
spec:
  replicas: 1
  strategy:
    type: Recreate
  selector:
    matchLabels:
      app: openebs-ndm-exporter
      release: release-name
      component: openebs-ndm-cluster-exporter
  template:
    metadata:
      labels:
        chart: openebs-ndm-1.8.0
        heritage: Helm
        openebs.io/version: "1.8.0"
        app: openebs-ndm-exporter
        release: release-name
        component: openebs-ndm-cluster-exporter
        openebs.io/component-name: openebs-ndm-cluster-exporter
        name: openebs-ndm-cluster-exporter
    spec:
      serviceAccountName: openebs-ndm
      containers:
        - name: release-name-openebs-ndm-cluster-exporter
          image: "openebs/node-disk-exporter:1.8.0"
          command:
            - /usr/local/bin/exporter
          args:
            - "start"
            - "--mode=cluster"
            - "--port=$(METRICS_LISTEN_PORT)"
            - "--metrics=/metrics"
          ports:
            - containerPort: 9100
              protocol: TCP
              name: metrics
          imagePullPolicy: IfNotPresent
          env:
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: METRICS_LISTEN_PORT
              value: :9100
---
# Source: iomesh/charts/openebs-ndm/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-openebs-ndm-operator
  labels:
    chart: openebs-ndm-1.8.0
    heritage: Helm
    openebs.io/version: "1.8.0"
    app: openebs-ndm-operator
    release: release-name
    component: openebs-ndm-operator
    openebs.io/component-name: openebs-ndm-operator
  annotations:
    helm.sh/resource-policy: keep
spec:
  replicas: 1
  strategy:
    type: "Recreate"
    rollingUpdate: null
  selector:
    matchLabels:
      app: openebs-ndm-operator
      release: release-name
      component: openebs-ndm-operator
  template:
    metadata:
      labels:
        chart: openebs-ndm-1.8.0
        heritage: Helm
        openebs.io/version: "1.8.0"
        app: openebs-ndm-operator
        release: release-name
        component: openebs-ndm-operator
        openebs.io/component-name: openebs-ndm-operator
        name: openebs-ndm-operator
    spec:
      serviceAccountName: openebs-ndm
      containers:
      - name: release-name-openebs-ndm-operator
        image: "openebs/node-disk-operator:1.8.0"
        imagePullPolicy: IfNotPresent
        resources:
            {}
        livenessProbe:
          httpGet:
            path: /healthz
            port: 8585
          initialDelaySeconds: 15
          periodSeconds: 20
        readinessProbe:
          httpGet:
            path: /readyz
            port: 8585
          initialDelaySeconds: 5
          periodSeconds: 10
        env:
        - name: WATCH_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: SERVICE_ACCOUNT
          valueFrom:
            fieldRef:
              fieldPath: spec.serviceAccountName
        - name: OPERATOR_NAME
          value: "node-disk-operator"
        - name: CLEANUP_JOB_IMAGE
          value: "openebs/linux-utils:3.1.0"
---
# Source: iomesh/charts/zookeeper-operator/templates/operator.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-zookeeper-operator
  namespace: default
  annotations:
    helm.sh/resource-policy: keep
  labels:
    app.kubernetes.io/name: zookeeper-operator
    app.kubernetes.io/version: "0.2.15"
    app.kubernetes.io/managed-by: Helm
    helm.sh/chart: "zookeeper-operator-0.2.15"
spec:
  replicas: 1
  selector:
    matchLabels:
      name: release-name-zookeeper-operator
  template:
    metadata:
      labels:
        name: release-name-zookeeper-operator
        component: zookeeper-operator
    spec:
      serviceAccountName: zookeeper-operator
      containers:
      - name: release-name-zookeeper-operator
        image: "docker.io/iomesh/zookeeper-operator:0.2.15"
        imagePullPolicy: IfNotPresent
        ports:
        - containerPort: 6000
          name: metrics
        command:
        - zookeeper-operator
        env:
        - name: WATCH_NAMESPACE
          value: ""
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: OPERATOR_NAME
          value: release-name-zookeeper-operator
---
# Source: iomesh/templates/operator.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: operator
  namespace: default
  labels:
    operator.iomesh.com/role: operator
    helm.sh/chart: iomesh-v1.0.1
    app.kubernetes.io/name: operator
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "v5.3.0-rc13"
    app.kubernetes.io/managed-by: Helm
  annotations:
    helm.sh/resource-policy: keep
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: operator
      app.kubernetes.io/instance: release-name
  replicas: 3
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 1
  template:
    metadata:
      labels:
        helm.sh/chart: iomesh-v1.0.1
        app.kubernetes.io/name: operator
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/version: "v5.3.0-rc13"
        app.kubernetes.io/managed-by: Helm
    spec:
      serviceAccountName: release-name-operator
      terminationGracePeriodSeconds: 10
      containers:
      - name: operator
        command:
        - /iomesh-controller
        args:
        - operator
        - --enable-leader-election=true
        - --leader-election-namespace=$(NAMESPACE)
        - --leader-election-id=operator-lock
        - --metrics-addr=:8080
        image: iomesh/operator:v1.0.1
        imagePullPolicy: IfNotPresent
        resources: 
          limits:
            cpu: 500m
            memory: 500Mi
        env:
        - name: NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: ZBSOP_IMAGE
          value: iomesh/operator:v1.0.1
        ports:
        - name: metrics
          protocol: TCP
          containerPort: 8080
        volumeMounts:
          - name: webhook-cert
            mountPath: /tmp/k8s-webhook-server/serving-certs/
            readOnly: true
      volumes:
        - name: webhook-cert
          secret:
            secretName: iomesh-webhook-cert
      tolerations:
---
# Source: iomesh/charts/csi-driver/templates/csidriver.yaml
apiVersion: storage.k8s.io/v1
kind: CSIDriver
metadata:
  name: com.iomesh.csi-driver
  labels:
    helm.sh/chart: csi-driver-2.6.0
    app.kubernetes.io/name: csi-driver
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "v2.6.0"
    app.kubernetes.io/managed-by: Helm
spec:
  attachRequired: true
---
# Source: iomesh/charts/iomesh-localpv-manager/templates/csidriver.yaml
apiVersion: storage.k8s.io/v1
kind: CSIDriver
metadata:
  name: com.iomesh.iomesh-localpv-manager
  labels:
    app.kubernetes.io/name: iomesh-localpv-manager
spec:
  attachRequired: false
---
# Source: iomesh/templates/iomeshcluster.yaml
apiVersion: iomesh.com/v1alpha1
kind: IOMeshCluster
metadata:
  namespace: default
  name: release-name
  labels:
    helm.sh/chart: iomesh-v1.0.1
    app.kubernetes.io/name: iomesh
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "v5.3.0-rc13"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: release-name
spec:
  diskDeploymentMode: hybridFlash
  storageClass: hostpath
  reclaimPolicy:
    volume: Delete
    blockdevice: Delete
  meta:
    replicas: 3
    image:
      repository: iomesh/zbs-metad
      tag: v5.3.0-rc13-community
      pullPolicy: IfNotPresent
  chunk:
    dataCIDR: 
    replicas: 3
    image:
      repository: iomesh/zbs-chunkd
      tag: v5.3.0-rc13-community
      pullPolicy: IfNotPresent
    devicemanager:
      image:
        repository: iomesh/operator-devicemanager
        tag: v1.0.1
        pullPolicy: IfNotPresent
  redirector:
    dataCIDR: 
    image:
      repository: iomesh/zbs-iscsi-redirectord
      tag: v5.3.0-rc13-community
      pullPolicy: IfNotPresent
  probe:
    image:
      repository: iomesh/operator-probe
      tag: v1.0.1
      pullPolicy: IfNotPresent
  toolbox:
    image:
      repository: iomesh/operator-toolbox
      tag: v1.0.1
      pullPolicy: IfNotPresent
---
# Source: iomesh/templates/webhook.yaml
apiVersion: admissionregistration.k8s.io/v1
kind: ValidatingWebhookConfiguration
metadata:
  name: iomesh-validating-webhook-configuration
webhooks:
- admissionReviewVersions:
  - v1beta1
  - v1
  clientConfig:
    caBundle: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURJekNDQWd1Z0F3SUJBZ0lRSDJrU2FFSStPMGcxTkc3TWJKOER5akFOQmdrcWhraUc5dzBCQVFzRkFEQWMKTVJvd0dBWURWUVFERXhGcGIyMWxjMmd0ZDJWaWFHOXZheTFqWVRBZUZ3MHlOREExTVRVeE1ETXdORGxhRncwegpOREExTVRNeE1ETXdORGxhTUJ3eEdqQVlCZ05WQkFNVEVXbHZiV1Z6YUMxM1pXSm9iMjlyTFdOaE1JSUJJakFOCkJna3Foa2lHOXcwQkFRRUZBQU9DQVE4QU1JSUJDZ0tDQVFFQW9haExoZDVaLys5Wm9uWUI0MnhOZitRMHVsTW0KTS9sN2ZIc2R0R1hZUk1yblhTRXV3SnFFbnRTOUVBZFJhNHd6bnQ4KzRsRkR3SDlteXNLUVEzUWJlL2YwS0w4NApQM1c3T3hhanVsaXIzcHVsVEZKR05UUDJQd2N4aVAvdUxDVGgvK0ltZFpSMGJtL3VxbER6Y1FZeHdPY0xKNEQwCkoxVUtFV0VkZFZvQ1pPRkpQVVpucUJ0YURhMTJad21OOGFzaG1QSjBoOG5pZDQ5R3E3NUVEdDk3dDA4Y3NrUVEKa2RTMHl2Q244SnFBTkVDeFhOZHBDdU1WVzllVmxheWVzZVZrck1QaWFacHV5N2dvSEkySlFjK2hYS1NKaEFKQgp0ZEZrRlZEMHpjRWo3Yjg4emVrRlR5VFNtNE45S1E4ZjA3NHJwSFZLVnBRcVIvbzl5RWZEY0ZtYmt3SURBUUFCCm8yRXdYekFPQmdOVkhROEJBZjhFQkFNQ0FxUXdIUVlEVlIwbEJCWXdGQVlJS3dZQkJRVUhBd0VHQ0NzR0FRVUYKQndNQ01BOEdBMVVkRXdFQi93UUZNQU1CQWY4d0hRWURWUjBPQkJZRUZERmR3dkxZRURwRnpMSkRIUE1SRlNRWAoxQ0JETUEwR0NTcUdTSWIzRFFFQkN3VUFBNElCQVFCWkxjc1BQdnRnb1E4U21SQ3NJdXQya1NrTzNqQVhobGNHCi9Id3EzMkJXNTNIVmlqdlNzM1NhbzRJdjRCbEFrL09STWJGYnFwK2xrNWxxQmN2TWhkeElISHdmeEw3bFMzTksKdXF3eURPMUplRTFrRytaSTN6d2lrc2tDbHY5VEZjdUltYno4bmVBNVRqdUlkSnp3WFJZMXY4cHg0WnZCZkdwdQo2VXNya052ajMyQ0Mwc3lXS3hISS92L252WWp0dlQ2alcxYkFtVXNQenhlT1A3dE91Mmd6ZmplVHFSOHpRMHdoCmtscG1BZCt6VEJjR3pFK2FjUmRWU2ZES0pMZ3J4VHpUZnIwMjZ3Nm1nUGdreHVJUm5QNnhQemJRVGRXdmJaSHkKWTQ5alMyNHl3ZFozc0xlVFVRaDQ4bWxpclBNV1REMm1VZWlGd05zVjJwazhmZ0NJZTRyOAotLS0tLUVORCBDRVJUSUZJQ0FURS0tLS0tCg==
    service:
      name: iomesh-webhook
      namespace: default
      path: /validate-iomesh-com-v1alpha1-iomeshcluster
  failurePolicy: Fail
  name: validate-iomeshcluster.iomesh.com
  rules:
  - apiGroups:
    - iomesh.com
    apiVersions:
    - v1alpha1
    operations:
    - CREATE
    - UPDATE
    resources:
    - iomeshclusters
  sideEffects: None
---
# Source: iomesh/templates/zookeeper.yaml
apiVersion: zookeeper.pravega.io/v1beta1
kind: ZookeeperCluster
metadata:
  namespace: default
  name: release-name-zookeeper
  labels:
    helm.sh/chart: iomesh-v1.0.1
    app.kubernetes.io/name: iomesh
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "v5.3.0-rc13"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: release-name
spec:
  replicas: 3
  image:
    repository: iomesh/zookeeper
    tag: 3.5.9
    pullPolicy: IfNotPresent
  pod:
    securityContext:
      runAsUser: 0
    resources:
      limits:
        cpu: "400m"
        memory: "2000Mi"
      requests:
        cpu: "400m"
        memory: "2000Mi"
    
  persistence:
    reclaimPolicy: Delete
    spec:
      storageClassName: hostpath
      resources:
        requests:
          storage: 20Gi
---
# Source: iomesh/charts/zookeeper-operator/templates/post-install-upgrade-hooks.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: release-name-zookeeper-operator-post-install-upgrade
  namespace: default
  annotations:
    "helm.sh/hook": post-install, post-upgrade
    "helm.sh/hook-weight": "1"
    "helm.sh/hook-delete-policy": hook-succeeded, before-hook-creation, hook-failed
---
# Source: iomesh/templates/post-delete-hook.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: iomesh-post-delete-hook
  namespace: default
  annotations:
    "helm.sh/hook": post-delete
    "helm.sh/hook-weight": "1"
    "helm.sh/hook-delete-policy": hook-succeeded, before-hook-creation, hook-failed
---
# Source: iomesh/charts/zookeeper-operator/templates/post-install-upgrade-hooks.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-zookeeper-operator-post-install-upgrade
  namespace: default
  annotations:
      "helm.sh/hook": post-install, post-upgrade
      "helm.sh/hook-weight": "1"
      "helm.sh/hook-delete-policy": hook-succeeded, before-hook-creation, hook-failed
data:
  validations.sh: |
    #!/bin/sh
    set -e
    sleep 30

    if [ -z "$(kubectl api-resources | grep ZookeeperCluster)" ]; then
        exit 1
    fi
---
# Source: iomesh/templates/post-delete-hook.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: iomesh-post-delete-hook
  annotations:
    "helm.sh/hook": post-delete
    "helm.sh/hook-weight": "1"
    "helm.sh/hook-delete-policy": hook-succeeded, before-hook-creation, hook-failed
rules:
- apiGroups:
  - ""
  resources:
  - serviceaccounts
  - configmaps
  verbs: ["*"]
- apiGroups:
  - "rbac.authorization.k8s.io"
  resources:
  - roles
  - rolebindings
  - clusterroles
  - clusterrolebindings
  verbs: ["*"]
- apiGroups:
  - apps
  resources:
  - deployments
  - daemonsets
  verbs: ["*"]
- apiGroups:
  - batch
  resources:
  - jobs
  verbs: ["*"]
- apiGroups:
  - "storage.k8s.io"
  resources:
  - storageclasses
  verbs: ["*"]
- apiGroups:
  - iomesh.com
  - openebs.io
  - zookeeper.pravega.io
  resources: ["*"]
  verbs: ["*"]
---
# Source: iomesh/templates/post-delete-hook.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: iomesh-post-delete-hook
  annotations:
    "helm.sh/hook": post-delete
    "helm.sh/hook-weight": "1"
    "helm.sh/hook-delete-policy": hook-succeeded, before-hook-creation, hook-failed
subjects:
- kind: ServiceAccount
  name: iomesh-post-delete-hook
  namespace: default
roleRef:
  kind: ClusterRole
  name: iomesh-post-delete-hook
  apiGroup: rbac.authorization.k8s.io
---
# Source: iomesh/charts/zookeeper-operator/templates/post-install-upgrade-hooks.yaml
kind: Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: release-name-zookeeper-operator-post-install-upgrade
  namespace: default
  annotations:
    "helm.sh/hook": post-install, post-upgrade
    "helm.sh/hook-weight": "1"
    "helm.sh/hook-delete-policy": hook-succeeded, before-hook-creation, hook-failed
rules:
- apiGroups:
  - zookeeper.pravega.io
  resources:
  - "*"
  verbs:
  - get
- apiGroups:
  - extensions
  resources:
  - "deployments"
  verbs:
  - get
---
# Source: iomesh/charts/zookeeper-operator/templates/post-install-upgrade-hooks.yaml
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: release-name-zookeeper-operator-post-install-upgrade
  namespace: default
  annotations:
    "helm.sh/hook": post-install, post-upgrade
    "helm.sh/hook-weight": "1"
    "helm.sh/hook-delete-policy": hook-succeeded, before-hook-creation, hook-failed
subjects:
- kind: ServiceAccount
  name: release-name-zookeeper-operator-post-install-upgrade
  namespace: default
roleRef:
  kind: Role
  name: release-name-zookeeper-operator-post-install-upgrade
  apiGroup: rbac.authorization.k8s.io
---
# Source: iomesh/templates/post-delete-hook.yaml
apiVersion: v1
kind: Pod
metadata:
  name: iomesh-post-delete-hook
  namespace: default
  annotations:
    "helm.sh/hook": post-delete
    "helm.sh/hook-weight": "1"
    "helm.sh/hook-delete-policy": hook-succeeded, before-hook-creation, hook-failed
spec:
  serviceAccountName: iomesh-post-delete-hook
  restartPolicy: Never
  containers:
  - name: post-delete
    image: iomesh/post-delete-hook:v1.0.1
    imagePullPolicy: IfNotPresent
    env:
    - name: RELEASE_NAME
      value: release-name
    - name: RELEASE_NAMESPACE
      value: default
---
# Source: iomesh/charts/zookeeper-operator/templates/post-install-upgrade-hooks.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: release-name-zookeeper-operator-post-install-upgrade
  namespace: default
  annotations:
    "helm.sh/hook": post-install, post-upgrade
    "helm.sh/hook-weight": "2"
    "helm.sh/hook-delete-policy": hook-succeeded, before-hook-creation, hook-failed
spec:
  backoffLimit: 10
  template:
    metadata:
      name: release-name-zookeeper-operator-post-install-upgrade
    spec:
      serviceAccountName: release-name-zookeeper-operator-post-install-upgrade
      restartPolicy: Never
      containers:
      - name: post-install-upgrade-job
        image: "docker.io/lachlanevenson/k8s-kubectl:v1.23.2"
        command:
          - /scripts/validations.sh
        volumeMounts:
          - name: sh
            mountPath: /scripts
            readOnly: true
      volumes:
        - name: sh
          configMap:
            name: release-name-zookeeper-operator-post-install-upgrade
            defaultMode: 0555
