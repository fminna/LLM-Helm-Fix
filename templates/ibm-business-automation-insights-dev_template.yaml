---
# Source: ibm-business-automation-insights-dev/templates/bai-network-policy-default.yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: release-name-allow-all
  namespace: default
  labels:
    app: ibm-business-automation-insights-dev
    chart: ibm-business-automation-insights-dev
    release: release-name
    heritage: Helm
spec:
  podSelector: {}
  ingress:
  - {}
  egress:
  - {}
  policyTypes:
  - Ingress
  - Egress
---
# Source: ibm-business-automation-insights-dev/templates/bai-flink-zookeeper.yaml
apiVersion: policy/v1beta1
kind: PodDisruptionBudget
metadata:
  name: release-name-bai-flink-zk-pdb
  labels:
    app: ibm-business-automation-insights-dev
    chart: ibm-business-automation-insights-dev
    release: release-name
    heritage: Helm
spec:
  selector:
    matchLabels:
      app: ibm-business-automation-insights-dev
      chart: ibm-business-automation-insights-dev
      release: release-name
      heritage: Helm
      component: bai-flink-zk
  minAvailable: 2
---
# Source: ibm-business-automation-insights-dev/charts/ibm-dba-ek/templates/es-security-config.yaml
apiVersion: v1
kind: Secret
metadata:
  name: release-name-ibm-dba-ek-elasticsearch-security-config
  labels:
    app: release-name-ibm-dba-ek-elasticsearch
    chart: ibm-dba-ek
    heritage: Helm
    release: release-name
    component: release-name-ibm-dba-ek-elasticsearch
data:
  internal_users.yml: IyBUaGlzIGlzIHRoZSBpbnRlcm5hbCB1c2VyIGRhdGFiYXNlCiMgVGhlIGhhc2ggdmFsdWUgaXMgYSBiY3J5cHQgaGFzaCBhbmQgY2FuIGJlIGdlbmVyYXRlZCB3aXRoIHBsdWdpbi90b29scy9oYXNoLnNoCgojcGFzc3dvcmQgaXM6IHBhc3N3MHJkCmFkbWluOgogIGhhc2g6ICQyeSQxMiRWSTZKSlZNTnpOWFZGZEZiQ2dUTFBlL1p5aDA5Zkk1S3l3MEhwMHVoVHBmSTI2VEF4UGhSVwogIHJvbGVzOgogICAgLSBhZG1pbgoKI3Bhc3N3b3JkIGlzOiBkZW1vCmRlbW86CiAgaGFzaDogJDJ5JDEyJHdOTk5NbDBDWVB0RTlZeThJSzNrSU9CWGYxREJwVFByRWF2dmRkRnRqd0ZjYnk3U3hIN2Y2CiAgcm9sZXM6CiAgICAtIGtpYmFuYXVzZXIKICAgIC0gcmVhZGFsbAo=
---
# Source: ibm-business-automation-insights-dev/charts/ibm-dba-ek/templates/kibana-security-config.yaml
apiVersion: v1
kind: Secret
metadata:
  name: release-name-ibm-dba-ek-kibana-security-config
  labels:
    app: release-name-ibm-dba-ek-elasticsearch
    chart: ibm-dba-ek
    component: release-name-ibm-dba-ek-kibana
    heritage: Helm
    release: release-name
data:
  kibana.yml: c2VydmVyLm5hbWU6ICIke1JFTEVBU0VfTkFNRX0taWJtLWRiYS1lay1raWJhbmEiCnNlcnZlci5ob3N0OiAiMCIKc2VydmVyLnBvcnQ6IDU2MDEKCiNEZWZhdWx0IEtpYmFuYSBjb25maWd1cmF0aW9uIGZvciBvcGVuZGlzdHJvCmVsYXN0aWNzZWFyY2guaG9zdHM6ICJodHRwczovLyR7UkVMRUFTRV9OQU1FfS1pYm0tZGJhLWVrLWNsaWVudDo5MjAwIgplbGFzdGljc2VhcmNoLnNzbC52ZXJpZmljYXRpb25Nb2RlOiBub25lCmVsYXN0aWNzZWFyY2gudXNlcm5hbWU6ICR7S0lCQU5BX1VTRVJOQU1FfQplbGFzdGljc2VhcmNoLnBhc3N3b3JkOiAke0tJQkFOQV9QQVNTV09SRH0KZWxhc3RpY3NlYXJjaC5yZXF1ZXN0SGVhZGVyc1doaXRlbGlzdDogWyJzZWN1cml0eXRlbmFudCIsIkF1dGhvcml6YXRpb24iXQojIEVuYWJsZSBTU0wgZW5jcnlwdGlvbiAoV2l0aG91dCBoYXZpbmcgdG8gZW5hYmxlIFgtUGFjaykgQ0YgOiAgaHR0cHM6Ly93d3cuZWxhc3RpYy5jby9ndWlkZS9lbi9raWJhbmEvNi41L2NvbmZpZ3VyaW5nLXRscy5odG1sCnNlcnZlci5zc2wuZW5hYmxlZDogdHJ1ZQpzZXJ2ZXIuc3NsLmNlcnRpZmljYXRlOiAvdXNyL3NoYXJlL2tpYmFuYS9jb25maWcvdGxzL3Rscy5jcnQKc2VydmVyLnNzbC5rZXk6IC91c3Ivc2hhcmUva2liYW5hL2NvbmZpZy90bHMvdGxzLmtleQoKb3BlbmRpc3Ryb19zZWN1cml0eS5tdWx0aXRlbmFuY3kuZW5hYmxlZDogJHtLSUJBTkFfTVVMVElURU5BTkNZfQpvcGVuZGlzdHJvX3NlY3VyaXR5Lm11bHRpdGVuYW5jeS50ZW5hbnRzLmVuYWJsZV9nbG9iYWw6IGZhbHNlCm9wZW5kaXN0cm9fc2VjdXJpdHkubXVsdGl0ZW5hbmN5LnRlbmFudHMuZW5hYmxlX3ByaXZhdGU6IGZhbHNlCm9wZW5kaXN0cm9fc2VjdXJpdHkubXVsdGl0ZW5hbmN5LmVuYWJsZV9maWx0ZXI6IGZhbHNlCm9wZW5kaXN0cm9fc2VjdXJpdHkubXVsdGl0ZW5hbmN5LnRlbmFudHMucHJlZmVycmVkOiBbIlByaXZhdGUiLCAiR2xvYmFsIl0Kb3BlbmRpc3Ryb19zZWN1cml0eS5yZWFkb25seV9tb2RlLnJvbGVzOiBbImtpYmFuYV9yZWFkX29ubHkiXQo=
---
# Source: ibm-business-automation-insights-dev/charts/ibm-dba-ek/templates/tls-secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: release-name-ibm-dba-ek-elasticsearch-tls
  labels:
    app: release-name-ibm-dba-ek-elasticsearch
    chart: ibm-dba-ek
    heritage: Helm
    release: release-name
    component: release-name-ibm-dba-ek-elasticsearch
data:
  tls.crt: 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
  tls.key: LS0tLS1CRUdJTiBQUklWQVRFIEtFWS0tLS0tCk1JSUpRZ0lCQURBTkJna3Foa2lHOXcwQkFRRUZBQVNDQ1N3d2dna29BZ0VBQW9JQ0FRQ1dtQUZOdHFJa0p2UlEKNi82bllUd2IrR1dpemQ5S2x0Z0g1b3I4cGxNaTUrUEp2TFJMbk1SSk9Dek9qKzIzU054c28xSnFQVmxueUtabwpJWWpubi9GY0FXNFVCZENNVEVIa0pneGVoSUhRV2pTUEJSVUFwRS9rbnVlRE0xUmNmUkpXL0RDaFJGbDNCQ1NaCjg1UlVqbWtwelgzZHZhaDYyNE1oZjBjejE0dVlURmlLSEVGN0Z6YWVFN3U2Y2NkV2xYRVg3WlM3Tm1KWGpvRTAKOHVVUllwTGxMNFdodjRXM0NDQzArNlVSN2pwdGozRjhwTE91cFVVeC9MQmJPaWZ6MGJ0U1dLbVNvdDE1ZXRodgozYWdHNmJhZml2M2s1VjM3bHVKTmEvQVEvbnNlNlcvbEY2eWpoVVBxeTU1UjIxNncyQlZCWUZCWGxHaTJtelA0Ck5iTU9tS0FxajNxaVloLzBvTkViQ1Qza3ErbU5OTTVEMXhRVTdWTEU1OXJxOW1WbDNzMncwRVVmVXg3ZWxGZDAKWmg1azRZa3lKTUFrbVFsd21NTEQrTU04QWprdXkxbDZkTGlVYVRUZzE1TzN1b3EvbzZkVnVac213dDE1aDBqdgpGRmRzYzJiNlFSTW12OU9kazVBWkdMUTB0U0lCaWFFV1lhb05PdXVtbzM0eTh6ekxJc2hzYVN2NkpkcXk4NVhkCjU2Nll0dnkzNStmdjVGRloxRGFSelYvSnpDa2FvYXlPR0ZUcGpubGxkNDRVL25oQVhvUW5FRDVIc0tPTXNycGYKTk0wTnhXQWJrUXFLamluZ25XUzFLZE9HRWJzNGpONHZGZTBpWnl1VU5IMm1PdDNUVERPa0RkbFJzUEhnNFBwVQorRlhUbi9UUWNXUWlNdkVyKy9TZFEyMXNOMjVsbHdJREFRQUJBb0lDQUNtd2xSUE5qcCtSaFN0dDJjYStuV1JrCjVNWW9WanVRL09kYkJIa2pGbnJnVldoQTdHek9UbXl5dDN6THpaUmpBRnEyOEJibk92d0hTVUlrbm9ENC8xbG8KTC9BdEYrbnZKb0tob2VUOHErOWhPWkdxWjRFUSsra2ZzSm5hdU8wTjF1anIwZzZqSEYxZGNVQ0pkVFBmWk8rawpxc2FiUGF3ZFh2VUVCbE1zeGNGNHlUNGF5bW5vS0QrazJPQ3BwUFNzVkcyNllPVmZEZVNOVittdm9JaXFrRjRRClJOOWRaUWdob09SWmtmNGZ4RjhXU2VXbXR2T1BYMU9TVDhSQm1sUGVhUXhIN1ZIaDhvd3gzUDlERHNRektWS0wKcVBRWUoyZUNBczVLSm1DZUFybXhDRUFVeUw5UUlsZzYzRzV1MjR6N2xRN1BPZzYwMERSVlRSTFcwdVlrakpvdQovS0ticGQrK3Exd2d3L25MbXQ5M2V1OURaWFprTUJ1TS9xaGFnOEJRd2JDRmw3UkFpSURSbUZJY3gyR2V6TGFBClFwc1BMQU1wTVJ1dzk3NFRtWG9WZmJrdWl2ay9OVWMzRmJGempFZWhLZlpPRStDbk9nR09pNTBFeFpxL1ZFMWwKZkNRR05oZDVFSmdLM1plWnUxVGtHZGhyRHdHbHI3R3VZMzB4K21zQ0NOY0s2Tm1uamN1RXpxUTBtdnJQKzdWKwpQL2loVHlCTG8rRDJ2ejVzaDViaVJ0UFNVbFpUVUlTZTBPRkVuVFpscTdPOVRxR2xTc3IyeFRsSHJCQjlVRmpiCkdvdm8vR2crK1UxZWhXOHc2VmtLR0s5eFF4ajRDZ2x6dFB0TFBaS3QzOXhnenk3SWRBSHJpYkdzdUF3cTJhT2oKalV3SGFYU0NFT2FNaStSR3oyRVJBb0lCQVFER0dKQ1RJM3JCZFAzdHJHcHBQdWNjTFo0SmtHaWJkcisvZjQvWQpZYmxDa1N0aG9JSUZNNTFNYThwb25NVFNWcUQ4N3hjcUpHUFowc1hyRzd0Vmw5ZWtiYlB1ekhZOWVOV0hpUFV3CmJzbzBXa2U1NlY2RGVSaXJJZU1hYjB3K2UvSUhyM2hjLzVTYU1LbnpMMjRETy9LazhyWFhzSENIVXpuZGhMZ1EKZnNJb3FHaFJDTVZMZzV0YVJUZHlBSUlHdmFxYWQvNnljdzlqbmRBcmlJaWczdmRZUTQyaWdjNHcwdWtyS24zLwprbzI2WWJKU3hHSXNpYTFxM0RzMTBvOURENWJiaWhXUXYwNWYxS3UvVFRLbzQ3c3U4b291ZzJGSXFaUzY2NmUzClUweWxNaWxrajI5UXAvK3BlK3JXRlhPL3A2a0xmNXpYc2k0aGk2OENNdThTSGZLZkFvSUJBUURDbk45R3RDOHgKclVPT1ZxdzY4L3BtTXdlY0NMVFZSaXlmU2NVUlY0d1g2VjNIWFVNQ3BSZ3czTmFpSDBsQVZxRFZEeWttQ3dzdApQeU5DdXdDUVRhdi9KYlBBdnNqMURPZEJsSmdiWUhKZnFKdlJzV0IzVi9OTkdnZC9jMFhFei95a2pGYmlXcHVYCkdFWjVoWG1lNzRSc3JhTFVabVFuQ2lXMnJUKzNJaVdIa1MyWWY3UllwYy9CZUY2OEJESmpITzFOSW1paUQ3WEQKeGYvQUQ5SFVUTzBCeW83TkZGUXhOS1ZlUmdyREpmRHBLUERkNVYvQXkvQTRFMnR6ZnJ0ampvZXVDOFFjcW00dgpDUnhsajRzMXo5dFpJSDQ2bGEwSjNWY0lKYURnTzM4T0I4RXNtb2VHc3dYc2NvOGY3VjNDMTVoMXNtaGRQaXlpCmptWUQ1azl5Z0dJSkFvSUJBUUM1WmRRcFlWTktLOHhiM0xuYXRseG1LdXQxMkFtUE5weFBCWHdDNzdNTGNnSS8KNUpETGZYc0NRdiswMk1QOGQ4ZEQ4aUNqK0ZyYlNrQ2h3ZHFhU1BveGtkcU03QjdkZVhHZTM3ZGFGTlo2R09SNApRc21LRXBQYjFtTk9Ja3doVHE4K01pTmNKbmRWdDZYWFM5U1NnbENkditvZ2E2bGxmYWJ5ZzN3aE5BRlRQQW9sCmpTZlpmTnF3cVljeTB2YmVpRFJiVFdLNmNLVStmanlPQWNLZGpRL0JNN2dqRjRsNmVHcHhVOXVJamdqSEh4aGUKRGg0endNYms5Q2tXUG5LR09OamZyMlJ2akJ3MTVEeTVWZTdMMGhjbDRTa2lUeU9GZGZFVTMraWYwdjR3dmJtdgp1KzVhZG1ENHBsa3E4L2pZcm5tdm9VZVJOOW1rMjY1M1NHUW5lSS9SQW9JQkFDY2NoZGJjMFh0SFdnTmFNZVRyCk1aQ21nc24rQ2ZHdTE3cnZoWFoxeE1idGRKWmpqTnNVT09kaENwV3NlZmsvTDdXQ0JZQUt5aVUrd2lSZ0ZyM3AKamo2SjRqVkRZbm0xTFNqRjUwZmhPenMwVkpSdzlIVW5yTkw2L3pUREF1dUo3VGxZcHdGNHVqcEVlNjFpZ00zTApUeTdVT3B3N003ZVExNEYrRWdjSkNzZlRDbm5TZUhrMFlhdDlPSFRLMXlHS0o3clB4bjJEY01FMm9xNkR2MlRPClRQZUdNT3JRUWhkZGdEcVJFd3FqTG1aOWZ1THBmVFB2Q0lrTWhoVEJESUgybkJnRGIxZGZmU05nemw4dTJRaG8KakttOTJRQ0hJaTZRV0RSZjg1UDlBUXpkekJuZHVJeituNXNrYnRVNHpCWWpaQldMVkdRZzRiR05zcnpuNVdHYQpvWmtDZ2dFQUtIUWxGK0dvUzhaSTN4YS9vRjQydjdyOWRZdVBtZXBNWmxJME5hV28wdU82ZDZhOVIyWnkveTdmClAvemc3N09RQmNSUE1CVlUwTUxjNmJ1dXVVV1JnNUd3cXRLcFFWTE5aTjJkWlQwcC9yckE3dHlJZm9aYUxEaFEKeTN0a001ajduRTJZYnBWcGE5OTlsUVJJTWFiMTkzTTVxSzQxcjFMM3dKU1c5VHUwL3RsQ2l4UjZkdkJqdUpuUgpYNys1WEEydXM1aTlRc3ExSEorNXUwNVg1WG9RQi9LZFd2V0lJTndHV1VncGlBQjlncVB5RHNLYVordVYrT2UyCmtGd0ZmQ0NJc3RseU9kMjA2OHNRNldqRmdBY25VSnI5TE5ld2YvYzNVR01WZEFEUzdjUkhRWWt3QWsxR2lCaW8KQlhYMWZsbFR6WHczTjJacm5XejA1Zng1akxXZm93PT0KLS0tLS1FTkQgUFJJVkFURSBLRVktLS0tLQo=
---
# Source: ibm-business-automation-insights-dev/templates/bai-secret.yaml
# secrets must be base64-encoded
apiVersion: v1
kind: Secret
metadata:
  name: release-name-bai-secrets
  labels:
      app: ibm-business-automation-insights-dev
      chart: ibm-business-automation-insights-dev
      release: release-name
      heritage: Helm
type: Opaque
data:  
  
  elasticsearch-password: "cGFzc3cwcmQ="
  flink-ssl-password: ZGJhT0lDQQ==
  flink-ssl-keystore: /u3+7QAAAAIAAAACAAAAAgACY2EAAAFkJ3uWggAFWC41MDkAAALEMIICwDCCAagCCQDKPg80a7M0eTANBgkqhkiG9w0BAQsFADAiMRIwEAYDVQQDDAlJQk0gT0kgQ0ExDDAKBgNVBAoMA0lCTTAeFw0xODA2MjIxMjMxMjJaFw0yODA2MTkxMjMxMjJaMCIxEjAQBgNVBAMMCUlCTSBPSSBDQTEMMAoGA1UECgwDSUJNMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAscLHPvsQPrlwaxpA2hvmgu4EHxlEu72dhLoLki+DYLeN2vOXYescmjwIO2YZZEqWU1B4dhKChq5l/tDfoAs4WtQkSCJBFyGxmmOk1gpbE1L4yLg79wevsWSlg5IoluDHtIEmleEDiIwWXW8BzeqATQT7PCj28XP7gBq78NIrQaKLEi/FGnZ3JLAtVpU3jKriaAO34XqDUxIkqbmbz2kUuO0YaTOZTDxfv1MT1RXAedQlSjzQvkQVUD6q8XEFObSmm7RUB30bWQnFURP33o3igqV5USPRR9UBOoBuFq9hQAB4ysMosh/bEVLvNsx0ZNcXTJ/ZGsClUDoFEnjD6b9zhwIDAQABMA0GCSqGSIb3DQEBCwUAA4IBAQCHkq+qwpMEXNb/9FsNzcrGWRCeVpR0O47Kx4Ly3UvkFvHx8IqmsgBB2aFC2q3Y6pegv6/Yipw6SLyX/Y8s5R6Y+rvpDE3I1XbK0UQI5EB0/LC6V+BL27VJSYrsCfmDypL0U5EL0i+o8FRFFcq9WQ85nsSTV6n66isGIjUo7rjucbqe0PJfnKAjALYbyutpw5ntSltM7mZEEp0iMQkd5rAxI+jjCOwvCWFz6iI5CX97D2ZaA6rxVsLeTtnN0AYVVSwKbCGideufRKgZabmHCl5w/ASIY5w/7en7gVeXYsanZXiRTdd8RTIJsPeTNEAYehl35GKYqBE384vUrsroOWx/AAAAAQAEcG9kcwAAAWQn0Fp7AAAFATCCBP0wDgYKKwYBBAEqAhEBAQUABIIE6T05y1EEAuXPqM8Zr0YjX2zcP2kb9kbpvwrBYdqluJ7lfTWtYAg0/F9fB6GySdTEQOGx9r0Tu4aMaZGaypE9Rktp32Bz2UIVfmi50Xy2Pz/lBXQfuHMFa67WKbNttg/7QXwozveqURrtIbxwOObcwhqBYU0d6+cxI7tIPsID1cP2lSG5P8+4wGo2HoFiyPxgqRKE0HTql+DazGBZTawGpINBoOY62BUCrJlY2/Ff7n3tT1byFfEyi00Xt5QUuBRyXa6XrWuftrQBdi0bBNQqNtEbw5M0s018FsuIXEciGT2c7uW+4bMyku5JKr76l5Mr52LTKQqD6aSOTD+PGpzZgVL1D0bX+2myOuLYQ0oJNpjpQyZ9bLvEiIl4FathPyI5bRWnx8sq9w8/8R9ikUsXVm3rJdIPasBSVOP6squCtYrme4oKRRSty0bkWvFy+9QfScx5etUfSxP6g33Ur6Pg/gfkyxNZuFKeC9N9tVaHXdVhtE8E6bBbkqKx6dKbjSV6Nyx6LtLOgXVEH3bHayeomStZ9XMs1wQmLp4kFo1E+wIN5HjlEE/qiiJsRoGpe9RDyWpQdEYnRoNjS+Yrmfvut/nWo8u0TnGkpene9GRZ4TW+zpLM9Syg4/Qs9ICCYUmqoc8lEV1e2atBTmVfUPjT70szTj8o5UUNC9f2uaSboNcsWyVfHRdtZfON5I9tAonoowq7MYVpA0vr4WYMrKCs4QrPeYDK/gO7jl2cDfslKG0sG3RccMsPH3lkf7J/wznXZFeq0gIcb6xJM7IXEkPg4RVy62I3lrZDLvMWQoA4L+DR2i2/GnthEIgPXpD7ph1zkjuyd+Ca/8mi43L9iNHPqZh0i2grXoe1m2NeDybrPIWnyZdH6Shtb+UpHrfwjulYGGet2E5TAa1oT4j+tTqhyQ6n5i3bNAexqVF2uQu9mGQK9NqfYqefgdOu4UhkMS6SH5HkzDkHzZZ24sm0zby1hrYOi3HH95B+/3RJG9+Y5cYfHbkulFqur6/n3PpNhb7j4iXTktdnlsn9/8HjqxUv4pom6fZigbXw+AyabUelouZQqsNTCzlzGuLrz7qXmpvbFe3UXt4rL2pH8Nrnq5YlmD5oM2dN3a++tP9xRSJ4MYNrp1cIW0H4BZ3mZ41PXHenq3hA26B15anWuCCwSPCsPHp2EIh2woECwkkIX0kBQWHmjMs20FkY7hxb8VZVcwTy/MG2EJgIdqCHfZG67spekKpFxlgaI3EIvpKKZTrrp53f/3+rxnPl0XiWpR0z+RaCNyVJgW06CVwCGRUbw9b0/K12yUshbvtx2+vJ2bJtbpSjbvJgmmccrPsoHH+oZEnkTiJutiGgCK0yvUPTPoLboEfY7SS35EQ4GWrDgkXTT17YRU9TipLRmDHOeKcmhfQlJNws7t6fLsqJinNc3m6LGRZt+YGP9EIflYNOYYiLB9mtkyw5P9i4y2ytAD0HxT3049pR0E8QkNBk+iRZrQO74Q+IMUFyfIWt1WVZFp83wQLA0OACD1jwjUd8GHXwvMvlfyW/m93WD3E2Vck8b58PBpak+fmqoW0efGZObKnTTryrpxBvqVHKN/KBvsGrP1l23z7OVpAz/RCdY1ojRRFqUrdbVDxmO0EJMVn/ie5scjVk7dclHXUyPgwLFaPEG8OGaXFzn+N/msSbnwAAAAIABVguNTA5AAADMTCCAy0wggIVoAMCAQICCQDuX3PV++uEPTANBgkqhkiG9w0BAQUFADAiMRIwEAYDVQQDDAlJQk0gT0kgQ0ExDDAKBgNVBAoMA0lCTTAeFw0xODA2MjIxNDA1MDZaFw0yODA2MTkxNDA1MDZaMB4xHDAaBgNVBAMMEyouc3ZjLmNsdXN0ZXIubG9jYWwwggEiMA0GCSqGSIb3DQEBAQUAA4IBDwAwggEKAoIBAQC6FCkzRts62ELBGURknaBbGMejLMjnoQU3FMvl0C386gMIqU4tPy5j4Cd3z+PHuwfimYRvwDudJfS6+ITwXaJ+NxN4sE0f6gHoaXEAkaq7jhTZbg3+WdwfQoxrRXLWXCly1SNMIpoZ7SmC8Wke+htamwCoPUVxYVIxDUyEe6JoAR2AMNl3C9q3uGP/SlpE4UYx/jttREtALuQ18E1m64WZn0LZI3T26PrZ6MCBqPFcWqwysv/CGxhUhBsjeMQEjVySVVR982LWpN2kMrcpMUFVRQhz3IKbmK35Xha40wYmLr2uc7SSo0SjWM1TXiNMgnXIpZn/a2fg6p/WfjkE1g2DAgMBAAGjajBoMAkGA1UdEwQCMAAwCwYDVR0PBAQDAgXgME4GA1UdEQRHMEWCEiotZmxpbmstam9ibWFuYWdlcoIvKi4qLWZsaW5rLXRhc2ttYW5hZ2VyLXN2Yy5iYWkuc3ZjLmNsdXN0ZXIubG9jYWwwDQYJKoZIhvcNAQEFBQADggEBALFJEcms/BKkReE9ZOAP2zhjqU2cqOfV0yUaKxN5SjEYA321h3k8N2YKYsNrCrVqKAqi8LrbDPqybogoj66zVibyDNNGHzpI/0aBX4Ppj1Hg6MQwBpUKdRE985i2EkwdzszfTLHidpRVGSGZqnMICltT6oWZr9AEZT1zYWgvNT0JciPWBSpRDlB4dr69M+ye5uQGC67FBryFWmgQOAsYIAAxbk8cLHLcybFYB502RM65czXgHXT+V6rdwTLU0sChE9Q+1Yd8M3hQGiOMSfY99VVAqSiaOkZPakAbAfp+t4ngEc8FSSwed3+pBmTbLGJz9LayRQhbo0TvggGgH79th7MABVguNTA5AAACxDCCAsAwggGoAgkAyj4PNGuzNHkwDQYJKoZIhvcNAQELBQAwIjESMBAGA1UEAwwJSUJNIE9JIENBMQwwCgYDVQQKDANJQk0wHhcNMTgwNjIyMTIzMTIyWhcNMjgwNjE5MTIzMTIyWjAiMRIwEAYDVQQDDAlJQk0gT0kgQ0ExDDAKBgNVBAoMA0lCTTCCASIwDQYJKoZIhvcNAQEBBQADggEPADCCAQoCggEBALHCxz77ED65cGsaQNob5oLuBB8ZRLu9nYS6C5Ivg2C3jdrzl2HrHJo8CDtmGWRKllNQeHYSgoauZf7Q36ALOFrUJEgiQRchsZpjpNYKWxNS+Mi4O/cHr7FkpYOSKJbgx7SBJpXhA4iMFl1vAc3qgE0E+zwo9vFz+4Aau/DSK0GiixIvxRp2dySwLVaVN4yq4mgDt+F6g1MSJKm5m89pFLjtGGkzmUw8X79TE9UVwHnUJUo80L5EFVA+qvFxBTm0ppu0VAd9G1kJxVET996N4oKleVEj0UfVATqAbhavYUAAeMrDKLIf2xFS7zbMdGTXF0yf2RrApVA6BRJ4w+m/c4cCAwEAATANBgkqhkiG9w0BAQsFAAOCAQEAh5KvqsKTBFzW//RbDc3KxlkQnlaUdDuOyseC8t1L5Bbx8fCKprIAQdmhQtqt2OqXoL+v2IqcOki8l/2PLOUemPq76QxNyNV2ytFECORAdPywulfgS9u1SUmK7An5g8qS9FORC9IvqPBURRXKvVkPOZ7Ek1ep+uorBiI1KO647nG6ntDyX5ygIwC2G8rracOZ7UpbTO5mRBKdIjEJHeawMSPo4wjsLwlhc+oiOQl/ew9mWgOq8VbC3k7ZzdAGFVUsCmwhonXrn0SoGWm5hwpecPwEiGOcP+3p+4FXl2LGp2V4kU3XfEUyCbD3kzRAGHoZd+RimKgRN/OL1K7K6Dlsf5fd9nid71C3EfGhEHmkKUmYqTND
  flink-ssl-truststore: /u3+7QAAAAIAAAABAAAAAgACY2EAAAFkJ3po2QAFWC41MDkAAALEMIICwDCCAagCCQDKPg80a7M0eTANBgkqhkiG9w0BAQsFADAiMRIwEAYDVQQDDAlJQk0gT0kgQ0ExDDAKBgNVBAoMA0lCTTAeFw0xODA2MjIxMjMxMjJaFw0yODA2MTkxMjMxMjJaMCIxEjAQBgNVBAMMCUlCTSBPSSBDQTEMMAoGA1UECgwDSUJNMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAscLHPvsQPrlwaxpA2hvmgu4EHxlEu72dhLoLki+DYLeN2vOXYescmjwIO2YZZEqWU1B4dhKChq5l/tDfoAs4WtQkSCJBFyGxmmOk1gpbE1L4yLg79wevsWSlg5IoluDHtIEmleEDiIwWXW8BzeqATQT7PCj28XP7gBq78NIrQaKLEi/FGnZ3JLAtVpU3jKriaAO34XqDUxIkqbmbz2kUuO0YaTOZTDxfv1MT1RXAedQlSjzQvkQVUD6q8XEFObSmm7RUB30bWQnFURP33o3igqV5USPRR9UBOoBuFq9hQAB4ysMosh/bEVLvNsx0ZNcXTJ/ZGsClUDoFEnjD6b9zhwIDAQABMA0GCSqGSIb3DQEBCwUAA4IBAQCHkq+qwpMEXNb/9FsNzcrGWRCeVpR0O47Kx4Ly3UvkFvHx8IqmsgBB2aFC2q3Y6pegv6/Yipw6SLyX/Y8s5R6Y+rvpDE3I1XbK0UQI5EB0/LC6V+BL27VJSYrsCfmDypL0U5EL0i+o8FRFFcq9WQ85nsSTV6n66isGIjUo7rjucbqe0PJfnKAjALYbyutpw5ntSltM7mZEEp0iMQkd5rAxI+jjCOwvCWFz6iI5CX97D2ZaA6rxVsLeTtnN0AYVVSwKbCGideufRKgZabmHCl5w/ASIY5w/7en7gVeXYsanZXiRTdd8RTIJsPeTNEAYehl35GKYqBE384vUrsroOWx/OHGGJ+TPH/IBQxV8gwbloMvzPaA=
  flink-ssl-internal-keystore: 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
  kafka-server-cert: ""
  kafka-ca-cert: ""
  kafka-password: ""
  flink-security-krb5-keytab: ""
  admin-password: cGFzc3cwcmQ=
  admin-key: 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
  admin-cert: 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

  elasticsearch-server-cert: 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
---
# Source: ibm-business-automation-insights-dev/charts/ibm-dba-ek/templates/es-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-ibm-dba-ek-elasticsearch-config
  labels:
    app: release-name-ibm-dba-ek-elasticsearch
    chart: ibm-dba-ek
    heritage: Helm
    release: release-name
    component: release-name-ibm-dba-ek-elasticsearch
data:
  master.yml: |-
    cluster.name: "release-name-ibm-dba-ek-elasticsearch"
    network.host: 0.0.0.0
    discovery.zen.ping.unicast.hosts: release-name-ibm-dba-ek-master
    discovery.zen.minimum_master_nodes: 1
    transport.tcp.port: 9300
    node.name: ${HOSTNAME}
    # Since that we are running the container as a normal user we can't opt for this option.
    # Another option available on Linux systems is to ensure that the sysctl value vm.swappiness is set to 1.
    # This reduces the kernel’s tendency to swap and should not lead to swapping under normal circumstances,
    # while still allowing the whole system to swap in emergency conditions.
    # So, we have set vm.swappiness to 1 from our initContainer.
    #bootstrap.memory_lock: true
    # ----------------------------------- Paths ------------------------------------
    #
    # Path to directory where to store the data (separate multiple locations by comma):
    #
    path.data: /usr/share/elasticsearch/data
    #
    # Path to log files:
    #
    path.logs: /usr/share/elasticsearch/logs
    #
    ######## Start OpenDistro for Elasticsearch Security Demo Configuration ########
    # WARNING: revise all the lines below before you go into production
    opendistro_security.ssl.transport.pemcert_filepath: security/esnode.pem
    opendistro_security.ssl.transport.pemkey_filepath: security/esnode-key.pem
    opendistro_security.ssl.transport.pemtrustedcas_filepath: security/root-ca.pem
    opendistro_security.ssl.transport.enforce_hostname_verification: false
    opendistro_security.ssl.http.enabled: true
    opendistro_security.ssl.http.pemcert_filepath: security/esnode.pem
    opendistro_security.ssl.http.pemkey_filepath: security/esnode-key.pem
    opendistro_security.ssl.http.pemtrustedcas_filepath: security/root-ca.pem
    opendistro_security.allow_unsafe_democertificates: true
    opendistro_security.allow_default_init_securityindex: true
    opendistro_security.authcz.admin_dn:
      - CN=kirk,OU=client,O=client,L=test, C=de
    
    opendistro_security.audit.type: internal_elasticsearch
    opendistro_security.enable_snapshot_restore_privilege: true
    opendistro_security.check_snapshot_restore_write_privileges: true
    opendistro_security.restapi.roles_enabled: ["all_access", "security_rest_api_access"]
    cluster.routing.allocation.disk.threshold_enabled: false
    node.max_local_storage_nodes: 3
    ######## End OpenDistro for Elasticsearch Security Demo Configuration ########
    node.master: true
    node.data: false

  data.yml: |-
    cluster.name: "release-name-ibm-dba-ek-elasticsearch"
    network.host: 0.0.0.0
    discovery.zen.ping.unicast.hosts: release-name-ibm-dba-ek-master
    discovery.zen.minimum_master_nodes: 1
    transport.tcp.port: 9300
    node.name: ${HOSTNAME}
    # Since that we are running the container as a normal user we can't opt for this option.
    # Another option available on Linux systems is to ensure that the sysctl value vm.swappiness is set to 1.
    # This reduces the kernel’s tendency to swap and should not lead to swapping under normal circumstances,
    # while still allowing the whole system to swap in emergency conditions.
    # So, we have set vm.swappiness to 1 from our initContainer.
    #bootstrap.memory_lock: true
    # ----------------------------------- Paths ------------------------------------
    #
    # Path to directory where to store the data (separate multiple locations by comma):
    #
    path.data: /usr/share/elasticsearch/data
    #
    # Path to log files:
    #
    path.logs: /usr/share/elasticsearch/logs
    #
    ######## Start OpenDistro for Elasticsearch Security Demo Configuration ########
    # WARNING: revise all the lines below before you go into production
    opendistro_security.ssl.transport.pemcert_filepath: security/esnode.pem
    opendistro_security.ssl.transport.pemkey_filepath: security/esnode-key.pem
    opendistro_security.ssl.transport.pemtrustedcas_filepath: security/root-ca.pem
    opendistro_security.ssl.transport.enforce_hostname_verification: false
    opendistro_security.ssl.http.enabled: true
    opendistro_security.ssl.http.pemcert_filepath: security/esnode.pem
    opendistro_security.ssl.http.pemkey_filepath: security/esnode-key.pem
    opendistro_security.ssl.http.pemtrustedcas_filepath: security/root-ca.pem
    opendistro_security.allow_unsafe_democertificates: true
    opendistro_security.allow_default_init_securityindex: true
    opendistro_security.authcz.admin_dn:
      - CN=kirk,OU=client,O=client,L=test, C=de
    
    opendistro_security.audit.type: internal_elasticsearch
    opendistro_security.enable_snapshot_restore_privilege: true
    opendistro_security.check_snapshot_restore_write_privileges: true
    opendistro_security.restapi.roles_enabled: ["all_access", "security_rest_api_access"]
    cluster.routing.allocation.disk.threshold_enabled: false
    node.max_local_storage_nodes: 3
    ######## End OpenDistro for Elasticsearch Security Demo Configuration ########
    node.master: false
    node.data: true

  client.yml: |-
    cluster.name: "release-name-ibm-dba-ek-elasticsearch"
    network.host: 0.0.0.0
    discovery.zen.ping.unicast.hosts: release-name-ibm-dba-ek-master
    discovery.zen.minimum_master_nodes: 1
    transport.tcp.port: 9300
    node.name: ${HOSTNAME}
    # Since that we are running the container as a normal user we can't opt for this option.
    # Another option available on Linux systems is to ensure that the sysctl value vm.swappiness is set to 1.
    # This reduces the kernel’s tendency to swap and should not lead to swapping under normal circumstances,
    # while still allowing the whole system to swap in emergency conditions.
    # So, we have set vm.swappiness to 1 from our initContainer.
    #bootstrap.memory_lock: true
    # ----------------------------------- Paths ------------------------------------
    #
    # Path to directory where to store the data (separate multiple locations by comma):
    #
    path.data: /usr/share/elasticsearch/data
    #
    # Path to log files:
    #
    path.logs: /usr/share/elasticsearch/logs
    #
    ######## Start OpenDistro for Elasticsearch Security Demo Configuration ########
    # WARNING: revise all the lines below before you go into production
    opendistro_security.ssl.transport.pemcert_filepath: security/esnode.pem
    opendistro_security.ssl.transport.pemkey_filepath: security/esnode-key.pem
    opendistro_security.ssl.transport.pemtrustedcas_filepath: security/root-ca.pem
    opendistro_security.ssl.transport.enforce_hostname_verification: false
    opendistro_security.ssl.http.enabled: true
    opendistro_security.ssl.http.pemcert_filepath: security/esnode.pem
    opendistro_security.ssl.http.pemkey_filepath: security/esnode-key.pem
    opendistro_security.ssl.http.pemtrustedcas_filepath: security/root-ca.pem
    opendistro_security.allow_unsafe_democertificates: true
    opendistro_security.allow_default_init_securityindex: true
    opendistro_security.authcz.admin_dn:
      - CN=kirk,OU=client,O=client,L=test, C=de
    
    opendistro_security.audit.type: internal_elasticsearch
    opendistro_security.enable_snapshot_restore_privilege: true
    opendistro_security.check_snapshot_restore_write_privileges: true
    opendistro_security.restapi.roles_enabled: ["all_access", "security_rest_api_access"]
    cluster.routing.allocation.disk.threshold_enabled: false
    node.max_local_storage_nodes: 3
    ######## End OpenDistro for Elasticsearch Security Demo Configuration ########
    node.master: false
    node.data: false
    http.port: 9200

  log4j2.properties: |
    status = error
    appender.console.type = Console
    appender.console.name = console
    appender.console.layout.type = PatternLayout
    appender.console.layout.pattern = [%d{ISO8601}][%-5p][%-25c{1.}] %marker%m%n

    rootLogger.level = info
    rootLogger.appenderRef.console.ref = console
---
# Source: ibm-business-automation-insights-dev/charts/ibm-dba-ek/templates/es-entrypoint.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-ibm-dba-ek-elasticsearch-entrypoint
  labels:
    app: release-name-ibm-dba-ek-elasticsearch
    chart: ibm-dba-ek
    heritage: Helm
    release: release-name
    component: release-name-ibm-dba-ek-elasticsearch
data:
  entrypoint.sh: |
     #!/bin/bash

     set -e

     echo -e "\n[$(date)] Setting production-ready ulimits"
     # https://www.elastic.co/guide/en/elasticsearch/reference/current/file-descriptors.html
     ulimit -n 65536
     # https://www.elastic.co/guide/en/elasticsearch/reference/current/max-number-of-threads.html
     ulimit -u 4096

     echo -e "\n[$(date)] Setting elasticsearch.yml"
     cp /usr/share/elasticsearch/ibm-dba-ek-config/elasticsearch.yml /usr/share/elasticsearch/config/elasticsearch.yml


     # Merge the opendistro security properties into elasticsearch.yml

     # Running command to start elasticsearch
     # passing all inputs of this entry point script to the es-docker startup script
     # NOTE: this entry point script is run as root; but executes the es-docker
     # startup script as the elasticsearch user, passing all the root environment-variables
     # to the elasticsearch user

     exec /docker-entrypoint.sh "$@"
---
# Source: ibm-business-automation-insights-dev/charts/ibm-dba-ek/templates/es-security-entrypoint.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-ibm-dba-ek-elasticsearch-security-entrypoint
  labels:
    app: release-name-ibm-dba-ek-elasticsearch
    chart: ibm-dba-ek
    heritage: Helm
    release: release-name
    component: release-name-ibm-dba-ek-security-config
    role: security-config
data:
  entrypoint.sh: |
    #!/bin/bash
    # The Security plugin stores its configuration-including users, roles, and permissions-in an index on the
    # Elasticsearch cluster (.opendistro_security).
    # It is possible to customize the Open Distro security config through a secret that contains files related to the
    # Open Distro security plugin configuration. All the keys contained in this secret will be copied as files in
    # `/usr/share/elasticsearch/plugins/opendistro_security/securityconfig` directory to override the default
    # configuration, and `/usr/share/elasticsearch/plugins/opendistro_security/tools/securityadmin.sh` will be run to
    # setup the `.opendistro_security` index. For more detail see the Open Distro fo Elasticsearch documentation:
    # (https://opendistro.github.io/for-elasticsearch-docs/docs/security/security-admin/)
    #
    # CF (for tutorial): https://github.com/opendistro/for-elasticsearch-docs/issues/5

    ES_CLUSTER_URL=https://release-name-ibm-dba-ek-master:9300
    ES_CREDS=$ELASTICSEARCH_USERNAME:$ELASTICSEARCH_PASSWORD
    set +e
    echo -e "\n[$(date)] Trying to reach Elasticsearch transport..."
    curl -X GET $ES_CLUSTER_URL -k --fail
    while [ "$?" -ne "58" ]; do
      echo "[$(date)] Elasticsearch transport layer not ready yet..."
        sleep 5
        curl -X GET $ES_CLUSTER_URL -k --fail
    done

    set -e
    echo -e "\n[$(date)] Setting up security config..."

    custom_config_files=$(ls /usr/share/elasticsearch/init-security-config)

    if [ ! -z "$custom_config_files" ]; then
      echo -e "\n[$(date)] Custom config files: $custom_config_files"
      mkdir /usr/share/elasticsearch/config/security/custom
      for file in $custom_config_files ; do
        if [[ $file == *.yml ]]; then
          echo -e "\n[$(date)] Copying $file in /usr/share/elasticsearch/plugins/opendistro_security/securityconfig/"
          cp -f /usr/share/elasticsearch/init-security-config/$file /usr/share/elasticsearch/plugins/opendistro_security/securityconfig/
          chmod 0655 /usr/share/elasticsearch/plugins/opendistro_security/securityconfig/$file
        else
          echo -e "\n[$(date)] Copying $file in /usr/share/elasticsearch/config/security/custom/"
          cp /usr/share/elasticsearch/init-security-config/$file /usr/share/elasticsearch/config/security/custom/
          chmod 0600 /usr/share/elasticsearch/config/security/custom/$file
        fi
      done
      chmod 0700 /usr/share/elasticsearch/config/security/custom
    fi

    if [[ $(egrep -c "^(.*#.*|    )kibana:" /usr/share/elasticsearch/plugins/opendistro_security/securityconfig/config.yml) = 1 ]]; then
      echo -e "\n[$(date)] Modifying existing multitenancy settings..."
      sed -i -e "s/^.*kibana:/    kibana:/" \
               -e "s/^.*multitenancy_enabled:.*$/      multitenancy_enabled: ${KIBANA_MULTITENANCY}/" \
               -e "s/^.*server_username: \(.*\)$/      server_username: ${ELASTICSEARCH_USERNAME}/" \
               -e "s/^.*index: \(.*\)$/      index: \1/" \
               -e "s/^.*do_not_fail_on_forbidden: \(.*\)$/      do_not_fail_on_forbidden: \1/" /usr/share/elasticsearch/plugins/opendistro_security/securityconfig/config.yml
    elif [[ $(egrep -c "^    kibana:"/usr/share/elasticsearch/plugins/opendistro_security/securityconfig/config.yml) = 0 ]]; then
      echo -e "\n[$(date)] Generating default multitenancy settings..."
      sed -i "/dynamic:/a\    # Auto-generated default multitenant configuration\n    kibana:\n      multitenancy_enabled: ${KIBANA_MULTITENANCY}\n      server_username: ${ELASTICSEARCH_USERNAME}\n      index: .kibana\n      do_not_fail_on_forbidden: false" /usr/share/elasticsearch/plugins/opendistro_security/securityconfig/config.yml
    fi
    
    echo -e "\n[$(date)] Preparing execution of securityadmin.sh..."
    
    chmod +x /usr/share/elasticsearch/plugins/opendistro_security/tools/securityadmin.sh
    cmd="/usr/share/elasticsearch/plugins/opendistro_security/tools/securityadmin.sh -cd /usr/share/elasticsearch/plugins/opendistro_security/securityconfig -h release-name-ibm-dba-ek-master -cn release-name-ibm-dba-ek-elasticsearch -accept-red-cluster "
    default_args="-nhnv -cacert /usr/share/elasticsearch/config/security/root-ca.pem -cert /usr/share/elasticsearch/config/security/kirk.pem -key /usr/share/elasticsearch/config/security/kirk-key.pem"
    cmd+="$default_args"

    echo -e "\n[$(date)] Executing securityadmin.sh..."
    eval $cmd
    
    echo -e "\n[$(date)] Security config has been initialized..."
---
# Source: ibm-business-automation-insights-dev/templates/bai-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-bai-env
  labels:
      app: ibm-business-automation-insights-dev
      chart: ibm-business-automation-insights-dev
      release: release-name
      heritage: Helm
data:
  bai-features: "kafka-egress"  
  
  elasticsearch-url: https://release-name-ibm-dba-ek-client:9200
  elasticsearch-username: "admin"
  storage-batch-size: "268435456"
  storage-inactive-bucket-check-interval-ms: "300000"
  storage-inactive-bucket-threshold-ms: "900000"

  storage-bucket-url: ""
  flink-heap-memory: "1024"
  flink-taskmanager-cpu-cores: "1"

  flink-job-checkpointing-interval: "5000"
  flink-job-elasticsearch-max-actions: "10"

  flink-security-krb5-enable-kafka: "false"
  flink-security-krb5-enable-hdfs: "false"

  flink-security-krb5-realm: ""
  flink-security-krb5-kdc: ""
  flink-security-krb5-principal: ""
  admin-username: admin
  kafka-username: ""
  kafka-bootstrap-servers: "kafka.bootstrapserver1.hostname:9093,kafka.bootstrapserver2.hostname:9093,kafka.bootstrapserver3.hostname:9093"
  kafka-security-protocol: SASL_SSL
  kafka-sasl-kerberos-service-name: ""
  ingress-topic: release-name-ibm-bai-ingress
  egress-topic: release-name-ibm-bai-egress
  service-topic: release-name-ibm-bai-service
  bpmn-end-aggregation-delay: "10000"
  es-config-version: 1.3.3
---
# Source: ibm-business-automation-insights-dev/templates/bai-flink-log4j.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-bai-flink-log4j
  labels:
      app: ibm-business-automation-insights-dev
      chart: ibm-business-automation-insights-dev
      release: release-name
      heritage: Helm
data:   
  
  log4j-console.properties: |-
    # -------------------------------------------------
    # DO NOT MOVE/REMOVE or UPDATE these properties:
    status=info
    name=FlinkConsolePropertiesConfig
    # -------------------------------------------------

    # Valid values for level attributes of internal Log4j2 events are:
    # "all", "trace", "debug", "info", "warn", "error", "fatal" and "off"
    # This affects logging for both user code and Flink
    
    # The appender definition
    appenders=console
    
    appender.console.type=Console
    appender.console.name=STDOUT
    appender.console.layout.type=JSONLayout
    appender.console.layout.compact=true
    appender.console.layout.eventEol=true
    appender.console.layout.locationInfo=false
    appender.console.layout.timestamp.type=KeyValuePair
    appender.console.layout.timestamp.key=@timestamp
    appender.console.layout.timestamp.value=$${date:yyyy-MM-dd'T'HH:mm:ss.SSSZ}
    
    # The loggers definitions
    loggers=akka, kafka, hadoop, zookeeper, flink, flink_akka_netty, flink_runtime_checkpoint, flink_runtime_state, flink_runtime_state_heap, flink_streaming_state, flink_streaming_sink, flink_sink_filesystem_buckets
    
    logger.akka.name=akka
    logger.akka.level=info
    logger.akka.appenderRefs=console
    
    logger.kafka.name=org.apache.kafka
    logger.kafka.level=info
    logger.kafka.appenderRefs=console
    
    logger.hadoop.name=org.apache.hadoop
    logger.hadoop.level=info
    logger.hadoop.appenderRefs=console
    
    logger.zookeeper.name=org.apache.zookeeper
    logger.zookeeper.level=info
    logger.zookeeper.appenderRefs=console
    
    # Uncomment this if you want to _only_ change Flink's logging
    logger.flink.name=org.apache.flink
    logger.flink.level=info
    logger.flink.appenderRefs=console
    
    # Suppress the irrelevant (wrong) warnings from the Netty channel handler
    logger.flink_akka_netty.name=org.apache.flink.shaded.akka.org.jboss.netty.channel.DefaultChannelPipeline
    logger.flink_akka_netty.level=error
    logger.flink_akka_netty.appenderRefs=console
    
    # Only show logs related to checkpointing at WARN level
    logger.flink_runtime_checkpoint.name=org.apache.flink.runtime.checkpoint.CheckpointCoordinator
    logger.flink_runtime_checkpoint.level=warn
    logger.flink_runtime_checkpoint.appenderRefs=console
    
    logger.flink_runtime_state.name=org.apache.flink.runtime.state.DefaultOperatorStateBackend
    logger.flink_runtime_state.level=warn
    logger.flink_runtime_state.appenderRefs=console
    
    logger.flink_runtime_state_heap.name=org.apache.flink.runtime.state.heap.HeapKeyedStateBackend
    logger.flink_runtime_state_heap.level=warn
    logger.flink_runtime_state_heap.appenderRefs=console
    
    logger.flink_streaming_state.name=org.apache.flink.contrib.streaming.state.RocksDBKeyedStateBackend
    logger.flink_streaming_state.level=warn
    logger.flink_streaming_state.appenderRefs=console
    
    logger.flink_streaming_sink.name=org.apache.flink.streaming.api.functions.sink.TwoPhaseCommitSinkFunction
    logger.flink_streaming_sink.level=warn
    logger.flink_streaming_sink.appenderRefs=console
    
    logger.flink_sink_filesystem_buckets.name=org.apache.flink.streaming.api.functions.sink.filesystem.Buckets
    logger.flink_sink_filesystem_buckets.level=warn
    logger.flink_sink_filesystem_buckets.appenderRefs=console
    
    # Generic logging level for packages not covered with loggers
    rootLogger.level=info
    rootLogger.appenderRefs=stdout
    rootLogger.appenderRef.stdout.ref=STDOUT
    
    # end of log4j-console.properties
    
  log4j-cli.properties: |-
    # -------------------------------------------------
    # DO NOT MOVE/REMOVE or UPDATE these properties:
    status=info
    name=FlinkCliPropertiesConfig
    # -------------------------------------------------

    # Valid values for level attributes of internal Log4j2 events are:
    # "all", "trace", "debug", "info", "warn", "error", "fatal" and "off"
    # This affects logging for both user code and Flink
    
    # The appender definition
    appenders=console
    
    appender.console.type=Console
    appender.console.name=STDOUT
    appender.console.layout.type=JSONLayout
    appender.console.layout.compact=true
    appender.console.layout.eventEol=true
    appender.console.layout.locationInfo=false
    appender.console.layout.timestamp.type=KeyValuePair
    appender.console.layout.timestamp.key=@timestamp
    appender.console.layout.timestamp.value=$${date:yyyy-MM-dd'T'HH:mm:ss.SSSZ}
    
    # The loggers definitions
    loggers=flink_akka_netty, flink_client_cli, flink_configuration, flink_zookeeper, hadoop_util
    
    # Suppress the irrelevant (wrong) warnings from the netty channel handler
    logger.flink_akka_netty.name=org.apache.flink.shaded.akka.org.jboss.netty.channel.DefaultChannelPipeline
    logger.flink_akka_netty.level=error
    logger.flink_akka_netty.appenderRefs=console
    
    logger.flink_client_cli.name=org.apache.flink.client.cli.CliFrontend
    logger.flink_client_cli.level=warn
    logger.flink_client_cli.appenderRefs=console
    
    logger.flink_configuration.name=org.apache.flink.configuration.GlobalConfiguration
    logger.flink_configuration.level=warn
    logger.flink_configuration.appenderRefs=console
    
    logger.flink_zookeeper.name=org.apache.flink.shaded.zookeeper.org.apache.zookeeper.ZooKeeper
    logger.flink_zookeeper.level=warn
    logger.flink_zookeeper.appenderRefs=console
    
    # Suppress the warning that hadoop native libraries are not loaded (irrelevant for the client)
    logger.hadoop_util.name=org.apache.hadoop.util.NativeCodeLoader
    logger.hadoop_util.level=off
    logger.hadoop_util.appenderRefs=console
    
    # Generic logging level for packages not covered with loggers
    rootLogger.level=info
    rootLogger.appenderRefs=stdout
    rootLogger.appenderRef.stdout.ref=STDOUT
    
    # end of log4j-cli.properties
---
# Source: ibm-business-automation-insights-dev/templates/bai-persistentVolume.yaml
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: release-name-bai-pvc
  labels:
    app: ibm-business-automation-insights-dev
    chart: ibm-business-automation-insights-dev
    release: release-name
    heritage: Helm
spec:
  storageClassName: ""
  accessModes:
    - ReadWriteMany
  resources:
    requests:
      storage: "20Gi"
---
# Source: ibm-business-automation-insights-dev/charts/ibm-dba-ek/templates/es-discovery-service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: release-name-ibm-dba-ek-elasticsearch
    component: release-name-ibm-dba-ek-master
    release: release-name
    role: master
    chart: ibm-dba-ek
    heritage: Helm
  name: release-name-ibm-dba-ek-master
spec:
  type: ClusterIP
  selector:
    app: release-name-ibm-dba-ek-elasticsearch
    component: release-name-ibm-dba-ek-master
    role: master
  ports:
  - name: transport
    port: 9300
    targetPort: transport
    protocol: TCP
---
# Source: ibm-business-automation-insights-dev/charts/ibm-dba-ek/templates/es-service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: release-name-ibm-dba-ek-elasticsearch
    chart: ibm-dba-ek
    component: release-name-ibm-dba-ek-client
    heritage: Helm
    release: release-name
  name: release-name-ibm-dba-ek-client
spec:
  
  type: NodePort
  
  selector:
    app: release-name-ibm-dba-ek-elasticsearch
    component: release-name-ibm-dba-ek-client
    role: client
  ports:
  - name: elasticsearch-rest-https
    port: 9200
    targetPort: es-rest
    protocol: TCP
---
# Source: ibm-business-automation-insights-dev/charts/ibm-dba-ek/templates/kibana-service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app: release-name-ibm-dba-ek-elasticsearch
    chart: ibm-dba-ek
    component: release-name-ibm-dba-ek-kibana
    heritage: Helm
    release: release-name
  name: release-name-ibm-dba-ek-kibana
spec:
  
  type: NodePort
  
  selector:
    app: release-name-ibm-dba-ek-elasticsearch
    component: release-name-ibm-dba-ek-kibana
    role: kibana
  ports:
  - name: kibana-ui-https
    port: 5601
    protocol: TCP
    targetPort: kibana-ui
---
# Source: ibm-business-automation-insights-dev/templates/bai-admin.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-bai-admin-service
  labels:
    app: ibm-business-automation-insights-dev
    chart: ibm-business-automation-insights-dev
    release: release-name
    heritage: Helm
    component: bai-admin
spec:
  selector:
    app: ibm-business-automation-insights-dev
    chart: ibm-business-automation-insights-dev
    release: release-name
    heritage: Helm
    component: bai-admin
  ports:
    - name: admin-rest-https
      protocol: TCP
      port: 6892
      targetPort: admin-rest
  
  type: NodePort
---
# Source: ibm-business-automation-insights-dev/templates/bai-flink-zookeeper.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-bai-flink-zk-svc
  labels:
    app: ibm-business-automation-insights-dev
    chart: ibm-business-automation-insights-dev
    release: release-name
    heritage: Helm
spec:
  ports:
  - port: 2888
    name: server
  - port: 3888
    name: leader-election
  clusterIP: None
  selector:
    app: ibm-business-automation-insights-dev
    chart: ibm-business-automation-insights-dev
    release: release-name
    heritage: Helm
    component: bai-flink-zk
---
# Source: ibm-business-automation-insights-dev/templates/bai-flink-zookeeper.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-bai-flink-zk-cs
  labels:
    app: ibm-business-automation-insights-dev
    chart: ibm-business-automation-insights-dev
    release: release-name
    heritage: Helm
spec:
  ports:
  - port: 2181
    name: client
  selector:
    app: ibm-business-automation-insights-dev
    chart: ibm-business-automation-insights-dev
    release: release-name
    heritage: Helm
    component: bai-flink-zk
---
# Source: ibm-business-automation-insights-dev/templates/bai-flink.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-bai-flink-taskmanager-svc
  labels:
    app: ibm-business-automation-insights-dev
    chart: ibm-business-automation-insights-dev
    release: release-name
    heritage: Helm
spec:
  ports:
  - port: 6121
    name: data
  - port: 6122
    name: rpc
  - port: 6125
    name: query
  clusterIP: None
  selector:
    app: ibm-business-automation-insights-dev
    chart: ibm-business-automation-insights-dev
    release: release-name
    heritage: Helm
    component: bai-taskmanager
---
# Source: ibm-business-automation-insights-dev/templates/bai-flink.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-bai-flink-jobmanager
  labels:
    app: ibm-business-automation-insights-dev
    chart: ibm-business-automation-insights-dev
    release: release-name
    heritage: Helm
spec:
  ports:
  - name: rpc
    port: 6123
  - name: blob
    port: 6124
  - name: query
    port: 6125
  - name: ui-rest
    port: 8081
  selector:
    app: ibm-business-automation-insights-dev
    chart: ibm-business-automation-insights-dev
    release: release-name
    heritage: Helm
    component: bai-jobmanager
---
# Source: ibm-business-automation-insights-dev/charts/ibm-dba-ek/templates/es-client-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: release-name-ibm-dba-ek-elasticsearch
    component: release-name-ibm-dba-ek-client
    release: release-name
    role: client
    chart: ibm-dba-ek
    heritage: Helm
  name: release-name-ibm-dba-ek-client
spec:
  replicas: 1
  selector:
    matchLabels:
      app: release-name-ibm-dba-ek-elasticsearch
      component: release-name-ibm-dba-ek-client
      role: client
      heritage: Helm
      release: release-name
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 1
  minReadySeconds: 5
  progressDeadlineSeconds: 900
  template:
    metadata:
      annotations:
        checksum/config: 6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b

        productName: "IBM Business Automation Insights"
        productID: "BAIID"
        productVersion: "19.0.2"
      labels:
        app: release-name-ibm-dba-ek-elasticsearch
        component: release-name-ibm-dba-ek-client
        role: client
        chart: ibm-dba-ek
        heritage: Helm
        release: release-name
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: beta.kubernetes.io/arch
                operator: In
                values:
                - amd64
      
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 1
            podAffinityTerm:
              topologyKey: kubernetes.io/hostname
              labelSelector:
                matchLabels:
                  app: release-name-ibm-dba-ek-elasticsearch
                  component: release-name-ibm-dba-ek-client
                  role: client
                  heritage: Helm
                  release: release-name
      serviceAccountName: release-name-bai-psp-sa
      initContainers:
      - name: sysctl
        image: ibmcom/bai-init-dev:19.0.2
        imagePullPolicy: 
        command: ["/bin/sh", "-c", "sysctl -w vm.max_map_count=262144 && sed -i '/^vm.max_map_count /d' /etc/sysctl.conf && echo 'vm.max_map_count = 262144' >> /etc/sysctl.conf && sysctl -w vm.swappiness=1 && sed -i '/^vm.swappiness /d' /etc/sysctl.conf && echo 'vm.swappiness=1' >> /etc/sysctl.conf"]
        securityContext:
          privileged: true
      
      containers:
      - name: es-client
        command: ["/bin/bash", "/scripts/entrypoint.sh"]
        image: ibmcom/bai-elasticsearch-dev:19.0.2
        imagePullPolicy: 
        securityContext:
          runAsNonRoot: true
          runAsUser: 1000
        readinessProbe:
          httpGet:
            scheme: HTTPS
            path: /_cluster/health
            port: 9200
            httpHeaders:
              - name: Authorization
                value: Basic YWRtaW46cGFzc3cwcmQ=
          initialDelaySeconds: 90
        livenessProbe:
          tcpSocket:
            port: 9300
          initialDelaySeconds: 90
        resources:
          limits:
            memory: "2Gi"
            cpu: "1000m"
          requests:
            memory: "1Gi"
            cpu: "100m"
        env:
        - name: ELASTICSEARCH_USERNAME
          value: admin
        - name: ELASTICSEARCH_PASSWORD
          value: passw0rd
        - name: ES_JAVA_OPTS
          value: "-Xms1024m -Xmx1024m"
        - name: CFG_BASEDIR
          value: /usr/share/elasticsearch
        ports:
        - containerPort: 9200
          name: es-rest
          protocol: TCP
        - containerPort: 9300
          name: transport
          protocol: TCP
        volumeMounts:
        - name: entrypoint
          mountPath: /scripts
        - name: config
          mountPath: /usr/share/elasticsearch/ibm-dba-ek-config/elasticsearch.yml
          subPath: elasticsearch.yml
      volumes:
        - name: entrypoint
          configMap:
            name: release-name-ibm-dba-ek-elasticsearch-entrypoint
            defaultMode: 365
            items:
              - key: entrypoint.sh
                path: entrypoint.sh
        - name: config
          configMap:
            name: release-name-ibm-dba-ek-elasticsearch-config
            items:
              - key: client.yml
                path: elasticsearch.yml
              - key: log4j2.properties
                path: log4j2.properties
---
# Source: ibm-business-automation-insights-dev/charts/ibm-dba-ek/templates/kibana-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: release-name-ibm-dba-ek-elasticsearch
    component: release-name-ibm-dba-ek-kibana
    release: release-name
    role: kibana
    chart: ibm-dba-ek
    heritage: Helm
  name: release-name-ibm-dba-ek-kibana
spec:
  selector:
    matchLabels:
      app: release-name-ibm-dba-ek-elasticsearch
      component: release-name-ibm-dba-ek-kibana
      release: release-name
      role: kibana
      heritage: Helm
  replicas: 1
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 1
  minReadySeconds: 5
  progressDeadlineSeconds: 900
  template:
    metadata:
      annotations:
        checksum/config: ad11d289ef57f36d20328393485989a59fc9610adec47613b3701a2334f998cd

        productName: "IBM Business Automation Insights"
        productID: "BAIID"
        productVersion: "19.0.2"
      labels:
        app: release-name-ibm-dba-ek-elasticsearch
        component: release-name-ibm-dba-ek-kibana
        role: kibana
        release: release-name
        chart: ibm-dba-ek
        heritage: Helm
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: beta.kubernetes.io/arch
                operator: In
                values:
                - amd64
      
      # Required for multi-platform config
      securityContext:
        fsGroup: 1000
      serviceAccountName: default
      initContainers:
        - name: wait-es-data-nodes
          image: ibmcom/bai-init-dev:19.0.2
          imagePullPolicy: 
          securityContext:
            runAsNonRoot: true
            runAsUser: 1000
          env:
          - name: ELASTICSEARCH_URL
            value: https://release-name-ibm-dba-ek-client:9200
          - name: KIBANA_USERNAME
            value: admin
          - name: KIBANA_PASSWORD
            value: passw0rd
          command: ['sh', '-c','
            [[ "${ELASTICSEARCH_URL: -1}" == "/" ]] && ELASTICSEARCH_URL=${ELASTICSEARCH_URL:$i:-1};
            healthUrl=$ELASTICSEARCH_URL/_cluster/health;
            expectedStr=\"number_of_data_nodes\":1

            while :; do
              echo "[`date`] Waiting for Elasticsearch data nodes availability...";
              curl -s -k -X GET -m 30 $healthUrl -u $KIBANA_USERNAME:$KIBANA_PASSWORD | grep $expectedStr;
              if [[ "$?" == "0" ]]; then
                printf "\n[`date`] Elasticsearch cluster data nodes have all joined the cluster.\n";
                break;
              fi;
              sleep 5;
            done;
          ']
      containers:
      - name: kibana
        image: ibmcom/bai-kibana-dev:19.0.2
        imagePullPolicy: 
        securityContext:
          runAsNonRoot: true
          runAsUser: 1000
        readinessProbe:
          httpGet:
            scheme: HTTPS
            path: /app/kibana
            port: 5601
            httpHeaders:
              - name: Authorization
                value: Basic YWRtaW46cGFzc3cwcmQ=
          initialDelaySeconds: 120
        livenessProbe:
          httpGet:
            scheme: HTTPS
            path: /app/kibana
            port: 5601
            httpHeaders:
              - name: Authorization
                value: Basic YWRtaW46cGFzc3cwcmQ=
          initialDelaySeconds: 120
        ports:
        - containerPort: 5601
          name: kibana-ui
          protocol: TCP
        volumeMounts:
        - name: security-config
          mountPath: /usr/share/kibana/config
        - name: tls-config
          mountPath: /usr/share/kibana/config/tls
        resources:
          limits:
            memory: "2Gi"
            cpu: "1000m"
          requests:
            memory: "1Gi"
            cpu: "100m"
        env:
        - name: CFG_BASEDIR
          value: /usr/share/kibana
        - name: RELEASE_NAME 
          value: release-name
        - name: KIBANA_MULTITENANCY
          value: "false"
        - name: KIBANA_USERNAME
          value: admin
        - name: KIBANA_PASSWORD
          value: passw0rd
      volumes:
        - name: security-config
          secret:
            secretName: release-name-ibm-dba-ek-kibana-security-config
        - name: tls-config
          secret:
            secretName: release-name-ibm-dba-ek-elasticsearch-tls
      restartPolicy: Always
---
# Source: ibm-business-automation-insights-dev/templates/bai-admin.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-bai-admin
  labels:
    app: ibm-business-automation-insights-dev
    chart: ibm-business-automation-insights-dev
    release: release-name
    heritage: Helm
spec:
  replicas: 1
  strategy:
    type: Recreate
    rollingUpdate: null
  selector:
    matchLabels:
      app: ibm-business-automation-insights-dev
      chart: ibm-business-automation-insights-dev
      release: release-name
      heritage: Helm
      component: bai-admin
  template:
    metadata:
      annotations:
        checksum/config: e692e81988f822b03269e902f0053d658b8a479e2a0c824be46d962388451e65

        productName: "IBM Business Automation Insights"
        productID: "BAIID"
        productVersion: "19.0.2"
      labels:
        app: ibm-business-automation-insights-dev
        chart: ibm-business-automation-insights-dev
        release: release-name
        heritage: Helm
        component: bai-admin
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: beta.kubernetes.io/arch
                operator: In
                values:
                - amd64
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchLabels:
                  app: ibm-business-automation-insights-dev
                  chart: ibm-business-automation-insights-dev
                  release: release-name
                  heritage: Helm
                  component: bai-admin
              topologyKey: kubernetes.io/hostname
      serviceAccountName: default
      containers:
      - name: bai-admin
        image: ibmcom/bai-admin-dev:19.0.2
        securityContext:
          runAsNonRoot: true
          runAsUser: 20181
        ports:
        - name: admin-rest
          containerPort: 6892
          protocol: TCP
        readinessProbe:
          httpGet:
            scheme: HTTPS
            path: /api/health
            port: admin-rest
          initialDelaySeconds: 10
          periodSeconds: 10
          timeoutSeconds: 5
        livenessProbe:
          httpGet:
            scheme: HTTPS
            path: /api/health
            port: admin-rest
          initialDelaySeconds: 25
          periodSeconds: 10
          timeoutSeconds: 5
        resources:
          
          requests:
            
            memory: "50Mi"
            cpu: "3m"
            
          limits:
            
            memory: "120Mi"
            
          
        env:
        - name: TAIGA_ADMIN_PORT
          value: "6892"
        - name: TAIGA_ADMIN_USER
          valueFrom:
            configMapKeyRef:
              name: release-name-bai-env
              key: admin-username
        - name: TAIGA_ADMIN_PASSWORD
          valueFrom:
            secretKeyRef:
              name: release-name-bai-secrets
              key: admin-password
        - name: KAFKA_USERNAME
          valueFrom:
            configMapKeyRef:
              name: release-name-bai-env
              key: kafka-username
        - name: KAFKA_PASSWORD
          valueFrom:
            secretKeyRef:
              name: release-name-bai-secrets
              key: kafka-password
        - name: KAFKA_BOOTSTRAP_SERVERS
          valueFrom:
            configMapKeyRef:
              name: release-name-bai-env
              key: kafka-bootstrap-servers
        - name: KAFKA_SECURITY_PROTOCOL
          valueFrom:
            configMapKeyRef:
              name: release-name-bai-env
              key: kafka-security-protocol
        - name: KAFKA_SASL_KERBEROS_SERVICE_NAME
          valueFrom:
            configMapKeyRef:
              name: release-name-bai-env
              key: kafka-sasl-kerberos-service-name
        - name: KAFKA_KRB5_ENABLED
          valueFrom:
            configMapKeyRef:
              name: release-name-bai-env
              key: flink-security-krb5-enable-kafka
        - name: KAFKA_KRB5_REALM
          valueFrom:
            configMapKeyRef:
              name: release-name-bai-env
              key: flink-security-krb5-realm
        - name: KAFKA_KRB5_KDC
          valueFrom:
            configMapKeyRef:
              name: release-name-bai-env
              key: flink-security-krb5-kdc
        - name: KAFKA_KRB5_PRINCIPAL
          valueFrom:
            configMapKeyRef:
              name: release-name-bai-env
              key: flink-security-krb5-principal
        - name: KAFKA_KRB5_KEYTAB
          value: "/etc/krb5/kafka.keytab"
        - name: KAFKA_SERVICE_TOPIC
          valueFrom:
            configMapKeyRef:
              name: release-name-bai-env
              key: service-topic
        volumeMounts:
        - name: kerberos-keytabs
          mountPath: /etc/krb5
          readOnly: true
        - name: admin-ssl
          mountPath: /etc/admin-ssl
          readOnly: true
        - name: admin-server-ssl-key
          mountPath: /usr/src/taiga-admin/src/server/resources/local-server.key
          subPath: local-server.key
        - name: admin-server-ssl-crt
          mountPath: /usr/src/taiga-admin/src/server/resources/local-server.crt
          subPath: local-server.crt
      volumes:
      - name: kerberos-keytabs
        secret:
          secretName: release-name-bai-secrets
          optional: true
          items:
          - key: flink-security-krb5-keytab
            path: kafka.keytab
      - name: admin-ssl
        secret:
          secretName: release-name-bai-secrets
          optional: true
          items:
          - key: kafka-ca-cert
            path: kafka-ca.pem
      - name: admin-server-ssl-key
        secret:
          secretName: release-name-bai-secrets
          items:
            - key: admin-key
              path: local-server.key
      - name: admin-server-ssl-crt
        secret:
          secretName: release-name-bai-secrets
          items:
            - key: admin-cert
              path: local-server.crt
---
# Source: ibm-business-automation-insights-dev/templates/bai-flink.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-bai-flink-jobmanager
  labels:
      app: ibm-business-automation-insights-dev
      chart: ibm-business-automation-insights-dev
      release: release-name
      heritage: Helm
spec:
  replicas: 1
  strategy:
    type: Recreate
    rollingUpdate: null
  selector:
    matchLabels:
        app: ibm-business-automation-insights-dev
        chart: ibm-business-automation-insights-dev
        release: release-name
        heritage: Helm
        component: bai-jobmanager
  template:
    metadata:
      annotations:
        checksum/config: 73a99585e8ef08066f51bbcb4d4d51c92ba48083e381c99d9a6946aea95be969

        productName: "IBM Business Automation Insights"
        productID: "BAIID"
        productVersion: "19.0.2"
      labels:
        app: ibm-business-automation-insights-dev
        chart: ibm-business-automation-insights-dev
        release: release-name
        heritage: Helm
        component: bai-jobmanager
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: beta.kubernetes.io/arch
                operator: In
                values:
                - amd64
      
      serviceAccountName: default
      containers:
      - name: jobmanager
        image: ibmcom/bai-flink-dev:19.0.2
        securityContext:
          runAsNonRoot: true
          runAsUser: 9999
        args:
        - jobmanager
        ports:
        - containerPort: 6123
          name: rpc
        - containerPort: 6124
          name: blob
        - containerPort: 6125
          name: query
        - containerPort: 8081
          name: ui-rest
        readinessProbe:
          exec:
            command:
              - "check-jobmanager.sh"
              - release-name
              - "1"
          initialDelaySeconds: 10
          periodSeconds: 10
        livenessProbe:
          httpGet:
            scheme: HTTPS
            path: /taskmanagers
            port: ui-rest
          initialDelaySeconds: 60
          periodSeconds: 10
          failureThreshold: 3
        resources:
          requests:
            memory: 256Mi
            cpu: 100m
          limits:
            memory: 1280Mi
        env:
        - name: JOB_MANAGER_RPC_ADDRESS
          value: release-name-bai-flink-jobmanager
        - name: ZOOKEEPER_ADDRESS
          value: release-name-bai-flink-zk-cs
        - name: INGRESS_TOPIC
          valueFrom:
            configMapKeyRef:
              name: release-name-bai-env
              key: ingress-topic
        - name: EGRESS_TOPIC
          valueFrom:
            configMapKeyRef:
              name: release-name-bai-env
              key: egress-topic
        - name: SERVICE_TOPIC
          valueFrom:
            configMapKeyRef:
              name: release-name-bai-env
              key: service-topic
        - name: SSL_PASSWORD
          valueFrom:
            secretKeyRef:
              name: release-name-bai-secrets
              key: flink-ssl-password
        - name: HEAP_MEMORY
          valueFrom:
            configMapKeyRef:
              name: release-name-bai-env
              key: flink-heap-memory
        - name: FLINK_SECURITY_KRB5_ENABLE_KAFKA
          valueFrom:
            configMapKeyRef:
              name: release-name-bai-env
              key: flink-security-krb5-enable-kafka
        - name: FLINK_SECURITY_KRB5_ENABLE_HDFS
          valueFrom:
            configMapKeyRef:
              name: release-name-bai-env
              key: flink-security-krb5-enable-hdfs
        - name: FLINK_SECURITY_KRB5_REALM
          valueFrom:
            configMapKeyRef:
              name: release-name-bai-env
              key: flink-security-krb5-realm
        - name: FLINK_SECURITY_KRB5_KDC
          valueFrom:
            configMapKeyRef:
              name: release-name-bai-env
              key: flink-security-krb5-kdc
        - name: FLINK_SECURITY_KRB5_PRINCIPAL
          valueFrom:
            configMapKeyRef:
              name: release-name-bai-env
              key: flink-security-krb5-principal
        - name: TAIGA_FEATURES
          valueFrom:
            configMapKeyRef:
              name: release-name-bai-env
              key: bai-features
        volumeMounts:
        - mountPath: /opt/flink/conf/log4j-console.properties
          name: flink-log4j
          subPath: log4j-console.properties
        - mountPath: /opt/flink/conf/log4j-cli.properties
          name: flink-log4j
          subPath: log4j-cli.properties
        - name: flink-ssl
          mountPath: /etc/flink-ssl
          readOnly: true
        - name: nfs-storage
          mountPath: /mnt/pv
        - name: kerberos-keytabs
          mountPath: /etc/krb5
          readOnly: true
      volumes:
      - name: flink-log4j
        configMap:
          name: release-name-bai-flink-log4j
          items:
            - key: log4j-console.properties
              path: log4j-console.properties
            - key: log4j-cli.properties
              path: log4j-cli.properties
      - name: kerberos-keytabs
        secret:
          secretName: release-name-bai-secrets
          optional: true
          items:
          - key: flink-security-krb5-keytab
            path: flink.keytab
      - name: flink-ssl
        secret:
          secretName: release-name-bai-secrets
          items:
          - key: flink-ssl-keystore
            path: pods.keystore
          - key: flink-ssl-truststore
            path: ca.truststore
          - key: flink-ssl-internal-keystore
            path: internal.keystore
          - key: kafka-server-cert
            path: kafka-server-cert
          - key: elasticsearch-server-cert
            path: elasticsearch-server-cert
      - name: nfs-storage
        persistentVolumeClaim:
            claimName: release-name-bai-pvc
---
# Source: ibm-business-automation-insights-dev/charts/ibm-dba-ek/templates/es-data-statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  labels:
    app: release-name-ibm-dba-ek-elasticsearch
    component: release-name-ibm-dba-ek-data
    release: release-name
    role: data
    chart: ibm-dba-ek
    heritage: Helm
  name: release-name-ibm-dba-ek-data
spec:
  selector:
    matchLabels:
      app: release-name-ibm-dba-ek-elasticsearch
      component: release-name-ibm-dba-ek-data
      release: release-name
      role: data
      heritage: Helm
  updateStrategy:
    type: RollingUpdate
  revisionHistoryLimit: 3
  podManagementPolicy: Parallel
  serviceName: release-name-ibm-dba-ek-data
  replicas: 1
  template:
    metadata:
      annotations:
        checksum/config: bbe879468b78d97753935ab6b844d8eacd9444cc90f1119b50a9bf843c8e510a

        productName: "IBM Business Automation Insights"
        productID: "BAIID"
        productVersion: "19.0.2"
      labels:
        app: release-name-ibm-dba-ek-elasticsearch
        component: release-name-ibm-dba-ek-data
        role: data
        release: release-name
        chart: ibm-dba-ek
        heritage: Helm
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: beta.kubernetes.io/arch
                operator: In
                values:
                - amd64
      
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            - topologyKey: "kubernetes.io/hostname"
              labelSelector:
                matchLabels:
                  app: release-name-ibm-dba-ek-elasticsearch
                  component: release-name-ibm-dba-ek-data
                  role: data
                  release: release-name
                  heritage: Helm
      securityContext:
        fsGroup: 1000
      serviceAccountName: release-name-bai-psp-sa
      initContainers:
      - name: sysctl
        image: ibmcom/bai-init-dev:19.0.2
        imagePullPolicy: 
        command: ["/bin/sh", "-c", "sysctl -w vm.max_map_count=262144 && sed -i '/^vm.max_map_count /d' /etc/sysctl.conf && echo 'vm.max_map_count = 262144' >> /etc/sysctl.conf && sysctl -w vm.swappiness=1 && sed -i '/^vm.swappiness /d' /etc/sysctl.conf && echo 'vm.swappiness=1' >> /etc/sysctl.conf"]
        securityContext:
          privileged: true
      - name: initcontainer
        image: ibmcom/bai-init-dev:19.0.2
        imagePullPolicy: 
        command: ["/bin/sh", "-c", "mkdir -p /usr/share/elasticsearch/data/nodes && chown -R 1000:1000 /usr/share/elasticsearch/data; chmod ug+x /usr/share/elasticsearch/data /usr/share/elasticsearch/data/nodes"]
        securityContext:
          privileged: true
        volumeMounts:
        - name: data
          mountPath: /usr/share/elasticsearch/data
      
      containers:
      - name: es-data
        command: ["/bin/bash", "/scripts/entrypoint.sh"]
        image: ibmcom/bai-elasticsearch-dev:19.0.2
        imagePullPolicy: 
        securityContext:
          runAsNonRoot: true
          runAsUser: 1000
        readinessProbe:
          tcpSocket:
            port: 9300
          initialDelaySeconds: 90
        livenessProbe:
          tcpSocket:
            port: 9300
          initialDelaySeconds: 90
        resources:
          limits:
            memory: "2Gi"
            cpu: "1000m"
          requests:
            memory: "1Gi"
            cpu: "100m"
        env:
        - name: ES_JAVA_OPTS
          value: "-Xms1024m -Xmx1024m"
        - name: CFG_BASEDIR
          value: /usr/share/elasticsearch
        ports:
        - containerPort: 9300
          name: transport
          protocol: TCP
        volumeMounts:
        - name: entrypoint
          mountPath: /scripts
        - name: data
          mountPath: /usr/share/elasticsearch/data
        - name: config
          mountPath: /usr/share/elasticsearch/ibm-dba-ek-config/elasticsearch.yml
          subPath: elasticsearch.yml
        - name: plugin-bundle
          mountPath: /usr/share/elasticsearch/plugin-bundles
      volumes:
        - name: entrypoint
          configMap:
            name: release-name-ibm-dba-ek-elasticsearch-entrypoint
            defaultMode: 365
            items:
              - key: entrypoint.sh
                path: entrypoint.sh
        - name: config
          configMap:
            name: release-name-ibm-dba-ek-elasticsearch-config
            items:
              - key: data.yml
                path: elasticsearch.yml
        - name: plugin-bundle
          emptyDir:
            medium: ""
  volumeClaimTemplates:
  - metadata:
      name: data
      labels:
        app: release-name-ibm-dba-ek-elasticsearch
        chart: ibm-dba-ek
        component: release-name-ibm-dba-ek-data
        heritage: Helm
        release: release-name
    spec:
      storageClassName: ""
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: "10Gi"
---
# Source: ibm-business-automation-insights-dev/charts/ibm-dba-ek/templates/es-master-statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  labels:
    app: release-name-ibm-dba-ek-elasticsearch
    component: release-name-ibm-dba-ek-master
    release: release-name
    role: master
    chart: ibm-dba-ek
    heritage: Helm
  name: release-name-ibm-dba-ek-master
spec:
  selector:
    matchLabels:
      app: release-name-ibm-dba-ek-elasticsearch
      component: release-name-ibm-dba-ek-master
      release: release-name
      role: master
      heritage: Helm
  serviceName: release-name-ibm-dba-ek-master
  replicas: 1
  updateStrategy:
    type: RollingUpdate
  revisionHistoryLimit: 3
  podManagementPolicy: Parallel
  template:
    metadata:
      annotations:
        checksum/config: bbe879468b78d97753935ab6b844d8eacd9444cc90f1119b50a9bf843c8e510a

        productName: "IBM Business Automation Insights"
        productID: "BAIID"
        productVersion: "19.0.2"
      labels:
        app: release-name-ibm-dba-ek-elasticsearch
        component: release-name-ibm-dba-ek-master
        role: master
        release: release-name
        chart: ibm-dba-ek
        heritage: Helm
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: beta.kubernetes.io/arch
                operator: In
                values:
                - amd64
      
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 1
            podAffinityTerm:
              topologyKey: kubernetes.io/hostname
              labelSelector:
                matchLabels:
                  app: "release-name-ibm-dba-ek-elasticsearch"
                  component: "release-name-ibm-dba-ek-master"
                  release: "release-name"
                  role: "master"
                  heritage: "Helm"
      securityContext:
        fsGroup: 1000
      serviceAccountName: release-name-bai-psp-sa
      initContainers:
      - name: sysctl
        image: ibmcom/bai-init-dev:19.0.2
        imagePullPolicy: 
        command: ["/bin/sh", "-c", "sysctl -w vm.max_map_count=262144 && sed -i '/^vm.max_map_count /d' /etc/sysctl.conf && echo 'vm.max_map_count = 262144' >> /etc/sysctl.conf && sysctl -w vm.swappiness=1 && sed -i '/^vm.swappiness /d' /etc/sysctl.conf && echo 'vm.swappiness=1' >> /etc/sysctl.conf"]
        securityContext:
          privileged: true
      - name: initcontainer
        image: ibmcom/bai-init-dev:19.0.2
        imagePullPolicy: 
        command: ["/bin/sh", "-c", "mkdir -p /usr/share/elasticsearch/data/nodes && chown -R 1000:1000 /usr/share/elasticsearch/data; chmod ug+x /usr/share/elasticsearch/data /usr/share/elasticsearch/data/nodes"]
        securityContext:
          privileged: true
        volumeMounts:
        - name: data
          mountPath: /usr/share/elasticsearch/data
      
      containers:
      - name: es-master
        command: ["/bin/bash", "/scripts/entrypoint.sh"]
        image: ibmcom/bai-elasticsearch-dev:19.0.2
        imagePullPolicy: 
        securityContext:
          runAsNonRoot: true
          runAsUser: 1000
        readinessProbe:
          tcpSocket:
            port: 9300
          initialDelaySeconds: 90
        livenessProbe:
          tcpSocket:
            port: 9300
          initialDelaySeconds: 90
        resources:
          limits:
            memory: "2Gi"
            cpu: "1000m"
          requests:
            memory: "1Gi"
            cpu: "100m"
        env:
        - name: ES_JAVA_OPTS
          value: "-Xms1024m -Xmx1024m"
        - name: CFG_BASEDIR
          value: /usr/share/elasticsearch
        ports:
        - containerPort: 9300
          name: transport
          protocol: TCP
        volumeMounts:
        - name: entrypoint
          mountPath: /scripts
        - name: data
          mountPath: /usr/share/elasticsearch/data
        - name: config
          mountPath: /usr/share/elasticsearch/ibm-dba-ek-config/elasticsearch.yml
          subPath: elasticsearch.yml
        - name: plugin-bundle
          mountPath: /usr/share/elasticsearch/plugin-bundles
      volumes:
        - name: entrypoint
          configMap:
            name: release-name-ibm-dba-ek-elasticsearch-entrypoint
            defaultMode: 365
            items:
              - key: entrypoint.sh
                path: entrypoint.sh
        - name: config
          configMap:
            name: release-name-ibm-dba-ek-elasticsearch-config
            items:
              - key: master.yml
                path: elasticsearch.yml
        - name: plugin-bundle
          emptyDir:
            medium: ""
  volumeClaimTemplates:
  - metadata:
      name: data
      labels:
        app: release-name-ibm-dba-ek-elasticsearch
        chart: ibm-dba-ek
        component: release-name-ibm-dba-ek-data
        heritage: Helm
        release: release-name
    spec:
      storageClassName: ""
      accessModes:
        - ReadWriteOnce
      resources:
        requests:
          storage: "10Gi"
---
# Source: ibm-business-automation-insights-dev/templates/bai-flink-zookeeper.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: release-name-bai-flink-zk
  labels:
    app: ibm-business-automation-insights-dev
    chart: ibm-business-automation-insights-dev
    release: release-name
    heritage: Helm
spec:
  selector:
    matchLabels:
      app: ibm-business-automation-insights-dev
      chart: ibm-business-automation-insights-dev
      release: release-name
      heritage: Helm
      component: bai-flink-zk
  serviceName: release-name-bai-flink-zk-svc
  replicas: 1
  podManagementPolicy: Parallel
  updateStrategy:
      type: RollingUpdate
  template:
    metadata:
      annotations:
        productName: "IBM Business Automation Insights"
        productID: "BAIID"
        productVersion: "19.0.2"
      labels:
        app: ibm-business-automation-insights-dev
        chart: ibm-business-automation-insights-dev
        release: release-name
        heritage: Helm
        component: bai-flink-zk
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: beta.kubernetes.io/arch
                operator: In
                values:
                - amd64
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            - labelSelector:
                matchLabels:
                  app: ibm-business-automation-insights-dev
                  chart: ibm-business-automation-insights-dev
                  release: release-name
                  heritage: Helm
                  component: bai-flink-zk
              topologyKey: "kubernetes.io/hostname"
      serviceAccountName: release-name-bai-psp-sa
      containers:
      - name: bai-flink-zk
        image: ibmcom/bai-flink-zookeeper-dev:19.0.2
        securityContext:
          runAsNonRoot: true
          runAsUser: 9999
        resources:
          
          limits:
            
            memory: "768Mi"
            cpu: "200m"
            
          requests:
            
            memory: "640Mi"
            cpu: "100m"
            
          

        ports:
        - containerPort: 2181
          name: client
        - containerPort: 2888
          name: server
        - containerPort: 3888
          name: leader-election
        env:
        - name : ZK_REPLICAS
          value: "1"
        - name : ZK_HEAP_SIZE
          value: "512M"
        - name : ZK_TICK_TIME
          value: "2000"
        - name : ZK_INIT_LIMIT
          value: "10"
        - name : ZK_SYNC_LIMIT
          value: "5"
        - name : ZK_MAX_CLIENT_CNXNS
          value: "60"
        - name: ZK_SNAP_RETAIN_COUNT
          value: "3"
        - name: ZK_PURGE_INTERVAL
          value: "12"
        - name: ZK_CLIENT_PORT
          value: "2181"
        - name: ZK_SERVER_PORT
          value: "2888"
        - name: ZK_ELECTION_PORT
          value: "3888"
        - name: ZK_DATA_DIR
          value: /mnt/pv/flink-zookeeper/zookeeper-data
        - name: ZK_DATA_LOG_DIR
          value: /mnt/pv/flink-zookeeper/zookeeper-data-log
        readinessProbe:
          exec:
            command:
            - "zkOk.sh"
          initialDelaySeconds: 10
          timeoutSeconds: 5
        livenessProbe:
          exec:
            command:
            - "zkOk.sh"
          initialDelaySeconds: 30
          periodSeconds: 20
          timeoutSeconds: 5
        volumeMounts:
        - name: nfs-storage
          mountPath: /mnt/pv
      volumes:
      - name: nfs-storage
        persistentVolumeClaim:
            claimName: release-name-bai-pvc
---
# Source: ibm-business-automation-insights-dev/templates/bai-flink.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: release-name-bai-flink-taskmanager
  labels:
      app: ibm-business-automation-insights-dev
      chart: ibm-business-automation-insights-dev
      release: release-name
      heritage: Helm
spec:
  selector:
    matchLabels:
      app: ibm-business-automation-insights-dev
      chart: ibm-business-automation-insights-dev
      release: release-name
      heritage: Helm
      component: bai-taskmanager
  serviceName: release-name-bai-flink-taskmanager-svc
  podManagementPolicy: Parallel
  updateStrategy:
    type: RollingUpdate

  replicas: 6

  template:
    metadata:
      annotations:
        checksum/config: 11df91aa48f5f4a1a5b793a5d25aae87d2d8f66922076070e627559d36cbe2cb

        productName: "IBM Business Automation Insights"
        productID: "BAIID"
        productVersion: "19.0.2"
      labels:
        app: ibm-business-automation-insights-dev
        chart: ibm-business-automation-insights-dev
        release: release-name
        heritage: Helm
        component: bai-taskmanager
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: beta.kubernetes.io/arch
                operator: In
                values:
                - amd64
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchLabels:
                  app: ibm-business-automation-insights-dev
                  chart: ibm-business-automation-insights-dev
                  release: release-name
                  heritage: Helm
                  component: bai-taskmanager
              topologyKey: kubernetes.io/hostname
      serviceAccountName: default
      containers:
      - name: taskmanager
        image: ibmcom/bai-flink-dev:19.0.2
        securityContext:
          runAsNonRoot: true
          runAsUser: 9999
        args:
        - taskmanager
        ports:
        - containerPort: 6121
          name: data
        - containerPort: 6122
          name: rpc
        - containerPort: 6125
          name: query
        readinessProbe:
          exec:
            command: ['sh', '-c',
                    'wget https://release-name-bai-flink-jobmanager:8081/taskmanagers -qO- -T 5 --no-check-certificate | grep `hostname`']
          initialDelaySeconds: 10
          periodSeconds: 10
        livenessProbe:
          exec:
            command: ['sh', '-c',
                    'ps aux | grep -v grep | grep "TaskManagerRunner"']
          initialDelaySeconds: 15
          periodSeconds: 20
        resources:
          requests:
            memory: 1280Mi
            cpu: 1
          limits:
            memory: 1536Mi
            cpu: 1

        env:
        - name: JOB_MANAGER_RPC_ADDRESS
          value: release-name-bai-flink-jobmanager
        - name: ZOOKEEPER_ADDRESS
          value: release-name-bai-flink-zk-cs
        - name: SSL_PASSWORD
          valueFrom:
            secretKeyRef:
              name: release-name-bai-secrets
              key: flink-ssl-password
        - name: HEAP_MEMORY
          valueFrom:
            configMapKeyRef:
              name: release-name-bai-env
              key: flink-heap-memory
        - name: FLINK_SECURITY_KRB5_ENABLE_KAFKA
          valueFrom:
            configMapKeyRef:
              name: release-name-bai-env
              key: flink-security-krb5-enable-kafka
        - name: FLINK_SECURITY_KRB5_ENABLE_HDFS
          valueFrom:
            configMapKeyRef:
              name: release-name-bai-env
              key: flink-security-krb5-enable-hdfs
        - name: FLINK_SECURITY_KRB5_REALM
          valueFrom:
            configMapKeyRef:
              name: release-name-bai-env
              key: flink-security-krb5-realm
        - name: FLINK_SECURITY_KRB5_KDC
          valueFrom:
            configMapKeyRef:
              name: release-name-bai-env
              key: flink-security-krb5-kdc
        - name: FLINK_SECURITY_KRB5_PRINCIPAL
          valueFrom:
            configMapKeyRef:
              name: release-name-bai-env
              key: flink-security-krb5-principal
        - name: INGRESS_TOPIC
          valueFrom:
            configMapKeyRef:
              name: release-name-bai-env
              key: ingress-topic
        - name: EGRESS_TOPIC
          valueFrom:
            configMapKeyRef:
              name: release-name-bai-env
              key: egress-topic
        - name: SERVICE_TOPIC
          valueFrom:
            configMapKeyRef:
              name: release-name-bai-env
              key: service-topic
        - name: CPU_CORES
          valueFrom:
            configMapKeyRef:
              name: release-name-bai-env
              key: flink-taskmanager-cpu-cores
        - name: TAIGA_FEATURES
          valueFrom:
            configMapKeyRef:
              name: release-name-bai-env
              key: bai-features
        volumeMounts:
        - mountPath: /opt/flink/conf/log4j-console.properties
          name: flink-log4j
          subPath: log4j-console.properties
        - mountPath: /opt/flink/conf/log4j-cli.properties
          name: flink-log4j
          subPath: log4j-cli.properties
        - name: flink-ssl
          mountPath: /etc/flink-ssl
          readOnly: true
        - name: nfs-storage
          mountPath: /mnt/pv
        - name: kerberos-keytabs
          mountPath: /etc/krb5
          readOnly: true
      volumes:
      - name: flink-log4j
        configMap:
          name: release-name-bai-flink-log4j
          items:
            - key: log4j-console.properties
              path: log4j-console.properties
            - key: log4j-cli.properties
              path: log4j-cli.properties
      - name: kerberos-keytabs
        secret:
          secretName: release-name-bai-secrets
          optional: true
          items:
          - key: flink-security-krb5-keytab
            path: flink.keytab
      - name: flink-ssl
        secret:
          secretName: release-name-bai-secrets
          items:
          - key: flink-ssl-keystore
            path: pods.keystore
          - key: flink-ssl-truststore
            path: ca.truststore
          - key: flink-ssl-internal-keystore
            path: internal.keystore
          - key: kafka-server-cert
            path: kafka-server-cert
          - key: elasticsearch-server-cert
            path: elasticsearch-server-cert
      - name: nfs-storage
        persistentVolumeClaim:
            claimName: release-name-bai-pvc
---
# Source: ibm-business-automation-insights-dev/charts/ibm-dba-ek/templates/es-security-job.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: release-name-ibm-dba-ek-security-config
  labels:
    app: release-name-ibm-dba-ek-elasticsearch
    chart: ibm-dba-ek
    heritage: Helm
    release: release-name
    component: release-name-ibm-dba-ek-security-config
    role: security-config
spec:
  backoffLimit: 3
  template:
    metadata:
      annotations:
        productName: "IBM Business Automation Insights"
        productID: "BAIID"
        productVersion: "19.0.2"
      labels:
        app: release-name-ibm-dba-ek-elasticsearch
        chart: ibm-dba-ek
        heritage: Helm
        release: release-name
        component: release-name-ibm-dba-ek-security-config
        role: security-config
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: beta.kubernetes.io/arch
                operator: In
                values:
                - amd64
      
      serviceAccountName: default
      restartPolicy: Never
      containers:
      - name: es-security-config
        command: ["/bin/bash", "/scripts/entrypoint.sh"]
        image: ibmcom/bai-elasticsearch-dev:19.0.2
        imagePullPolicy: 
        securityContext:
         runAsNonRoot: true
         runAsUser: 1000
        env:
        - name: ELASTICSEARCH_USERNAME
          value: admin
        - name: ELASTICSEARCH_PASSWORD
          value: passw0rd
        - name: KIBANA_MULTITENANCY
          value: "false"
        volumeMounts:
        - name: init-security-config
          mountPath: /usr/share/elasticsearch/init-security-config
        - name: entrypoint
          mountPath: /scripts
      volumes:
      - name: init-security-config
        secret:
          secretName: release-name-ibm-dba-ek-elasticsearch-security-config
      - name: entrypoint
        configMap:
          name: release-name-ibm-dba-ek-elasticsearch-security-entrypoint
          defaultMode: 365
          items:
            - key: entrypoint.sh
              path: entrypoint.sh
---
# Source: ibm-business-automation-insights-dev/templates/bai-baiw.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: release-name-bai-baiw
  labels:
    app: ibm-business-automation-insights-dev
    chart: ibm-business-automation-insights-dev
    release: release-name
    heritage: Helm
spec:
  backoffLimit: 0
  template:
    metadata:
      labels:
        app: ibm-business-automation-insights-dev
        chart: ibm-business-automation-insights-dev
        release: release-name
        heritage: Helm
        component: bai-baiw
      annotations:
        productName: "IBM Business Automation Insights"
        productID: "BAIID"
        productVersion: "19.0.2"
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: beta.kubernetes.io/arch
                operator: In
                values:
                - amd64
      
      serviceAccountName: default
      initContainers:
        - name: wait-bai-flink-es
          image: ibmcom/bai-init-dev:19.0.2
          securityContext:
            runAsNonRoot: true
            runAsUser: 9999
          env:
          - name: ES_CONFIG_VERSION
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: es-config-version
          - name: ELASTICSEARCH_URL
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: elasticsearch-url
          - name: ELASTICSEARCH_USERNAME
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: elasticsearch-username
          - name: ELASTICSEARCH_PASSWORD
            valueFrom:
              secretKeyRef:
                name: release-name-bai-secrets
                key: elasticsearch-password
          command: ['sh', '-c','
            [[ "${ELASTICSEARCH_URL: -1}" == "/" ]] && ELASTICSEARCH_URL=${ELASTICSEARCH_URL:$i:-1};
            templateUrl=$ELASTICSEARCH_URL/_template/baiw-timeseries;
            esRequest="curl -s -k -X GET -m 30 $templateUrl -u $ELASTICSEARCH_USERNAME:$ELASTICSEARCH_PASSWORD";
      
            while :; do
              echo "[`date`] Waiting for Flink cluster to start...";
              sleep 5;
              wget "https://release-name-bai-flink-jobmanager:8081/overview" -qO- -T 5 --no-check-certificate;
              if [[ "$?" == "0" ]]; then
                printf "\n[`date`] Flink cluster is ready.\n";
                break;
              fi;
            done;
      
            while :; do
              echo "[`date`] Waiting for Elasticsearch cluster availability...";
              ${esRequest};
              if [[ "$?" == "0" ]]; then
                printf "\n[`date`] Elasticsearch cluster is available.\n";
                break;
              fi;
            done;
      
            i=0;
            while :; do
              echo "[`date`] Checking if mappings version is up-to-date (${templateUrl}). Expecting version: $ES_CONFIG_VERSION... (iteration $i)";
              i=$((i+1));
              ${esRequest} | grep "\"version\":\"$ES_CONFIG_VERSION\"";
              if [[ "$?" == "0" ]]; then
                printf "\n[`date`] Mappings are up-to-date.\n";
                break;
              else
                printf "\n[`date`] Mappings are NOT up-to-date.\n";
              fi;
              sleep 5;
            done;
          ']
      
      containers:
      - name: bai-baiw
        image: ibmcom/bai-baiw-dev:19.0.2
        securityContext:
          runAsUser: 9999
        readinessProbe:
          exec:
            command: ['sh', '-c',
                    'ps aux | grep -v grep | grep "run-job"']
          periodSeconds: 10
        livenessProbe:
          exec:
            command: ['sh', '-c',
                    'ps aux | grep -v grep | grep "run-job"']
          initialDelaySeconds: 15
          periodSeconds: 20
        
        env:
          - name: JOB_MANAGER_RPC_ADDRESS
            value: release-name-bai-flink-jobmanager
          - name: ZOOKEEPER_ADDRESS
            value: release-name-bai-flink-zk-cs
          - name: TAIGA_FEATURES
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: bai-features
          - name: KAFKA_USERNAME
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: kafka-username
          - name: KAFKA_PASSWORD
            valueFrom:
              secretKeyRef:
                name: release-name-bai-secrets
                key: kafka-password
          - name: KAFKA_BOOTSTRAP_SERVERS
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: kafka-bootstrap-servers
          - name: KAFKA_SECURITY_PROTOCOL
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: kafka-security-protocol
          - name: KAFKA_SASL_KERBEROS_SERVICE_NAME
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: kafka-sasl-kerberos-service-name
          - name: FLINK_SECURITY_KRB5_ENABLE_KAFKA
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: flink-security-krb5-enable-kafka
          - name: SSL_PASSWORD
            valueFrom:
              secretKeyRef:
                name: release-name-bai-secrets
                key: flink-ssl-password
          - name: JOB_PARALLELISM
          
            value: "1"
          
          - name: CHECKPOINTING_INTERVAL
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: flink-job-checkpointing-interval
          - name: SUMMARY_END_AGGREGATION_DELAY_MS
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: bpmn-end-aggregation-delay
                optional: true
          - name: STORAGE_BATCH_SIZE
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: storage-batch-size
          - name: INACTIVE_BUCKET_CHECK_INTERVAL
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: storage-inactive-bucket-check-interval-ms
          - name: INACTIVE_BUCKET_THRESHOLD
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: storage-inactive-bucket-threshold-ms
          - name: STORAGE_BUCKET_URL
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: storage-bucket-url
          - name: INGRESS_TOPIC
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: ingress-topic
          - name: EGRESS_TOPIC
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: egress-topic
          - name: SERVICE_TOPIC
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: service-topic
          - name: SAVEPOINT
            value: ""
          - name: ELASTICSEARCH_URL
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: elasticsearch-url
          - name: ELASTICSEARCH_USERNAME
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: elasticsearch-username
          - name: ELASTICSEARCH_PASSWORD
            valueFrom:
              secretKeyRef:
                name: release-name-bai-secrets
                key: elasticsearch-password
          - name: ELASTICSEARCH_MAX_ACTIONS
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: flink-job-elasticsearch-max-actions
        
        volumeMounts:
        - mountPath: /opt/flink/conf/log4j-cli.properties
          name: flink-log4j
          subPath: log4j-cli.properties
        - name: flink-ssl
          mountPath: /etc/flink-ssl
          readOnly: true
        - name: nfs-storage
          mountPath: /mnt/pv
        
      volumes:
      - name: flink-log4j
        configMap:
          name: release-name-bai-flink-log4j
          items:
            - key: log4j-cli.properties
              path: log4j-cli.properties
      - name: flink-ssl
        secret:
          secretName: release-name-bai-secrets
          items:
          - key: flink-ssl-keystore
            path: pods.keystore
          - key: flink-ssl-truststore
            path: ca.truststore
          - key: flink-ssl-internal-keystore
            path: internal.keystore 
      - name: nfs-storage
        persistentVolumeClaim:
            claimName: release-name-bai-pvc
      
      restartPolicy: Never
---
# Source: ibm-business-automation-insights-dev/templates/bai-bawadv.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: release-name-bai-bawadv
  labels:
    app: ibm-business-automation-insights-dev
    chart: ibm-business-automation-insights-dev
    release: release-name
    heritage: Helm
spec:
  backoffLimit: 0
  template:
    metadata:
      annotations:
        productName: "IBM Business Automation Insights"
        productID: "BAIID"
        productVersion: "19.0.2"
      labels:
        app: ibm-business-automation-insights-dev
        chart: ibm-business-automation-insights-dev
        release: release-name
        heritage: Helm
        component: bai-bawadv
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: beta.kubernetes.io/arch
                operator: In
                values:
                - amd64
      
      serviceAccountName: default
      initContainers:
        - name: wait-bai-flink-es
          image: ibmcom/bai-init-dev:19.0.2
          securityContext:
            runAsNonRoot: true
            runAsUser: 9999
          env:
          - name: ES_CONFIG_VERSION
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: es-config-version
          - name: ELASTICSEARCH_URL
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: elasticsearch-url
          - name: ELASTICSEARCH_USERNAME
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: elasticsearch-username
          - name: ELASTICSEARCH_PASSWORD
            valueFrom:
              secretKeyRef:
                name: release-name-bai-secrets
                key: elasticsearch-password
          command: ['sh', '-c','
            [[ "${ELASTICSEARCH_URL: -1}" == "/" ]] && ELASTICSEARCH_URL=${ELASTICSEARCH_URL:$i:-1};
            templateUrl=$ELASTICSEARCH_URL/_template/bawadv-summaries;
            esRequest="curl -s -k -X GET -m 30 $templateUrl -u $ELASTICSEARCH_USERNAME:$ELASTICSEARCH_PASSWORD";
      
            while :; do
              echo "[`date`] Waiting for Flink cluster to start...";
              sleep 5;
              wget "https://release-name-bai-flink-jobmanager:8081/overview" -qO- -T 5 --no-check-certificate;
              if [[ "$?" == "0" ]]; then
                printf "\n[`date`] Flink cluster is ready.\n";
                break;
              fi;
            done;
      
            while :; do
              echo "[`date`] Waiting for Elasticsearch cluster availability...";
              ${esRequest};
              if [[ "$?" == "0" ]]; then
                printf "\n[`date`] Elasticsearch cluster is available.\n";
                break;
              fi;
            done;
      
            i=0;
            while :; do
              echo "[`date`] Checking if mappings version is up-to-date (${templateUrl}). Expecting version: $ES_CONFIG_VERSION... (iteration $i)";
              i=$((i+1));
              ${esRequest} | grep "\"version\":\"$ES_CONFIG_VERSION\"";
              if [[ "$?" == "0" ]]; then
                printf "\n[`date`] Mappings are up-to-date.\n";
                break;
              else
                printf "\n[`date`] Mappings are NOT up-to-date.\n";
              fi;
              sleep 5;
            done;
          ']
      
      containers:
      - name: bai-bawadv
        image: ibmcom/bai-bawadv-dev:19.0.2
        securityContext:
          runAsNonRoot: true
          runAsUser: 9999
        readinessProbe:
          exec:
            command: ['sh', '-c',
                    'ps aux | grep -v grep | grep "run-job"']
          periodSeconds: 10
        livenessProbe:
          exec:
            command: ['sh', '-c',
                    'ps aux | grep -v grep | grep "run-job"']
          initialDelaySeconds: 15
          periodSeconds: 20
        
        env:
          - name: JOB_MANAGER_RPC_ADDRESS
            value: release-name-bai-flink-jobmanager
          - name: ZOOKEEPER_ADDRESS
            value: release-name-bai-flink-zk-cs
          - name: TAIGA_FEATURES
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: bai-features
          - name: KAFKA_USERNAME
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: kafka-username
          - name: KAFKA_PASSWORD
            valueFrom:
              secretKeyRef:
                name: release-name-bai-secrets
                key: kafka-password
          - name: KAFKA_BOOTSTRAP_SERVERS
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: kafka-bootstrap-servers
          - name: KAFKA_SECURITY_PROTOCOL
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: kafka-security-protocol
          - name: KAFKA_SASL_KERBEROS_SERVICE_NAME
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: kafka-sasl-kerberos-service-name
          - name: FLINK_SECURITY_KRB5_ENABLE_KAFKA
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: flink-security-krb5-enable-kafka
          - name: SSL_PASSWORD
            valueFrom:
              secretKeyRef:
                name: release-name-bai-secrets
                key: flink-ssl-password
          - name: JOB_PARALLELISM
          
            value: "1"
          
          - name: CHECKPOINTING_INTERVAL
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: flink-job-checkpointing-interval
          - name: SUMMARY_END_AGGREGATION_DELAY_MS
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: bpmn-end-aggregation-delay
                optional: true
          - name: STORAGE_BATCH_SIZE
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: storage-batch-size
          - name: INACTIVE_BUCKET_CHECK_INTERVAL
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: storage-inactive-bucket-check-interval-ms
          - name: INACTIVE_BUCKET_THRESHOLD
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: storage-inactive-bucket-threshold-ms
          - name: STORAGE_BUCKET_URL
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: storage-bucket-url
          - name: INGRESS_TOPIC
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: ingress-topic
          - name: EGRESS_TOPIC
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: egress-topic
          - name: SERVICE_TOPIC
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: service-topic
          - name: SAVEPOINT
            value: ""
          - name: ELASTICSEARCH_URL
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: elasticsearch-url
          - name: ELASTICSEARCH_USERNAME
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: elasticsearch-username
          - name: ELASTICSEARCH_PASSWORD
            valueFrom:
              secretKeyRef:
                name: release-name-bai-secrets
                key: elasticsearch-password
          - name: ELASTICSEARCH_MAX_ACTIONS
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: flink-job-elasticsearch-max-actions
        
        volumeMounts:
        - mountPath: /opt/flink/conf/log4j-cli.properties
          name: flink-log4j
          subPath: log4j-cli.properties
        - name: flink-ssl
          mountPath: /etc/flink-ssl
          readOnly: true
        - name: nfs-storage
          mountPath: /mnt/pv
        
      volumes:
      - name: flink-log4j
        configMap:
          name: release-name-bai-flink-log4j
          items:
            - key: log4j-cli.properties
              path: log4j-cli.properties
      - name: flink-ssl
        secret:
          secretName: release-name-bai-secrets
          items:
          - key: flink-ssl-keystore
            path: pods.keystore
          - key: flink-ssl-truststore
            path: ca.truststore
          - key: flink-ssl-internal-keystore
            path: internal.keystore 
      - name: nfs-storage
        persistentVolumeClaim:
            claimName: release-name-bai-pvc
      
      restartPolicy: Never
---
# Source: ibm-business-automation-insights-dev/templates/bai-bpmn.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: release-name-bai-bpmn
  labels:
    app: ibm-business-automation-insights-dev
    chart: ibm-business-automation-insights-dev
    release: release-name
    heritage: Helm
spec:
  backoffLimit: 0
  template:
    metadata:
      annotations:
        productName: "IBM Business Automation Insights"
        productID: "BAIID"
        productVersion: "19.0.2"
      labels:
        app: ibm-business-automation-insights-dev
        chart: ibm-business-automation-insights-dev
        release: release-name
        heritage: Helm
        component: bai-bpmn
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: beta.kubernetes.io/arch
                operator: In
                values:
                - amd64
      
      serviceAccountName: default
      initContainers:
        - name: wait-bai-flink-es
          image: ibmcom/bai-init-dev:19.0.2
          securityContext:
            runAsNonRoot: true
            runAsUser: 9999
          env:
          - name: ES_CONFIG_VERSION
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: es-config-version
          - name: ELASTICSEARCH_URL
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: elasticsearch-url
          - name: ELASTICSEARCH_USERNAME
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: elasticsearch-username
          - name: ELASTICSEARCH_PASSWORD
            valueFrom:
              secretKeyRef:
                name: release-name-bai-secrets
                key: elasticsearch-password
          command: ['sh', '-c','
            [[ "${ELASTICSEARCH_URL: -1}" == "/" ]] && ELASTICSEARCH_URL=${ELASTICSEARCH_URL:$i:-1};
            templateUrl=$ELASTICSEARCH_URL/_template/process-summaries;
            esRequest="curl -s -k -X GET -m 30 $templateUrl -u $ELASTICSEARCH_USERNAME:$ELASTICSEARCH_PASSWORD";
      
            while :; do
              echo "[`date`] Waiting for Flink cluster to start...";
              sleep 5;
              wget "https://release-name-bai-flink-jobmanager:8081/overview" -qO- -T 5 --no-check-certificate;
              if [[ "$?" == "0" ]]; then
                printf "\n[`date`] Flink cluster is ready.\n";
                break;
              fi;
            done;
      
            while :; do
              echo "[`date`] Waiting for Elasticsearch cluster availability...";
              ${esRequest};
              if [[ "$?" == "0" ]]; then
                printf "\n[`date`] Elasticsearch cluster is available.\n";
                break;
              fi;
            done;
      
            i=0;
            while :; do
              echo "[`date`] Checking if mappings version is up-to-date (${templateUrl}). Expecting version: $ES_CONFIG_VERSION... (iteration $i)";
              i=$((i+1));
              ${esRequest} | grep "\"version\":\"$ES_CONFIG_VERSION\"";
              if [[ "$?" == "0" ]]; then
                printf "\n[`date`] Mappings are up-to-date.\n";
                break;
              else
                printf "\n[`date`] Mappings are NOT up-to-date.\n";
              fi;
              sleep 5;
            done;
          ']
      
      containers:
      - name: bai-bpmn
        image: ibmcom/bai-bpmn-dev:19.0.2
        securityContext:
          runAsNonRoot: true
          runAsUser: 9999
        readinessProbe:
          exec:
            command: ['sh', '-c',
                    'ps aux | grep -v grep | grep "run-job"']
          periodSeconds: 10
        livenessProbe:
          exec:
            command: ['sh', '-c',
                    'ps aux | grep -v grep | grep "run-job"']
          initialDelaySeconds: 15
          periodSeconds: 20
        
        env:
          - name: JOB_MANAGER_RPC_ADDRESS
            value: release-name-bai-flink-jobmanager
          - name: ZOOKEEPER_ADDRESS
            value: release-name-bai-flink-zk-cs
          - name: TAIGA_FEATURES
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: bai-features
          - name: KAFKA_USERNAME
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: kafka-username
          - name: KAFKA_PASSWORD
            valueFrom:
              secretKeyRef:
                name: release-name-bai-secrets
                key: kafka-password
          - name: KAFKA_BOOTSTRAP_SERVERS
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: kafka-bootstrap-servers
          - name: KAFKA_SECURITY_PROTOCOL
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: kafka-security-protocol
          - name: KAFKA_SASL_KERBEROS_SERVICE_NAME
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: kafka-sasl-kerberos-service-name
          - name: FLINK_SECURITY_KRB5_ENABLE_KAFKA
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: flink-security-krb5-enable-kafka
          - name: SSL_PASSWORD
            valueFrom:
              secretKeyRef:
                name: release-name-bai-secrets
                key: flink-ssl-password
          - name: JOB_PARALLELISM
          
            value: "1"
          
          - name: CHECKPOINTING_INTERVAL
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: flink-job-checkpointing-interval
          - name: SUMMARY_END_AGGREGATION_DELAY_MS
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: bpmn-end-aggregation-delay
                optional: true
          - name: STORAGE_BATCH_SIZE
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: storage-batch-size
          - name: INACTIVE_BUCKET_CHECK_INTERVAL
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: storage-inactive-bucket-check-interval-ms
          - name: INACTIVE_BUCKET_THRESHOLD
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: storage-inactive-bucket-threshold-ms
          - name: STORAGE_BUCKET_URL
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: storage-bucket-url
          - name: INGRESS_TOPIC
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: ingress-topic
          - name: EGRESS_TOPIC
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: egress-topic
          - name: SERVICE_TOPIC
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: service-topic
          - name: SAVEPOINT
            value: ""
          - name: ELASTICSEARCH_URL
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: elasticsearch-url
          - name: ELASTICSEARCH_USERNAME
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: elasticsearch-username
          - name: ELASTICSEARCH_PASSWORD
            valueFrom:
              secretKeyRef:
                name: release-name-bai-secrets
                key: elasticsearch-password
          - name: ELASTICSEARCH_MAX_ACTIONS
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: flink-job-elasticsearch-max-actions
        
        volumeMounts:
        - mountPath: /opt/flink/conf/log4j-cli.properties
          name: flink-log4j
          subPath: log4j-cli.properties
        - name: flink-ssl
          mountPath: /etc/flink-ssl
          readOnly: true
        - name: nfs-storage
          mountPath: /mnt/pv
        
      volumes:
      - name: flink-log4j
        configMap:
          name: release-name-bai-flink-log4j
          items:
            - key: log4j-cli.properties
              path: log4j-cli.properties
      - name: flink-ssl
        secret:
          secretName: release-name-bai-secrets
          items:
          - key: flink-ssl-keystore
            path: pods.keystore
          - key: flink-ssl-truststore
            path: ca.truststore
          - key: flink-ssl-internal-keystore
            path: internal.keystore 
      - name: nfs-storage
        persistentVolumeClaim:
            claimName: release-name-bai-pvc
      
      restartPolicy: Never
---
# Source: ibm-business-automation-insights-dev/templates/bai-content.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: release-name-bai-content
  labels:
    app: ibm-business-automation-insights-dev
    chart: ibm-business-automation-insights-dev
    release: release-name
    heritage: Helm
spec:
  backoffLimit: 0
  template:
    metadata:
      labels:
        app: ibm-business-automation-insights-dev
        chart: ibm-business-automation-insights-dev
        release: release-name
        heritage: Helm
        component: bai-content
      annotations:
        productName: "IBM Business Automation Insights"
        productID: "BAIID"
        productVersion: "19.0.2"
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: beta.kubernetes.io/arch
                operator: In
                values:
                - amd64
      
      serviceAccountName: default
      initContainers:
        - name: wait-bai-flink-es
          image: ibmcom/bai-init-dev:19.0.2
          securityContext:
            runAsNonRoot: true
            runAsUser: 9999
          env:
          - name: ES_CONFIG_VERSION
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: es-config-version
          - name: ELASTICSEARCH_URL
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: elasticsearch-url
          - name: ELASTICSEARCH_USERNAME
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: elasticsearch-username
          - name: ELASTICSEARCH_PASSWORD
            valueFrom:
              secretKeyRef:
                name: release-name-bai-secrets
                key: elasticsearch-password
          command: ['sh', '-c','
            [[ "${ELASTICSEARCH_URL: -1}" == "/" ]] && ELASTICSEARCH_URL=${ELASTICSEARCH_URL:$i:-1};
            templateUrl=$ELASTICSEARCH_URL/_template/content-timeseries;
            esRequest="curl -s -k -X GET -m 30 $templateUrl -u $ELASTICSEARCH_USERNAME:$ELASTICSEARCH_PASSWORD";
      
            while :; do
              echo "[`date`] Waiting for Flink cluster to start...";
              sleep 5;
              wget "https://release-name-bai-flink-jobmanager:8081/overview" -qO- -T 5 --no-check-certificate;
              if [[ "$?" == "0" ]]; then
                printf "\n[`date`] Flink cluster is ready.\n";
                break;
              fi;
            done;
      
            while :; do
              echo "[`date`] Waiting for Elasticsearch cluster availability...";
              ${esRequest};
              if [[ "$?" == "0" ]]; then
                printf "\n[`date`] Elasticsearch cluster is available.\n";
                break;
              fi;
            done;
      
            i=0;
            while :; do
              echo "[`date`] Checking if mappings version is up-to-date (${templateUrl}). Expecting version: $ES_CONFIG_VERSION... (iteration $i)";
              i=$((i+1));
              ${esRequest} | grep "\"version\":\"$ES_CONFIG_VERSION\"";
              if [[ "$?" == "0" ]]; then
                printf "\n[`date`] Mappings are up-to-date.\n";
                break;
              else
                printf "\n[`date`] Mappings are NOT up-to-date.\n";
              fi;
              sleep 5;
            done;
          ']
      
      containers:
      - name: bai-content
        image: ibmcom/bai-content-dev:19.0.2
        securityContext:
          runAsNonRoot: true
          runAsUser: 9999
        readinessProbe:
          exec:
            command: ['sh', '-c',
                    'ps aux | grep -v grep | grep "run-job"']
          periodSeconds: 10
        livenessProbe:
          exec:
            command: ['sh', '-c',
                    'ps aux | grep -v grep | grep "run-job"']
          initialDelaySeconds: 15
          periodSeconds: 20
        
        env:
          - name: JOB_MANAGER_RPC_ADDRESS
            value: release-name-bai-flink-jobmanager
          - name: ZOOKEEPER_ADDRESS
            value: release-name-bai-flink-zk-cs
          - name: TAIGA_FEATURES
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: bai-features
          - name: KAFKA_USERNAME
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: kafka-username
          - name: KAFKA_PASSWORD
            valueFrom:
              secretKeyRef:
                name: release-name-bai-secrets
                key: kafka-password
          - name: KAFKA_BOOTSTRAP_SERVERS
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: kafka-bootstrap-servers
          - name: KAFKA_SECURITY_PROTOCOL
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: kafka-security-protocol
          - name: KAFKA_SASL_KERBEROS_SERVICE_NAME
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: kafka-sasl-kerberos-service-name
          - name: FLINK_SECURITY_KRB5_ENABLE_KAFKA
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: flink-security-krb5-enable-kafka
          - name: SSL_PASSWORD
            valueFrom:
              secretKeyRef:
                name: release-name-bai-secrets
                key: flink-ssl-password
          - name: JOB_PARALLELISM
          
            value: "1"
          
          - name: CHECKPOINTING_INTERVAL
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: flink-job-checkpointing-interval
          - name: SUMMARY_END_AGGREGATION_DELAY_MS
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: bpmn-end-aggregation-delay
                optional: true
          - name: STORAGE_BATCH_SIZE
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: storage-batch-size
          - name: INACTIVE_BUCKET_CHECK_INTERVAL
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: storage-inactive-bucket-check-interval-ms
          - name: INACTIVE_BUCKET_THRESHOLD
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: storage-inactive-bucket-threshold-ms
          - name: STORAGE_BUCKET_URL
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: storage-bucket-url
          - name: INGRESS_TOPIC
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: ingress-topic
          - name: EGRESS_TOPIC
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: egress-topic
          - name: SERVICE_TOPIC
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: service-topic
          - name: SAVEPOINT
            value: ""
          - name: ELASTICSEARCH_URL
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: elasticsearch-url
          - name: ELASTICSEARCH_USERNAME
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: elasticsearch-username
          - name: ELASTICSEARCH_PASSWORD
            valueFrom:
              secretKeyRef:
                name: release-name-bai-secrets
                key: elasticsearch-password
          - name: ELASTICSEARCH_MAX_ACTIONS
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: flink-job-elasticsearch-max-actions
        
        volumeMounts:
        - mountPath: /opt/flink/conf/log4j-cli.properties
          name: flink-log4j
          subPath: log4j-cli.properties
        - name: flink-ssl
          mountPath: /etc/flink-ssl
          readOnly: true
        - name: nfs-storage
          mountPath: /mnt/pv
        
      volumes:
      - name: flink-log4j
        configMap:
          name: release-name-bai-flink-log4j
          items:
            - key: log4j-cli.properties
              path: log4j-cli.properties
      - name: flink-ssl
        secret:
          secretName: release-name-bai-secrets
          items:
          - key: flink-ssl-keystore
            path: pods.keystore
          - key: flink-ssl-truststore
            path: ca.truststore
          - key: flink-ssl-internal-keystore
            path: internal.keystore 
      - name: nfs-storage
        persistentVolumeClaim:
            claimName: release-name-bai-pvc
      
      restartPolicy: Never
---
# Source: ibm-business-automation-insights-dev/templates/bai-icm.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: release-name-bai-icm
  labels:
    app: ibm-business-automation-insights-dev
    chart: ibm-business-automation-insights-dev
    release: release-name
    heritage: Helm
spec:
  backoffLimit: 0
  template:
    metadata:
      annotations:
        productName: "IBM Business Automation Insights"
        productID: "BAIID"
        productVersion: "19.0.2"
      labels:
        app: ibm-business-automation-insights-dev
        chart: ibm-business-automation-insights-dev
        release: release-name
        heritage: Helm
        component: bai-icm
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: beta.kubernetes.io/arch
                operator: In
                values:
                - amd64
      
      serviceAccountName: default
      initContainers:
        - name: wait-bai-flink-es
          image: ibmcom/bai-init-dev:19.0.2
          securityContext:
            runAsNonRoot: true
            runAsUser: 9999
          env:
          - name: ES_CONFIG_VERSION
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: es-config-version
          - name: ELASTICSEARCH_URL
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: elasticsearch-url
          - name: ELASTICSEARCH_USERNAME
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: elasticsearch-username
          - name: ELASTICSEARCH_PASSWORD
            valueFrom:
              secretKeyRef:
                name: release-name-bai-secrets
                key: elasticsearch-password
          command: ['sh', '-c','
            [[ "${ELASTICSEARCH_URL: -1}" == "/" ]] && ELASTICSEARCH_URL=${ELASTICSEARCH_URL:$i:-1};
            templateUrl=$ELASTICSEARCH_URL/_template/case-summaries;
            esRequest="curl -s -k -X GET -m 30 $templateUrl -u $ELASTICSEARCH_USERNAME:$ELASTICSEARCH_PASSWORD";
      
            while :; do
              echo "[`date`] Waiting for Flink cluster to start...";
              sleep 5;
              wget "https://release-name-bai-flink-jobmanager:8081/overview" -qO- -T 5 --no-check-certificate;
              if [[ "$?" == "0" ]]; then
                printf "\n[`date`] Flink cluster is ready.\n";
                break;
              fi;
            done;
      
            while :; do
              echo "[`date`] Waiting for Elasticsearch cluster availability...";
              ${esRequest};
              if [[ "$?" == "0" ]]; then
                printf "\n[`date`] Elasticsearch cluster is available.\n";
                break;
              fi;
            done;
      
            i=0;
            while :; do
              echo "[`date`] Checking if mappings version is up-to-date (${templateUrl}). Expecting version: $ES_CONFIG_VERSION... (iteration $i)";
              i=$((i+1));
              ${esRequest} | grep "\"version\":\"$ES_CONFIG_VERSION\"";
              if [[ "$?" == "0" ]]; then
                printf "\n[`date`] Mappings are up-to-date.\n";
                break;
              else
                printf "\n[`date`] Mappings are NOT up-to-date.\n";
              fi;
              sleep 5;
            done;
          ']
      
      containers:
      - name: bai-icm
        image: ibmcom/bai-icm-dev:19.0.2
        securityContext:
          runAsNonRoot: true
          runAsUser: 9999
        readinessProbe:
          exec:
            command: ['sh', '-c',
                    'ps aux | grep -v grep | grep "run-job"']
          periodSeconds: 10
        livenessProbe:
          exec:
            command: ['sh', '-c',
                    'ps aux | grep -v grep | grep "run-job"']
          initialDelaySeconds: 15
          periodSeconds: 20
        
        env:
          - name: JOB_MANAGER_RPC_ADDRESS
            value: release-name-bai-flink-jobmanager
          - name: ZOOKEEPER_ADDRESS
            value: release-name-bai-flink-zk-cs
          - name: TAIGA_FEATURES
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: bai-features
          - name: KAFKA_USERNAME
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: kafka-username
          - name: KAFKA_PASSWORD
            valueFrom:
              secretKeyRef:
                name: release-name-bai-secrets
                key: kafka-password
          - name: KAFKA_BOOTSTRAP_SERVERS
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: kafka-bootstrap-servers
          - name: KAFKA_SECURITY_PROTOCOL
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: kafka-security-protocol
          - name: KAFKA_SASL_KERBEROS_SERVICE_NAME
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: kafka-sasl-kerberos-service-name
          - name: FLINK_SECURITY_KRB5_ENABLE_KAFKA
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: flink-security-krb5-enable-kafka
          - name: SSL_PASSWORD
            valueFrom:
              secretKeyRef:
                name: release-name-bai-secrets
                key: flink-ssl-password
          - name: JOB_PARALLELISM
          
            value: "1"
          
          - name: CHECKPOINTING_INTERVAL
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: flink-job-checkpointing-interval
          - name: SUMMARY_END_AGGREGATION_DELAY_MS
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: bpmn-end-aggregation-delay
                optional: true
          - name: STORAGE_BATCH_SIZE
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: storage-batch-size
          - name: INACTIVE_BUCKET_CHECK_INTERVAL
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: storage-inactive-bucket-check-interval-ms
          - name: INACTIVE_BUCKET_THRESHOLD
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: storage-inactive-bucket-threshold-ms
          - name: STORAGE_BUCKET_URL
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: storage-bucket-url
          - name: INGRESS_TOPIC
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: ingress-topic
          - name: EGRESS_TOPIC
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: egress-topic
          - name: SERVICE_TOPIC
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: service-topic
          - name: SAVEPOINT
            value: ""
          - name: ELASTICSEARCH_URL
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: elasticsearch-url
          - name: ELASTICSEARCH_USERNAME
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: elasticsearch-username
          - name: ELASTICSEARCH_PASSWORD
            valueFrom:
              secretKeyRef:
                name: release-name-bai-secrets
                key: elasticsearch-password
          - name: ELASTICSEARCH_MAX_ACTIONS
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: flink-job-elasticsearch-max-actions
        
        volumeMounts:
        - mountPath: /opt/flink/conf/log4j-cli.properties
          name: flink-log4j
          subPath: log4j-cli.properties
        - name: flink-ssl
          mountPath: /etc/flink-ssl
          readOnly: true
        - name: nfs-storage
          mountPath: /mnt/pv
        
      volumes:
      - name: flink-log4j
        configMap:
          name: release-name-bai-flink-log4j
          items:
            - key: log4j-cli.properties
              path: log4j-cli.properties
      - name: flink-ssl
        secret:
          secretName: release-name-bai-secrets
          items:
          - key: flink-ssl-keystore
            path: pods.keystore
          - key: flink-ssl-truststore
            path: ca.truststore
          - key: flink-ssl-internal-keystore
            path: internal.keystore 
      - name: nfs-storage
        persistentVolumeClaim:
            claimName: release-name-bai-pvc
      
      restartPolicy: Never
---
# Source: ibm-business-automation-insights-dev/templates/bai-odm.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: release-name-bai-odm
  labels:
    app: ibm-business-automation-insights-dev
    chart: ibm-business-automation-insights-dev
    release: release-name
    heritage: Helm
spec:
  backoffLimit: 0
  template:
    metadata:
      labels:
        app: ibm-business-automation-insights-dev
        chart: ibm-business-automation-insights-dev
        release: release-name
        heritage: Helm
        component: bai-odm
      annotations:
        productName: "IBM Business Automation Insights"
        productID: "BAIID"
        productVersion: "19.0.2"
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: beta.kubernetes.io/arch
                operator: In
                values:
                - amd64
      
      serviceAccountName: default
      initContainers:
        - name: wait-bai-flink-es
          image: ibmcom/bai-init-dev:19.0.2
          securityContext:
            runAsNonRoot: true
            runAsUser: 9999
          env:
          - name: ES_CONFIG_VERSION
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: es-config-version
          - name: ELASTICSEARCH_URL
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: elasticsearch-url
          - name: ELASTICSEARCH_USERNAME
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: elasticsearch-username
          - name: ELASTICSEARCH_PASSWORD
            valueFrom:
              secretKeyRef:
                name: release-name-bai-secrets
                key: elasticsearch-password
          command: ['sh', '-c','
            [[ "${ELASTICSEARCH_URL: -1}" == "/" ]] && ELASTICSEARCH_URL=${ELASTICSEARCH_URL:$i:-1};
            templateUrl=$ELASTICSEARCH_URL/_template/odm-timeseries;
            esRequest="curl -s -k -X GET -m 30 $templateUrl -u $ELASTICSEARCH_USERNAME:$ELASTICSEARCH_PASSWORD";
      
            while :; do
              echo "[`date`] Waiting for Flink cluster to start...";
              sleep 5;
              wget "https://release-name-bai-flink-jobmanager:8081/overview" -qO- -T 5 --no-check-certificate;
              if [[ "$?" == "0" ]]; then
                printf "\n[`date`] Flink cluster is ready.\n";
                break;
              fi;
            done;
      
            while :; do
              echo "[`date`] Waiting for Elasticsearch cluster availability...";
              ${esRequest};
              if [[ "$?" == "0" ]]; then
                printf "\n[`date`] Elasticsearch cluster is available.\n";
                break;
              fi;
            done;
      
            i=0;
            while :; do
              echo "[`date`] Checking if mappings version is up-to-date (${templateUrl}). Expecting version: $ES_CONFIG_VERSION... (iteration $i)";
              i=$((i+1));
              ${esRequest} | grep "\"version\":\"$ES_CONFIG_VERSION\"";
              if [[ "$?" == "0" ]]; then
                printf "\n[`date`] Mappings are up-to-date.\n";
                break;
              else
                printf "\n[`date`] Mappings are NOT up-to-date.\n";
              fi;
              sleep 5;
            done;
          ']
      
      containers:
      - name: bai-odm
        image: ibmcom/bai-odm-dev:19.0.2
        securityContext:
          runAsNonRoot: true
          runAsUser: 9999
        readinessProbe:
          exec:
            command: ['sh', '-c',
                    'ps aux | grep -v grep | grep "run-job"']
          periodSeconds: 10
        livenessProbe:
          exec:
            command: ['sh', '-c',
                    'ps aux | grep -v grep | grep "run-job"']
          initialDelaySeconds: 15
          periodSeconds: 20
        
        env:
          - name: JOB_MANAGER_RPC_ADDRESS
            value: release-name-bai-flink-jobmanager
          - name: ZOOKEEPER_ADDRESS
            value: release-name-bai-flink-zk-cs
          - name: TAIGA_FEATURES
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: bai-features
          - name: KAFKA_USERNAME
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: kafka-username
          - name: KAFKA_PASSWORD
            valueFrom:
              secretKeyRef:
                name: release-name-bai-secrets
                key: kafka-password
          - name: KAFKA_BOOTSTRAP_SERVERS
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: kafka-bootstrap-servers
          - name: KAFKA_SECURITY_PROTOCOL
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: kafka-security-protocol
          - name: KAFKA_SASL_KERBEROS_SERVICE_NAME
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: kafka-sasl-kerberos-service-name
          - name: FLINK_SECURITY_KRB5_ENABLE_KAFKA
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: flink-security-krb5-enable-kafka
          - name: SSL_PASSWORD
            valueFrom:
              secretKeyRef:
                name: release-name-bai-secrets
                key: flink-ssl-password
          - name: JOB_PARALLELISM
          
            value: "1"
          
          - name: CHECKPOINTING_INTERVAL
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: flink-job-checkpointing-interval
          - name: SUMMARY_END_AGGREGATION_DELAY_MS
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: bpmn-end-aggregation-delay
                optional: true
          - name: STORAGE_BATCH_SIZE
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: storage-batch-size
          - name: INACTIVE_BUCKET_CHECK_INTERVAL
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: storage-inactive-bucket-check-interval-ms
          - name: INACTIVE_BUCKET_THRESHOLD
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: storage-inactive-bucket-threshold-ms
          - name: STORAGE_BUCKET_URL
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: storage-bucket-url
          - name: INGRESS_TOPIC
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: ingress-topic
          - name: EGRESS_TOPIC
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: egress-topic
          - name: SERVICE_TOPIC
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: service-topic
          - name: SAVEPOINT
            value: ""
          - name: ELASTICSEARCH_URL
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: elasticsearch-url
          - name: ELASTICSEARCH_USERNAME
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: elasticsearch-username
          - name: ELASTICSEARCH_PASSWORD
            valueFrom:
              secretKeyRef:
                name: release-name-bai-secrets
                key: elasticsearch-password
          - name: ELASTICSEARCH_MAX_ACTIONS
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: flink-job-elasticsearch-max-actions
        
        volumeMounts:
        - mountPath: /opt/flink/conf/log4j-cli.properties
          name: flink-log4j
          subPath: log4j-cli.properties
        - name: flink-ssl
          mountPath: /etc/flink-ssl
          readOnly: true
        - name: nfs-storage
          mountPath: /mnt/pv
        
      volumes:
      - name: flink-log4j
        configMap:
          name: release-name-bai-flink-log4j
          items:
            - key: log4j-cli.properties
              path: log4j-cli.properties
      - name: flink-ssl
        secret:
          secretName: release-name-bai-secrets
          items:
          - key: flink-ssl-keystore
            path: pods.keystore
          - key: flink-ssl-truststore
            path: ca.truststore
          - key: flink-ssl-internal-keystore
            path: internal.keystore 
      - name: nfs-storage
        persistentVolumeClaim:
            claimName: release-name-bai-pvc
      
      restartPolicy: Never
---
# Source: ibm-business-automation-insights-dev/templates/bai-setup.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: release-name-bai-setup
  labels:
    app: ibm-business-automation-insights-dev
    chart: ibm-business-automation-insights-dev
    release: release-name
    heritage: Helm
spec:
  backoffLimit: 3
  template:
    metadata:
      annotations:
        productName: "IBM Business Automation Insights"
        productID: "BAIID"
        productVersion: "19.0.2"
      labels:
        app: ibm-business-automation-insights-dev
        chart: ibm-business-automation-insights-dev
        release: release-name
        heritage: Helm
        component: bai-setup
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: beta.kubernetes.io/arch
                operator: In
                values:
                - amd64
      
      serviceAccountName: default
      initContainers:
        - name: wait-elasticsearch
          image: ibmcom/bai-init-dev:19.0.2
          securityContext:
            runAsNonRoot: true
            runAsUser: 20181
          env:
          - name: ELASTICSEARCH_URL
            valueFrom:
              configMapKeyRef:
                name: release-name-bai-env
                key: elasticsearch-url
          command: ['sh', '-c',
              'until curl -k -X GET -m 30 ${ELASTICSEARCH_URL} ;
              do echo Waiting for elasticsearch to start...; sleep 2; done;']
      containers:
      - name: es-bootstrap
        image: ibmcom/bai-setup-dev:19.0.2
        securityContext:
          runAsNonRoot: true
          runAsUser: 20181
        resources:
          
          requests:
            
            memory: "50Mi"
            cpu: "200m"
            
          limits:
            
            memory: "120Mi"
            
          
        env:
        - name: ELASTICSEARCH_URL
          valueFrom:
            configMapKeyRef:
              name: release-name-bai-env
              key: elasticsearch-url
        - name: ELASTICSEARCH_USERNAME
          valueFrom:
            configMapKeyRef:
              name: release-name-bai-env
              key: elasticsearch-username
        - name: ELASTICSEARCH_PASSWORD
          valueFrom:
            secretKeyRef:
              name: release-name-bai-secrets
              key: elasticsearch-password
        - name: KAFKA_USERNAME
          valueFrom:
            configMapKeyRef:
              name: release-name-bai-env
              key: kafka-username
        - name: KAFKA_PASSWORD
          valueFrom:
            secretKeyRef:
              name: release-name-bai-secrets
              key: kafka-password
        - name: KAFKA_BOOTSTRAP_SERVERS
          valueFrom:
            configMapKeyRef:
              name: release-name-bai-env
              key: kafka-bootstrap-servers
        - name: KAFKA_SECURITY_PROTOCOL
          valueFrom:
            configMapKeyRef:
              name: release-name-bai-env
              key: kafka-security-protocol
        - name: KAFKA_SASL_KERBEROS_SERVICE_NAME
          valueFrom:
            configMapKeyRef:
              name: release-name-bai-env
              key: kafka-sasl-kerberos-service-name
        - name: KAFKA_KRB5_ENABLED
          valueFrom:
            configMapKeyRef:
              name: release-name-bai-env
              key: flink-security-krb5-enable-kafka
        - name: KAFKA_KRB5_REALM
          valueFrom:
            configMapKeyRef:
              name: release-name-bai-env
              key: flink-security-krb5-realm
        - name: KAFKA_KRB5_KDC
          valueFrom:
            configMapKeyRef:
              name: release-name-bai-env
              key: flink-security-krb5-kdc
        - name: KAFKA_KRB5_PRINCIPAL
          valueFrom:
            configMapKeyRef:
              name: release-name-bai-env
              key: flink-security-krb5-principal
        - name: KAFKA_KRB5_KEYTAB
          value: "/etc/krb5/kafka.keytab"
        - name: KAFKA_INGRESS_TOPIC
          valueFrom:
            configMapKeyRef:
              name: release-name-bai-env
              key: ingress-topic
        - name: KAFKA_EGRESS_TOPIC
          valueFrom:
            configMapKeyRef:
              name: release-name-bai-env
              key: egress-topic
        - name: KAFKA_SERVICE_TOPIC
          valueFrom:
            configMapKeyRef:
              name: release-name-bai-env
              key: service-topic
        volumeMounts:
        - name: kerberos-keytabs
          mountPath: /etc/krb5
          readOnly: true
        - name: setup-ssl
          mountPath: /etc/setup-ssl
          readOnly: true
      volumes:
      - name: kerberos-keytabs
        secret:
          secretName: release-name-bai-secrets
          optional: true
          items:
          - key: flink-security-krb5-keytab
            path: kafka.keytab
      - name: setup-ssl
        secret:
          secretName: release-name-bai-secrets
          optional: true
          items:
          - key: kafka-ca-cert
            path: kafka-ca.pem
      restartPolicy: Never
---
# Source: ibm-business-automation-insights-dev/charts/ibm-dba-ek/templates/tests/test-es-health.yaml
apiVersion: v1
kind: Pod
metadata:
  name: "release-name-test-es-health"
  annotations:
    "helm.sh/hook": test-success
    "helm.sh/hook-delete-policy": hook-succeeded
  labels:
    app: release-name-ibm-dba-ek-elasticsearch
    chart: "ibm-dba-ek"
    release: release-name
    heritage: "Helm"
    component: "es-test"
spec:
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: beta.kubernetes.io/arch
            operator: In
            values:
            - amd64
  serviceAccountName: default
  containers:
  - name: release-name-test-es-health
    image: ibmcom/bai-init-dev:19.0.2
    env:
    - name: "ES_HOST"
      value: "release-name-ibm-dba-ek-client"
    - name: "ES_PORT"
      value: "9200"
    - name: ES_USERNAME
      value: admin
    - name: ES_PASSWORD
      value: passw0rd
    command: ["sh", "-c", "echo $ES_HOST && echo $ES_PORT && curl https://$ES_HOST:$ES_PORT -u $ES_USERNAME:$ES_PASSWORD --insecure"]
  restartPolicy: Never
---
# Source: ibm-business-automation-insights-dev/templates/tests/bai-admin-test.yaml
###############################################################################
#
# Licensed Materials - Property of IBM
#
# (C) Copyright IBM Corp. 2018. All Rights Reserved.
#
# US Government Users Restricted Rights - Use, duplication or
# disclosure restricted by GSA ADP Schedule Contract with IBM Corp.
#
###############################################################################
# Checks that bai-admin service run successfully after Helm installation
###############################################################################
apiVersion: v1
kind: Pod
metadata:
  name: release-name-bai-admin-test
  labels:
    app: ibm-business-automation-insights-dev
    chart: ibm-business-automation-insights-dev
    release: release-name
    heritage: Helm
    component: bai-admin-test
  annotations:
    "helm.sh/hook": test-success
    "helm.sh/hook-delete-policy": hook-succeeded
spec:
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: beta.kubernetes.io/arch
            operator: In
            values:
            - amd64
  serviceAccountName: default
  containers:
    - name: ibm-business-automation-insights-dev
      image: ibmcom/bai-init-dev:19.0.2
      command:
        - "sh"
        - "-c"
        - "echo 'Testing API health at https://taiga-admin-service:6892'
        && curl -s https://release-name-bai-admin-service:6892/api/health --insecure | grep '\"status\":0'
        && echo 'Testing API is secure at https://taiga-admin-service:6892'
        && touch file.txt && curl -s -X POST -F \"file=@file.txt\" -u user:pass https://release-name-bai-admin-service:6892/api/actions --insecure | grep Unauthorized
        && echo 'Testing API has valid credentials at https://release-name-bai-admin-service:6892'
        && curl -s -X POST -F \"file=@file.txt\" -u admin:passw0rd https://release-name-bai-admin-service:6892/api/actions --insecure | grep 'File must be in JSON format.'"
  restartPolicy: Never
---
# Source: ibm-business-automation-insights-dev/templates/tests/bai-processing-jobs-test.yaml
###############################################################################
#
# Licensed Materials - Property of IBM
#
# (C) Copyright IBM Corp. 2018, 2019. All Rights Reserved.
#
# US Government Users Restricted Rights - Use, duplication or
# disclosure restricted by GSA ADP Schedule Contract with IBM Corp.
#
###############################################################################
# Checks that processing jobs are successfully running after Helm installation
#
# 1. wait until jobmanager is ready (check 60 times, frequency: 5 sec),
#    or exit on error.
# 2. for each installed job:
#   - check job state until it is RUNNING (check 10 times, frequency 3 sec),
#     or exit on error.
#   - exit on error if state is RESTARTING, FAILING, SUSPENDED or FAILED
#   - Job must stay ~10 sec in RUNNING state (check 3 times, frequency 3 sec) to
#     be declared RUNNING.
#
# Note: In case of an upgrade there can be 2 instances of the same job; one
#       in a CANCEL state and the new instance to be in a RUNNING state.
###############################################################################
apiVersion: v1
kind: Pod
metadata:
  name: release-name-test-bai-processing-jobs
  labels:
    app: ibm-business-automation-insights-dev
    chart: ibm-business-automation-insights-dev
    release: release-name
    heritage: Helm
    component: test-bai-processing-jobs
  annotations:
    "helm.sh/hook": test-success
    "helm.sh/hook-delete-policy": hook-succeeded
spec:
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: beta.kubernetes.io/arch
            operator: In
            values:
            - amd64
  serviceAccountName: default
  containers:
    - name: ibm-business-automation-insights-dev
      image: ibmcom/bai-init-dev:19.0.2
      command: ['sh', '-c','
        log_msg()
        {
          echo "[`date`] $1";
        }

        log_msg "starting test-bai-processing-jobs...";

        readonly getJobsOverview="wget http://release-name-bai-flink-jobmanager:8081/jobs/overview -qO- -T 5 --no-check-certificate";
        jobsOverview="";

        secondsBeforeRetry="5";
        maximumRetries="100";
        tryCount=0;

        while :; do
          log_msg "trying... ${getJobsOverview}";

          jobsOverview=`${getJobsOverview}`;
          returnCode=$?;
          if [ "${returnCode}" = "0" ]; then
            break;
          fi;

          tryCount=`expr ${tryCount} + 1`;
          if [ "${tryCount}" = "${maximumRetries}" ]; then
            log_msg "ERROR (${returnCode}) - unable to reach Flink jobmanager.";
            exit 1;
          fi;

          log_msg "waiting for the jobmanager to be available... (${tryCount}/${maximumRetries})";
          sleep ${secondsBeforeRetry};
        done;

        log_msg "jobmanager is ready.";

        secondsBeforeRetry=3;
        maximumRetries=10;

        check_job()
        {
          jobName="dba/bai-$1";
          isJobInstalled=$2;

          if [ "${isJobInstalled}" == "true" ]; then
            log_msg "checking installed job ${jobName}...";
            echo "${jobsOverview}" | jq .;

            tryCount=0;
            successCount=0;
            minimumConsecutiveSuccess=3;

            while :; do
              state=`echo "${jobsOverview}" | jq -r ''.[] | .[] | select(.name==''\"$jobName\"'') | .state''`;

              if [ "`echo "${state}" | grep RUNNING`" ]; then
                successCount=`expr ${successCount} + 1`;
                log_msg "job ${jobName} state: ${state} (${successCount}/${minimumConsecutiveSuccess})";
                if [ "${successCount}" = "${minimumConsecutiveSuccess}" ]; then
                  break;
                fi;
              else
                successCount=0;

                if [ -n "${state}" ]; then
                  log_msg "job ${jobName} state: ${state}";
                fi;

                if [ "${state}" = "RESTARTING" ] ||
                   [ "${state}" = "FAILING"    ] ||
                   [ "${state}" = "SUSPENDED"  ] ||
                   [ "${state}" = "FAILED"     ];
                then
                  tryCount="${maximumRetries}";
                else
                  tryCount=`expr ${tryCount} + 1`;
                fi;

                if [ "${tryCount}" = "${maximumRetries}" ]; then
                  log_msg "ERROR - job ${jobName} is not running.";
                  exit 1;
                fi;

                log_msg "waiting for job ${jobName} to be running... (${tryCount}/${maximumRetries})";
              fi;
              sleep ${secondsBeforeRetry};
              jobsOverview=`${getJobsOverview}`;
            done;
          fi;
        }

        check_job ingestion false;
        check_job bpmn true;
        check_job bawadv true;
        check_job icm true;
        check_job odm true;
        check_job content true;

        log_msg "All installed jobs are in RUNNING state.";
        exit 0;
      ']
  restartPolicy: Never
