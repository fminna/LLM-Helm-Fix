---
# Source: lizardcd/charts/etcd/templates/networkpolicy.yaml
kind: NetworkPolicy
apiVersion: networking.k8s.io/v1
metadata:
  name: release-name-etcd
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: etcd
    app.kubernetes.io/version: 3.5.12
    helm.sh/chart: etcd-9.14.2
    app.kubernetes.io/component: etcd
spec:
  podSelector:
    matchLabels:
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/name: etcd
      app.kubernetes.io/component: etcd
  policyTypes:
    - Ingress
    - Egress
  egress:
    - {}
  ingress:
    # Allow inbound connections
    - ports:
        - port: 2379
        - port: 2380
---
# Source: lizardcd/charts/etcd/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
automountServiceAccountToken: false
metadata:
  name: release-name-etcd
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: etcd
    app.kubernetes.io/version: 3.5.12
    helm.sh/chart: etcd-9.14.2
---
# Source: lizardcd/templates/agent/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: "release-name-lizardcd-agent"
secrets:
  - name: lizardcd-token
---
# Source: lizardcd/templates/server-job/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: "release-name-lizardcd-initjob"
---
# Source: lizardcd/templates/server/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: "release-name-lizardcd-server"
---
# Source: lizardcd/templates/ui/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
automountServiceAccountToken: true
metadata:
  name: "release-name-lizardcd-ui"
---
# Source: lizardcd/charts/etcd/templates/token-secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: release-name-etcd-jwt-token
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: etcd
    app.kubernetes.io/version: 3.5.12
    helm.sh/chart: etcd-9.14.2
type: Opaque
data:
  jwt-token.pem: "LS0tLS1CRUdJTiBSU0EgUFJJVkFURSBLRVktLS0tLQpNSUlKS1FJQkFBS0NBZ0VBMXo0UTdPc0xQSy9CdGV0SWlRWXl2NGVsZXptVXR1WkhXTStEbzBFcnpmNkJ1MmlqClNUSTMzWFpWbHFqc0Z5LzRocHVFdGp2S3RkeHpwd3cwOFY5M2M1SmIwcXhucC9XRExuZE9PZm9iS2llNVRwL0oKT2djekYySVpDTGZGak4rS0ZVaXV6bXAxcDBhZjA3NG5vYjdyY0h0dDRkZ2N1MXh5V3hyMlk2OStOd3F4LzR5QworbDZiaXREMEFrSkV2Uy9iUmNkL0sydWxsMFdrYTdWWHF2bDRUdkEvL01ET3Q1emJabW5FZXoxdHRYWHBSUk9WCkp4R1ROdmpCdDZBY1dYbnBUcVpqcDdCQzJDaVdqMmFQMlc0cy9xcmIzWFhVMkxCdC92ejJSOFk1bmgzWHdTclQKcSt1eUdnR0lDV0ZjT3ZxRFY4Z2J0Uk5GZ29mOVJTcUlrWXgvTDF1WlB4VGFtNlhsUFlUQmdXUTlzU1VzTHJQegorNVFuYVlUdVk0NE00VC9XbjdoWTg4MEx5bDR0azB6OHRjM2hUeERmRzhFS2NYWjlRNDJoSnJzSU5iZWducWkxCmxrYXR2Nzlzdkw0OGZHK2tGWXE1bjVmMmVJcG9WZElEMEZrVEYrVjdyVG4vTjRTbTNxc0pRZkczZjBzUXBOQXIKUitIV1dpSlBIR3dRSFlYUmtEM3BMMTE1WUI0b3J6TFY1QVkreGc0cCs1Mm9pbjR4SXBITTd4ZU4wcTMzRW5FUQoxRXNiZDZ0SEhzeUh4RDN1aUdxb1BRZyswVVdzWmRmYThtRWpybFNLSlZ6ZmtVWU1vRTllUEFpTElNN2V1SzNHCmRYbWE5M1lCRWc4bWVTc2p6elRidmMrc0p6OTNCQlNKNDNJVzRvMEM0ZkNFQjgzSEhvdGgySXlzTUhNQ0F3RUEKQVFLQ0FnQVh5Y0UvSGQ3NUR3ZWVubWsrMDVPS1BXaVpqTXlWeGk5K2JqakRNekd2SzRDVkFNU0RFMnkvS2hQZAplYi9WOURSSVZDbS9waTRLR1ZvaXpTT1F4WmREQzVyZ1ZyT0NDWTA4OW15TDFjdG94a2tobW1FMzY1SEc5TTJGCmZDSDJKc0p4QmI1a0M3b0RDYmdpUTdMSG1uMFV5bDlqaFdudmZ4RVlab3R5aXZPdEM1Nk9lcTRERTYrbkVON1cKM1JJUndwYytTQVVTL0d1cG8wVy9yYVFKdmxhQWl1YlhmVXViV1ZlYUl2aFhFbnZzZ1NLTnd0TktKUlFiRURVQQpvVTVneVN0eXlNcmN2b3Mwcm8rdE80Mk1YelBUMVhoRktuK2lqeVVvK0RZVHlxR1Zpd0RNVlhwZFZzZ3hQWmdXClNVOVRLVnFZdWdIdDZqcFZhY2dnKzhscUpKZnRwUTdTWDdaU2tteTByekluVnVFeGpPWldSVFgrMTJ0eGxMS1cKK0h3YjFzSkVUdWVwODh1WUV4eWpUblNjOUVTYnZlTHIxc0c5dmJ4elA3ZmFxQ2RHNE4wSGtXTnhWWExNQ0h6YQpuMlA4bk1aS0tpbFFhdHhIOVBEUzl3eUI0ZjJzQ2QxL0NGYU5jSjUvRERuemJPbTlNSFR0NlRwRWFURm1KdS8zClNPV1RnL0YwOWw1WTU2OFV4SVBpcElvcVkrZnZwVFo4aklGMlNIbngrMzhpTE9YdEg4Q05qc0pvQzlTR1lTYXkKT2xMcFdKaHRMMzNJcDRyRkdjS1VCY0d6VTYrYTE4MVpsQU1nM2ZWejQ2VHFHSkoyaWsxM0gzTnl6aDE3SXkwRwo0c3I5MVVCR3N5V2FGT3NkTjMvdXRUUElMaHE0YWFxSm10dFlFRldscDRRUnlseXphUUtDQVFFQThXMTZIQzJlCjdCdzJCN1dWTHhXVzBZZzhaSFB3NThDeXBlb3NsNVBXY3gwQ1Y5RWRpNzVQMzBweUdCNmlxUEFCTFBHakxCcU4KN1kxN3hOcmUzMzhaRk1sY2FmUUtZVkN1ZmZ3eDNEWnI1VGlqWGJDdFBKKzJHa1NRbysyakdib3RGZ0FUZnU5dApxMlVSTTFmbFRDVUYzaWJWQ1FJTTBXdGhmY1hSbXBaRGlSaHlrY0U2NnFoUkhJTTVpL085bXBkZ3d4UlI1Ylp4CmpMeVpVL0Z5ZTJYYi82ODR6MW13YmJ6eUo5S3lUSU4rcFpZdG8vQTZPN0RReUVYZC95UXBvTUN5ejdlWFNqZ0kKNWUrNGlXZ2F3RDhzZVgrWnRLdTJ3WVZvRzVSMnkwVXRBRFdma011aEwxRnlVK1dFaXk4REMxOEdHU0NxeFlqNApVcXUzQSt0eEtUTHVOUUtDQVFFQTVEdjZMbWo1Y3BkNDhwdW1WSmdxT25xb2ZlN3padkJ6cEJkWkNEK1BoZHNNCldrYVBqTWQwOVB1MjlTMzVZZVJWSGxRZS9yUGJOa3RrMEZXbzh0UjNFK0F2aUh2MmlMaVhzaWc1VEpuZ0JXd0QKZnhaL24xb3h3K256TS9qekJIcXJqMnR6b3A0eS9nMktONEhmQ1k1TTBGVkgrcDNHTXZURVpFYWY3cjhCamYxbgpub21hRzEvNXgxY1laZTFTUjgyVlpGRGZsWEw0aU5QWUMwK0l4SEg1WU5velhEcThBNm1WOWNxZGw4TmtIV1BIClVtL0MvYUlYRjNGc3A2RmN5N3dSTkxtZnFWK2xkZnJXc3MvS1dtaWRaUFZSNkV1d0l5SHI3cmxOUkNyS3VraWkKWTdDamFXd09XdmdHY1E1WG4wWGJZUERXcWQ2QlJCOExsNmo0a1lLWkJ3S0NBUUVBamNwNFB2aGtMOU5ad0NsYgpGcTRkUjY0MW1lR21DTlpabGF2MHlJa2hGN1pmMitlSzdMbTIrek1qMHhxYStaRUxmN1BpMjFJMUxPRTlZWjRSCjZ6MGdJOThuRVdzc2RYOEhIQ0x6dlp1UXZxMEc5VTJBVU95VDdOVjhCV3Jac1pCd1RrMTVKY0hFclRiTVpWVW4KN0JLS1liQjR5Yk9VaDZJRFBmVGlaMkg5QkJXQnBDelNSMkxYVUdHWmVLS01KckRsT1cxRHRCLzBqRzF2dDZkRQpUMGpCYm1jZ2ZGYjJrVnk0ODc2QXpRTWxiR2JKSTFGQlFqRlVUV3NMT0grcW15alJXOEU5YjI5OWVsM1NDWkZFCnRNZmxmTzM5L2Vnamk0Q29aaHBKc3BSTUc2VmlzNDJFZXQvZ3YzazY0T3VaWkNKSTJKVWc5cWE5QVFDc21mYTcKSFRFMlNRS0NBUUFJaUQxNEVyQ1FtaDBKWk13NUNWODZ4RzhjRmh5L1VtbmdUb2NqaWN6QndraVo3MTFhYy9KcApYaWVlenRNdDE2MWU3dUlodjNPSWVoVVF2TU1PSU9jNnRQelI2MkJ5Q0FTVHduRXg3ZWEwRFMrc1Jwa0t5Z0ptClFvNjIrSzJORTFEcWthZkhBb2NCZkZ3WWF5QjlhUFp5SzEzL2ZucDBXVFltVVlXVkZVcm5sZnVUcjYwMUxNZFgKcm1mWkY2QWwwd2Vzc21GSll2enJrSS9aREdZZWdleEN0S1dLNHg4NE85VEJWWXZDcXFsSmQvdHhsNEFBbjFpaApwYm5jSW1vbnE2WXhCR2QxbTMvQ0ExaVhZckU3NUFGT1R1VjYrNmxnQnRxZEdBeE5haFFlRnEwTGNRVUs0ZUUvCmdWb3NTODcydzFQS01mYTBidjhDSHU3K0FuRVliM3R0QW9JQkFRRGRDeFFrSElJSGlmclMxelRucUhVVjB1UmUKYVZzd1dzUEtTcjh6bDc3V1ZteUVzU3RmYlBaTlNRTllDd2VNOVNnbjFhOXRaN01Bc2RVb1htYU00SmVTZzlmVQo2WkN5Rm82SjBQSGhoT1ZLUmdvL2xYaXRTMFV3UjFGNFFYc0V0b0pVNEVTNVcxZEdKN1FHWmQrNDRVeTl2RDNtClVWYjZWR3h4aU01U0dleDJOTlJLSjF2V0RCTmc2M3VVSnI3bnlhNXZiRXRjT1ozNlVTSE5MdlQ3K2tMd1dFOFMKbUZFdWpEblpzSDZ5T0FYeHo3THQ1NElDSk9NaW5wcTBZenFOWTU4UmpQWGMyalV1cmliWXhqQkJiRjZVSWE0NgpTOEg5NGZBVXlPQ0pvNmJUTTFnN2IwSVVmUlQxME1mS0RtaE5IeDFoS1VUY0dZUkhEcDluc00xcXp2cFQKLS0tLS1FTkQgUlNBIFBSSVZBVEUgS0VZLS0tLS0K"
---
# Source: lizardcd/templates/agent/secret.yaml
kind: Secret
apiVersion: v1
metadata:
  name: lizardcd-token
  annotations:
    kubernetes.io/service-account.name: release-name-lizardcd-agent
type: kubernetes.io/service-account-token
---
# Source: lizardcd/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: lizardcd
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: lizardcd
    app.kubernetes.io/version: 2.0.0
    helm.sh/chart: lizardcd-2.0.0

data:
  nginx.conf: |
    user  nginx;
    worker_processes  auto;
    error_log  /var/log/nginx/error.log warn;
    pid        /tmp/nginx.pid;
    events {
      worker_connections  8192;
    }
    http {
      include       /etc/nginx/mime.types;
      default_type  application/octet-stream;
      log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                        '$status $body_bytes_sent "$http_referer" '
                        '"$http_user_agent" "$http_x_forwarded_for" '
                        '"$upstream_addr" $request_time $upstream_response_time';
      access_log  /var/log/nginx/access.log  main;
      sendfile        on;
      keepalive_timeout  65;
      client_max_body_size 100m;
      server {
        listen       80;
        server_name  localhost;
        
        location / {
          root   /usr/share/nginx/html;
          index  index.html;
          try_files $uri $uri/ /index.html;
        }
        error_page   500 502 503 504  /50x.html;
        location = /50x.html {
          root   /usr/share/nginx/html;
        }

        # Todo: To be removed after frondend adjusted to real service labels.
        location /kubernetes {
          # proxy_http_version 1.1;
          proxy_set_header Host $proxy_host;
          proxy_set_header X-Real-IP $remote_addr;
          proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
          proxy_pass http://release-name-lizardcd-server:5117;
        }
        location /lizardcd {
          # proxy_http_version 1.1;
          proxy_set_header Host $proxy_host;
          proxy_set_header X-Real-IP $remote_addr;
          proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
          proxy_pass http://release-name-lizardcd-server:5117;
        }
        location /db {
          # proxy_http_version 1.1;
          proxy_set_header Host $proxy_host;
          proxy_set_header X-Real-IP $remote_addr;
          proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
          proxy_pass http://release-name-lizardcd-server:5117;
        }
        location /auth {
          # proxy_http_version 1.1;
          proxy_set_header Host $proxy_host;
          proxy_set_header X-Real-IP $remote_addr;
          proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
          proxy_pass http://release-name-lizardcd-server:5117;
        }
        location /swagger {
          # proxy_http_version 1.1;
          proxy_set_header Host $proxy_host;
          proxy_set_header X-Real-IP $remote_addr;
          proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
          proxy_pass http://release-name-lizardcd-ui:8080/;
        }
        location /server-static {
          # proxy_http_version 1.1;
          proxy_set_header Host $proxy_host;
          proxy_set_header X-Real-IP $remote_addr;
          proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
          proxy_pass http://release-name-lizardcd-server:5117;
        }
      }
    }
  lizardcd-server.yaml: |
    Name: lizardServer
    Host: 0.0.0.0
    Port: 5117
    Timeout: 60000
    Log:
      Encoding: plain
      Level: info 
    Prometheus:
      Host: 0.0.0.0
      Port: 15117
      Path: /metrics
    Auth:
      AccessSecret: wLnOk8keh/WO5u7lX8H1dB1/mcuHvnI/jfWCMXMPg9o=
      AccessExpire: 86400
    Etcd:
      Address: "release-name-etcd-0.release-name-etcd-headless.default.svc.cluster.local:2379,release-name-etcd-1.release-name-etcd-headless.default.svc.cluster.local:2379,release-name-etcd-2.release-name-etcd-headless.default.svc.cluster.local:2379"
    Sqlite: /var/data/lizardcd/lizardcd.db
  lizardcd-agent.yaml: |
    Name: LizardAgent
    ListenOn: 0.0.0.0:5017
    Timeout: 60000
    Log:
      Encoding: plain
      Level: info 
    Prometheus:
      Host: 0.0.0.0
      Port: 15017
      Path: /metrics
    etcd:
      hosts:
        - release-name-etcd-0.release-name-etcd-headless.default.svc.cluster.local:2379
        - release-name-etcd-1.release-name-etcd-headless.default.svc.cluster.local:2379
        - release-name-etcd-2.release-name-etcd-headless.default.svc.cluster.local:2379
      Key: lizardcd-agent.default.k8s
    KubernetesSecretPrefix: "lizardcd-token"
---
# Source: lizardcd/templates/server-job/pvc.yaml
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: lizardcd-data
  labels:
    app.kubernetes.io/instance: lizardcd
    app.kubernetes.io/name: lizardcd
spec:
  accessModes:
  - "ReadWriteMany"
  resources:
    requests:
      storage: "8Gi"
  storageClassName: nfs-client
---
# Source: lizardcd/templates/agent/role.yaml
kind: Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: lizardcd-agent-role
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: lizardcd
    app.kubernetes.io/version: 2.0.0
    helm.sh/chart: lizardcd-2.0.0
    app.kubernetes.io/part-of: lizardcd
    app.kubernetes.io/component: agent
rules:
  - apiGroups:
      - ""
      - apps
      - extensions
      - events.k8s.io
      - networking.k8s.io
    resources:
      - "*"
    verbs:
      - get
      - list
      - watch
      - update
      - create
      - patch
      - delete
---
# Source: lizardcd/templates/agent/rolebindding.yaml
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: release-name-lizardcd-agent
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: lizardcd
    app.kubernetes.io/version: 2.0.0
    helm.sh/chart: lizardcd-2.0.0
    app.kubernetes.io/part-of: lizardcd
    app.kubernetes.io/component: agent
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: lizardcd-agent-role
subjects:
  - kind: ServiceAccount
    name: release-name-lizardcd-agent
    namespace: "default"
---
# Source: lizardcd/charts/etcd/templates/svc-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-etcd-headless
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: etcd
    app.kubernetes.io/version: 3.5.12
    helm.sh/chart: etcd-9.14.2
    app.kubernetes.io/component: etcd
  annotations:
    service.alpha.kubernetes.io/tolerate-unready-endpoints: "true"
spec:
  type: ClusterIP
  clusterIP: None
  publishNotReadyAddresses: true
  ports:
    - name: client
      port: 2379
      targetPort: client
    - name: peer
      port: 2380
      targetPort: peer
  selector:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/name: etcd
    app.kubernetes.io/component: etcd
---
# Source: lizardcd/charts/etcd/templates/svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-etcd
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: etcd
    app.kubernetes.io/version: 3.5.12
    helm.sh/chart: etcd-9.14.2
    app.kubernetes.io/component: etcd
spec:
  type: ClusterIP
  sessionAffinity: None
  ports:
    - name: "client"
      port: 2379
      targetPort: client
      nodePort: null
    - name: "peer"
      port: 2380
      targetPort: peer
      nodePort: null
  selector:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/name: etcd
    app.kubernetes.io/component: etcd
---
# Source: lizardcd/templates/agent/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-lizardcd-agent
  labels:
    helm.sh/chart: lizardcd-2.0.0
    app: release-name-lizardcd-agent
    app.kubernetes.io/name: release-name-lizardcd-agent
    app.kubernetes.io/instance: release-name
    app: release-name-lizardcd-agent
    app.kubernetes.io/version: "2.0.0"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  sessionAffinity: None
  ports:
    - name: http
      port: 5017
      targetPort: grpc
    - name: metrics 
      port: 15017
      targetPort: metrics
  selector:
      app.kubernetes.io/name: release-name-lizardcd-agent
      app.kubernetes.io/instance: release-name
      app: release-name-lizardcd-agent
---
# Source: lizardcd/templates/server/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-lizardcd-server
  labels:
    helm.sh/chart: lizardcd-2.0.0
    app: release-name-lizardcd-server
    app.kubernetes.io/name: release-name-lizardcd-server
    app.kubernetes.io/instance: release-name
    app: release-name-lizardcd-server
    app.kubernetes.io/version: "2.0.0"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  sessionAffinity: None
  ports:
    - name: http
      port: 5117
      targetPort: grpc
    - name: metrics 
      port: 15117
      targetPort: metrics
  selector:
      app.kubernetes.io/name: release-name-lizardcd-server
      app.kubernetes.io/instance: release-name
      app: release-name-lizardcd-server
---
# Source: lizardcd/templates/ui/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-lizardcd-ui
  labels:
    helm.sh/chart: lizardcd-2.0.0
    app: release-name-lizardcd-ui
    app.kubernetes.io/name: release-name-lizardcd-ui
    app.kubernetes.io/instance: release-name
    app: release-name-lizardcd-ui
    app.kubernetes.io/version: "2.0.0"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  sessionAffinity: None
  ports:
    - name: http
      port: 8080
      protocol: TCP
      targetPort: 8080
    - name: web
      port: 80
      protocol: TCP
      targetPort: http
      nodePort: null
  selector:
      app.kubernetes.io/name: release-name-lizardcd-ui
      app.kubernetes.io/instance: release-name
      app: release-name-lizardcd-ui
---
# Source: lizardcd/templates/agent/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-lizardcd-agent
  labels:
    helm.sh/chart: lizardcd-2.0.0
    app: release-name-lizardcd-agent
    app.kubernetes.io/name: release-name-lizardcd-agent
    app.kubernetes.io/instance: release-name
    app: release-name-lizardcd-agent
    app.kubernetes.io/version: "2.0.0"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  strategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/name: release-name-lizardcd-agent
      app.kubernetes.io/instance: release-name
      app: release-name-lizardcd-agent
  template:
    metadata:
      labels:
        app.kubernetes.io/name: release-name-lizardcd-agent
        app.kubernetes.io/instance: release-name
        app: release-name-lizardcd-agent
    spec:
      
      serviceAccountName: release-name-lizardcd-agent
      securityContext:
        fsGroup: 1001
        fsGroupChangePolicy: Always
        supplementalGroups: []
        sysctls: []
      volumes:
        - name: host-time 
          hostPath:
            path: /etc/localtime
        - name: agent-config
          configMap:
            name: lizardcd
      containers:
        - name: release-name-lizardcd-agent-container
          image: "docker.io/lizardcd/lizardcd-agent:v1.0.0"
          imagePullPolicy: IfNotPresent
          args:
            - '-f'
            - '/etc/config/lizardcd-agent.yaml'
          ports:
            - name: grpc
              containerPort: 5017
              protocol: TCP
            - name: metrics
              containerPort: 15017
              protocol: TCP
          volumeMounts:
            - name: host-time 
              mountPath: /etc/localtime 
            - name: agent-config 
              mountPath: /etc/config/lizardcd-agent.yaml
              subPath: lizardcd-agent.yaml
          livenessProbe:
            failureThreshold: 3
            initialDelaySeconds: 10
            periodSeconds: 30
            successThreshold: 1
            timeoutSeconds: 5
            httpGet:
              path: /metrics
              port: 15017
              scheme: HTTP
          readinessProbe:
            failureThreshold: 3
            initialDelaySeconds: 10
            periodSeconds: 30
            successThreshold: 1
            timeoutSeconds: 5
            httpGet:
              path: /metrics
              port: 15017
              scheme: HTTP
---
# Source: lizardcd/templates/server/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-lizardcd-server
  labels:
    helm.sh/chart: lizardcd-2.0.0
    app: release-name-lizardcd-server
    app.kubernetes.io/name: release-name-lizardcd-server
    app.kubernetes.io/instance: release-name
    app: release-name-lizardcd-server
    app.kubernetes.io/version: "2.0.0"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  strategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/name: release-name-lizardcd-server
      app.kubernetes.io/instance: release-name
      app: release-name-lizardcd-server
  template:
    metadata:
      labels:
        app.kubernetes.io/name: release-name-lizardcd-server
        app.kubernetes.io/instance: release-name
        app: release-name-lizardcd-server
    spec:
      
      serviceAccountName: release-name-lizardcd-server
      securityContext:
        fsGroup: 1001
        fsGroupChangePolicy: Always
        supplementalGroups: []
        sysctls: []
      volumes:
        - name: host-time 
          hostPath:
            path: /etc/localtime
        - name: lizardcd-data
          persistentVolumeClaim:
            claimName: lizardcd-data
        - name: server-config
          configMap:
            name: lizardcd
      containers:
        - name: release-name-lizardcd-server-container
          image: "docker.io/lizardcd/lizardcd-server:v1.0.0"
          imagePullPolicy: IfNotPresent
          args:
            - '-f'
            - '/etc/config/lizardcd-server.yaml'
          ports:
            - name: grpc
              containerPort: 5117
              protocol: TCP
            - name: metrics
              containerPort: 15117
              protocol: TCP
          volumeMounts:
            - name: host-time 
              mountPath: /etc/localtime 
            - name: lizardcd-data
              mountPath: /var/data/lizardcd/
            - name: server-config 
              mountPath: /etc/config/lizardcd-server.yaml
              subPath: lizardcd-server.yaml
          livenessProbe:
            failureThreshold: 3
            initialDelaySeconds: 10
            periodSeconds: 30
            successThreshold: 1
            timeoutSeconds: 5
            httpGet:
              path: /metrics
              port: 15117
              scheme: HTTP
          readinessProbe:
            failureThreshold: 3
            initialDelaySeconds: 10
            periodSeconds: 30
            successThreshold: 1
            timeoutSeconds: 5
            httpGet:
              path: /metrics
              port: 15117
              scheme: HTTP
---
# Source: lizardcd/templates/ui/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-lizardcd-ui
  labels:
    helm.sh/chart: lizardcd-2.0.0
    app: release-name-lizardcd-ui
    app.kubernetes.io/name: release-name-lizardcd-ui
    app.kubernetes.io/instance: release-name
    app: release-name-lizardcd-ui
    app.kubernetes.io/version: "2.0.0"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  strategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/name: release-name-lizardcd-ui
      app.kubernetes.io/instance: release-name
      app: release-name-lizardcd-ui
  template:
    metadata:
      labels:
        app.kubernetes.io/name: release-name-lizardcd-ui
        app.kubernetes.io/instance: release-name
        app: release-name-lizardcd-ui
    spec:
      
      serviceAccountName: release-name-lizardcd-ui
      securityContext:
        fsGroup: 1001
        fsGroupChangePolicy: Always
        supplementalGroups: []
        sysctls: []
      volumes:
        - name: host-time 
          hostPath:
            path: /etc/localtime
        - name: ui-config
          configMap:
            name: lizardcd
      containers:
        - name: release-name-lizardcd-ui-container
          image: "docker.io/lizardcd/lizardcd-ui:v1.0.0"
          imagePullPolicy: IfNotPresent
          ports:
            - name: http
              containerPort: 80
              protocol: TCP
          volumeMounts:
            - name: host-time 
              mountPath: /etc/localtime 
            - name: ui-config 
              mountPath: /etc/nginx/nginx.conf
              subPath: nginx.conf
          resources:
            {}
        - name: swagger-ui-container
          image: "docker.io/swaggerapi/swagger-ui:v5.17.1"
          imagePullPolicy: IfNotPresent
          ports:
            - name: http
              containerPort: 8080
              protocol: TCP
          env: 
            - name: SWAGGER_JSON_URL
              value: /server-static/docs/swagger.json/
---
# Source: lizardcd/charts/etcd/templates/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: release-name-etcd
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: etcd
    app.kubernetes.io/version: 3.5.12
    helm.sh/chart: etcd-9.14.2
    app.kubernetes.io/component: etcd
spec:
  replicas: 3
  selector:
    matchLabels:
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/name: etcd
      app.kubernetes.io/component: etcd
  serviceName: release-name-etcd-headless
  podManagementPolicy: Parallel
  updateStrategy:
    type: RollingUpdate
  template:
    metadata:
      labels:
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: etcd
        app.kubernetes.io/version: 3.5.12
        helm.sh/chart: etcd-9.14.2
        app.kubernetes.io/component: etcd
      annotations:
        checksum/token-secret: 29f9986e26c10adfe3075eb9704b7e64de41f9b815069e66299ebf6f70c0a5d6
    spec:
      
      automountServiceAccountToken: false
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/instance: release-name
                    app.kubernetes.io/name: etcd
                    app.kubernetes.io/component: etcd
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      securityContext:
        fsGroup: 1001
        fsGroupChangePolicy: Always
        supplementalGroups: []
        sysctls: []
      serviceAccountName: "release-name-etcd"
      containers:
        - name: etcd
          image: docker.io/bitnami/etcd:3.4.31-debian-12-r3
          imagePullPolicy: "IfNotPresent"
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            privileged: false
            readOnlyRootFilesystem: false
            runAsGroup: 0
            runAsNonRoot: true
            runAsUser: 1001
            seccompProfile:
              type: RuntimeDefault
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: MY_POD_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
            - name: MY_POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: MY_STS_NAME
              value: "release-name-etcd"
            - name: ETCDCTL_API
              value: "3"
            - name: ETCD_ON_K8S
              value: "yes"
            - name: ETCD_START_FROM_SNAPSHOT
              value: "no"
            - name: ETCD_DISASTER_RECOVERY
              value: "no"
            - name: ETCD_NAME
              value: "$(MY_POD_NAME)"
            - name: ETCD_DATA_DIR
              value: "/bitnami/etcd/data"
            - name: ETCD_LOG_LEVEL
              value: "info"
            - name: ALLOW_NONE_AUTHENTICATION
              value: "yes"
            - name: ETCD_AUTH_TOKEN
              value: "jwt,priv-key=/opt/bitnami/etcd/certs/token/jwt-token.pem,sign-method=RS256,ttl=10m"
            - name: ETCD_ADVERTISE_CLIENT_URLS
              value: "http://$(MY_POD_NAME).release-name-etcd-headless.default.svc.cluster.local:2379,http://release-name-etcd.default.svc.cluster.local:2379"
            - name: ETCD_LISTEN_CLIENT_URLS
              value: "http://0.0.0.0:2379"
            - name: ETCD_INITIAL_ADVERTISE_PEER_URLS
              value: "http://$(MY_POD_NAME).release-name-etcd-headless.default.svc.cluster.local:2380"
            - name: ETCD_LISTEN_PEER_URLS
              value: "http://0.0.0.0:2380"
            - name: ETCD_INITIAL_CLUSTER_TOKEN
              value: "etcd-cluster-k8s"
            - name: ETCD_INITIAL_CLUSTER_STATE
              value: "new"
            - name: ETCD_INITIAL_CLUSTER
              value: "release-name-etcd-0=http://release-name-etcd-0.release-name-etcd-headless.default.svc.cluster.local:2380,release-name-etcd-1=http://release-name-etcd-1.release-name-etcd-headless.default.svc.cluster.local:2380,release-name-etcd-2=http://release-name-etcd-2.release-name-etcd-headless.default.svc.cluster.local:2380"
            - name: ETCD_CLUSTER_DOMAIN
              value: "release-name-etcd-headless.default.svc.cluster.local"
          envFrom:
          ports:
            - name: client
              containerPort: 2379
              protocol: TCP
            - name: peer
              containerPort: 2380
              protocol: TCP
          livenessProbe:
            exec:
              command:
                - /opt/bitnami/scripts/etcd/healthcheck.sh
            initialDelaySeconds: 60
            periodSeconds: 30
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 5
          readinessProbe:
            exec:
              command:
                - /opt/bitnami/scripts/etcd/healthcheck.sh
            initialDelaySeconds: 60
            periodSeconds: 10
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 5
          lifecycle:
            preStop:
              exec:
                command:
                  - /opt/bitnami/scripts/etcd/prestop.sh
          volumeMounts:
            - name: empty-dir
              mountPath: /opt/bitnami/etcd/conf/
              subPath: app-conf-dir
            - name: empty-dir
              mountPath: /tmp
              subPath: tmp-dir
            - name: data
              mountPath: /bitnami/etcd
            - name: etcd-jwt-token
              mountPath: /opt/bitnami/etcd/certs/token/
              readOnly: true
      volumes:
        - name: empty-dir
          emptyDir: {}
        - name: etcd-jwt-token
          secret:
            secretName: release-name-etcd-jwt-token
            defaultMode: 256
  volumeClaimTemplates:
    - metadata:
        name: data
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: "8Gi"
        storageClassName: nfs-client
---
# Source: lizardcd/templates/server-job/server-job.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: release-name-lizardcd-initjob
  labels:
    app.kubernetes.io/name: release-name-lizardcd-initjob
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: 2.0.0
    app.kubernetes.io/component: database
    app.kubernetes.io/part-of: lizardcd
  annotations:
    "helm.sh/hook": post-install
    "helm.sh/hook-weight": "5"
spec:
  backoffLimit: 3
  template:
    metadata:
      name: release-name-lizardcd-initjob
      labels:
        app.kubernetes.io/name: release-name-lizardcd-initjob
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/version: 2.0.0
        app.kubernetes.io/component: database
        app.kubernetes.io/part-of: lizardcd
    spec:
      volumes:
        - name: lizardcd-data
          persistentVolumeClaim:
            claimName: lizardcd-data
      serviceAccountName: release-name-lizardcd-initjob
      restartPolicy: "OnFailure"
      containers:
        - name: container-migrate
          image: "docker.io/lizardcd/migrate:v1.0.0"
          imagePullPolicy: IfNotPresent
          args:
            - '-d'
            - /var/data/lizardcd/lizardcd.db
          volumeMounts:
            - name: lizardcd-data
              mountPath: /var/data/lizardcd
