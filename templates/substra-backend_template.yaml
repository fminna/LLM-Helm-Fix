---
# Source: substra-backend/charts/redis/templates/networkpolicy.yaml
kind: NetworkPolicy
apiVersion: networking.k8s.io/v1
metadata:
  name: release-name-redis
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: redis
    app.kubernetes.io/version: 7.2.4
    helm.sh/chart: redis-18.17.0
spec:
  podSelector:
    matchLabels:
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/name: redis
  policyTypes:
    - Ingress
    - Egress
  egress:
    - {}
  ingress:
    # Allow inbound connections
    - ports:
        - port: 6379
---
# Source: substra-backend/templates/network-task-deny-all.yaml
# Deny ALL networking in launched substra ml task
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: release-name-substra-backend-deny-ingress
  labels:
    
    helm.sh/chart: substra-backend-26.4.0
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.45.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: substra-backend
spec:
  podSelector:
    matchLabels:
      substra.ai/pod-type: compute-task
  policyTypes:
  - Ingress
  - Egress
---
# Source: substra-backend/charts/minio/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: release-name-minio
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: minio
    app.kubernetes.io/version: 2023.9.30
    helm.sh/chart: minio-12.8.12
automountServiceAccountToken: true
secrets:
  - name: release-name-minio
---
# Source: substra-backend/charts/redis/templates/master/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
automountServiceAccountToken: false
metadata:
  name: release-name-redis-master
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: redis
    app.kubernetes.io/version: 7.2.4
    helm.sh/chart: redis-18.17.0
---
# Source: substra-backend/templates/rbac.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: release-name-substra-backend-worker
  labels:
    
    helm.sh/chart: substra-backend-26.4.0
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.45.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: substra-backend
    app.kubernetes.io/name: substra-backend
---
# Source: substra-backend/templates/rbac.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: release-name-substra-backend-builder
  labels:
    
    helm.sh/chart: substra-backend-26.4.0
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.45.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: substra-backend
    app.kubernetes.io/name: substra-backend
---
# Source: substra-backend/templates/rbac.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: release-name-substra-backend-event
  labels:
    
    helm.sh/chart: substra-backend-26.4.0
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.45.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: substra-backend
    app.kubernetes.io/name: substra-backend
---
# Source: substra-backend/templates/rbac.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: release-name-substra-backend-api-event
  labels:
    
    helm.sh/chart: substra-backend-26.4.0
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.45.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: substra-backend
    app.kubernetes.io/name: substra-backend
---
# Source: substra-backend/charts/docker-registry/templates/secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: release-name-docker-registry-secret
  namespace: default
  labels:
    app: docker-registry
    chart: docker-registry-2.2.2
    heritage: Helm
    release: release-name
type: Opaque
data:
  haSharedSecret: "a1BVTDNvbWdDNWJCYnAyNg=="
  proxyUsername: ""
  proxyPassword: ""
---
# Source: substra-backend/charts/minio/templates/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: release-name-minio
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: minio
    app.kubernetes.io/version: 2023.9.30
    helm.sh/chart: minio-12.8.12
type: Opaque
data:
  root-user: "bWluaW8="
  root-password: "bWluaW8xMjM0"
---
# Source: substra-backend/charts/postgresql/templates/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: release-name-postgresql
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: 16.0.0
    helm.sh/chart: postgresql-13.1.2
type: Opaque
data:
  postgres-password: "cG9zdGdyZXM="
  # We don't auto-generate LDAP password when it's not provided as we do for other passwords
---
# Source: substra-backend/charts/redis/templates/secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: release-name-redis
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: redis
    app.kubernetes.io/version: 7.2.4
    helm.sh/chart: redis-18.17.0
type: Opaque
data:
  redis-password: "cmVkaXM="
---
# Source: substra-backend/templates/secret-add-account.yaml
apiVersion: v1
kind: Secret
metadata:
  name: release-name-substra-backend-add-account
  labels:
    
    helm.sh/chart: substra-backend-26.4.0
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.45.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: substra-backend
    app.kubernetes.io/name: substra-backend-add-account
data:
  users: ""
  incoming_organizations: ""
  outgoing_organizations: ""
---
# Source: substra-backend/templates/secret-database.yaml
apiVersion: v1
kind: Secret
metadata:
  name: release-name-substra-backend-database
  labels:
    helm.sh/chart: substra-backend-26.4.0
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.45.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: substra-backend
type: Opaque
stringData:
  DATABASE_PASSWORD: "postgres"
  DATABASE_USERNAME: "postgres"
---
# Source: substra-backend/templates/secret-objectstore.yaml
apiVersion: v1
kind: Secret
metadata:
  name: release-name-substra-backend-objectstore
  labels:
    
    helm.sh/chart: substra-backend-26.4.0
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.45.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: substra-backend
    app.kubernetes.io/name: substra-backend
type: Opaque
data:
  OBJECTSTORE_ACCESSKEY: bWluaW8=
  OBJECTSTORE_SECRETKEY: bWluaW8xMjM0
---
# Source: substra-backend/templates/secret-redis.yaml
apiVersion: v1
kind: Secret
metadata:
  name: release-name-substra-backend-redis
  labels:
    helm.sh/chart: substra-backend-26.4.0
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.45.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: substra-backend
type: Opaque
data:
  CELERY_BROKER_PASSWORD: "cmVkaXM="
---
# Source: substra-backend/templates/secret-server-key.yaml
apiVersion: v1
kind: Secret
metadata:
  name: release-name-substra-backend-server-key
  labels:
    helm.sh/chart: substra-backend-26.4.0
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.45.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: substra-backend
type: Opaque
stringData:
  SECRET_KEY: "eCVfTfCXmRusR0JDUL483MI7e3uxDM26nJbXcHqqarWroqeywnO2gJgo8K9fE2kMPz437gVukVj2h6eMF8aMNh7ZIS5G5qkWLC1EU7rXVPuPpcxt0o8WP6uDaR0N9t6P"
---
# Source: substra-backend/charts/docker-registry/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-docker-registry-config
  namespace: default
  labels:
    app: docker-registry
    chart: docker-registry-2.2.2
    heritage: Helm
    release: release-name
data:
  config.yml: |-
    health:
      storagedriver:
        enabled: true
        interval: 10s
        threshold: 3
    http:
      addr: :5000
      debug:
        addr: :5001
        prometheus:
          enabled: false
          path: /metrics
      headers:
        X-Content-Type-Options:
        - nosniff
    log:
      fields:
        service: registry
    storage:
      cache:
        blobdescriptor: inmemory
    version: 0.1
---
# Source: substra-backend/charts/redis/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-redis-configuration
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: redis
    app.kubernetes.io/version: 7.2.4
    helm.sh/chart: redis-18.17.0
data:
  redis.conf: |-
    # User-supplied common configuration:
    # Enable AOF https://redis.io/topics/persistence
    appendonly yes
    # Disable RDB persistence since AOF persistence is enabled
    save ""
    # End of common configuration
  master.conf: |-
    dir /data
    # User-supplied master configuration:
    rename-command FLUSHDB ""
    rename-command FLUSHALL ""
    # End of master configuration
  replica.conf: |-
    dir /data
    # User-supplied replica configuration:
    rename-command FLUSHDB ""
    rename-command FLUSHALL ""
    # End of replica configuration
---
# Source: substra-backend/charts/redis/templates/health-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-redis-health
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: redis
    app.kubernetes.io/version: 7.2.4
    helm.sh/chart: redis-18.17.0
data:
  ping_readiness_local.sh: |-
    #!/bin/bash

    [[ -f $REDIS_PASSWORD_FILE ]] && export REDIS_PASSWORD="$(< "${REDIS_PASSWORD_FILE}")"
    [[ -n "$REDIS_PASSWORD" ]] && export REDISCLI_AUTH="$REDIS_PASSWORD"
    response=$(
      timeout -s 15 $1 \
      redis-cli \
        -h localhost \
        -p $REDIS_PORT \
        ping
    )
    if [ "$?" -eq "124" ]; then
      echo "Timed out"
      exit 1
    fi
    if [ "$response" != "PONG" ]; then
      echo "$response"
      exit 1
    fi
  ping_liveness_local.sh: |-
    #!/bin/bash

    [[ -f $REDIS_PASSWORD_FILE ]] && export REDIS_PASSWORD="$(< "${REDIS_PASSWORD_FILE}")"
    [[ -n "$REDIS_PASSWORD" ]] && export REDISCLI_AUTH="$REDIS_PASSWORD"
    response=$(
      timeout -s 15 $1 \
      redis-cli \
        -h localhost \
        -p $REDIS_PORT \
        ping
    )
    if [ "$?" -eq "124" ]; then
      echo "Timed out"
      exit 1
    fi
    responseFirstWord=$(echo $response | head -n1 | awk '{print $1;}')
    if [ "$response" != "PONG" ] && [ "$responseFirstWord" != "LOADING" ] && [ "$responseFirstWord" != "MASTERDOWN" ]; then
      echo "$response"
      exit 1
    fi
  ping_readiness_master.sh: |-
    #!/bin/bash

    [[ -f $REDIS_MASTER_PASSWORD_FILE ]] && export REDIS_MASTER_PASSWORD="$(< "${REDIS_MASTER_PASSWORD_FILE}")"
    [[ -n "$REDIS_MASTER_PASSWORD" ]] && export REDISCLI_AUTH="$REDIS_MASTER_PASSWORD"
    response=$(
      timeout -s 15 $1 \
      redis-cli \
        -h $REDIS_MASTER_HOST \
        -p $REDIS_MASTER_PORT_NUMBER \
        ping
    )
    if [ "$?" -eq "124" ]; then
      echo "Timed out"
      exit 1
    fi
    if [ "$response" != "PONG" ]; then
      echo "$response"
      exit 1
    fi
  ping_liveness_master.sh: |-
    #!/bin/bash

    [[ -f $REDIS_MASTER_PASSWORD_FILE ]] && export REDIS_MASTER_PASSWORD="$(< "${REDIS_MASTER_PASSWORD_FILE}")"
    [[ -n "$REDIS_MASTER_PASSWORD" ]] && export REDISCLI_AUTH="$REDIS_MASTER_PASSWORD"
    response=$(
      timeout -s 15 $1 \
      redis-cli \
        -h $REDIS_MASTER_HOST \
        -p $REDIS_MASTER_PORT_NUMBER \
        ping
    )
    if [ "$?" -eq "124" ]; then
      echo "Timed out"
      exit 1
    fi
    responseFirstWord=$(echo $response | head -n1 | awk '{print $1;}')
    if [ "$response" != "PONG" ] && [ "$responseFirstWord" != "LOADING" ]; then
      echo "$response"
      exit 1
    fi
  ping_readiness_local_and_master.sh: |-
    script_dir="$(dirname "$0")"
    exit_status=0
    "$script_dir/ping_readiness_local.sh" $1 || exit_status=$?
    "$script_dir/ping_readiness_master.sh" $1 || exit_status=$?
    exit $exit_status
  ping_liveness_local_and_master.sh: |-
    script_dir="$(dirname "$0")"
    exit_status=0
    "$script_dir/ping_liveness_local.sh" $1 || exit_status=$?
    "$script_dir/ping_liveness_master.sh" $1 || exit_status=$?
    exit $exit_status
---
# Source: substra-backend/charts/redis/templates/scripts-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-redis-scripts
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: redis
    app.kubernetes.io/version: 7.2.4
    helm.sh/chart: redis-18.17.0
data:
  start-master.sh: |
    #!/bin/bash

    [[ -f $REDIS_PASSWORD_FILE ]] && export REDIS_PASSWORD="$(< "${REDIS_PASSWORD_FILE}")"
    if [[ -f /opt/bitnami/redis/mounted-etc/master.conf ]];then
        cp /opt/bitnami/redis/mounted-etc/master.conf /opt/bitnami/redis/etc/master.conf
    fi
    if [[ -f /opt/bitnami/redis/mounted-etc/redis.conf ]];then
        cp /opt/bitnami/redis/mounted-etc/redis.conf /opt/bitnami/redis/etc/redis.conf
    fi
    ARGS=("--port" "${REDIS_PORT}")
    ARGS+=("--requirepass" "${REDIS_PASSWORD}")
    ARGS+=("--masterauth" "${REDIS_PASSWORD}")
    ARGS+=("--include" "/opt/bitnami/redis/etc/redis.conf")
    ARGS+=("--include" "/opt/bitnami/redis/etc/master.conf")
    exec redis-server "${ARGS[@]}"
---
# Source: substra-backend/templates/configmap-database.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-substra-backend-database
  labels:
    helm.sh/chart: substra-backend-26.4.0
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.45.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: substra-backend
data:
  DATABASE_DATABASE: !!str substra
  DATABASE_HOSTNAME: !!str release-name-postgresql.default
  DATABASE_PORT: !!str 5432
---
# Source: substra-backend/templates/configmap-oidc.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-substra-backend-oidc
  labels:
    helm.sh/chart: substra-backend-26.4.0
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.45.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: substra-backend
data:
  OIDC_ENABLED: "false"
  OIDC_USERS_APPEND_DOMAIN: "false"
  OIDC_USERS_DEFAULT_CHANNEL: ""
  OIDC_USERS_MUST_BE_APPROVED: ""
  OIDC_USERS_LOGIN_VALIDITY_DURATION: "3600"
  OIDC_USERS_USE_REFRESH_TOKEN: "true"
  OIDC_RP_SIGN_ALGO: "RS256"
  OIDC_OP_URL: ""
  OIDC_OP_DISPLAY_NAME: ""
  OIDC_OP_AUTHORIZATION_ENDPOINT: ""
  OIDC_OP_TOKEN_ENDPOINT: ""
  OIDC_OP_USER_ENDPOINT: ""
  OIDC_OP_JWKS_URI: ""
---
# Source: substra-backend/templates/configmap-orchestrator.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-substra-backend-orchestrator
  labels:
    
    helm.sh/chart: substra-backend-26.4.0
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.45.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: substra-backend
    app.kubernetes.io/name: substra-backend
data:
  ORCHESTRATOR_HOST: "orchestrator.local"
  ORCHESTRATOR_PORT: "9000"
  ORCHESTRATOR_TLS_ENABLED: "false"
  ORCHESTRATOR_MTLS_ENABLED: "false"
  ORCHESTRATOR_TLS_SERVER_CACERT_PATH: "/var/substra/orchestrator/tls/server/ca.crt"
  ORCHESTRATOR_TLS_CLIENT_CERT_PATH: "/var/substra/orchestrator/tls/client/tls.crt"
  ORCHESTRATOR_TLS_CLIENT_KEY_PATH: "/var/substra/orchestrator/tls/client/tls.key"

  # Organization identity
  MSP_ID: "OwkinPeerMSP"
  # Orchestrator channels configuration
  CHANNELS: "[{\"mychannel\":{\"model_export_enabled\":false,\"restricted\":false}}]"
---
# Source: substra-backend/templates/configmap-redis.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-substra-backend-redis
  labels:
    helm.sh/chart: substra-backend-26.4.0
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.45.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: substra-backend
data:
  CELERY_BROKER_USER: "default"
  CELERY_BROKER_HOST: release-name-redis-master
  CELERY_BROKER_PORT: "6379"
---
# Source: substra-backend/templates/configmap-registry.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-substra-backend-registry
  labels:
    helm.sh/chart: substra-backend-26.4.0
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.45.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: substra-backend
data:
  REGISTRY_IS_LOCAL: "true"
  REGISTRY: release-name-docker-registry:5000
  REGISTRY_SERVICE_NAME: release-name-docker-registry
  REGISTRY_SCHEME: http
  REGISTRY_PULL_DOMAIN: 127.0.0.1
  USER_IMAGE_REPOSITORY: substra/user-image
---
# Source: substra-backend/templates/configmap-server-uwsgi.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-substra-backend-server-uwsgi
  labels:
    
    helm.sh/chart: substra-backend-26.4.0
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.45.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: substra-backend
    app.kubernetes.io/name: substra-backend
data:
  uwsgi.ini: |
    [uwsgi]
    module                        = backend.wsgi
    env                           = DJANGO_SETTINGS_MODULE=backend.settings.server.prod
    static-map                    = /static=/usr/src/app/backend/statics

    master                        = 1
    processes                     = 20
    threads                       = 10

    http-socket                   = :8000

    need-app                      = true
    socket-timeout                = 300
    http-timeout                  = 300
    http-keepalive                = 300
    harakiri                      = 300
    harakiri-verbose              = true
    die-on-term                   = 1
    vacuum                        = true
    buffer-size                   = 65535

    add-header                    = Connection: Keep-Alive
    ignore-sigpipe                = true
    ignore-write-errors           = true
    disable-write-exception       = true
    wsgi-disable-file-wrapper     = true
    ; lazy-apps is required to prevent django-prometheus from leaking file descriptors
    ; https://github.com/korfuri/django-prometheus/blob/49d0e4f14947af1f46716ed8cbca0c6451301ee3/documentation/exports.md?plain=1#L132-L134
    lazy-apps                     = true
---
# Source: substra-backend/templates/configmap-settings.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-substra-backend-settings
  labels:
    helm.sh/chart: substra-backend-26.4.0
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.45.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: substra-backend
data:
  ORG_NAME: "owkin"
  MEDIA_ROOT: /var/substra/medias/
  SERVERMEDIAS_ROOT: /var/substra/servermedias/
  SUBTUPLE_DIR: /var/substra/medias/subtuple/
  DEFAULT_DOMAIN: "localhost"
  COMMON_HOST_DOMAIN: ""

  BUILDER_ENABLED: "true"

  COMPUTE_POD_RUN_AS_USER: "1001"
  COMPUTE_POD_RUN_AS_GROUP: "1001"
  COMPUTE_POD_FS_GROUP: "1001"

  KANIKO_IMAGE: gcr.io/kaniko-project/executor:v1.8.1
  KANIKO_MIRROR: "false"

  OBJECTSTORE_URL: "release-name-minio:9000"

  WORKER_REPLICA_SET_NAME: release-name-substra-backend-worker
  ENABLE_DATASAMPLE_STORAGE_IN_SERVERMEDIAS: "false"

  EXPIRY_TOKEN_ENABLED: "true"
---
# Source: substra-backend/templates/configmap-wait-init-migrations.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-substra-backend-wait-init-migrations
  labels:
    helm.sh/chart: substra-backend-26.4.0
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.45.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: substra-backend
data:
  wait-init-migration.sh: |
    #!/usr/bin/env bash

    # Ensure the django migration have finished running before deploying the event app
    # FIXME when moving to Django 4.0 replace with ./manage.py migrate --check
    # link to doc: https://docs.djangoproject.com/fr/4.0/ref/django-admin/#cmdoption-migrate-check

    for i in {1..5}
    do
        all_migrations=$(./manage.py showmigrations)
        all_migrations_status=$?

        unapplied_migrations=$(echo "$all_migrations" | grep '\[ \]')

        if [ $all_migrations_status -eq 0 ] && [ -z "$unapplied_migrations" ]
        then
            exit 0
        else
            echo "retrying wait for migration $i"
            sleep 15
        fi
    done
    exit 1
---
# Source: substra-backend/charts/docker-registry/templates/pvc.yaml
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: release-name-docker-registry
  namespace: default
  labels:
    app: release-name-docker-registry
    chart: "docker-registry-2.2.2"
    release: "release-name"
    heritage: "Helm"
spec:
  accessModes:
    - "ReadWriteOnce"
  resources:
    requests:
      storage: "50Gi"
---
# Source: substra-backend/charts/minio/templates/pvc.yaml
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: release-name-minio
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: minio
    app.kubernetes.io/version: 2023.9.30
    helm.sh/chart: minio-12.8.12
spec:
  accessModes:
    - "ReadWriteOnce"
  resources:
    requests:
      storage: "8Gi"
---
# Source: substra-backend/templates/storage-server.yaml
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: release-name-substra-backend-servermedias
  labels:
  
    helm.sh/chart: substra-backend-26.4.0
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.45.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: substra-backend
spec:
  accessModes:
    - ReadWriteOnce
  # if DataSampleStorageInServerMedia, add labels selector to be able
  # to match PersistanceVolume properly
  resources:
    requests:
      storage: "10Gi"
---
# Source: substra-backend/templates/rbac.yaml
kind: Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: release-name-substra-backend-worker
  labels:
    
    helm.sh/chart: substra-backend-26.4.0
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.45.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: substra-backend
    app.kubernetes.io/name: substra-backend
rules:
  - apiGroups: [""]
    resources: ["secrets"]
    verbs: ["get", "watch", "list"]
  - apiGroups: [""]
    resources: ["pods/log", "pods/status"]
    verbs: ["get", "list", "watch"]
  - apiGroups: [""]
    resources: ["pods", "pods/exec"]
    verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]
  - apiGroups: [""]
    resources: ["services"]
    verbs: ["get"]
---
# Source: substra-backend/templates/rbac.yaml
kind: Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: release-name-substra-backend-builder
  labels:
    
    helm.sh/chart: substra-backend-26.4.0
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.45.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: substra-backend
    app.kubernetes.io/name: substra-backend
rules:
  - apiGroups: [""]
    resources: ["pods/log", "pods/status"]
    verbs: ["get", "list", "watch"]
  - apiGroups: [""]
    resources: ["pods", "pods/exec", "secrets"]
    verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]
  - apiGroups: [""]
    resources: ["services"]
    verbs: ["get"]
---
# Source: substra-backend/templates/rbac.yaml
kind: Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: release-name-substra-backend-worker-event
  labels:
    
    helm.sh/chart: substra-backend-26.4.0
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.45.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: substra-backend
    app.kubernetes.io/name: substra-backend
rules:
  - apiGroups: ["apps"]
    resources: ["statefulsets/scale"]
    verbs: ["get"]
---
# Source: substra-backend/templates/rbac.yaml
kind: Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: release-name-substra-backend-api-event
  labels:
    
    helm.sh/chart: substra-backend-26.4.0
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.45.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: substra-backend
    app.kubernetes.io/name: substra-backend
rules:
  - apiGroups: ["apps"]
    resources: ["statefulsets/scale"]
    verbs: ["get"]
---
# Source: substra-backend/templates/rbac.yaml
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: release-name-substra-backend-worker
  labels:
    
    helm.sh/chart: substra-backend-26.4.0
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.45.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: substra-backend
    app.kubernetes.io/name: substra-backend
subjects:
  - kind: ServiceAccount
    name: release-name-substra-backend-worker
roleRef:
  kind: Role
  name: release-name-substra-backend-worker
  apiGroup: rbac.authorization.k8s.io
---
# Source: substra-backend/templates/rbac.yaml
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: release-name-substra-backend-builder
  labels:
    
    helm.sh/chart: substra-backend-26.4.0
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.45.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: substra-backend
    app.kubernetes.io/name: substra-backend
subjects:
  - kind: ServiceAccount
    name: release-name-substra-backend-builder
roleRef:
  kind: Role
  name: release-name-substra-backend-builder
  apiGroup: rbac.authorization.k8s.io
---
# Source: substra-backend/templates/rbac.yaml
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: release-name-substra-backend-worker-event
  labels:
    
    helm.sh/chart: substra-backend-26.4.0
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.45.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: substra-backend
    app.kubernetes.io/name: substra-backend
subjects:
  - kind: ServiceAccount
    name: release-name-substra-backend-event
roleRef:
  kind: Role
  name: release-name-substra-backend-worker-event
  apiGroup: rbac.authorization.k8s.io
---
# Source: substra-backend/templates/rbac.yaml
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: release-name-substra-backend-api-event
  labels:
    
    helm.sh/chart: substra-backend-26.4.0
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.45.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: substra-backend
    app.kubernetes.io/name: substra-backend
subjects:
  - kind: ServiceAccount
    name: release-name-substra-backend-api-event
roleRef:
  kind: Role
  name: release-name-substra-backend-api-event
  apiGroup: rbac.authorization.k8s.io
---
# Source: substra-backend/charts/docker-registry/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-docker-registry
  namespace: default
  labels:
    app: docker-registry
    chart: docker-registry-2.2.2
    release: release-name
    heritage: Helm
spec:
  type: NodePort
  ports:
    - port: 5000
      protocol: TCP
      name: http-5000
      targetPort: 5000
  selector:
    app: docker-registry
    release: release-name
---
# Source: substra-backend/charts/minio/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-minio
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: minio
    app.kubernetes.io/version: 2023.9.30
    helm.sh/chart: minio-12.8.12
spec:
  type: ClusterIP
  ports:
    - name: minio-api
      port: 9000
      targetPort: minio-api
      nodePort: null
    - name: minio-console
      port: 9001
      targetPort: minio-console
      nodePort: null
  selector:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/name: minio
---
# Source: substra-backend/charts/postgresql/templates/primary/svc-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-postgresql-hl
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: 16.0.0
    helm.sh/chart: postgresql-13.1.2
    app.kubernetes.io/component: primary
  annotations:
    # Use this annotation in addition to the actual publishNotReadyAddresses
    # field below because the annotation will stop being respected soon but the
    # field is broken in some versions of Kubernetes:
    # https://github.com/kubernetes/kubernetes/issues/58662
    service.alpha.kubernetes.io/tolerate-unready-endpoints: "true"
spec:
  type: ClusterIP
  clusterIP: None
  # We want all pods in the StatefulSet to have their addresses published for
  # the sake of the other Postgresql pods even before they're ready, since they
  # have to be able to talk to each other in order to become ready.
  publishNotReadyAddresses: true
  ports:
    - name: tcp-postgresql
      port: 5432
      targetPort: tcp-postgresql
  selector:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/component: primary
---
# Source: substra-backend/charts/postgresql/templates/primary/svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-postgresql
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: 16.0.0
    helm.sh/chart: postgresql-13.1.2
    app.kubernetes.io/component: primary
spec:
  type: ClusterIP
  sessionAffinity: None
  ports:
    - name: tcp-postgresql
      port: 5432
      targetPort: tcp-postgresql
      nodePort: null
  selector:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/component: primary
---
# Source: substra-backend/charts/redis/templates/headless-svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-redis-headless
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: redis
    app.kubernetes.io/version: 7.2.4
    helm.sh/chart: redis-18.17.0
  annotations:
    
spec:
  type: ClusterIP
  clusterIP: None
  ports:
    - name: tcp-redis
      port: 6379
      targetPort: redis
  selector:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/name: redis
---
# Source: substra-backend/charts/redis/templates/master/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-redis-master
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: redis
    app.kubernetes.io/version: 7.2.4
    helm.sh/chart: redis-18.17.0
    app.kubernetes.io/component: master
spec:
  type: ClusterIP
  internalTrafficPolicy: Cluster
  sessionAffinity: None
  ports:
    - name: tcp-redis
      port: 6379
      targetPort: redis
      nodePort: null
  selector:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/name: redis
    app.kubernetes.io/component: master
---
# Source: substra-backend/templates/service-server.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-substra-backend-server
  labels:
    
    helm.sh/chart: substra-backend-26.4.0
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.45.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: substra-backend
    app.kubernetes.io/name: substra-backend-server
spec:
  type: ClusterIP
  ports:
    - name: http
      port: 8000
      protocol: TCP
      targetPort: http

  selector:
    app.kubernetes.io/name: substra-backend-server
    app.kubernetes.io/instance: release-name
---
# Source: substra-backend/templates/statefulset-builder.yaml
## Headless service doesn't get its own file
apiVersion: v1
kind: Service
metadata:
  name: release-name-substra-backend-builder
  labels:
    helm.sh/chart: substra-backend-26.4.0
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.45.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: substra-backend
    app.kubernetes.io/name: substra-backend-builder
spec:
  clusterIP: None
  selector:
    app.kubernetes.io/component: substra-builder
    app.kubernetes.io/instance: release-name
---
# Source: substra-backend/templates/statefulset-worker.yaml
## Headless service doesn't get its own file
apiVersion: v1
kind: Service
metadata:
  name: release-name-substra-backend-worker
  labels:
    helm.sh/chart: substra-backend-26.4.0
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.45.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: substra-backend
    app.kubernetes.io/name: substra-backend-worker
spec:
  clusterIP: None
  selector:
    app.kubernetes.io/component: substra-worker
    app.kubernetes.io/instance: release-name
---
# Source: substra-backend/charts/docker-registry/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-docker-registry
  namespace: default
  labels:
    app: docker-registry
    chart: docker-registry-2.2.2
    release: release-name
    heritage: Helm
spec:
  selector:
    matchLabels:
      app: docker-registry
      release: release-name
  replicas: 1
  minReadySeconds: 5
  template:
    metadata:
      labels:
        app: docker-registry
        release: release-name
      annotations:
        checksum/config: 9e4f80a4e5b81e5962c947178afa733ac81915e76dd15841779195bc6f404b5c
        checksum/secret: 413c31a99873ec1df5bcce097927aff65e79eb1c350de7683dba55de66508542
    spec:
      securityContext:
        fsGroup: 1000
        runAsUser: 1000
      containers:
        - name: docker-registry
          image: "registry:2.8.1"
          imagePullPolicy: IfNotPresent
          command:
          - /bin/registry
          - serve
          - /etc/docker/registry/config.yml
          ports:
            - containerPort: 5000
          livenessProbe:
            httpGet:
              path: /
              port: 5000
          readinessProbe:
            httpGet:
              path: /
              port: 5000
          resources: 
            limits:
              cpu: 500m
              memory: 64Gi
            requests:
              cpu: 100m
              memory: 256Mi
          env: 
            - name: REGISTRY_HTTP_SECRET
              valueFrom:
                secretKeyRef:
                  name: release-name-docker-registry-secret
                  key: haSharedSecret
            - name: REGISTRY_STORAGE_FILESYSTEM_ROOTDIRECTORY
              value: "/var/lib/registry"
            - name: REGISTRY_STORAGE_DELETE_ENABLED
              value: "true"
          volumeMounts: 
            - name: "release-name-docker-registry-config"
              mountPath: "/etc/docker/registry"
            - name: data
              mountPath: /var/lib/registry/
      volumes: 
        - name: release-name-docker-registry-config
          configMap:
            name: release-name-docker-registry-config
        - name: data
          persistentVolumeClaim:
            claimName: release-name-docker-registry
---
# Source: substra-backend/charts/minio/templates/standalone/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-minio
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: minio
    app.kubernetes.io/version: 2023.9.30
    helm.sh/chart: minio-12.8.12
spec:
  selector:
    matchLabels:
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/name: minio
  strategy:
    type: Recreate
  template:
    metadata:
      labels:
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: minio
        app.kubernetes.io/version: 2023.9.30
        helm.sh/chart: minio-12.8.12
      annotations:
        checksum/credentials-secret: 81c38367c3b2ea066728e839e17a74efbc7d210e71732d782be721ed1baa4dfe
    spec:
      
      serviceAccountName: release-name-minio
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/instance: release-name
                    app.kubernetes.io/name: minio
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      securityContext:
        fsGroup: 1001
        seccompProfile:
          type: RuntimeDefault
      containers:
        - name: minio
          image: docker.io/bitnami/minio:2023.9.30-debian-11-r2
          imagePullPolicy: "IfNotPresent"
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            runAsNonRoot: true
            runAsUser: 1001
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: MINIO_SCHEME
              value: "http"
            - name: MINIO_FORCE_NEW_KEYS
              value: "yes"
            - name: MINIO_ROOT_USER
              valueFrom:
                secretKeyRef:
                  name: release-name-minio
                  key: root-user
            - name: MINIO_ROOT_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: release-name-minio
                  key: root-password
            - name: MINIO_BROWSER
              value: "on"
            - name: MINIO_PROMETHEUS_AUTH_TYPE
              value: "public"
            - name: MINIO_CONSOLE_PORT_NUMBER
              value: "9001"
          envFrom:
          ports:
            - name: minio-api
              containerPort: 9000
              protocol: TCP
            - name: minio-console
              containerPort: 9001
              protocol: TCP
          livenessProbe:
            httpGet:
              path: /minio/health/live
              port: minio-api
              scheme: "HTTP"
            initialDelaySeconds: 5
            periodSeconds: 5
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 5
          readinessProbe:
            tcpSocket:
              port: minio-api
            initialDelaySeconds: 5
            periodSeconds: 5
            timeoutSeconds: 1
            successThreshold: 1
            failureThreshold: 5
          resources:
            limits:
              cpu: 1000m
              memory: 64Gi
            requests:
              cpu: 100m
              memory: 1Gi
          volumeMounts:
            - name: data
              mountPath: /bitnami/minio/data
      volumes:
        - name: data
          persistentVolumeClaim:
            claimName: release-name-minio
---
# Source: substra-backend/templates/deployment-api-events.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-substra-backend-api-events
  labels:
    
    helm.sh/chart: substra-backend-26.4.0
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.45.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: substra-backend
    app.kubernetes.io/name: substra-backend-api-events
spec:
  replicas: 1
  selector:
    matchLabels:
        app.kubernetes.io/name: substra-backend-api-events
        
        app.kubernetes.io/instance: release-name
  template:
    metadata:
      labels:
        app.kubernetes.io/name: substra-backend-api-events
        
        helm.sh/chart: substra-backend-26.4.0
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/version: "0.45.0"
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/part-of: substra-backend
      annotations:
        # This will cause the pod to restart if the content of the ConfigMap is updated through Helm
        checksum-cm-orchestrator: 7fb58d3e25fbd6ea6acbb5588dbffc9a5706f7bbc4f299c048d580f34893d7f8
        checksum-cm-settings: 1f882f1a5e1e5b5fb543b21fe957c242de5971fd5692637bf5380133e2bc8558
        checksum-cm-db: 33c676bec9db656cba3d03e10ea865cc06cc0c014f15ffbd818e5437d2b36cf8
        checksum-cm-redis: 264b5affa56b5e88eed5ddc20e36253edbba046a4631250fd0addf3c962a9f84
        checksum-secret-database : 240d15002756a2f3814b00b45a923d1a3d38e2f161bd09b400bf1ca275fdea81
        checksum-secret-redis: e9f2847d2e2a087f31f994f2aed36bef1958307dd134c7854cf9da3756cc519c
    spec:
      securityContext:
        fsGroup: 1001
        runAsUser: 1001
        runAsGroup: 1001
      serviceAccountName: release-name-substra-backend-api-event
      containers:
        - name: api-event-app
          image: ghcr.io/substra/substra-backend:0.45.0
          imagePullPolicy: IfNotPresent
          resources:
            limits:
              cpu: 500m
              memory: 400Mi
            requests:
              cpu: 100m
              memory: 50Mi
          command: ["/bin/bash"]
          args: ["-c", "python manage.py consume"]
          envFrom:
            - configMapRef:
                name: release-name-substra-backend-orchestrator
            - configMapRef:
                name: release-name-substra-backend-settings
            - configMapRef:
                name: release-name-substra-backend-database
            - configMapRef:
                name: release-name-substra-backend-redis
            - secretRef:
                name: release-name-substra-backend-redis
            - secretRef:
                name: release-name-substra-backend-database
          readinessProbe:
            exec:
              command:
              - cat
              - /tmp/ready
            initialDelaySeconds: 5
            periodSeconds: 20
          env:
            - name: NAMESPACE
              valueFrom:
                  fieldRef:
                    fieldPath: metadata.namespace
            - name: DJANGO_SETTINGS_MODULE
              value: backend.settings.api.events.prod
          volumeMounts:
            
      initContainers:
        
        - name: wait-postgresql
          image: postgres
          env:
           - name: PGUSER
             value: postgres
           - name: PGPASSWORD
             value: postgres
           - name: PGDATABASE
             value: substra
          command: ['sh', '-c', 'until pg_isready --host=release-name-postgresql.default --port=5432; do echo "Waiting for postgresql service"; sleep 2; done;']
        - name: wait-init-migrations
          image: ghcr.io/substra/substra-backend:0.45.0
          command: ['bash', '/usr/src/app/wait-init-migration.sh']
          volumeMounts:
          - name: volume-wait-init-migrations
            mountPath: /usr/src/app/wait-init-migration.sh
            subPath: wait-init-migration.sh
          envFrom:
          - configMapRef:
              name: release-name-substra-backend-orchestrator
          - configMapRef:
              name: release-name-substra-backend-database
          - configMapRef:
              name: release-name-substra-backend-settings
          - secretRef:
              name: release-name-substra-backend-database
          env:
          - name: DJANGO_SETTINGS_MODULE
            value: backend.settings.prod
      volumes:
      - name: volume-wait-init-migrations
        configMap:
          name: release-name-substra-backend-wait-init-migrations
---
# Source: substra-backend/templates/deployment-scheduler-worker.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-substra-backend-scheduler-worker
  labels:
    
    helm.sh/chart: substra-backend-26.4.0
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.45.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: substra-backend
    app.kubernetes.io/name: substra-backend-scheduler-worker
spec:
  replicas: 1
  selector:
    matchLabels:
        app.kubernetes.io/name: substra-backend-scheduler-worker
        
        app.kubernetes.io/instance: release-name
  template:
    metadata:
      labels:
        app.kubernetes.io/name: substra-backend-scheduler-worker
        
        helm.sh/chart: substra-backend-26.4.0
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/version: "0.45.0"
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/part-of: substra-backend
      annotations:
        # This will cause the pod to restart if the content of the ConfigMap is updated through Helm
        checksum-cm-orchestrator: 7fb58d3e25fbd6ea6acbb5588dbffc9a5706f7bbc4f299c048d580f34893d7f8
        checksum-cm-settings: 1f882f1a5e1e5b5fb543b21fe957c242de5971fd5692637bf5380133e2bc8558
        checksum-cm-db: 33c676bec9db656cba3d03e10ea865cc06cc0c014f15ffbd818e5437d2b36cf8
        checksum-cm-redis: 264b5affa56b5e88eed5ddc20e36253edbba046a4631250fd0addf3c962a9f84
        checksum-cm-registry: 0a84c216ae57353e86de39a9fa289078c50f82f64f945f9f7b672c8c123e8236
        checksum-secret-database : 240d15002756a2f3814b00b45a923d1a3d38e2f161bd09b400bf1ca275fdea81
        checksum-secret-redis : e9f2847d2e2a087f31f994f2aed36bef1958307dd134c7854cf9da3756cc519c
    spec:
      securityContext:
        fsGroup: 1001
        runAsUser: 1001
        runAsGroup: 1001
      containers:
        - name: scheduler-worker
          image: ghcr.io/substra/substra-backend:0.45.0
          imagePullPolicy: IfNotPresent
          command: ["/bin/bash"]
          args: ["-c", "celery -A backend worker -l info -n owkin -Q owkin,scheduler,celery --hostname owkin.scheduler"]
          envFrom:
            - configMapRef:
                name: release-name-substra-backend-orchestrator
            - configMapRef:
                name: release-name-substra-backend-settings
            - configMapRef:
                name: release-name-substra-backend-database
            - configMapRef:
                name: release-name-substra-backend-redis
            - configMapRef:
                name: release-name-substra-backend-registry
            - secretRef:
                name: release-name-substra-backend-redis
            - secretRef:
                name: release-name-substra-backend-database
          env:
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: NODE_NAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
            - name: DJANGO_SETTINGS_MODULE
              value: backend.settings.celery.prod
          volumeMounts:
          resources:
            limits:
              cpu: 250m
              memory: 400Mi
            requests:
              cpu: 50m
              memory: 50Mi
      initContainers:
        
      volumes:
---
# Source: substra-backend/templates/deployment-scheduler.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-substra-backend-scheduler
  labels:
    
    helm.sh/chart: substra-backend-26.4.0
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.45.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: substra-backend
    app.kubernetes.io/name: substra-backend-scheduler
spec:
  replicas: 1
  selector:
    matchLabels:
        app.kubernetes.io/name: substra-backend-scheduler
        
        app.kubernetes.io/instance: release-name
  template:
    metadata:
      labels:
        app.kubernetes.io/name: substra-backend-scheduler
        
        helm.sh/chart: substra-backend-26.4.0
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/version: "0.45.0"
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/part-of: substra-backend
      annotations:
        # This will cause the pod to restart if the content of the ConfigMap is updated through Helm
        checksum-cm-orchestrator: 7fb58d3e25fbd6ea6acbb5588dbffc9a5706f7bbc4f299c048d580f34893d7f8
        checksum-cm-settings: 1f882f1a5e1e5b5fb543b21fe957c242de5971fd5692637bf5380133e2bc8558
        checksum-cm-db: 33c676bec9db656cba3d03e10ea865cc06cc0c014f15ffbd818e5437d2b36cf8
        checksum-cm-redis: 264b5affa56b5e88eed5ddc20e36253edbba046a4631250fd0addf3c962a9f84
        checksum-cm-registry: 0a84c216ae57353e86de39a9fa289078c50f82f64f945f9f7b672c8c123e8236
        checksum-secret-database : 240d15002756a2f3814b00b45a923d1a3d38e2f161bd09b400bf1ca275fdea81
        checksum-secret-redis : e9f2847d2e2a087f31f994f2aed36bef1958307dd134c7854cf9da3756cc519c
    spec:
      securityContext:
        fsGroup: 1001
        runAsGroup: 1001
        runAsUser: 1001
      containers:
        - name: scheduler
          image: ghcr.io/substra/substra-backend:0.45.0
          imagePullPolicy: IfNotPresent
          command: ["/bin/bash"]
          args: ["-c", "celery -A backend beat -l debug --schedule /var/substra/runtime-db/celerybeat-scheduler"]
          envFrom:
            - configMapRef:
                name: release-name-substra-backend-orchestrator
            - configMapRef:
                name: release-name-substra-backend-settings
            - configMapRef:
                name: release-name-substra-backend-database
            - configMapRef:
                name: release-name-substra-backend-redis
            - configMapRef:
                name: release-name-substra-backend-registry
            - secretRef:
                name: release-name-substra-backend-redis
            - secretRef:
                name: release-name-substra-backend-database
          env:
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: NODE_NAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
            - name: DJANGO_SETTINGS_MODULE
              value: backend.settings.celery.prod
          volumeMounts:
            - name: runtime-db
              mountPath: /var/substra/runtime-db
            
          resources:
            limits:
              cpu: 250m
              memory: 400Mi
            requests:
              cpu: 50m
              memory: 50Mi
      volumes:
      - name: runtime-db
        emptyDir: {}
---
# Source: substra-backend/templates/deployment-server.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-substra-backend-server
  labels:
    
    helm.sh/chart: substra-backend-26.4.0
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.45.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: substra-backend
    app.kubernetes.io/name: substra-backend-server
spec:
  replicas: 1
  selector:
    matchLabels:
        app.kubernetes.io/name: substra-backend-server
        
        app.kubernetes.io/instance: release-name
  template:
    metadata:
      labels:
        app.kubernetes.io/name: substra-backend-server
        
        helm.sh/chart: substra-backend-26.4.0
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/version: "0.45.0"
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/part-of: substra-backend
      annotations:
        # This will cause the pod to restart if the content of the ConfigMap is updated through Helm
        checksum-cm-orchestrator: 7fb58d3e25fbd6ea6acbb5588dbffc9a5706f7bbc4f299c048d580f34893d7f8
        checksum-cm-settings: 1f882f1a5e1e5b5fb543b21fe957c242de5971fd5692637bf5380133e2bc8558
        checksum-cm-db: 33c676bec9db656cba3d03e10ea865cc06cc0c014f15ffbd818e5437d2b36cf8
        checksum-secret-objectstore : 6d97165cffab02b7858e66effcd5f9366495029d5e605ffe3ed4b8ba40a2e612
        checksum-secret-database : 240d15002756a2f3814b00b45a923d1a3d38e2f161bd09b400bf1ca275fdea81
    spec:
      securityContext:
        fsGroup: 1001
        runAsUser: 1001
        runAsGroup: 1001
      containers:
      - name: server
        image: ghcr.io/substra/substra-backend:0.45.0
        imagePullPolicy: "IfNotPresent"
        command: ["/bin/bash"]
        args: ["-c", "uwsgi --ini uwsgi.ini"]
        envFrom:
          - configMapRef:
              name: release-name-substra-backend-orchestrator
          - secretRef:
              name: release-name-substra-backend-objectstore
          - configMapRef:
              name: release-name-substra-backend-settings
          - configMapRef:
              name: release-name-substra-backend-database
          - secretRef:
              name: release-name-substra-backend-database
          - secretRef:
              name: release-name-substra-backend-server-key
          - configMapRef:
              name: release-name-substra-backend-oidc
        env:
          - name: HOST_IP
            valueFrom:
              fieldRef:
                fieldPath: status.hostIP
          - name: POD_IP
            valueFrom:
              fieldRef:
                fieldPath: status.podIP
        ports:
          - name: http
            containerPort: 8000
            protocol: TCP
        volumeMounts:
          - name: data-servermedias
            mountPath: /var/substra/servermedias
          - name: statics
            mountPath: /usr/src/app/backend/statics
          - name: uwsgi
            mountPath: /usr/src/app/uwsgi.ini
            subPath: uwsgi.ini
            readOnly: true
          - name: runtime-secrets
            mountPath: /var/substra/runtime-secrets
          
        livenessProbe:
          httpGet:
            path: /liveness
            port: http
          initialDelaySeconds: 60
          periodSeconds: 45
          timeoutSeconds: 5
          successThreshold: 1
          failureThreshold: 6
        readinessProbe:
          httpGet:
            path: /readiness
            port: http
          initialDelaySeconds: 5
          periodSeconds: 30
          timeoutSeconds: 2
          successThreshold: 1
          failureThreshold: 3
        resources:
            limits:
              cpu: 2000m
              memory: 12Gi
            requests:
              cpu: 200m
              memory: 512Mi
      initContainers:
      
      - name: init-collectstatic
        image: ghcr.io/substra/substra-backend:0.45.0
        command: ['python', 'manage.py', 'collectstatic', '--noinput']
        envFrom:
          - configMapRef:
              name: release-name-substra-backend-orchestrator
          - configMapRef:
              name: release-name-substra-backend-settings
        env:
          - name: DJANGO_SETTINGS_MODULE
            value: backend.settings.prod
        volumeMounts:
          - name: statics
            mountPath: /usr/src/app/backend/statics
      - name: wait-postgresql
        image: postgres
        env:
         - name: PGUSER
           value: postgres
         - name: PGPASSWORD
           value: postgres
         - name: PGDATABASE
           value: substra
        command: ['sh', '-c', 'until pg_isready --host=release-name-postgresql.default --port=5432; do echo "Waiting for postgresql service"; sleep 2; done;']
      - name: init-migrate
        image: ghcr.io/substra/substra-backend:0.45.0
        command: ['python', 'manage.py', 'migrate']
        envFrom:
          - configMapRef:
              name: release-name-substra-backend-orchestrator
          - secretRef:
              name: release-name-substra-backend-objectstore
          - configMapRef:
              name: release-name-substra-backend-database
          - configMapRef:
              name: release-name-substra-backend-settings
          - secretRef:
              name: release-name-substra-backend-database
        env:
        - name: DJANGO_SETTINGS_MODULE
          value: backend.settings.prod
      
      - name: wait-minio
        image: jwilder/dockerize:0.6.1
        command: ['dockerize', '-wait', 'tcp://release-name-minio:9000', '-timeout', '15s']
      volumes:
      - name: data-servermedias
        persistentVolumeClaim:
          claimName: release-name-substra-backend-servermedias
      - name: statics
        emptyDir: {}
      - name: runtime-secrets
        emptyDir: {}
      - name: uwsgi
        configMap:
          name: release-name-substra-backend-server-uwsgi
---
# Source: substra-backend/templates/deployment-worker-events.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-substra-backend-worker-events
  labels:
    
    helm.sh/chart: substra-backend-26.4.0
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.45.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: substra-backend
    app.kubernetes.io/name: substra-backend-worker-events
spec:
  replicas: 1
  selector:
    matchLabels:
        app.kubernetes.io/name: substra-backend-worker-events
        
        app.kubernetes.io/instance: release-name
  template:
    metadata:
      labels:
        app.kubernetes.io/name: substra-backend-worker-events
        
        helm.sh/chart: substra-backend-26.4.0
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/version: "0.45.0"
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/part-of: substra-backend
      annotations:
        # This will cause the pod to restart if the content of the ConfigMap is updated through Helm
        checksum-cm-orchestrator: 7fb58d3e25fbd6ea6acbb5588dbffc9a5706f7bbc4f299c048d580f34893d7f8
        checksum-cm-settings: 1f882f1a5e1e5b5fb543b21fe957c242de5971fd5692637bf5380133e2bc8558
        checksum-cm-db: 33c676bec9db656cba3d03e10ea865cc06cc0c014f15ffbd818e5437d2b36cf8
        checksum-cm-redis: 264b5affa56b5e88eed5ddc20e36253edbba046a4631250fd0addf3c962a9f84
        checksum-secret-database : 240d15002756a2f3814b00b45a923d1a3d38e2f161bd09b400bf1ca275fdea81
        checksum-secret-redis: e9f2847d2e2a087f31f994f2aed36bef1958307dd134c7854cf9da3756cc519c
    spec:
      securityContext:
        fsGroup: 1001
        runAsUser: 1001
        runAsGroup: 1001
      serviceAccountName: release-name-substra-backend-event
      containers:
        - name: worker-event-app
          image: ghcr.io/substra/substra-backend:0.45.0
          imagePullPolicy: IfNotPresent
          resources:
            limits:
              cpu: 500m
              memory: 400Mi
            requests:
              cpu: 100m
              memory: 50Mi
          command: ["/bin/bash"]
          args: ["-c", "python manage.py consume"]
          envFrom:
            - configMapRef:
                name: release-name-substra-backend-orchestrator
            - configMapRef:
                name: release-name-substra-backend-settings
            - configMapRef:
                name: release-name-substra-backend-database
            - configMapRef:
                name: release-name-substra-backend-redis
            - secretRef:
                name: release-name-substra-backend-redis
            - secretRef:
                name: release-name-substra-backend-database
          readinessProbe:
            exec:
              command:
              - cat
              - /tmp/ready
            initialDelaySeconds: 5
            periodSeconds: 20
          env:
            - name: NAMESPACE
              valueFrom:
                  fieldRef:
                    fieldPath: metadata.namespace
            - name: DJANGO_SETTINGS_MODULE
              value: backend.settings.worker.events.prod
          volumeMounts:
            
      initContainers:
        
        - name: wait-postgresql
          image: postgres
          env:
           - name: PGUSER
             value: postgres
           - name: PGPASSWORD
             value: postgres
           - name: PGDATABASE
             value: substra
          command: ['sh', '-c', 'until pg_isready --host=release-name-postgresql.default --port=5432; do echo "Waiting for postgresql service"; sleep 2; done;']
        - name: wait-init-migrations
          image: ghcr.io/substra/substra-backend:0.45.0
          command: ['bash', '/usr/src/app/wait-init-migration.sh']
          volumeMounts:
          - name: volume-wait-init-migrations
            mountPath: /usr/src/app/wait-init-migration.sh
            subPath: wait-init-migration.sh
          envFrom:
          - configMapRef:
              name: release-name-substra-backend-orchestrator
          - configMapRef:
              name: release-name-substra-backend-database
          - configMapRef:
              name: release-name-substra-backend-settings
          - secretRef:
              name: release-name-substra-backend-database
          env:
          - name: DJANGO_SETTINGS_MODULE
            value: backend.settings.prod
      volumes:
      - name: volume-wait-init-migrations
        configMap:
          name: release-name-substra-backend-wait-init-migrations
---
# Source: substra-backend/charts/postgresql/templates/primary/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: release-name-postgresql
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: 16.0.0
    helm.sh/chart: postgresql-13.1.2
    app.kubernetes.io/component: primary
spec:
  replicas: 1
  serviceName: release-name-postgresql-hl
  updateStrategy:
    rollingUpdate: {}
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/name: postgresql
      app.kubernetes.io/component: primary
  template:
    metadata:
      name: release-name-postgresql
      labels:
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: postgresql
        app.kubernetes.io/version: 16.0.0
        helm.sh/chart: postgresql-13.1.2
        app.kubernetes.io/component: primary
    spec:
      serviceAccountName: default
      
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/instance: release-name
                    app.kubernetes.io/name: postgresql
                    app.kubernetes.io/component: primary
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      securityContext:
        fsGroup: 1001
        runAsNonRoot: true
        seccompProfile:
          type: RuntimeDefault
      hostNetwork: false
      hostIPC: false
      containers:
        - name: postgresql
          image: docker.io/bitnami/postgresql:16.0.0-debian-11-r10
          imagePullPolicy: "IfNotPresent"
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            runAsGroup: 0
            runAsNonRoot: true
            runAsUser: 1001
            seccompProfile:
              type: RuntimeDefault
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: POSTGRESQL_PORT_NUMBER
              value: "5432"
            - name: POSTGRESQL_VOLUME_DIR
              value: "/bitnami/postgresql"
            - name: PGDATA
              value: "/bitnami/postgresql/data"
            # Authentication
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: release-name-postgresql
                  key: postgres-password
            - name: POSTGRES_DATABASE
              value: "substra"
            # Replication
            # Initdb
            # Standby
            # LDAP
            - name: POSTGRESQL_ENABLE_LDAP
              value: "no"
            # TLS
            - name: POSTGRESQL_ENABLE_TLS
              value: "no"
            # Audit
            - name: POSTGRESQL_LOG_HOSTNAME
              value: "false"
            - name: POSTGRESQL_LOG_CONNECTIONS
              value: "false"
            - name: POSTGRESQL_LOG_DISCONNECTIONS
              value: "false"
            - name: POSTGRESQL_PGAUDIT_LOG_CATALOG
              value: "off"
            # Others
            - name: POSTGRESQL_CLIENT_MIN_MESSAGES
              value: "error"
            - name: POSTGRESQL_SHARED_PRELOAD_LIBRARIES
              value: "pgaudit"
          ports:
            - name: tcp-postgresql
              containerPort: 5432
          livenessProbe:
            failureThreshold: 6
            initialDelaySeconds: 30
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            exec:
              command:
                - /bin/sh
                - -c
                - exec pg_isready -U "postgres" -d "dbname=substra" -h 127.0.0.1 -p 5432
          readinessProbe:
            failureThreshold: 6
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            exec:
              command:
                - /bin/sh
                - -c
                - -e
                - |
                  exec pg_isready -U "postgres" -d "dbname=substra" -h 127.0.0.1 -p 5432
                  [ -f /opt/bitnami/postgresql/tmp/.initialized ] || [ -f /bitnami/postgresql/.initialized ]
          resources:
            limits:
              cpu: 1000m
              memory: 4Gi
            requests:
              cpu: 50m
              memory: 256Mi
          volumeMounts:
            - name: dshm
              mountPath: /dev/shm
            - name: data
              mountPath: /bitnami/postgresql
      volumes:
        - name: dshm
          emptyDir:
            medium: Memory
  volumeClaimTemplates:
    - apiVersion: v1
      kind: PersistentVolumeClaim
      metadata:
        name: data
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: "8Gi"
---
# Source: substra-backend/charts/redis/templates/master/application.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: release-name-redis-master
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: redis
    app.kubernetes.io/version: 7.2.4
    helm.sh/chart: redis-18.17.0
    app.kubernetes.io/component: master
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/name: redis
      app.kubernetes.io/component: master
  serviceName: release-name-redis-headless
  updateStrategy:
    type: RollingUpdate
  template:
    metadata:
      labels:
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: redis
        app.kubernetes.io/version: 7.2.4
        helm.sh/chart: redis-18.17.0
        app.kubernetes.io/component: master
      annotations:
        checksum/configmap: 6b43007e91db6e015984e1074078f28383a277b606e80be84314fd73e558922d
        checksum/health: aff24913d801436ea469d8d374b2ddb3ec4c43ee7ab24663d5f8ff1a1b6991a9
        checksum/scripts: 560c33ff34d845009b51830c332aa05fa211444d1877d3526d3599be7543aaa5
        checksum/secret: 5c1a2f40d70b5c07f99cb8cbb9d9c99fa0b5aa688b89c0a608a6564626f447f7
    spec:
      
      securityContext:
        fsGroup: 1001
        fsGroupChangePolicy: Always
        supplementalGroups: []
        sysctls: []
      serviceAccountName: release-name-redis-master
      automountServiceAccountToken: false
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/instance: release-name
                    app.kubernetes.io/name: redis
                    app.kubernetes.io/component: master
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      enableServiceLinks: true
      terminationGracePeriodSeconds: 30
      containers:
        - name: redis
          image: docker.io/bitnami/redis:7.2.4-debian-12-r9
          imagePullPolicy: "IfNotPresent"
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: false
            runAsGroup: 0
            runAsNonRoot: true
            runAsUser: 1001
            seccompProfile:
              type: RuntimeDefault
          command:
            - /bin/bash
          args:
            - -c
            - /opt/bitnami/scripts/start-scripts/start-master.sh
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: REDIS_REPLICATION_MODE
              value: master
            - name: ALLOW_EMPTY_PASSWORD
              value: "no"
            - name: REDIS_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: release-name-redis
                  key: redis-password
            - name: REDIS_TLS_ENABLED
              value: "no"
            - name: REDIS_PORT
              value: "6379"
          ports:
            - name: redis
              containerPort: 6379
          livenessProbe:
            initialDelaySeconds: 20
            periodSeconds: 5
            # One second longer than command timeout should prevent generation of zombie processes.
            timeoutSeconds: 6
            successThreshold: 1
            failureThreshold: 5
            exec:
              command:
                - sh
                - -c
                - /health/ping_liveness_local.sh 5
          readinessProbe:
            initialDelaySeconds: 20
            periodSeconds: 5
            timeoutSeconds: 2
            successThreshold: 1
            failureThreshold: 5
            exec:
              command:
                - sh
                - -c
                - /health/ping_readiness_local.sh 1
          resources:
            limits:
              cpu: 500m
              memory: 1024Mi
            requests:
              cpu: 50m
              memory: 256Mi
          volumeMounts:
            - name: start-scripts
              mountPath: /opt/bitnami/scripts/start-scripts
            - name: health
              mountPath: /health
            - name: redis-data
              mountPath: /data
            - name: config
              mountPath: /opt/bitnami/redis/mounted-etc
            - name: empty-dir
              mountPath: /opt/bitnami/redis/etc/
              subPath: app-conf-dir
            - name: empty-dir
              mountPath: /tmp
              subPath: tmp-dir
      volumes:
        - name: start-scripts
          configMap:
            name: release-name-redis-scripts
            defaultMode: 0755
        - name: health
          configMap:
            name: release-name-redis-health
            defaultMode: 0755
        - name: config
          configMap:
            name: release-name-redis-configuration
        - name: empty-dir
          emptyDir: {}
  volumeClaimTemplates:
    - apiVersion: v1
      kind: PersistentVolumeClaim
      metadata:
        name: redis-data
        labels:
          app.kubernetes.io/instance: release-name
          app.kubernetes.io/name: redis
          app.kubernetes.io/component: master
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: "8Gi"
---
# Source: substra-backend/templates/statefulset-builder.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: release-name-substra-backend-builder
  labels:
    
    helm.sh/chart: substra-backend-26.4.0
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.45.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: substra-backend
    app.kubernetes.io/name: substra-backend-builder
spec:
  replicas: 1
  serviceName: release-name-substra-backend-builder
  selector:
    matchLabels:
        app.kubernetes.io/name: substra-backend-builder
        
        app.kubernetes.io/instance: release-name
  template:
    metadata:
      labels:
        app.kubernetes.io/name: substra-backend-builder
        
        helm.sh/chart: substra-backend-26.4.0
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/version: "0.45.0"
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/part-of: substra-backend
        app.kubernetes.io/component: substra-builder
      annotations:
        # This will cause the pod to restart if the content of the ConfigMap is updated through Helm
        checksum-cm-orchestrator: 7fb58d3e25fbd6ea6acbb5588dbffc9a5706f7bbc4f299c048d580f34893d7f8
        checksum-cm-settings: 1f882f1a5e1e5b5fb543b21fe957c242de5971fd5692637bf5380133e2bc8558
        checksum-secret-objectstore : 6d97165cffab02b7858e66effcd5f9366495029d5e605ffe3ed4b8ba40a2e612
        checksum-secret-redis: e9f2847d2e2a087f31f994f2aed36bef1958307dd134c7854cf9da3756cc519c
    spec:
      securityContext:
        fsGroup: 1001
        runAsUser: 1001
        runAsGroup: 1001
      serviceAccountName: release-name-substra-backend-builder
      initContainers:
      - name: wait-postgresql
        image: postgres
        env:
         - name: PGUSER
           value: postgres
         - name: PGPASSWORD
           value: postgres
         - name: PGDATABASE
           value: substra
        command: ['sh', '-c', 'until pg_isready --host=release-name-postgresql.default --port=5432; do echo "Waiting for postgresql service"; sleep 2; done;']
      
      - name: wait-minio
        image: jwilder/dockerize:0.6.1
        command: ['dockerize', '-wait', 'tcp://release-name-minio:9000', '-timeout', '15s']
      containers:
      - name: builder
        image: ghcr.io/substra/substra-backend:0.45.0
        imagePullPolicy: "IfNotPresent"
        command: ["/bin/bash", "-c"]
        args: ["celery -A backend worker -E -l info -Q owkin.builder,owkin.builder-${HOSTNAME##*-},owkin.broadcast --hostname owkin.builder-${HOSTNAME##*-}"]
        
        envFrom:
          # TODO: Remove dependency for LDEGER_MSP_ID
          - configMapRef:
              name: release-name-substra-backend-orchestrator
          - configMapRef:
              name: release-name-substra-backend-settings
          - configMapRef:
              name: release-name-substra-backend-redis
          - configMapRef:
              name: release-name-substra-backend-registry
          # TODO: Remove once moved ImageResitryEntrypoint logic
          - configMapRef:
                name: release-name-substra-backend-database
          - secretRef:
              name: release-name-substra-backend-objectstore
          - secretRef:
              name: release-name-substra-backend-redis
          # TODO: Remove once moved ImageResitryEntrypoint logic
          - secretRef:
                name: release-name-substra-backend-database
        env:
          - name: HOST_IP
            valueFrom:
              fieldRef:
                fieldPath: status.hostIP
          - name: POD_IP
            valueFrom:
              fieldRef:
                fieldPath: status.podIP
          - name: DJANGO_SETTINGS_MODULE
            value: backend.settings.celery.prod
          - name: DEFAULT_DOMAIN
            value: "localhost"
          - name: "CELERY_WORKER_CONCURRENCY"
            value: "1"
          - name: WORKER_PVC_DOCKER_CACHE
            value: docker-cache
          - name: WORKER_PVC_SUBTUPLE
            value: subtuple
          - name: PRIVATE_CA_ENABLED
            value: "false"
          - name: NAMESPACE
            valueFrom:
              fieldRef:
                fieldPath: metadata.namespace
          - name: NODE_NAME
            valueFrom:
              fieldRef:
                fieldPath: spec.nodeName
          - name: KANIKO_DOCKER_CONFIG_SECRET_NAME
            value: 
          - name: OBJECTSTORE_URL
            value: "release-name-minio:9000"
          - name: KANIKO_RESOURCES
            value: "limits:\n  memory: 32Gi\nrequests:\n  cpu: 500m\n  memory: 256Mi"
        ports:
          - name: http
            containerPort: 8000
            protocol: TCP
        volumeMounts:
          - name: subtuple
            mountPath: /var/substra/medias/subtuple
          
        resources:
            limits:
              cpu: 2000m
              memory: 8Gi
            requests:
              cpu: 200m
              memory: 512Mi
      volumes:
      
  volumeClaimTemplates:
  - metadata:
      name: subtuple
    spec:
      accessModes: [ "ReadWriteOnce" ]
      
      resources:
        requests:
          storage: 10Gi
  - metadata:
      name: docker-cache
    spec:
      accessModes: [ "ReadWriteOnce" ]
      
      resources:
        requests:
          storage: 10Gi
---
# Source: substra-backend/templates/statefulset-worker.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: release-name-substra-backend-worker
  labels:
    
    helm.sh/chart: substra-backend-26.4.0
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.45.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: substra-backend
    app.kubernetes.io/name: substra-backend-worker
spec:
  replicas: 1
  serviceName: release-name-substra-backend-worker
  selector:
    matchLabels:
        app.kubernetes.io/name: substra-backend-worker
        
        app.kubernetes.io/instance: release-name
  template:
    metadata:
      labels:
        
        helm.sh/chart: substra-backend-26.4.0
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/version: "0.45.0"
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/part-of: substra-backend
        app.kubernetes.io/name: substra-backend-worker
        app.kubernetes.io/component: substra-worker
      annotations:
        # This will cause the pod to restart if the content of the ConfigMap is updated through Helm
        checksum-cm-orchestrator: 7fb58d3e25fbd6ea6acbb5588dbffc9a5706f7bbc4f299c048d580f34893d7f8
        checksum-cm-settings: 1f882f1a5e1e5b5fb543b21fe957c242de5971fd5692637bf5380133e2bc8558
        checksum-cm-db: 33c676bec9db656cba3d03e10ea865cc06cc0c014f15ffbd818e5437d2b36cf8
        checksum-cm-registry: 0a84c216ae57353e86de39a9fa289078c50f82f64f945f9f7b672c8c123e8236
        checksum-cm-redis: 264b5affa56b5e88eed5ddc20e36253edbba046a4631250fd0addf3c962a9f84
        checksum-secret-objectstore : 6d97165cffab02b7858e66effcd5f9366495029d5e605ffe3ed4b8ba40a2e612
        checksum-secret-database : 240d15002756a2f3814b00b45a923d1a3d38e2f161bd09b400bf1ca275fdea81
        checksum-secret-redis : e9f2847d2e2a087f31f994f2aed36bef1958307dd134c7854cf9da3756cc519c
    spec:
      securityContext:
        runAsUser: 1001
        runAsGroup: 1001
        fsGroup: 1001
      serviceAccountName: release-name-substra-backend-worker
      initContainers:
      
      - name: wait-postgresql
        image: postgres
        env:
         - name: PGUSER
           value: postgres
         - name: PGPASSWORD
           value: postgres
         - name: PGDATABASE
           value: substra
        command: ['sh', '-c', 'until pg_isready --host=release-name-postgresql.default --port=5432; do echo "Waiting for postgresql service"; sleep 2; done;']
      
      - name: wait-minio
        image: jwilder/dockerize:0.6.1
        command: ['dockerize', '-wait', 'tcp://release-name-minio:9000', '-timeout', '15s']
      containers:
        - name: worker
          image: ghcr.io/substra/substra-backend:0.45.0
          imagePullPolicy: "IfNotPresent"
          command: ["/bin/bash"]
          args: ["-c", "celery -A backend worker -E -l info -Q owkin.worker,owkin.worker-${HOSTNAME##*-},owkin.broadcast,celery --hostname owkin.worker-${HOSTNAME##*-}"]
          
          envFrom:
            - configMapRef:
                name: release-name-substra-backend-orchestrator
            - configMapRef:
                name: release-name-substra-backend-settings
            - configMapRef:
                name: release-name-substra-backend-database
            - configMapRef:
                name: release-name-substra-backend-redis
            - configMapRef:
                name: release-name-substra-backend-registry
            - secretRef:
                name: release-name-substra-backend-objectstore
            - secretRef:
                name: release-name-substra-backend-redis
            - secretRef:
                name: release-name-substra-backend-database
          env:
            - name: DJANGO_SETTINGS_MODULE
              value: backend.settings.celery.prod
            - name: DEFAULT_DOMAIN
              value: "localhost"
            - name: "CELERY_WORKER_CONCURRENCY"
              value: "1"
            - name: WORKER_PVC_SUBTUPLE
              value: subtuple
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: NODE_NAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
            - name: COMPUTE_POD_RESOURCES
              value: "limits:\n  memory: 64Gi\nrequests:\n  cpu: 500m\n  memory: 512Mi"
            - name: COMPUTE_POD_MAX_STARTUP_WAIT_SECONDS
              value: "300"
            - name: OBJECTSTORE_URL
              value: "release-name-minio:9000"
            - name: ENABLE_DATASAMPLE_STORAGE_IN_SERVERMEDIAS
              value: "false"
          volumeMounts:
            - name: subtuple
              mountPath: /var/substra/medias/subtuple
            
          resources:
            limits:
              cpu: 2000m
              memory: 8Gi
            requests:
              cpu: 200m
              memory: 512Mi
      volumes:
      
  volumeClaimTemplates:
  - metadata:
      name: subtuple
    spec:
      accessModes: [ "ReadWriteOnce" ]
      
      resources:
        requests:
          storage: 10Gi
---
# Source: substra-backend/templates/job-migrations.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: release-name-substra-backend-migrations
  labels:
    
    helm.sh/chart: substra-backend-26.4.0
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.45.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: substra-backend
    app.kubernetes.io/name: release-name-substra-backend-migrations
  annotations:
    "helm.sh/hook": post-install,post-upgrade
    "helm.sh/hook-delete-policy": before-hook-creation
spec:
  template:
    metadata:
      name: release-name-substra-backend-migrations
    spec:
      restartPolicy: OnFailure
      automountServiceAccountToken: false
      securityContext:
        fsGroup: 1001
        runAsUser: 1001
        runAsGroup: 1001
      containers:
      - name: db-migrations
        image: ghcr.io/substra/substra-backend:0.45.0
        imagePullPolicy: IfNotPresent
        command: ["/bin/bash", "-c"]
        args:
          - |
            set -euo pipefail
            ./manage.py migrate

            ## Users
            while read -r user_password_channel; do
                read user password channel <<< "$user_password_channel"
                ./manage.py add_user "$user" "$password" "$channel"
            done < /accounts/users

            ## IncomingOrganization
            while read -r user_password; do
                read user password <<< "$user_password"
                ./manage.py create_incoming_organization "$user" "$password"
            done < /accounts/incoming_organizations

            ## OutgoingOrganization
            while read -r user_password; do
                read user password <<< "$user_password"
                ./manage.py create_outgoing_organization "$user" "$password"
            done < /accounts/outgoing_organizations
        envFrom:
          - configMapRef:
              name: release-name-substra-backend-orchestrator
          - configMapRef:
              name: release-name-substra-backend-database
          - secretRef:
              name: release-name-substra-backend-database
        env:
          - name: DJANGO_SETTINGS_MODULE
            value: backend.settings.prod
        volumeMounts:
          - mountPath: /accounts
            name: accounts
            readOnly: True
      volumes:
        - name: accounts
          secret:
            secretName: release-name-substra-backend-add-account
