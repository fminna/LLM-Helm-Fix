---
# Source: calico-aws/templates/poddisruptionbudget-typha.yaml
# This manifest creates a Pod Disruption Budget for Typha to allow K8s Cluster Autoscaler to evict
apiVersion: policy/v1beta1
kind: PodDisruptionBudget
metadata:
  name: release-name-calico-aws-typha
  labels:
    app: calico-aws-typha
    chart: calico-aws-0.1.4
    release: release-name
    heritage: Helm
spec:
  maxUnavailable: 1
  selector:
    matchLabels:
      app: calico-aws-typha
      release: release-name
---
# Source: calico-aws/templates/sa-calico.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: release-name-calico-aws-node
  labels:
    heritage: Helm
    release: release-name
    chart: calico-aws-0.1.4
    app: release-name-calico-aws
---
# Source: calico-aws/templates/sa-typha-cpha.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: release-name-calico-aws-typha-cpha
  labels:
    heritage: Helm
    release: release-name
    chart: calico-aws-0.1.4
    app: release-name-calico-aws
---
# Source: calico-aws/templates/cm-typha-cpha.yaml
kind: ConfigMap
apiVersion: v1
metadata:
  name: release-name-calico-aws-typha-cpha
  labels:
    app: calico-aws-typha-cpha
    chart: calico-aws-0.1.4
    release: release-name
    heritage: Helm
data:
  ladder: |-
    {
      "coresToReplicas": [],
      "nodesToReplicas":
      [
        [1, 1],
        [10, 2],
        [100, 3],
        [250, 4],
        [500, 5],
        [1000, 6],
        [1500, 7],
        [2000, 8]
      ]
    }
---
# Source: calico-aws/templates/customresourcedefinition.yaml
# Create all the CustomResourceDefinitions needed for
# Calico policy-only mode.

apiVersion: apiextensions.k8s.io/v1beta1
kind: CustomResourceDefinition
metadata:
  name: felixconfigurations.crd.projectcalico.org
spec:
  scope: Cluster
  group: crd.projectcalico.org
  versions:
    - name: v1
      served: true
      storage: true
  names:
    kind: FelixConfiguration
    plural: felixconfigurations
    singular: felixconfiguration
---
# Source: calico-aws/templates/customresourcedefinition.yaml
apiVersion: apiextensions.k8s.io/v1beta1
kind: CustomResourceDefinition
metadata:
  name: bgpconfigurations.crd.projectcalico.org
spec:
  scope: Cluster
  group: crd.projectcalico.org
  versions:
    - name: v1
      served: true
      storage: true
  names:
    kind: BGPConfiguration
    plural: bgpconfigurations
    singular: bgpconfiguration
---
# Source: calico-aws/templates/customresourcedefinition.yaml
apiVersion: apiextensions.k8s.io/v1beta1
kind: CustomResourceDefinition
metadata:
  name: bgppeers.crd.projectcalico.org
spec:
  scope: Cluster
  group: crd.projectcalico.org
  versions:
    - name: v1
      served: true
      storage: true
  names:
    kind: BGPPeer
    plural: bgppeers
    singular: bgppeer
---
# Source: calico-aws/templates/customresourcedefinition.yaml
apiVersion: apiextensions.k8s.io/v1beta1
kind: CustomResourceDefinition
metadata:
  name: ippools.crd.projectcalico.org
spec:
  scope: Cluster
  group: crd.projectcalico.org
  versions:
    - name: v1
      served: true
      storage: true
  names:
    kind: IPPool
    plural: ippools
    singular: ippool
---
# Source: calico-aws/templates/customresourcedefinition.yaml
apiVersion: apiextensions.k8s.io/v1beta1
kind: CustomResourceDefinition
metadata:
  name: hostendpoints.crd.projectcalico.org
spec:
  scope: Cluster
  group: crd.projectcalico.org
  versions:
    - name: v1
      served: true
      storage: true
  names:
    kind: HostEndpoint
    plural: hostendpoints
    singular: hostendpoint
---
# Source: calico-aws/templates/customresourcedefinition.yaml
apiVersion: apiextensions.k8s.io/v1beta1
kind: CustomResourceDefinition
metadata:
  name: clusterinformations.crd.projectcalico.org
spec:
  scope: Cluster
  group: crd.projectcalico.org
  versions:
    - name: v1
      served: true
      storage: true
  names:
    kind: ClusterInformation
    plural: clusterinformations
    singular: clusterinformation
---
# Source: calico-aws/templates/customresourcedefinition.yaml
apiVersion: apiextensions.k8s.io/v1beta1
kind: CustomResourceDefinition
metadata:
  name: globalnetworkpolicies.crd.projectcalico.org
spec:
  scope: Cluster
  group: crd.projectcalico.org
  versions:
    - name: v1
      served: true
      storage: true
  names:
    kind: GlobalNetworkPolicy
    plural: globalnetworkpolicies
    singular: globalnetworkpolicy
---
# Source: calico-aws/templates/customresourcedefinition.yaml
apiVersion: apiextensions.k8s.io/v1beta1
kind: CustomResourceDefinition
metadata:
  name: globalnetworksets.crd.projectcalico.org
spec:
  scope: Cluster
  group: crd.projectcalico.org
  versions:
    - name: v1
      served: true
      storage: true
  names:
    kind: GlobalNetworkSet
    plural: globalnetworksets
    singular: globalnetworkset
---
# Source: calico-aws/templates/customresourcedefinition.yaml
apiVersion: apiextensions.k8s.io/v1beta1
kind: CustomResourceDefinition
metadata:
  name: networkpolicies.crd.projectcalico.org
spec:
  scope: Namespaced
  group: crd.projectcalico.org
  versions:
    - name: v1
      served: true
      storage: true
  names:
    kind: NetworkPolicy
    plural: networkpolicies
    singular: networkpolicy
---
# Source: calico-aws/templates/clusterrole-calico.yaml
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: release-name-calico-aws-node
rules:
  - apiGroups: [""]
    resources:
      - namespaces
      - serviceaccounts
    verbs:
      - get
      - list
      - watch
  - apiGroups: [""]
    resources:
      - pods/status
    verbs:
      - patch
  - apiGroups: [""]
    resources:
      - pods
    verbs:
      - get
      - list
      - watch
  - apiGroups: [""]
    resources:
      - services
    verbs:
      - get
  - apiGroups: [""]
    resources:
      - endpoints
    verbs:
      - get
  - apiGroups: [""]
    resources:
      - nodes
    verbs:
      - get
      - list
      - update
      - watch
  - apiGroups: ["extensions"]
    resources:
      - networkpolicies
    verbs:
      - get
      - list
      - watch
  - apiGroups: ["networking.k8s.io"]
    resources:
      - networkpolicies
    verbs:
      - watch
      - list
  - apiGroups: ["crd.projectcalico.org"]
    resources:
      - globalfelixconfigs
      - felixconfigurations
      - bgppeers
      - globalbgpconfigs
      - bgpconfigurations
      - ippools
      - globalnetworkpolicies
      - globalnetworksets
      - networkpolicies
      - clusterinformations
      - hostendpoints
    verbs:
      - create
      - get
      - list
      - update
      - watch
---
# Source: calico-aws/templates/clusterrole-typha-cpha.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: release-name-calico-aws-typha-cpha
rules:
  - apiGroups: [""]
    resources: ["nodes"]
    verbs: ["list"]
---
# Source: calico-aws/templates/clusterrolebinding-calico.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: release-name-calico-aws-node
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: release-name-calico-aws-node
subjects:
  - kind: ServiceAccount
    name: release-name-calico-aws-node
    namespace: default
---
# Source: calico-aws/templates/clusterrolebinding-typha-cpha.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: release-name-calico-aws-typha-cpha
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: release-name-calico-aws-typha-cpha
subjects:
  - kind: ServiceAccount
    name: release-name-calico-aws-typha-cpha
    namespace: default
---
# Source: calico-aws/templates/role-typha-cpha.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: release-name-calico-aws-typha-cpha
rules:
  - apiGroups: [""]
    resources: ["configmaps"]
    verbs: ["get"]
  - apiGroups: ["extensions"]
    resources: ["deployments/scale"]
    verbs: ["get", "update"]
---
# Source: calico-aws/templates/rolebinding-typha-cpha.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: release-name-calico-aws-typha-cpha
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: release-name-calico-aws-typha-cpha
subjects:
  - kind: ServiceAccount
    name: release-name-calico-aws-typha-cpha
---
# Source: calico-aws/templates/service-typha.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-calico-aws-typha
  labels:
    app: calico-aws-typha
    chart: calico-aws-0.1.4
    release: release-name
    heritage: Helm
spec:
  ports:
    - port: 5473
      protocol: TCP
      targetPort: calico-typha
      name: calico-typha
  selector:
    app: calico-aws-typha
    release: release-name
---
# Source: calico-aws/templates/daemonset-calico.yaml
kind: DaemonSet
apiVersion: apps/v1
metadata:
  name: release-name-calico-aws-node
  labels:
    app: calico-aws-node
    chart: calico-aws-0.1.4
    release: release-name
    heritage: Helm
spec:
  selector:
    matchLabels:
      app: calico-aws-node
      release: release-name
  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
  template:
    metadata:
      labels:
        app: calico-aws-node
        chart: calico-aws-0.1.4
        release: release-name
        heritage: Helm
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: '9091'
    spec:
      priorityClassName: system-node-critical
      nodeSelector:
        beta.kubernetes.io/os: linux
      tolerations:
        # Make sure calico/node gets scheduled on all nodes.
        - effect: NoSchedule
          operator: Exists
        # Mark the pod as a critical add-on for rescheduling.
        - key: CriticalAddonsOnly
          operator: Exists
        - effect: NoExecute
          operator: Exists
      hostNetwork: true
      dnsPolicy: ClusterFirstWithHostNet
      serviceAccountName: release-name-calico-aws-node
      automountServiceAccountToken: true
      # Minimize downtime during a rolling upgrade or deletion; tell Kubernetes to do a "force
      # deletion": https://kubernetes.io/docs/concepts/workloads/pods/pod/#termination-of-pods.
      terminationGracePeriodSeconds: 0
      containers:
        # Runs calico/node container on each Kubernetes node.  This
        # container programs network policy and routes on each
        # host.
        - name: calico-node
          image: "quay.io/calico/node:v3.3.6"
          ports:
            - containerPort: 9091
              name: metrics
              protocol: TCP
          env:
            - name: CALICO_DISABLE_FILE_LOGGING
              value: "true"
            - name: CALICO_NETWORKING_BACKEND
              value: "none"
            - name: CLUSTER_TYPE
              value: "k8s,ecs"
            - name: DATASTORE_TYPE
              value: "kubernetes"
            - name: FELIX_DEFAULTENDPOINTTOHOSTACTION
              value: "ACCEPT"
            - name: FELIX_HEALTHENABLED
              value: "true"
            - name: FELIX_INTERFACEPREFIX
              value: "eni"
            - name: FELIX_IPTABLESMANGLEALLOWACTION
              value: "Return"
            - name: FELIX_IPV6SUPPORT
              value: "false"
            - name: FELIX_LOGSEVERITYSCREEN
              value: "info"
            - name: FELIX_LOGSEVERITYSYS
              value: "none"
            - name: FELIX_PROMETHEUSMETRICSENABLED
              value: "true"
            - name: FELIX_PROMETHEUSMETRICSPORT
              value: "9091"
            - name: FELIX_TYPHAK8SNAMESPACE
              value: "default"
            - name: FELIX_TYPHAK8SSERVICENAME
              value: "release-name-calico-aws-typha"
            - name: IP
              value: ""
            - name: NO_DEFAULT_POOLS
              value: "true"
            - name: WAIT_FOR_DATASTORE
              value: "true"
            # Set based on the k8s node name.
            - name: NODENAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
          securityContext:
            privileged: true
          livenessProbe:
            httpGet:
              path: /liveness
              port: 9099
              host: localhost
            periodSeconds: 10
            initialDelaySeconds: 10
            failureThreshold: 6
            
          readinessProbe:
            exec:
              command:
                - /bin/calico-node
                - -felix-ready
            periodSeconds: 10
            
          volumeMounts:
            - mountPath: /lib/modules
              name: lib-modules
              readOnly: true
            - mountPath: /run/xtables.lock
              name: xtables-lock
              readOnly: false
            - mountPath: /var/run/calico
              name: var-run-calico
              readOnly: false
            - mountPath: /var/lib/calico
              name: var-lib-calico
              readOnly: false
      volumes:
        # Used to ensure proper kmods are installed.
        - name: lib-modules
          hostPath:
            path: /lib/modules
        - name: var-run-calico
          hostPath:
            path: /var/run/calico
        - name: var-lib-calico
          hostPath:
            path: /var/lib/calico
        - name: xtables-lock
          hostPath:
            path: /run/xtables.lock
            type: FileOrCreate
---
# Source: calico-aws/templates/deployment-typha-cpha.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-calico-aws-typha-cpha
  labels:
    app: calico-aws-typha-cpha
    chart: calico-aws-0.1.4
    release: release-name
    heritage: Helm
spec:
  selector:
    matchLabels:
      app: calico-aws-typha-cpha
      release: release-name
  replicas: 1
  template:
    metadata:
      labels:
        app: calico-aws-typha-cpha
        chart: calico-aws-0.1.4
        release: release-name
        heritage: Helm
      annotations:
    spec:      
      priorityClassName: system-cluster-critical
      nodeSelector:
        beta.kubernetes.io/os: linux
      serviceAccountName: release-name-calico-aws-typha-cpha
      automountServiceAccountToken: true
      containers:
        - image: "k8s.gcr.io/cluster-proportional-autoscaler-amd64:1.1.2"
          name: autoscaler
          command:
            - /cluster-proportional-autoscaler
            - "--configmap=release-name-calico-aws-typha-cpha"
            - "--logtostderr=true"
            - "--namespace=default"
            - "--target=deployment/release-name-calico-aws-typha"
            - "--v=2"
          resources:
            limits:
              cpu: 10m
            requests:
              cpu: 10m
---
# Source: calico-aws/templates/deployment-typha.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-calico-aws-typha
  labels:
    app: calico-aws-typha
    chart: calico-aws-0.1.4
    release: release-name
    heritage: Helm
spec:
  selector:
    matchLabels:
      app: calico-aws-typha
      release: release-name
  strategy:
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 1
    type: RollingUpdate
  template:
    metadata:
      labels:
        app: calico-aws-typha
        chart: calico-aws-0.1.4
        release: release-name
        heritage: Helm
      annotations:
        cluster-autoscaler.kubernetes.io/safe-to-evict: "true"
        prometheus.io/scrape: "true"
        prometheus.io/port: '9093'
    spec:
      priorityClassName: system-cluster-critical
      nodeSelector:
        beta.kubernetes.io/os: linux
      tolerations:
        # Mark the pod as a critical add-on for rescheduling.
        - key: CriticalAddonsOnly
          operator: Exists
      hostNetwork: true
      serviceAccountName: release-name-calico-aws-node
      automountServiceAccountToken: true
      containers:
        - image: "quay.io/calico/typha:v3.3.6"
          name: calico-typha
          ports:
            - containerPort: 5473
              name: calico-typha
              protocol: TCP
            - containerPort: 9098
              name: health
              protocol: TCP
            - containerPort: 9093
              name: metrics
              protocol: TCP
          env:
            - name: FELIX_INTERFACEPREFIX
              value: "eni"
            - name: FELIX_IPTABLESMANGLEALLOWACTION
              value: "Return"
            - name: TYPHA_CONNECTIONREBALANCINGMODE
              value: "kubernetes"
            - name: TYPHA_DATASTORETYPE
              value: "kubernetes"
            - name: TYPHA_HEALTHENABLED
              value: "true"
            - name: TYPHA_HEALTHPORT
              value: "9098"
            - name: TYPHA_K8SNAMESPACE
              value: "default"
            - name: TYPHA_K8SSERVICENAME
              value: "release-name-calico-aws-typha"
            - name: TYPHA_LOGFILEPATH
              value: "none"
            - name: TYPHA_LOGSEVERITYSCREEN
              value: "info"
            - name: TYPHA_LOGSEVERITYSYS
              value: "none"
            - name: TYPHA_MAXCONNECTIONSLOWERLIMIT
              value: "1"
            - name: TYPHA_PROMETHEUSMETRICSENABLED
              value: "true"
            - name: TYPHA_PROMETHEUSMETRICSPORT
              value: "9093"
          livenessProbe:
            exec:
              command:
                - calico-typha
                - check
                - liveness
            periodSeconds: 30
            initialDelaySeconds: 30
            
          readinessProbe:
            exec:
              command:
                - calico-typha
                - check
                - readiness
            periodSeconds: 10
