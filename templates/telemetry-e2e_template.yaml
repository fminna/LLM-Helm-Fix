---
# Source: telemetry-e2e/charts/ditto/templates/concierge-networkpolicy.yaml
kind: NetworkPolicy
apiVersion: networking.k8s.io/v1
metadata:
  name: ditto-concierge
  labels:
    app.kubernetes.io/name: ditto-concierge
    helm.sh/chart: ditto-2.1.2
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "2.1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  podSelector:
    matchLabels:
      app.kubernetes.io/name: ditto-concierge
      app.kubernetes.io/instance: release-name
  policyTypes:
  - Ingress
  - Egress
  ingress:
  # Allow inner cluster communication
  - from:
    - podSelector:
        matchLabels:
          actorSystemName: ditto-cluster
    ports:
    - protocol: TCP
      port: 2551
    - protocol: TCP
      port: 8558
# Open all egress
  egress:
  - {}
---
# Source: telemetry-e2e/charts/ditto/templates/connectivity-networkpolicy.yaml
kind: NetworkPolicy
apiVersion: networking.k8s.io/v1
metadata:
  name: ditto-connectivity
  labels:
    app.kubernetes.io/name: ditto-connectivity
    helm.sh/chart: ditto-2.1.2
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "2.1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  podSelector:
    matchLabels:
      app.kubernetes.io/name: ditto-connectivity
      app.kubernetes.io/instance: release-name
  policyTypes:
  - Ingress
  - Egress
  ingress:
  # Allow inner cluster communication
  - from:
    - podSelector:
        matchLabels:
          actorSystemName: ditto-cluster
    ports:
    - protocol: TCP
      port: 2551
    - protocol: TCP
      port: 8558
  # Open all egress
  egress:
  - {}
---
# Source: telemetry-e2e/charts/ditto/templates/gateway-networkpolicy.yaml
kind: NetworkPolicy
apiVersion: networking.k8s.io/v1
metadata:
  name: ditto-gateway
  labels:
    app.kubernetes.io/name: ditto-gateway
    helm.sh/chart: ditto-2.1.2
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "2.1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  podSelector:
    matchLabels:
      app.kubernetes.io/name: ditto-gateway
      app.kubernetes.io/instance: release-name
  policyTypes:
  - Ingress
  - Egress
  ingress:
  # Allow access from Nginx
  - from:
    - podSelector:
        matchLabels:
          app.kubernetes.io/name: ditto-nginx
          app.kubernetes.io/instance: release-name
    ports:
    - protocol: TCP
      port: http
  # Allow inner cluster communication
  - from:
    - podSelector:
        matchLabels:
          actorSystemName: ditto-cluster
    ports:
    - protocol: TCP
      port: 2551
    - protocol: TCP
      port: 8558
  # Open all egress
  egress:
  - {}
---
# Source: telemetry-e2e/charts/ditto/templates/policies-networkpolicy.yaml
kind: NetworkPolicy
apiVersion: networking.k8s.io/v1
metadata:
  name: ditto-policies
  labels:
    app.kubernetes.io/name: ditto-policies
    helm.sh/chart: ditto-2.1.2
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "2.1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  podSelector:
    matchLabels:
      app.kubernetes.io/name: ditto-policies
      app.kubernetes.io/instance: release-name
  policyTypes:
  - Ingress
  - Egress
  ingress:
  # Allow inner cluster communication
  - from:
    - podSelector:
        matchLabels:
          actorSystemName: ditto-cluster
    ports:
    - protocol: TCP
      port: 2551
    - protocol: TCP
      port: 8558
  # Open all egress
  egress:
  - {}
---
# Source: telemetry-e2e/charts/ditto/templates/swaggerui-networkpolicy.yaml
kind: NetworkPolicy
apiVersion: networking.k8s.io/v1
metadata:
  name: ditto-swaggerui
  labels:
    app.kubernetes.io/name: ditto-swaggerui
    helm.sh/chart: ditto-2.1.2
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "2.1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  podSelector:
    matchLabels:
      app.kubernetes.io/name: ditto-swaggerui
      app.kubernetes.io/instance: release-name
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - podSelector:
        matchLabels:
          app.kubernetes.io/name: ditto-nginx
          app.kubernetes.io/instance: release-name
    ports:
    - protocol: TCP
      port: 8080
---
# Source: telemetry-e2e/charts/ditto/templates/things-networkpolicy.yaml
kind: NetworkPolicy
apiVersion: networking.k8s.io/v1
metadata:
  name: ditto-things
  labels:
    app.kubernetes.io/name: ditto-things
    helm.sh/chart: ditto-2.1.2
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "2.1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  podSelector:
    matchLabels:
      app.kubernetes.io/name: ditto-things
      app.kubernetes.io/instance: release-name
  policyTypes:
  - Ingress
  - Egress
  ingress:
  # Allow access from concierge
  - from:
    - podSelector:
        matchLabels:
          app.kubernetes.io/name: ditto-concierge
          app.kubernetes.io/instance: release-name
    ports:
    - protocol: TCP
      port: http
  # Allow inner cluster communication
  - from:
    - podSelector:
        matchLabels:
          actorSystemName: ditto-cluster
    ports:
    - protocol: TCP
      port: 2551
    - protocol: TCP
      port: 8558
  # Open all egress
  egress:
  - {}
---
# Source: telemetry-e2e/charts/ditto/templates/thingssearch-networkpolicy.yaml
kind: NetworkPolicy
apiVersion: networking.k8s.io/v1
metadata:
  name: ditto-thingssearch
  labels:
    app.kubernetes.io/name: ditto-thingssearch
    helm.sh/chart: ditto-2.1.2
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "2.1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  podSelector:
    matchLabels:
      app.kubernetes.io/name: ditto-thingssearch
      app.kubernetes.io/instance: release-name
  policyTypes:
  - Ingress
  - Egress
  ingress:
  # Allow inner cluster communication
  - from:
    - podSelector:
        matchLabels:
          actorSystemName: ditto-cluster
    ports:
    - protocol: TCP
      port: 2551
    - protocol: TCP
      port: 8558
  # Open all egress
  egress:
  - {}
---
# Source: telemetry-e2e/charts/ditto/charts/mongodb/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: ditto-mongodb
  namespace: default
  labels:
    app: mongodb
    chart: mongodb-7.14.8
    release: "release-name"
    heritage: "Helm"
secrets:
  - name: ditto-mongodb
---
# Source: telemetry-e2e/charts/ditto/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: ditto
  labels:
    app.kubernetes.io/name: ditto
    helm.sh/chart: ditto-2.1.2
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "2.1.0"
    app.kubernetes.io/managed-by: Helm
---
# Source: telemetry-e2e/charts/drogueCloud/templates/service/console/service-account-backend.yaml
kind: ServiceAccount
apiVersion: v1
metadata:
  name: console-backend
  labels:
    app.kubernetes.io/name: console-backend
    app.kubernetes.io/component: console
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.7.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: drogue-iot
---
# Source: telemetry-e2e/charts/drogueCloud/templates/service/registry/topic-operator/service-account.yaml
kind: ServiceAccount
apiVersion: v1
metadata:
  name: topic-operator
  labels:
    app.kubernetes.io/name: topic-operator
    app.kubernetes.io/component: device-registry
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.7.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: drogue-iot
---
# Source: telemetry-e2e/charts/drogueCloud/templates/service/registry/ttn-operator/service-account.yaml
kind: ServiceAccount
apiVersion: v1
metadata:
  name: ttn-operator
  labels:
    app.kubernetes.io/name: ttn-operator
    app.kubernetes.io/component: device-registry
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.7.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: drogue-iot
---
# Source: telemetry-e2e/charts/streamsheets/charts/mongodb/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: streamsheets-mongodb
  namespace: default
  labels:
    app.kubernetes.io/name: mongodb
    helm.sh/chart: mongodb-10.25.2
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
secrets:
  - name: streamsheets-mongodb
---
# Source: telemetry-e2e/charts/streamsheets/charts/redis/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
automountServiceAccountToken: true
metadata:
  name: streamsheets-redis
  namespace: "default"
  labels:
    app.kubernetes.io/name: redis
    helm.sh/chart: redis-14.8.11
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
---
# Source: telemetry-e2e/charts/strimzi/templates/010-ServiceAccount-strimzi-cluster-operator.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: strimzi-cluster-operator
  labels:
    app: strimzi
    chart: strimzi-0.25.0
    component: service-account
    release: release-name
    heritage: Helm
---
# Source: telemetry-e2e/templates/keycloak/service_account.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: keycloak-operator
---
# Source: telemetry-e2e/charts/ditto/templates/gateway-secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: ditto-gateway-secret
  labels:
    app.kubernetes.io/name: ditto-gateway-secret
    helm.sh/chart: ditto-2.1.2
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "2.1.0"
    app.kubernetes.io/managed-by: Helm
type: Opaque
data:
  devops-password: "amFNMDJLQThBa1Mx"
  status-password: "M2NYUWFEWkxTV0w4"
---
# Source: telemetry-e2e/charts/ditto/templates/mongodb-secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: ditto-mongodb-secret
  labels:
    app.kubernetes.io/name: ditto-mongodb-secret
    helm.sh/chart: ditto-2.1.2
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "2.1.0"
    app.kubernetes.io/managed-by: Helm
type: Opaque
data:
  concierge-uri: "bW9uZ29kYjovL2RpdHRvLW1vbmdvZGI6MjcwMTcvY29uY2llcmdl"
  connectivity-uri: "bW9uZ29kYjovL2RpdHRvLW1vbmdvZGI6MjcwMTcvY29ubmVjdGl2aXR5"
  things-uri: "bW9uZ29kYjovL2RpdHRvLW1vbmdvZGI6MjcwMTcvdGhpbmdz"
  searchDB-uri: "bW9uZ29kYjovL2RpdHRvLW1vbmdvZGI6MjcwMTcvc2VhcmNoREI="
  policies-uri: "bW9uZ29kYjovL2RpdHRvLW1vbmdvZGI6MjcwMTcvcG9saWNpZXM="
---
# Source: telemetry-e2e/charts/drogueCloud/templates/kafka/external-secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: external-kafka-secret
  labels:
    app.kubernetes.io/name: external-kafka-secret
    app.kubernetes.io/component: kafka
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.7.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: drogue-iot
data:
  
  
  mechanism: U0NSQU0tU0hBLTUxMg==
  username: ZHJvZ3VlLWlvdA==
---
# Source: telemetry-e2e/charts/drogueCloud/templates/service/registry/postgres/secret.yaml
kind: Secret
apiVersion: v1
metadata:
  name: postgres-secret
  labels:
    app.kubernetes.io/name: postgres-secret
    app.kubernetes.io/component: device-registry
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.7.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: drogue-iot
type: Opaque
data:
  admin.username: "YWRtaW4="
  admin.password: "YWRtaW4xMjM0NTY="
---
# Source: telemetry-e2e/charts/drogueCloud/templates/sso/credential-sso.yaml
apiVersion: v1
kind: Secret
metadata:
  name: credential-sso
  labels:
    app.kubernetes.io/part-of: sso
data:
  ADMIN_USERNAME: YWRtaW4= # admin
  ADMIN_PASSWORD: YWRtaW4xMjM0NTY=
---
# Source: telemetry-e2e/charts/drogueCloud/templates/sso/database.yaml
apiVersion: v1
kind: Secret
metadata:
  name: keycloak-db-secret
data:
  POSTGRES_DATABASE: "cmVnaXN0cnk="
  POSTGRES_EXTERNAL_ADDRESS: "cG9zdGdyZXMuZGVmYXVsdC5zdmMuY2x1c3Rlci5sb2NhbC4="
  POSTGRES_EXTERNAL_PORT: "NTQzMg=="
  POSTGRES_USERNAME: "YWRtaW4="
  POSTGRES_PASSWORD: "YWRtaW4xMjM0NTY="
---
# Source: telemetry-e2e/charts/streamsheets/charts/mongodb/templates/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: streamsheets-mongodb
  namespace: default
  labels:
    app.kubernetes.io/name: mongodb
    helm.sh/chart: mongodb-10.25.2
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: mongodb
type: Opaque
data:
  mongodb-root-password:  "YWRtaW4xMjM0NTY="
  mongodb-password:  "c3RyZWFtc2hlZXRzMTIzNDU2"
---
# Source: telemetry-e2e/charts/streamsheets/templates/broker/secrets.yaml
kind: Secret
apiVersion: v1
metadata:
  name: streamsheets-broker
  labels:
    helm.sh/chart: streamsheets-0.2.3
    app.kubernetes.io/name: streamsheets-broker
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "2.4.0"
    app.kubernetes.io/managed-by: Helm
data:
  USERNAME: "aW50ZXJuYWw="
  PASSWORD: "aW50ZXJuYWwxMjM0NTY="
---
# Source: telemetry-e2e/templates/kafka/kafka-user-secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: ditto-kafka-user-credentials
data:
  password: "Y2hhbmdlbWU="
---
# Source: telemetry-e2e/templates/post-install/secret.yaml
kind: Secret
apiVersion: v1
metadata:
  name: post-install-data
  labels:
    app.kubernetes.io/name: post-install
    app.kubernetes.io/component: post-install
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.1.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: deployment
type: Opaque
data:
  
  drogue-cloud-application.json: "ewogICJtZXRhZGF0YSI6IHsKICAgICJuYW1lIjogImVjbGlwc2UiCiAgfQp9Cg=="
  drogue-cloud-create-connection.json: "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"
  drogue-cloud-delete-connection.json: "ewogICJ0YXJnZXRBY3RvclNlbGVjdGlvbiI6ICIvc3lzdGVtL3NoYXJkaW5nL2Nvbm5lY3Rpb24iLAogICJoZWFkZXJzIjogewogICAgImFnZ3JlZ2F0ZSI6IGZhbHNlCiAgfSwKICAicGlnZ3liYWNrQ29tbWFuZCI6IHsKICAgICJ0eXBlIjogImNvbm5lY3Rpdml0eS5jb21tYW5kczpkZWxldGVDb25uZWN0aW9uIiwKICAgICJjb25uZWN0aW9uSWQiOiAiZHJvZ3VlLWlvdC1lY2xpcHNlLWlvdC1rYWZrYSIKICB9Cn0K"
  drogue-cloud-device.json: "ewogICJtZXRhZGF0YSI6IHsKICAgICJhcHBsaWNhdGlvbiI6ICJlY2xpcHNlIiwKICAgICJuYW1lIjogImRldmljZS0xIgogIH0sCiAgInNwZWMiOiB7CiAgICAiY3JlZGVudGlhbHMiOiB7CiAgICAgICJjcmVkZW50aWFscyI6IFsKICAgICAgICB7ICJwYXNzIjogImRldmljZTEyIiB9CiAgICAgIF0KICAgIH0KICB9Cn0K"
  streamsheets-create-connection.json: "ewogICJ0YXJnZXRBY3RvclNlbGVjdGlvbiI6ICIvc3lzdGVtL3NoYXJkaW5nL2Nvbm5lY3Rpb24iLAogICJoZWFkZXJzIjogewogICAgImFnZ3JlZ2F0ZSI6IGZhbHNlCiAgfSwKICAicGlnZ3liYWNrQ29tbWFuZCI6IHsKICAgICJ0eXBlIjogImNvbm5lY3Rpdml0eS5jb21tYW5kczpjcmVhdGVDb25uZWN0aW9uIiwKICAgICJjb25uZWN0aW9uIjogewogICAgICAiaWQiOiAic3RyZWFtc2hlZXRzLXZpYS1tcXR0IiwKICAgICAgImNvbm5lY3Rpb25UeXBlIjogIm1xdHQiLAogICAgICAiY29ubmVjdGlvblN0YXR1cyI6ICJvcGVuIiwKICAgICAgImZhaWxvdmVyRW5hYmxlZCI6IHRydWUsCiAgICAgICJ1cmkiOiAidGNwOi8vaW50ZXJuYWw6aW50ZXJuYWwxMjM0NTZAc3RyZWFtc2hlZXRzLWJyb2tlcjoxODgzIiwKICAgICAgInZhbGlkYXRlQ2VydGlmaWNhdGVzIjogZmFsc2UsCiAgICAgICJzcGVjaWZpY0NvbmZpZyI6IHsKICAgICAgICAicmVjb25uZWN0Rm9yUmVkZWxpdmVyeSI6IGZhbHNlLAogICAgICAgICJjbGVhblNlc3Npb24iOiB0cnVlLAogICAgICAgICJzZXBhcmF0ZVB1Ymxpc2hlckNsaWVudCI6IGZhbHNlCiAgICAgIH0sCiAgICAgICJzb3VyY2VzIjogWwogICAgICBdLAogICAgICAidGFyZ2V0cyI6IFsKICAgICAgICB7CiAgICAgICAgICAiYWRkcmVzcyI6ICJkaXR0by10d2luLWV2ZW50cyIsCiAgICAgICAgICAidG9waWNzIjogWwogICAgICAgICAgICAiXy9fL3RoaW5ncy90d2luL2V2ZW50cyIKICAgICAgICAgIF0sCiAgICAgICAgICAiYXV0aG9yaXphdGlvbkNvbnRleHQiOiBbInByZS1hdXRoZW50aWNhdGVkOnN0cmVhbXNoZWV0cyJdLAogICAgICAgICAgInFvcyI6IDAsCiAgICAgICAgICAicGF5bG9hZE1hcHBpbmciOiBbCiAgICAgICAgICAgICJOb3JtYWxpemVkIgogICAgICAgICAgXQogICAgICAgIH0KICAgICAgXQogICAgfQogIH0KfQo="
  streamsheets-delete-connection.json: "ewogICJ0YXJnZXRBY3RvclNlbGVjdGlvbiI6ICIvc3lzdGVtL3NoYXJkaW5nL2Nvbm5lY3Rpb24iLAogICJoZWFkZXJzIjogewogICAgImFnZ3JlZ2F0ZSI6IGZhbHNlCiAgfSwKICAicGlnZ3liYWNrQ29tbWFuZCI6IHsKICAgICJ0eXBlIjogImNvbm5lY3Rpdml0eS5jb21tYW5kczpkZWxldGVDb25uZWN0aW9uIiwKICAgICJjb25uZWN0aW9uSWQiOiAic3RyZWFtc2hlZXRzLXZpYS1tcXR0IgogIH0KfQo="
  thing-definition.json: "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"
---
# Source: telemetry-e2e/templates/streamsheets/init.yaml
kind: Secret
apiVersion: v1
metadata:
  name: streamsheets-init
data:
  init.json: |
    {
  "version": 2,
  "machines": [
    {
      "machine": {
        "id": "rybIEm3_zF",
        "name": "Eclipse IoT",
        "state": "running",
        "metadata": {
          "owner": "anon",
          "lastModified": 1631278075551,
          "lastModifiedBy": "unknown",
          "fileVersion": "2.0.0"
        },
        "streamsheets": [
          {
            "id": "HJVUN72OzF",
            "name": "S1",
            "loop": {
              "path": "",
              "enabled": false,
              "recursively": false
            },
            "inbox": {
              "max": 20,
              "type": "MessageBox",
              "id": "HySLVXh_Mt",
              "stream": {
                "id": "S1eMm7hOGK",
                "name": "EclipseDittoConsumer"
              }
            },
            "sheet": {
              "cells": {
                "B3": {
                  "value": "Temp",
                  "type": "string",
                  "level": 0,
                  "ref": {
                    "col": "B",
                    "row": 3
                  }
                },
                "C3": {
                  "formula": "READ(INBOXDATA(,,\"features\",\"temperature\",\"properties\",\"value\"),D3,\"Number\",,TRUE)",
                  "value": "value",
                  "type": "undefined",
                  "level": 0,
                  "ref": {
                    "col": "C",
                    "row": 3
                  }
                },
                "D3": {
                  "value": "#NA!",
                  "type": "string",
                  "level": 0,
                  "ref": {
                    "col": "D",
                    "row": 3
                  }
                },
                "B4": {
                  "value": "Hum",
                  "type": "string",
                  "level": 0,
                  "ref": {
                    "col": "B",
                    "row": 4
                  }
                },
                "C4": {
                  "formula": "READ(INBOXDATA(,,\"features\",\"humidity\",\"properties\",\"value\"),D4,\"Number\",,TRUE)",
                  "value": "value",
                  "type": "undefined",
                  "level": 0,
                  "ref": {
                    "col": "C",
                    "row": 4
                  }
                },
                "D4": {
                  "value": "#NA!",
                  "type": "string",
                  "level": 0,
                  "ref": {
                    "col": "D",
                    "row": 4
                  }
                },
                "B5": {
                  "value": "Battery",
                  "type": "string",
                  "level": 0,
                  "ref": {
                    "col": "B",
                    "row": 5
                  }
                },
                "C5": {
                  "formula": "READ(INBOXDATA(,,\"features\",\"battery\",\"properties\",\"value\"),D5,\"Number\",,TRUE)",
                  "value": "value",
                  "type": "undefined",
                  "level": 0,
                  "ref": {
                    "col": "C",
                    "row": 5
                  }
                },
                "D5": {
                  "value": "#NA!",
                  "type": "string",
                  "level": 0,
                  "ref": {
                    "col": "D",
                    "row": 5
                  }
                },
                "B7": {
                  "value": "Location",
                  "type": "string",
                  "level": 0
                },
                "C7": {
                  "formula": "READ(INBOXDATA(,,\"features\",\"location\",\"properties\",\"latitude\"),D7,\"Number\",,TRUE)",
                  "value": "latitude",
                  "type": "undefined",
                  "level": 0,
                  "ref": {
                    "col": "C",
                    "row": 7
                  }
                },
                "D7": {
                  "value": 1,
                  "type": "number",
                  "level": 0,
                  "ref": {
                    "col": "D",
                    "row": 7
                  }
                },
                "C8": {
                  "formula": "READ(INBOXDATA(,,\"features\",\"location\",\"properties\",\"longitude\"),D8,\"Number\",,TRUE)",
                  "value": "longitude",
                  "type": "undefined",
                  "level": 0,
                  "ref": {
                    "col": "C",
                    "row": 8
                  }
                },
                "D8": {
                  "value": 1,
                  "type": "number",
                  "level": 0,
                  "ref": {
                    "col": "D",
                    "row": 8
                  }
                }
              },
              "namedCells": {},
              "shapes": {
                "shapes": [],
                "changed": 487512673183,
                "version": 1
              },
              "properties": {
                "cols": [],
                "rows": [],
                "cells": []
              },
              "settings": {
                "maxchars": 1000,
                "minrow": 1,
                "maxrow": 100,
                "mincol": -2,
                "maxcol": 50,
                "protected": false
              }
            },
            "trigger": {
              "repeat": "once",
              "type": "arrival"
            }
          }
        ],
        "settings": {
          "view": {
            "maximize": "HJVUN72OzF",
            "showInbox": false,
            "showGrid": false,
            "showHeader": false,
            "showOutbox": false,
            "allowZoom": false,
            "allowScroll": true
          },
          "locale": "en",
          "isOPCUA": false,
          "cycletime": 100
        },
        "extensionSettings": {},
        "className": "Machine",
        "scope": {
          "id": "root"
        },
        "namedCells": {
          "|Wind_Data": {
            "value": {
              "id": "HkZRIJtchH",
              "name": "Wind_Data",
              "type": "stream",
              "state": "connected",
              "timestamp": 1631269491893,
              "scope": {
                "id": "root"
              }
            },
            "type": "object",
            "info": {
              "rawtype": "object"
            },
            "level": 0
          },
          "|MQTT_Consumer": {
            "value": {
              "id": "CONSUMER_MQTT",
              "name": "MQTT_Consumer",
              "type": "stream",
              "state": "connected",
              "timestamp": 1631269491893,
              "scope": {
                "id": "root"
              }
            },
            "type": "object",
            "info": {
              "rawtype": "object"
            },
            "level": 0
          },
          "|MQTT_Producer": {
            "value": {
              "id": "PRODUCER_MQTT",
              "name": "MQTT_Producer",
              "type": "producer",
              "state": "connected",
              "timestamp": 1631269491894,
              "scope": {
                "id": "root"
              }
            },
            "type": "object",
            "info": {
              "rawtype": "object"
            },
            "level": 0
          },
          "|EclipseDittoConsumer": {
            "value": {
              "id": "S1eMm7hOGK",
              "name": "EclipseDittoConsumer",
              "type": "stream",
              "state": "connected",
              "timestamp": 1631269664359,
              "scope": {
                "id": "root"
              }
            },
            "type": "object",
            "info": {
              "rawtype": "object"
            },
            "level": 0
          }
        }
      },
      "graph": {
        "id": "SkP4XndfF",
        "graphdef": {
          "version": "3",
          "uniqueid": "1",
          "o-outbox": {
            "split": "5000",
            "width": "5000"
          },
          "a-graphitem": [
            {
              "id": "1000",
              "o-attributes": {
                "o-sheetid": {
                  "v": "HJVUN72OzF",
                  "t": "s"
                }
              },
              "o-pin": {
                "o-p": {
                  "o-x": {
                    "v": "11000"
                  },
                  "o-y": {
                    "v": "7000"
                  }
                },
                "o-lp": {
                  "o-x": {
                    "f": "WIDTH%20*%200.5",
                    "v": "10500"
                  },
                  "o-y": {
                    "f": "HEIGHT%20*%200.5",
                    "v": "6500"
                  }
                }
              },
              "o-size": {
                "o-w": {
                  "v": "21000"
                },
                "o-h": {
                  "v": "13000"
                }
              },
              "o-inbox": {
                "split": "5000",
                "width": "9207"
              },
              "o-processsheet": {
                "o-attributes": {
                  "o-calcondemand": {
                    "v": "true",
                    "t": "b"
                  }
                },
                "o-name": {
                  "v": "S1",
                  "t": "s"
                },
                "o-rows": {
                  "outline": "above"
                },
                "o-columns": {
                  "outline": "above",
                  "a-section": [
                    {
                      "index": "0",
                      "size": "0",
                      "visible": "0"
                    },
                    {
                      "index": "1",
                      "size": "700",
                      "visible": "1"
                    }
                  ]
                },
                "o-defaultcell": {
                  "o-cell": {}
                },
                "o-data": {}
              }
            }
          ],
          "o-images": {}
        },
        "machineId": "rybIEm3_zF"
      }
    }
  ],
  "streams": [
    {
      "id": "Syx0g7ndfY",
      "name": "EclipseDitto",
      "disabled": false,
      "className": "ConnectorConfiguration",
      "lastModified": "2021-09-10T10:27:26.616Z",
      "lastAccessed": "2021-09-10T10:27:01.622Z",
      "provider": {
        "_id": "@cedalo/stream-mqtt",
        "id": "@cedalo/stream-mqtt",
        "className": "ProviderConfiguration",
        "isRef": true
      },
      "protocolVersion": 4,
      "url": "mqtt://streamsheets-broker:1883",
      "userPropertiesConnect": [],
      "userName": "internal",
      "password": "internal123456",
      "baseTopic": "ditto-twin-events/",
      "retain": false,
      "qos": 0,
      "scope": {
        "id": "root"
      },
      "state": "disconnected"
    },
    {
      "id": "S1eMm7hOGK",
      "name": "EclipseDittoConsumer",
      "className": "ConsumerConfiguration",
      "lastModified": "2021-09-10T10:27:44.347Z",
      "lastAccessed": "2021-09-10T10:27:37.987Z",
      "connector": {
        "_id": "Syx0g7ndfY",
        "id": "Syx0g7ndfY",
        "className": "ConnectorConfiguration",
        "disabled": false,
        "lastModified": "2021-09-10T10:27:26.616Z",
        "lastAccessed": "2021-09-10T10:27:01.622Z",
        "isRef": true
      },
      "providerId": "@cedalo/stream-mqtt",
      "mimeType": "auto",
      "fixedClientId": false,
      "clientId": "",
      "clean": true,
      "userPropertiesSubscribe": [],
      "topics": [
        "#"
      ],
      "scope": {
        "id": "root"
      },
      "state": "connected"
    }
  ]
}

---
# Source: telemetry-e2e/charts/ditto/templates/nginx-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-nginx-config-ditto-down-svg
  labels:
    app.kubernetes.io/name: ditto-nginx-config
    helm.sh/chart: ditto-2.1.2
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "2.1.0"
    app.kubernetes.io/managed-by: Helm
data:
  ditto-down.svg: |-
    <?xml version="1.0" encoding="UTF-8" standalone="no"?>
    <!-- Created with Inkscape (http://www.inkscape.org/) -->
    
    <svg
            xmlns:dc="http://purl.org/dc/elements/1.1/"
            xmlns:cc="http://creativecommons.org/ns#"
            xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
            xmlns="http://www.w3.org/2000/svg"
            xmlns:sodipodi="http://sodipodi.sourceforge.net/DTD/sodipodi-0.dtd"
            xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"
            width="64px"
            height="64px"
            viewBox="0 0 64 64"
            version="1.1"
            id="SVGRoot"
            inkscape:version="0.92.1 r15371"
            sodipodi:docname="ditto-sandbox-down.svg">
      <sodipodi:namedview
         id="base"
         pagecolor="#ffffff"
         bordercolor="#666666"
         borderopacity="1.0"
         inkscape:pageopacity="0.0"
         inkscape:pageshadow="2"
         inkscape:zoom="4"
         inkscape:cx="36.5"
         inkscape:cy="32"
         inkscape:document-units="px"
         inkscape:current-layer="layer1"
         showgrid="false"
         inkscape:window-width="1600"
         inkscape:window-height="1137"
         inkscape:window-x="3832"
         inkscape:window-y="-8"
         inkscape:window-maximized="1"
         inkscape:grid-bbox="true" />
      <defs
         id="defs4485" />
      <metadata
         id="metadata4488">
        <rdf:RDF>
          <cc:Work
             rdf:about="">
            <dc:format>image/svg+xml</dc:format>
            <dc:type
               rdf:resource="http://purl.org/dc/dcmitype/StillImage" />
            <dc:title></dc:title>
          </cc:Work>
        </rdf:RDF>
      </metadata>
      <g
         id="layer1"
         inkscape:groupmode="layer"
         inkscape:label="Layer 1">
        <circle
           style="opacity:1;fill:#3a8c9a;fill-opacity:1;stroke:none;stroke-width:5.99148989;stroke-linecap:round;stroke-miterlimit:4;stroke-dasharray:none;stroke-opacity:1;paint-order:stroke fill markers"
           id="path5283"
           cx="32.187649"
           cy="32"
           r="31.999998" />
        <g
           id="g6928-2-3"
           transform="matrix(0.4753937,0,0,0.4753937,-13.450147,-13.637795)"
           style="fill:#ffffff;fill-opacity:1"
           inkscape:export-xdpi="96"
           inkscape:export-ydpi="96">
          <g
             id="g6926-1-4"
             style="fill:#ffffff;fill-opacity:1">
            <path
               id="path6924-2-3"
               d="m 103.1,128.9 c 0,3.9 -3.2,7.1 -7.1,7.1 -4,0 -7.1,-3.1 -7.1,-7.1 0,-4 3.1,-7.1 7.1,-7.1 3.9,0 7.1,3.2 7.1,7.1 z M 90.9,80.9 V 56 h 10.2 v 24.9 l -2.7,30.7 h -4.9 z"
               inkscape:connector-curvature="0"
               style="fill:#ffffff;fill-opacity:1" />
          </g>
        </g>
      </g>
    </svg>
---
# Source: telemetry-e2e/charts/ditto/templates/nginx-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-nginx-config-ditto-up-svg
  labels:
    app.kubernetes.io/name: ditto-nginx-config
    helm.sh/chart: ditto-2.1.2
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "2.1.0"
    app.kubernetes.io/managed-by: Helm
data:
  ditto-up.svg: |-
    <?xml version="1.0" encoding="UTF-8" standalone="no"?>
    <!-- Created with Inkscape (http://www.inkscape.org/) -->
    
    <svg
            xmlns:dc="http://purl.org/dc/elements/1.1/"
            xmlns:cc="http://creativecommons.org/ns#"
            xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
            xmlns="http://www.w3.org/2000/svg"
            xmlns:sodipodi="http://sodipodi.sourceforge.net/DTD/sodipodi-0.dtd"
            xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"
            width="64px"
            height="64px"
            viewBox="0 0 64 64"
            version="1.1"
            id="SVGRoot"
            inkscape:version="0.92.1 r15371"
            sodipodi:docname="ditto-sandbox-up.svg">
      <sodipodi:namedview
         id="base"
         pagecolor="#ffffff"
         bordercolor="#666666"
         borderopacity="1.0"
         inkscape:pageopacity="0.0"
         inkscape:pageshadow="2"
         inkscape:zoom="4"
         inkscape:cx="36.5"
         inkscape:cy="32"
         inkscape:document-units="px"
         inkscape:current-layer="layer1"
         showgrid="false"
         inkscape:window-width="1600"
         inkscape:window-height="1137"
         inkscape:window-x="3832"
         inkscape:window-y="-8"
         inkscape:window-maximized="1"
         inkscape:grid-bbox="true" />
      <defs
         id="defs4485" />
      <metadata
         id="metadata4488">
        <rdf:RDF>
          <cc:Work
             rdf:about="">
            <dc:format>image/svg+xml</dc:format>
            <dc:type
               rdf:resource="http://purl.org/dc/dcmitype/StillImage" />
            <dc:title></dc:title>
          </cc:Work>
        </rdf:RDF>
      </metadata>
      <g
         id="layer1"
         inkscape:groupmode="layer"
         inkscape:label="Layer 1">
        <circle
           style="opacity:1;fill:#3a8c9a;fill-opacity:1;stroke:none;stroke-width:5.99148989;stroke-linecap:round;stroke-miterlimit:4;stroke-dasharray:none;stroke-opacity:1;paint-order:stroke fill markers"
           id="path5283"
           cx="32.25"
           cy="32.25"
           r="31.999998" />
        <polygon
           points="129.2,69.2 84,114.3 62.8,93.2 57.2,98.8 84,125.7 134.8,74.8 "
           id="polygon2339-8-2-8-5-2"
           style="fill:#ffffff;fill-opacity:1;stroke:#008ecf;stroke-opacity:1"
           transform="matrix(0.39751555,0,0,0.39751555,-5.911566,-6.488167)" />
      </g>
    </svg>
---
# Source: telemetry-e2e/charts/ditto/templates/nginx-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-nginx-config-index-html
  labels:
    app.kubernetes.io/name: ditto-nginx-config
    helm.sh/chart: ditto-2.1.2
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "2.1.0"
    app.kubernetes.io/managed-by: Helm
data:
  index.html: |-
    <!doctype html>
    <!--
      ~ Copyright (c) 2019 Contributors to the Eclipse Foundation
      ~
      ~ See the NOTICE file(s) distributed with this work for additional
      ~ information regarding copyright ownership.
      ~
      ~ This program and the accompanying materials are made available under the
      ~ terms of the Eclipse Public License 2.0 which is available at
      ~ http://www.eclipse.org/legal/epl-2.0
      ~
      ~ SPDX-License-Identifier: EPL-2.0
      -->
    <html>
    <head>
      <title>Welcome to Eclipse Ditto</title>
    
      <script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.1.4/jquery.min.js"></script>
    
      <style>
        body {
          text-align: center;
          padding: 150px;
        }
    
        h1 {
          font-size: 50px;
        }
    
        body {
          font: 20px Helvetica, sans-serif;
          color: #333;
        }
    
        article {
          display: block;
          text-align: left;
          width: 750px;
          margin: 0 auto;
        }
    
        a {
          color: #dc8100;
          text-decoration: none;
        }
    
        a:hover {
          color: #333;
          text-decoration: none;
        }
    
        .stats {
          line-height: 3em;
        }
    
        .stats-count {
          font: normal 2em Abel;
          color: #3a8c9a;
          font-weight: bold;
          text-align: center;
          margin: 5px;
          clear: left;
          float: left;
          width: 5em;
          background-color: lightgray;
        }
    
        .stats-count-text {
          padding-left: 1em;
          vertical-align: middle;
        }
    
        .health {
          background-size: contain;
          height: 30px;
          width: 30px;
          float: left;
        }
    
        .health-up {
          background-image: url(ditto-up.svg);
        }
    
        .health-down {
          background-image: url(ditto-down.svg);
        }
    
        .health-list li {
          clear: both;
          line-height: 30px;
          padding-bottom: 5px;
        }
    
        .health-key {
          float: left;
          width: 9em;
        }
    
        .health-status {
          line-height: 30px;
          padding-left: 1em;
        }
      </style>
    </head>
    <body>
    
    <article>
      <h1>You have started Eclipse Ditto</h1>
      <div>
        <p>Thank you for trying out Eclipse Ditto!</p>
        <p>For more information about how to start, please consult the
          <a href="https://www.eclipse.org/ditto/intro-hello-world.html">Ditto documentation intro</a> and/or the
          <a href="https://www.eclipse.org/ditto/http-api-doc.html">Ditto HTTP API documentation</a>.
        </p>
        <p>In order to get started quickly and if you started the local swagger-ui, you can now have a look at the OpenAPI documentation for
        <ul>
          <li><a href="/apidoc/2">API version 2</a></li>
        </ul>
        <p>Try out the HTTP APIs by using username "ditto" and password "ditto" when asked for by your browser.</p>
        <p>&mdash; the Ditto team</p>
      </div>
      <h2 style="clear: both">Health</h2>
      <div id="health-content">
      </div>
      <h2>Statistics</h2>
      <div>
        <div class="stats">
          <span id="total-things-count" class="stats-count"></span><span
          class="stats-count-text"> persisted <em>Things</em></span>
        </div>
        <div class="stats">
          <span id="hot-things-count" class="stats-count"></span><span class="stats-count-text"> currently "hot" <em>Things</em> (accessed within the last 2 hours)</span>
        </div>
      </div>
    </article>
    
    <script>
      function update_count(selector, count) {
        $(selector).animate({
                              counter: count
                            }, {
                              duration: 3000,
                              easing: 'swing',
                              step: function (now) {
                                $(this).text(Math.ceil(now));
                              }
                            });
      }
    
      $.getJSON("/stats/search", function (data) {
        let allThingsCount = data.allThingsCount;
        update_count('#total-things-count', allThingsCount);
      }).fail(function () {
        update_count('#total-things-count', 0);
      });
      $.getJSON("/stats/things", function (data) {
        let hotThings = data.hotThings;
        update_count('#hot-things-count', hotThings);
      }).fail(function () {
        update_count('#hot-things-count', 0);
      });
    
      function calcHealthStatusClass(status) {
        let healthStatusClass;
        if (status === "UP") {
          healthStatusClass = "health-up";
        } else if (status === "DOWN") {
          healthStatusClass = "health-down";
        } else {
          healthStatusClass = "health-down";
        }
        return healthStatusClass;
      }
    
      $.getJSON("/status/health", function (data) {
        const keysToIgnore = ['status', 'thing-cache-aware', 'dc-default', 'policy-cache-aware', 'blocked-namespaces-aware'];
        let overallStatus = data.status;
        $(`<p>
                <span class="health-key"></span>
                <span class="health ${calcHealthStatusClass(overallStatus)}"></span>
                <span class="health-status">${overallStatus}</span>
            </p>`).appendTo("#health-content");
    
        let items = [];
        $.each(data.children, function (idx, child) {
          if (keysToIgnore.includes(child.label)) {
            // ignore
          } else {
            items.push(`<li>
                        <span class="health-key">${child.label}:</span>
                        <span class="health ${calcHealthStatusClass(child.status)}"></span>
                        <span class="health-status">${child.status}</span>
                    </li>`);
          }
        });
    
        $("<ul/>", {
          "class": "health-list",
          html: items.join("")
        }).appendTo("#health-content");
      }).fail(function () {
        $(`<p>
                <span class="health-key"></span>
                <span class="health health-down"></span>
                <span class="health-status">COULD NOT BE DETERMINED</span>
            </p>`).appendTo("#health-content");
      })
    </script>
    
    </body>
    </html>
---
# Source: telemetry-e2e/charts/ditto/templates/nginx-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-nginx-config-nginx-cors-conf
  labels:
    app.kubernetes.io/name: ditto-nginx-config
    helm.sh/chart: ditto-2.1.2
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "2.1.0"
    app.kubernetes.io/managed-by: Helm
data:
  nginx-cors.conf: |-
    # Copyright (c) 2019 Contributors to the Eclipse Foundation
    #
    # See the NOTICE file(s) distributed with this work for additional
    # information regarding copyright ownership.
    #
    # This program and the accompanying materials are made available under the
    # terms of the Eclipse Public License 2.0 which is available at
    # http://www.eclipse.org/legal/epl-2.0
    #
    # SPDX-License-Identifier: EPL-2.0
    
    #
    # CORS header support
    #
    # As of Nginx 1.7.5, add_header supports an "always" parameter which
    # allows CORS to work if the backend returns 4xx or 5xx status code.
    #
    # For more information on CORS, please see: http://enable-cors.org/
    # From this Gist: https://gist.github.com/Stanback/7145487
    # And this: https://gist.github.com/pauloricardomg/7084524
    #
    
    set $cors '1';
    
    # OPTIONS indicates a CORS pre-flight request
    if ($request_method = 'OPTIONS') {
      set $cors "${cors}o";
    }
    
    if ($cors = '1') {
      add_header 'Access-Control-Allow-Origin' '$http_origin' always;
      add_header 'Access-Control-Allow-Methods' 'GET, POST, PUT, PATCH, DELETE, OPTIONS' always;
      add_header 'Access-Control-Allow-Credentials' 'true' always;
      add_header 'Access-Control-Allow-Headers' '$http_access_control_request_headers' always;
      add_header 'Access-Control-Expose-Headers' '*' always;
    }
    
    # OPTIONS (pre-flight) request from allowed CORS domain. return response directly
    if ($cors = '1o') {
      # Tell client that this pre-flight info is valid for 20 days
      add_header 'Access-Control-Max-Age' 1728000;
      add_header 'Access-Control-Allow-Origin' '$http_origin' always;
      add_header 'Access-Control-Allow-Methods' 'GET, POST, PUT, PATCH, DELETE, OPTIONS' always;
      add_header 'Access-Control-Allow-Credentials' 'true' always;
      add_header 'Access-Control-Allow-Headers' '$http_access_control_request_headers' always;
      add_header 'Access-Control-Expose-Headers' '*' always;
      add_header 'Content-Type' 'text/plain charset=UTF-8';
      add_header 'Content-Length' 0;
      return 200;
    }
---
# Source: telemetry-e2e/charts/ditto/templates/nginx-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-nginx-config-nginx-htpasswd
  labels:
    app.kubernetes.io/name: ditto-nginx-config
    helm.sh/chart: ditto-2.1.2
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "2.1.0"
    app.kubernetes.io/managed-by: Helm
data:
  nginx.htpasswd: |-
    # this file contains sample users and their hashed password
    ditto:A6BgmB8IEtPTs
---
# Source: telemetry-e2e/charts/ditto/templates/nginx-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-nginx-conf
  labels:
    app.kubernetes.io/name: ditto-nginx-conf
    helm.sh/chart: ditto-2.1.2
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "2.1.0"
    app.kubernetes.io/managed-by: Helm
data:
  nginx.conf: |-
    worker_processes 1;
    pid /run/nginx/nginx.pid;
    
    events {worker_connections 1024;}
    
    http {
      charset utf-8;
      default_type application/json;
      include mime.types;
    
      # timeouts are configured slightly higher than ditto-eclipse-ditto-gateway read-timeout of 60 seconds
      proxy_connect_timeout 70; # seconds, default: 60
      proxy_send_timeout 70; # seconds, default: 60
      proxy_read_timeout 70; # seconds, default: 60
      send_timeout 70; # seconds, default: 60
    
      client_header_buffer_size 8k; # allow longer URIs + headers (default: 1k)
      large_client_header_buffers 4 16k;
    
      merge_slashes off; # allow multiple slashes for CRS Authentication
    
      upstream ditto-gateway {
        server ditto-gateway:8080;
      }
    
      server {
        listen 8080;
        server_name localhost;
    
        location / {
          index index.html;
        }
    
        # api
        location /api {
          include nginx-cors.conf;

          
          auth_basic                    "Authentication required";
          auth_basic_user_file          nginx.htpasswd;
          proxy_set_header              X-Forwared-User           $remote_user;
          proxy_set_header              x-ditto-pre-authenticated "nginx:${remote_user}";
        
          proxy_pass                    http://ditto-gateway;
          proxy_http_version            1.1;
          proxy_set_header              Host                      $http_host;
          proxy_set_header              X-Real-IP                 $remote_addr;
          proxy_set_header              X-Forwarded-For           $proxy_add_x_forwarded_for;
    
          proxy_set_header Connection  '';
          chunked_transfer_encoding    off;
          proxy_buffering              off;
          proxy_cache                  off;
        }
    
        # ws
        location /ws {

          
          auth_basic                    "Authentication required";
          auth_basic_user_file          nginx.htpasswd;
          proxy_set_header              X-Forwared-User           $remote_user;
          proxy_set_header              x-ditto-pre-authenticated "nginx:${remote_user}";
          
          proxy_pass                    http://ditto-gateway;
          proxy_http_version            1.1;
          proxy_set_header              Host                      $http_host;
          proxy_set_header              X-Real-IP                 $remote_addr;
          proxy_set_header              X-Forwarded-For           $proxy_add_x_forwarded_for;
    
          proxy_set_header              Upgrade                   $http_upgrade;
          proxy_set_header              Connection                "upgrade";
          proxy_read_timeout            1d;
          proxy_send_timeout            1d;
        }
    
        # health
        location /health {
          include nginx-cors.conf;
    
          proxy_pass                    http://ditto-gateway/health;
          proxy_http_version            1.1;
          proxy_set_header              Host                      $http_host;
          proxy_set_header              X-Real-IP                 $remote_addr;
          proxy_set_header              X-Forwarded-For           $proxy_add_x_forwarded_for;
          proxy_set_header              X-Forwarded-User          $remote_user;
        }
    
        # status
        location /status {
          include nginx-cors.conf;
    
          proxy_pass                    http://ditto-gateway/overall/status;
          proxy_http_version            1.1;
          proxy_set_header              Host                      $http_host;
          proxy_set_header              X-Real-IP                 $remote_addr;
          proxy_set_header              X-Forwarded-For           $proxy_add_x_forwarded_for;
          proxy_set_header              X-Forwarded-User          $remote_user;
        }

        # stats
        location /stats {
          include nginx-cors.conf;

          proxy_pass                    http://ditto-gateway/stats;
          proxy_http_version            1.1;
          proxy_set_header              Host                      $http_host;
          proxy_set_header              X-Real-IP                 $remote_addr;
          proxy_set_header              X-Forwarded-For           $proxy_add_x_forwarded_for;
          proxy_set_header              X-Forwarded-User          $remote_user;
        }
    
        # devops
        location /devops {
          include nginx-cors.conf;

          proxy_pass                    http://ditto-gateway/devops;
          proxy_http_version            1.1;
          proxy_set_header              Host                      $http_host;
          proxy_set_header              X-Real-IP                 $remote_addr;
          proxy_set_header              X-Forwarded-For           $proxy_add_x_forwarded_for;
          proxy_set_header              X-Forwarded-User          $remote_user;
        }

        # swagger
        # access API doc on: /apidoc/2
        location /apidoc/ {
          rewrite ^/apidoc/([0-9])$ $scheme://$http_host/apidoc/?url=//raw.githubusercontent.com/eclipse/ditto/2.1.0/documentation/src/main/resources/openapi/ditto-api-$1.yml  redirect;
          proxy_pass                    http://ditto-swaggerui:8080/;
          proxy_http_version            1.1;
          proxy_set_header              Host                      $http_host;
        }
      }
    }
---
# Source: telemetry-e2e/charts/ditto/templates/swaggerui-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: ditto-swaggerui
  labels:
    app.kubernetes.io/name: ditto-swaggerui
    helm.sh/chart: ditto-2.1.2
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "2.1.0"
    app.kubernetes.io/managed-by: Helm
data:
  {}
---
# Source: telemetry-e2e/charts/drogueCloud/templates/configuration/configuration.yaml
apiVersion: v1
kind: ConfigMap

metadata:
  name: configuration
  labels:
    app.kubernetes.io/name: configuration
    app.kubernetes.io/component: global
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.7.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: drogue-iot

data:
  instance: drogue
---
# Source: telemetry-e2e/charts/drogueCloud/templates/service/registry/postgres/config-map.yaml
kind: ConfigMap
apiVersion: v1
metadata:
  name: postgres-config
  labels:
    app.kubernetes.io/name: postgres-config
    app.kubernetes.io/component: device-registry
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.7.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: drogue-iot
data:
  databaseName: registry
---
# Source: telemetry-e2e/charts/streamsheets/charts/redis/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: streamsheets-redis-configuration
  namespace: "default"
  labels:
    app.kubernetes.io/name: redis
    helm.sh/chart: redis-14.8.11
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
data:
  redis.conf: |-
    # User-supplied common configuration:
    # Enable AOF https://redis.io/topics/persistence#append-only-file
    appendonly yes
    # Disable RDB persistence, AOF persistence already enabled.
    save ""
    # End of common configuration
  master.conf: |-
    dir /data
    # User-supplied master configuration:
    rename-command FLUSHDB ""
    rename-command FLUSHALL ""
    # End of master configuration
  replica.conf: |-
    dir /data
    slave-read-only yes
    # User-supplied replica configuration:
    rename-command FLUSHDB ""
    rename-command FLUSHALL ""
    # End of replica configuration
---
# Source: telemetry-e2e/charts/streamsheets/charts/redis/templates/health-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: streamsheets-redis-health
  namespace: "default"
  labels:
    app.kubernetes.io/name: redis
    helm.sh/chart: redis-14.8.11
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
data:
  ping_readiness_local.sh: |-
    #!/bin/bash

    [[ -f $REDIS_PASSWORD_FILE ]] && export REDIS_PASSWORD="$(< "${REDIS_PASSWORD_FILE}")"
    export REDISCLI_AUTH="$REDIS_PASSWORD"
    response=$(
      timeout -s 3 $1 \
      redis-cli \
        -h localhost \
        -p $REDIS_PORT \
        ping
    )
    if [ "$response" != "PONG" ]; then
      echo "$response"
      exit 1
    fi
  ping_liveness_local.sh: |-
    #!/bin/bash

    [[ -f $REDIS_PASSWORD_FILE ]] && export REDIS_PASSWORD="$(< "${REDIS_PASSWORD_FILE}")"
    export REDISCLI_AUTH="$REDIS_PASSWORD"
    response=$(
      timeout -s 3 $1 \
      redis-cli \
        -h localhost \
        -p $REDIS_PORT \
        ping
    )
    if [ "$response" != "PONG" ] && [ "$response" != "LOADING Redis is loading the dataset in memory" ]; then
      echo "$response"
      exit 1
    fi
  ping_readiness_master.sh: |-
    #!/bin/bash

    [[ -f $REDIS_MASTER_PASSWORD_FILE ]] && export REDIS_MASTER_PASSWORD="$(< "${REDIS_MASTER_PASSWORD_FILE}")"
    export REDISCLI_AUTH="$REDIS_MASTER_PASSWORD"
    response=$(
      timeout -s 3 $1 \
      redis-cli \
        -h $REDIS_MASTER_HOST \
        -p $REDIS_MASTER_PORT_NUMBER \
        ping
    )
    if [ "$response" != "PONG" ]; then
      echo "$response"
      exit 1
    fi
  ping_liveness_master.sh: |-
    #!/bin/bash

    [[ -f $REDIS_MASTER_PASSWORD_FILE ]] && export REDIS_MASTER_PASSWORD="$(< "${REDIS_MASTER_PASSWORD_FILE}")"
    export REDISCLI_AUTH="$REDIS_MASTER_PASSWORD"
    response=$(
      timeout -s 3 $1 \
      redis-cli \
        -h $REDIS_MASTER_HOST \
        -p $REDIS_MASTER_PORT_NUMBER \
        ping
    )
    if [ "$response" != "PONG" ] && [ "$response" != "LOADING Redis is loading the dataset in memory" ]; then
      echo "$response"
      exit 1
    fi
  ping_readiness_local_and_master.sh: |-
    script_dir="$(dirname "$0")"
    exit_status=0
    "$script_dir/ping_readiness_local.sh" $1 || exit_status=$?
    "$script_dir/ping_readiness_master.sh" $1 || exit_status=$?
    exit $exit_status
  ping_liveness_local_and_master.sh: |-
    script_dir="$(dirname "$0")"
    exit_status=0
    "$script_dir/ping_liveness_local.sh" $1 || exit_status=$?
    "$script_dir/ping_liveness_master.sh" $1 || exit_status=$?
    exit $exit_status
---
# Source: telemetry-e2e/charts/streamsheets/charts/redis/templates/scripts-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: streamsheets-redis-scripts
  namespace: "default"
  labels:
    app.kubernetes.io/name: redis
    helm.sh/chart: redis-14.8.11
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
data:
  start-master.sh: |
    #!/bin/bash

    [[ -f $REDIS_PASSWORD_FILE ]] && export REDIS_PASSWORD="$(< "${REDIS_PASSWORD_FILE}")"
    if [[ ! -f /opt/bitnami/redis/etc/master.conf ]];then
        cp /opt/bitnami/redis/mounted-etc/master.conf /opt/bitnami/redis/etc/master.conf
    fi
    if [[ ! -f /opt/bitnami/redis/etc/redis.conf ]];then
        cp /opt/bitnami/redis/mounted-etc/redis.conf /opt/bitnami/redis/etc/redis.conf
    fi
    ARGS=("--port" "${REDIS_PORT}")
    ARGS+=("--protected-mode" "no")
    ARGS+=("--include" "/opt/bitnami/redis/etc/redis.conf")
    ARGS+=("--include" "/opt/bitnami/redis/etc/master.conf")
    exec redis-server "${ARGS[@]}"
---
# Source: telemetry-e2e/charts/streamsheets/templates/broker/configmap.yaml
kind: ConfigMap
apiVersion: v1
metadata:
  name: streamsheets-broker
  labels:
    helm.sh/chart: streamsheets-0.2.3
    app.kubernetes.io/name: streamsheets-broker
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "2.4.0"
    app.kubernetes.io/managed-by: Helm
data:
  mosquitto.conf: |
    allow_anonymous false
    password_file /mosquitto/secrets/pw.txt

    listener 1883
    protocol mqtt
---
# Source: telemetry-e2e/charts/streamsheets/templates/gateway/configmap.yaml
kind: ConfigMap
apiVersion: v1
metadata:
  name: streamsheets-gateway
  labels:
    helm.sh/chart: streamsheets-0.2.3
    app.kubernetes.io/name: streamsheets-gateway
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "2.4.0"
    app.kubernetes.io/managed-by: Helm
data:
  gateway.json: |
    {
      "app": {
        "appUrl": "http://streamsheets-default.change.me"
      },
      "http": {
        "port": 8080,
        "ipaddress": "0.0.0.0"
      },
      "auth": {
        "jwtSecret": "lTsdnk4imQuYi3jdBJTp2CEDrWYbvJq0WMDRvThrUwfqKMXzUVj6OamXYYox8J3R"
      }
    }
---
# Source: telemetry-e2e/charts/strimzi/templates/050-ConfigMap-strimzi-cluster-operator.yaml
kind: ConfigMap
apiVersion: v1
metadata:
  name: strimzi-cluster-operator
  labels:
    app: strimzi
data:
  log4j2.properties: |
    name = COConfig
    monitorInterval = 30

    appender.console.type = Console
    appender.console.name = STDOUT
    appender.console.layout.type = PatternLayout
    appender.console.layout.pattern = %d{yyyy-MM-dd HH:mm:ss} %-5p %c{1}:%L - %m%n

    rootLogger.level = ${env:STRIMZI_LOG_LEVEL:-INFO}
    rootLogger.appenderRefs = stdout
    rootLogger.appenderRef.console.ref = STDOUT
    rootLogger.additivity = false

    # Kafka AdminClient logging is a bit noisy at INFO level
    logger.kafka.name = org.apache.kafka
    logger.kafka.level = WARN
    logger.kafka.additivity = false

    # Zookeeper is very verbose even on INFO level -> We set it to WARN by default
    logger.zookeepertrustmanager.name = org.apache.zookeeper
    logger.zookeepertrustmanager.level = WARN
    logger.zookeepertrustmanager.additivity = false

    # Keeps separate level for Netty logging -> to not be changed by the root logger
    logger.netty.name = io.netty
    logger.netty.level = INFO
    logger.netty.additivity = false
---
# Source: telemetry-e2e/templates/drogue-cloud/demos.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: demo-ditto
  labels:
    demo: drogue
data:
  label: Eclipse Ditto Console
  href: "http://ditto-default.change.me"
---
# Source: telemetry-e2e/templates/drogue-cloud/demos.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: demo-streamsheets
  labels:
    demo: drogue
data:
  label: Eclipse Streamsheets Console
  href: "http://streamsheets-default.change.me"
---
# Source: telemetry-e2e/charts/drogueCloud/templates/service/registry/postgres/persistent-volume-claim.yaml
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
 name: postgres-pvc
 labels:
    app.kubernetes.io/name: postgres-pvc
    app.kubernetes.io/component: device-registry
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.7.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: drogue-iot
spec:
 accessModes:
 - ReadWriteOnce
 resources:
   requests:
     storage: 1G
---
# Source: telemetry-e2e/charts/strimzi/templates/020-ClusterRole-strimzi-cluster-operator-role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: strimzi-cluster-operator-namespaced
  labels:
    app: strimzi
    chart: strimzi-0.25.0
    component: role
    release: release-name
    heritage: Helm
rules:
- apiGroups:
  - "rbac.authorization.k8s.io"
  resources:
    # The cluster operator needs to access and manage rolebindings to grant Strimzi components cluster permissions
  - rolebindings
  verbs:
  - get
  - list
  - watch
  - create
  - delete
  - patch
  - update
- apiGroups:
  - "rbac.authorization.k8s.io"
  resources:
    # The cluster operator needs to access and manage roles to grant the entity operator permissions
  - roles
  verbs:
  - get
  - list
  - watch
  - create
  - delete
  - patch
  - update
- apiGroups:
  - ""
  resources:
    # The cluster operator needs to access and delete pods, this is to allow it to monitor pod health and coordinate rolling updates
  - pods
    # The cluster operator needs to access and manage service accounts to grant Strimzi components cluster permissions
  - serviceaccounts
    # The cluster operator needs to access and manage config maps for Strimzi components configuration
  - configmaps
    # The cluster operator needs to access and manage services and endpoints to expose Strimzi components to network traffic
  - services
  - endpoints
    # The cluster operator needs to access and manage secrets to handle credentials
  - secrets
    # The cluster operator needs to access and manage persistent volume claims to bind them to Strimzi components for persistent data
  - persistentvolumeclaims
  verbs:
  - get
  - list
  - watch
  - create
  - delete
  - patch
  - update
- apiGroups:
  - "kafka.strimzi.io"
  resources:
    # The cluster operator runs the KafkaAssemblyOperator, which needs to access and manage Kafka resources
  - kafkas
  - kafkas/status
    # The cluster operator runs the KafkaConnectAssemblyOperator, which needs to access and manage KafkaConnect resources
  - kafkaconnects
  - kafkaconnects/status
    # The cluster operator runs the KafkaConnectorAssemblyOperator, which needs to access and manage KafkaConnector resources
  - kafkaconnectors
  - kafkaconnectors/status
    # The cluster operator runs the KafkaMirrorMakerAssemblyOperator, which needs to access and manage KafkaMirrorMaker resources
  - kafkamirrormakers
  - kafkamirrormakers/status
    # The cluster operator runs the KafkaBridgeAssemblyOperator, which needs to access and manage BridgeMaker resources
  - kafkabridges
  - kafkabridges/status
    # The cluster operator runs the KafkaMirrorMaker2AssemblyOperator, which needs to access and manage KafkaMirrorMaker2 resources
  - kafkamirrormaker2s
  - kafkamirrormaker2s/status
    # The cluster operator runs the KafkaRebalanceAssemblyOperator, which needs to access and manage KafkaRebalance resources
  - kafkarebalances
  - kafkarebalances/status
  verbs:
  - get
  - list
  - watch
  - create
  - delete
  - patch
  - update
- apiGroups:
    # The cluster operator needs the extensions api as the operator supports Kubernetes version 1.11+
    # apps/v1 was introduced in Kubernetes 1.14
  - "extensions"
  resources:
    # The cluster operator needs to access and manage deployments to run deployment based Strimzi components
  - deployments
  - deployments/scale
    # The cluster operator needs to access replica sets to manage Strimzi components and to determine error states
  - replicasets
    # The cluster operator needs to access and manage replication controllers to manage replicasets
  - replicationcontrollers
    # The cluster operator needs to access and manage network policies to lock down communication between Strimzi components
  - networkpolicies
    # The cluster operator needs to access and manage ingresses which allow external access to the services in a cluster
  - ingresses
  verbs:
  - get
  - list
  - watch
  - create
  - delete
  - patch
  - update
- apiGroups:
  - "apps"
  resources:
    # The cluster operator needs to access and manage deployments to run deployment based Strimzi components
  - deployments
  - deployments/scale
  - deployments/status
    # The cluster operator needs to access and manage stateful sets to run stateful sets based Strimzi components
  - statefulsets
    # The cluster operator needs to access replica-sets to manage Strimzi components and to determine error states
  - replicasets
  verbs:
  - get
  - list
  - watch
  - create
  - delete
  - patch
  - update
- apiGroups:
  - ""
  resources:
    # The cluster operator needs to be able to create events and delegate permissions to do so
  - events
  verbs:
  - create
- apiGroups:
    # Kafka Connect Build on OpenShift requirement
  - build.openshift.io
  resources:
  - buildconfigs
  - buildconfigs/instantiate
  - builds
  verbs:
  - get
  - list
  - watch
  - create
  - delete
  - patch
  - update
- apiGroups:
  - networking.k8s.io
  resources:
    # The cluster operator needs to access and manage network policies to lock down communication between Strimzi components
  - networkpolicies
    # The cluster operator needs to access and manage ingresses which allow external access to the services in a cluster
  - ingresses
  verbs:
  - get
  - list
  - watch
  - create
  - delete
  - patch
  - update
- apiGroups:
  - route.openshift.io
  resources:
    # The cluster operator needs to access and manage routes to expose Strimzi components for external access
  - routes
  - routes/custom-host
  verbs:
  - get
  - list
  - watch
  - create
  - delete
  - patch
  - update
- apiGroups:
  - policy
  resources:
    # The cluster operator needs to access and manage pod disruption budgets this limits the number of concurrent disruptions
    # that a Strimzi component experiences, allowing for higher availability
  - poddisruptionbudgets
  verbs:
  - get
  - list
  - watch
  - create
  - delete
  - patch
  - update
---
# Source: telemetry-e2e/charts/strimzi/templates/021-ClusterRole-strimzi-cluster-operator-role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: strimzi-cluster-operator-global
  labels:
    app: strimzi
    chart: strimzi-0.25.0
    component: role
    release: release-name
    heritage: Helm
rules:
- apiGroups:
  - "rbac.authorization.k8s.io"
  resources:
    # The cluster operator needs to create and manage cluster role bindings in the case of an install where a user
    # has specified they want their cluster role bindings generated
  - clusterrolebindings
  verbs:
  - get
  - list
  - watch
  - create
  - delete
  - patch
  - update
- apiGroups:
  - storage.k8s.io
  resources:
    # The cluster operator requires "get" permissions to view storage class details
    # This is because only a persistent volume of a supported storage class type can be resized
  - storageclasses
  verbs:
  - get
- apiGroups:
    - ""
  resources:
    # The cluster operator requires "list" permissions to view all nodes in a cluster
    # The listing is used to determine the node addresses when NodePort access is configured
    # These addresses are then exposed in the custom resource states
  - nodes
  verbs:
  - list
---
# Source: telemetry-e2e/charts/strimzi/templates/030-ClusterRole-strimzi-kafka-broker.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: strimzi-kafka-broker
  labels:
    app: strimzi
    chart: strimzi-0.25.0
    component: broker-role
    release: release-name
    heritage: Helm
rules:
- apiGroups:
  - ""
  resources:
    # The Kafka Brokers require "get" permissions to view the node they are on
    # This information is used to generate a Rack ID that is used for High Availability configurations
  - nodes
  verbs:
  - get
---
# Source: telemetry-e2e/charts/strimzi/templates/031-ClusterRole-strimzi-entity-operator.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: strimzi-entity-operator
  labels:
    app: strimzi
    chart: strimzi-0.25.0
    component: entity-operator-role
    release: release-name
    heritage: Helm
rules:
- apiGroups:
  - "kafka.strimzi.io"
  resources:
    # The entity operator runs the KafkaTopic assembly operator, which needs to access and manage KafkaTopic resources
  - kafkatopics
  - kafkatopics/status
    # The entity operator runs the KafkaUser assembly operator, which needs to access and manage KafkaUser resources
  - kafkausers
  - kafkausers/status
  verbs:
  - get
  - list
  - watch
  - create
  - patch
  - update
  - delete
- apiGroups:
  - ""
  resources:
  - events
  verbs:
    # The entity operator needs to be able to create events
  - create
- apiGroups:
  - ""
  resources:
    # The entity operator user-operator needs to access and manage secrets to store generated credentials
  - secrets
  verbs:
  - get
  - list
  - watch
  - create
  - delete
  - patch
  - update
---
# Source: telemetry-e2e/charts/strimzi/templates/033-ClusterRole-strimzi-kafka-client.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: strimzi-kafka-client
  labels:
    app: strimzi
    chart: strimzi-0.25.0
    component: client-role
    release: release-name
    heritage: Helm
rules:
- apiGroups:
  - ""
  resources:
    # The Kafka clients (Connect, Mirror Maker, etc.) require "get" permissions to view the node they are on
    # This information is used to generate a Rack ID (client.rack option) that is used for consuming from the closest
    # replicas when enabled
  - nodes
  verbs:
  - get
---
# Source: telemetry-e2e/charts/strimzi/templates/021-ClusterRoleBinding-strimzi-cluster-operator.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: strimzi-cluster-operator
  labels:
    app: strimzi
    chart: strimzi-0.25.0
    component: role-binding
    release: release-name
    heritage: Helm
subjects:
  - kind: ServiceAccount
    name: strimzi-cluster-operator
    namespace: default
roleRef:
  kind: ClusterRole
  name: strimzi-cluster-operator-global
  apiGroup: rbac.authorization.k8s.io
---
# Source: telemetry-e2e/charts/strimzi/templates/030-ClusterRoleBinding-strimzi-cluster-operator-kafka-broker-delegation.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: strimzi-cluster-operator-kafka-broker-delegation
  labels:
    app: strimzi
    chart: strimzi-0.25.0
    component: broker-role-binding
    release: release-name
    heritage: Helm
# The Kafka broker cluster role must be bound to the cluster operator service account so that it can delegate the cluster role to the Kafka brokers.
# This must be done to avoid escalating privileges which would be blocked by Kubernetes.
subjects:
  - kind: ServiceAccount
    name: strimzi-cluster-operator
    namespace: default
roleRef:
  kind: ClusterRole
  name: strimzi-kafka-broker
  apiGroup: rbac.authorization.k8s.io
---
# Source: telemetry-e2e/charts/strimzi/templates/033-ClusterRoleBinding-strimzi-cluster-operator-kafka-client-delegation.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: strimzi-cluster-operator-kafka-client-delegation
  labels:
    app: strimzi
    chart: strimzi-0.25.0
    component: client-role-binding
    release: release-name
    heritage: Helm
# The Kafka clients cluster role must be bound to the cluster operator service account so that it can delegate the
# cluster role to the Kafka clients using it for consuming from closest replica.
# This must be done to avoid escalating privileges which would be blocked by Kubernetes.
subjects:
  - kind: ServiceAccount
    name: strimzi-cluster-operator
    namespace: default
roleRef:
  kind: ClusterRole
  name: strimzi-kafka-client
  apiGroup: rbac.authorization.k8s.io
---
# Source: telemetry-e2e/charts/ditto/templates/role.yaml
kind: Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: ditto
  labels:
    app.kubernetes.io/name: ditto
    helm.sh/chart: ditto-2.1.2
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "2.1.0"
    app.kubernetes.io/managed-by: Helm
rules:
- apiGroups: [""]
  resources: ["pods"]
  verbs: ["get", "watch", "list"]
---
# Source: telemetry-e2e/charts/drogueCloud/templates/service/console/role-backend.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role

metadata:
  name: console-backend
  labels:
    app.kubernetes.io/name: console-backend
    app.kubernetes.io/component: console
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.7.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: drogue-iot

rules:
  - apiGroups: [ "" ]
    resources: [ "configmaps" ]
    verbs: [ "get", "watch", "list" ]
---
# Source: telemetry-e2e/charts/drogueCloud/templates/service/registry/topic-operator/role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: topic-operator
  labels:
    app.kubernetes.io/name: topic-operator
    app.kubernetes.io/component: device-registry
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.7.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: drogue-iot
rules:
  - apiGroups: [ "kafka.strimzi.io" ]
    resources: [ "kafkatopics" ]
    verbs: [ "get", "watch", "list", "create", "update", "delete", "patch" ]
  - apiGroups: [ "kafka.strimzi.io" ]
    resources: [ "kafkausers" ]
    verbs: [ "get", "watch", "list", "create", "update", "delete", "patch" ]
  - apiGroups: [ "" ]
    resources: [ "secrets" ]
    verbs: [ "get", "watch", "list", "create", "update", "delete", "patch" ]
---
# Source: telemetry-e2e/charts/drogueCloud/templates/service/registry/ttn-operator/role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: ttn-operator
  labels:
    app.kubernetes.io/name: ttn-operator
    app.kubernetes.io/component: device-registry
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.7.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: drogue-iot
rules:
  - apiGroups: [ "route.openshift.io" ]
    resources: [ "routes" ]
    verbs: [ "get", "watch", "list" ]
  - apiGroups: [ "networking.k8s.io" ]
    resources: [ "ingresses" ]
    verbs: [ "get", "watch", "list" ]
  - apiGroups: [ "serving.knative.dev" ]
    resources: [ "services" ]
    verbs: [ "get", "watch", "list" ]
---
# Source: telemetry-e2e/templates/keycloak/role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: keycloak-operator
rules:
  - apiGroups:
      - ""
    resources:
      - pods
      - services
      - services/finalizers
      - endpoints
      - persistentvolumeclaims
      - events
      - configmaps
      - secrets
    verbs:
      - list
      - get
      - create
      - patch
      - update
      - watch
      - delete
  - apiGroups:
      - apps
    resources:
      - deployments
      - daemonsets
      - replicasets
      - statefulsets
    verbs:
      - list
      - get
      - create
      - update
      - watch
  - apiGroups:
      - batch
    resources:
      - cronjobs
      - jobs
    verbs:
      - list
      - get
      - create
      - update
      - watch
  - apiGroups:
      - route.openshift.io
    resources:
      - routes/custom-host
    verbs:
      - create
  - apiGroups:
      - route.openshift.io
    resources:
      - routes
    verbs:
      - list
      - get
      - create
      - update
      - watch
  - apiGroups:
      - networking.k8s.io
    resources:
      - ingresses
    verbs:
      - list
      - get
      - create
      - update
      - watch
  - apiGroups:
      - monitoring.coreos.com
    resources:
      - servicemonitors
      - prometheusrules
    verbs:
      - list
      - get
      - create
      - update
      - watch
  - apiGroups:
      - integreatly.org
    resources:
      - grafanadashboards
    verbs:
      - get
      - list
      - create
      - update
      - watch
  - apiGroups:
      - apps
    resourceNames:
      - keycloak-operator
    resources:
      - deployments/finalizers
    verbs:
      - update
  - apiGroups:
      - policy
    resources:
      - poddisruptionbudgets
    verbs:
      - get
      - list
      - create
      - update
      - watch
  - apiGroups:
      - keycloak.org
    resources:
      - keycloaks
      - keycloaks/status
      - keycloaks/finalizers
      - keycloakrealms
      - keycloakrealms/status
      - keycloakrealms/finalizers
      - keycloakclients
      - keycloakclients/status
      - keycloakclients/finalizers
      - keycloakbackups
      - keycloakbackups/status
      - keycloakbackups/finalizers
      - keycloakusers
      - keycloakusers/status
      - keycloakusers/finalizers
    verbs:
      - get
      - list
      - update
      - watch
---
# Source: telemetry-e2e/charts/ditto/templates/rolebinding.yaml
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: ditto
  labels:
    app.kubernetes.io/name: ditto
    helm.sh/chart: ditto-2.1.2
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "2.1.0"
    app.kubernetes.io/managed-by: Helm
roleRef:
  kind: Role
  name: ditto
  apiGroup: rbac.authorization.k8s.io
subjects:
- kind: ServiceAccount
  name: ditto
---
# Source: telemetry-e2e/charts/drogueCloud/templates/service/console/role-binding-backend.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: console-backend
  labels:
    app.kubernetes.io/name: console-backend
    app.kubernetes.io/component: console
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.7.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: drogue-iot

subjects:
  - kind: ServiceAccount
    name: console-backend

roleRef:
  kind: Role
  name: console-backend
  apiGroup: rbac.authorization.k8s.io
---
# Source: telemetry-e2e/charts/drogueCloud/templates/service/registry/topic-operator/role-binding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: topic-operator
  labels:
    app.kubernetes.io/name: topic-operator
    app.kubernetes.io/component: device-registry
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.7.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: drogue-iot
subjects:
  - kind: ServiceAccount
    name: topic-operator
roleRef:
  kind: Role
  name: topic-operator
  apiGroup: rbac.authorization.k8s.io
---
# Source: telemetry-e2e/charts/drogueCloud/templates/service/registry/ttn-operator/role-binding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: ttn-operator
  labels:
    app.kubernetes.io/name: ttn-operator
    app.kubernetes.io/component: device-registry
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.7.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: drogue-iot
subjects:
  - kind: ServiceAccount
    name: ttn-operator
roleRef:
  kind: Role
  name: ttn-operator
  apiGroup: rbac.authorization.k8s.io
---
# Source: telemetry-e2e/charts/strimzi/templates/020-RoleBinding-strimzi-cluster-operator.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: strimzi-cluster-operator
  namespace: default
  labels:
    app: strimzi
    chart: strimzi-0.25.0
    component: role-binding
    release: release-name
    heritage: Helm
subjects:
  - kind: ServiceAccount
    name: strimzi-cluster-operator
    namespace: default
roleRef:
  kind: ClusterRole
  name: strimzi-cluster-operator-namespaced
  apiGroup: rbac.authorization.k8s.io
---
# Source: telemetry-e2e/charts/strimzi/templates/031-RoleBinding-strimzi-cluster-operator-entity-operator-delegation.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: strimzi-cluster-operator-entity-operator-delegation
  namespace: default
  labels:
    app: strimzi
    chart: strimzi-0.25.0
    component: entity-operator-role-binding
    release: release-name
    heritage: Helm
# The Entity Operator cluster role must be bound to the cluster operator service account so that it can delegate the cluster role to the Entity Operator.
# This must be done to avoid escalating privileges which would be blocked by Kubernetes.
subjects:
  - kind: ServiceAccount
    name: strimzi-cluster-operator
    namespace: default
roleRef:
  kind: ClusterRole
  name: strimzi-entity-operator
  apiGroup: rbac.authorization.k8s.io
---
# Source: telemetry-e2e/templates/keycloak/role_binding.yaml
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: keycloak-operator
subjects:
  - kind: ServiceAccount
    name: keycloak-operator
roleRef:
  kind: Role
  name: keycloak-operator
  apiGroup: rbac.authorization.k8s.io
---
# Source: telemetry-e2e/charts/ditto/charts/mongodb/templates/svc-standalone.yaml
apiVersion: v1
kind: Service
metadata:
  name: ditto-mongodb
  namespace: default
  labels:
    app: mongodb
    chart: mongodb-7.14.8
    release: "release-name"
    heritage: "Helm"
spec:
  type: ClusterIP
  ports:
    - name: mongodb
      port: 27017
      targetPort: mongodb
  selector:
    app: mongodb
    release: "release-name"
---
# Source: telemetry-e2e/charts/ditto/templates/gateway-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: ditto-gateway
  labels:
    app.kubernetes.io/name: ditto-gateway
    helm.sh/chart: ditto-2.1.2
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "2.1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  ports:
    - port: 8080
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/name: ditto-gateway
    app.kubernetes.io/instance: release-name
---
# Source: telemetry-e2e/charts/ditto/templates/nginx-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: ditto-nginx
  labels:
    app.kubernetes.io/name: ditto-nginx
    helm.sh/chart: ditto-2.1.2
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "2.1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 8080
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/name: ditto-nginx
    app.kubernetes.io/instance: release-name
---
# Source: telemetry-e2e/charts/ditto/templates/swaggerui-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: ditto-swaggerui
  labels:
    app.kubernetes.io/name: ditto-swaggerui
    helm.sh/chart: ditto-2.1.2
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "2.1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  ports:
    - port: 8080
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/name: ditto-swaggerui
    app.kubernetes.io/instance: release-name
---
# Source: telemetry-e2e/charts/drogueCloud/templates/integration/mqtt/service.yaml
kind: Service
apiVersion: v1
metadata:
  name: mqtt-integration
  labels:
    app.kubernetes.io/name: mqtt-integration
    app.kubernetes.io/component: integrations
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.7.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: drogue-iot
spec:
  selector:
    app.kubernetes.io/name: mqtt-integration
    app.kubernetes.io/component: integrations
    app.kubernetes.io/instance: release-name
  type: NodePort

  ports:
    - name: service
      protocol: TCP
      port: 1883
      targetPort: service
      nodePort: 30002
---
# Source: telemetry-e2e/charts/drogueCloud/templates/integration/websocket/service.yaml
kind: Service
apiVersion: v1
metadata:
  name: websocket-integration
  labels:
    app.kubernetes.io/name: websocket-integration
    app.kubernetes.io/component: integrations
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.7.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: drogue-iot
spec:
  selector:
    app.kubernetes.io/name: websocket-integration
    app.kubernetes.io/component: integrations
    app.kubernetes.io/instance: release-name
  type: NodePort

  ports:
    - name: service
      protocol: TCP
      port: 8080
      targetPort: service
      nodePort: 30004
---
# Source: telemetry-e2e/charts/drogueCloud/templates/service/console/service-backend.yaml
kind: Service
apiVersion: v1
metadata:
  name: console-backend
  labels:
    app.kubernetes.io/name: console-backend
    app.kubernetes.io/component: console
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.7.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: drogue-iot
spec:

  selector:
    app.kubernetes.io/name: console-backend
    app.kubernetes.io/component: console
    app.kubernetes.io/instance: release-name

  type: ClusterIP

  ports:
    - name: endpoint
      protocol: TCP
      port: 8080
      targetPort: endpoint
---
# Source: telemetry-e2e/charts/drogueCloud/templates/service/console/service-frontend.yaml
kind: Service
apiVersion: v1
metadata:
  name: console
  labels:
    app.kubernetes.io/name: console-frontend
    app.kubernetes.io/component: console
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.7.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: drogue-iot
spec:

  selector:
    app.kubernetes.io/name: console-frontend
    app.kubernetes.io/component: console
    app.kubernetes.io/instance: release-name

  type: ClusterIP

  ports:
    - name: endpoint
      protocol: TCP
      port: 8080
      targetPort: endpoint
---
# Source: telemetry-e2e/charts/drogueCloud/templates/service/registry/auth/service.yaml
kind: Service
apiVersion: v1
metadata:
  name: authentication-service
  labels:
    app.kubernetes.io/name: authentication-service
    app.kubernetes.io/component: device-registry
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.7.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: drogue-iot
spec:

  selector:
    app.kubernetes.io/name: authentication-service
    app.kubernetes.io/component: device-registry
    app.kubernetes.io/instance: release-name

  type: ClusterIP

  ports:
    - name: api
      port: 80
      protocol: TCP
      targetPort: 8080
---
# Source: telemetry-e2e/charts/drogueCloud/templates/service/registry/outbox/service.yaml
kind: Service
apiVersion: v1
metadata:
  name: outbox-controller
  labels:
    app.kubernetes.io/name: outbox-controller
    app.kubernetes.io/component: device-registry
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.7.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: drogue-iot
spec:
  selector:
    app.kubernetes.io/name: outbox-controller
    app.kubernetes.io/component: device-registry
    app.kubernetes.io/instance: release-name
  ports:
    - name: api
      port: 80
      protocol: TCP
      targetPort: api
  type: ClusterIP
---
# Source: telemetry-e2e/charts/drogueCloud/templates/service/registry/postgres/service.yaml
kind: Service
apiVersion: v1
metadata:
  name: postgres
  labels:
    app.kubernetes.io/name: postgres
    app.kubernetes.io/component: device-registry
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.7.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: drogue-iot
spec:
  selector:
    app.kubernetes.io/name: postgres
    app.kubernetes.io/component: device-registry
    app.kubernetes.io/instance: release-name

  type: ClusterIP

  ports:
    - name: postgres
      port: 5432
      protocol: TCP
      targetPort: 5432
---
# Source: telemetry-e2e/charts/drogueCloud/templates/service/registry/registry/service.yaml
kind: Service
apiVersion: v1
metadata:
  name: device-management-service
  labels:
    app.kubernetes.io/name: device-management-service
    app.kubernetes.io/component: device-registry
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.7.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: drogue-iot
spec:

  selector:
    app.kubernetes.io/name: device-management-service
    app.kubernetes.io/component: device-registry
    app.kubernetes.io/instance: release-name

  type: ClusterIP

  ports:
    - name: api
      port: 80
      protocol: TCP
      targetPort: 8080
---
# Source: telemetry-e2e/charts/drogueCloud/templates/service/registry/user-auth/service.yaml
kind: Service
apiVersion: v1
metadata:
  name: user-auth-service
  labels:
    app.kubernetes.io/name: user-auth-service
    app.kubernetes.io/component: device-registry
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.7.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: drogue-iot

spec:

  selector:
    app.kubernetes.io/name: user-auth-service
    app.kubernetes.io/component: device-registry
    app.kubernetes.io/instance: release-name

  type: ClusterIP

  ports:
    - name: api
      port: 80
      protocol: TCP
      targetPort: 8080
---
# Source: telemetry-e2e/charts/drogueCloud/templates/source/coap/service.yaml
kind: Service
apiVersion: v1
metadata:
  name: coap-endpoint
  labels:
    app.kubernetes.io/name: coap-endpoint
    app.kubernetes.io/component: endpoints
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.7.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: drogue-iot
spec:
  selector:
    app.kubernetes.io/name: coap-endpoint
    app.kubernetes.io/component: endpoints
    app.kubernetes.io/instance: release-name
  type: NodePort

  ports:
    - name: endpoint
      port: 5683
      protocol: UDP
      targetPort: endpoint
      nodePort: 30003
---
# Source: telemetry-e2e/charts/drogueCloud/templates/source/command/service.yaml
kind: Service
apiVersion: v1
metadata:
  name: command-endpoint
  labels:
    app.kubernetes.io/name: command-endpoint
    app.kubernetes.io/component: endpoints
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.7.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: drogue-iot
spec:
  selector:
    app.kubernetes.io/name: command-endpoint
    app.kubernetes.io/component: endpoints
    app.kubernetes.io/instance: release-name

  type: ClusterIP

  ports:
    - name: endpoint
      protocol: TCP
      port: 8080
      targetPort: endpoint
---
# Source: telemetry-e2e/charts/drogueCloud/templates/source/http/service.yaml
kind: Service
apiVersion: v1
metadata:
  name: http-endpoint
  labels:
    app.kubernetes.io/name: http-endpoint
    app.kubernetes.io/component: endpoints
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.7.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: drogue-iot
spec:
  selector:
    app.kubernetes.io/name: http-endpoint
    app.kubernetes.io/component: endpoints
    app.kubernetes.io/instance: release-name
  type: NodePort

  ports:
    - name: endpoint
      port: 8080
      protocol: TCP
      targetPort: endpoint
      nodePort: 30443
---
# Source: telemetry-e2e/charts/drogueCloud/templates/source/mqtt/service.yaml
kind: Service
apiVersion: v1
metadata:
  name: mqtt-endpoint
  labels:
    app.kubernetes.io/name: mqtt-endpoint
    app.kubernetes.io/component: endpoints
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.7.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: drogue-iot
spec:
  selector:
    app.kubernetes.io/name: mqtt-endpoint
    app.kubernetes.io/component: endpoints
    app.kubernetes.io/instance: release-name
  type: NodePort

  ports:
    - name: endpoint
      protocol: TCP
      port: 1883
      targetPort: endpoint
      nodePort: 30001
---
# Source: telemetry-e2e/charts/streamsheets/charts/mongodb/templates/standalone/svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: streamsheets-mongodb
  namespace: default
  labels:
    app.kubernetes.io/name: mongodb
    helm.sh/chart: mongodb-10.25.2
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: mongodb
spec:
  type: ClusterIP
  ports:
    - name: mongodb
      port: 27017
      targetPort: mongodb
      nodePort: null
  selector:
    app.kubernetes.io/name: mongodb
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/component: mongodb
---
# Source: telemetry-e2e/charts/streamsheets/charts/redis/templates/headless-svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: streamsheets-redis-headless
  namespace: "default"
  labels:
    app.kubernetes.io/name: redis
    helm.sh/chart: redis-14.8.11
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  clusterIP: None
  ports:
    - name: tcp-redis
      port: 6379
      targetPort: redis
  selector:
    app.kubernetes.io/name: redis
    app.kubernetes.io/instance: release-name
---
# Source: telemetry-e2e/charts/streamsheets/charts/redis/templates/master/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: streamsheets-redis-master
  namespace: "default"
  labels:
    app.kubernetes.io/name: redis
    helm.sh/chart: redis-14.8.11
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: master
spec:
  type: ClusterIP
  
  ports:
    - name: tcp-redis
      port: 6379
      targetPort: redis
      nodePort: null
  selector:
    app.kubernetes.io/name: redis
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/component: master
---
# Source: telemetry-e2e/charts/streamsheets/templates/broker/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: streamsheets-broker
  labels:
    helm.sh/chart: streamsheets-0.2.3
    app.kubernetes.io/name: streamsheets-broker
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "2.4.0"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP

  selector:
    
    helm.sh/chart: streamsheets-0.2.3
    app.kubernetes.io/name: streamsheets-broker
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "2.4.0"
    app.kubernetes.io/managed-by: Helm

  ports:
    - name: mqtt
      port: 1883
      targetPort: mqtt
---
# Source: telemetry-e2e/charts/streamsheets/templates/gateway/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: streamsheets-gateway
  labels:
    helm.sh/chart: streamsheets-0.2.3
    app.kubernetes.io/name: streamsheets-gateway
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "2.4.0"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP

  selector:
    helm.sh/chart: streamsheets-0.2.3
    app.kubernetes.io/name: streamsheets-gateway
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "2.4.0"
    app.kubernetes.io/managed-by: Helm

  ports:
    - name: gateway
      port: 8080
      targetPort: gateway
---
# Source: telemetry-e2e/charts/ditto/charts/mongodb/templates/deployment-standalone.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ditto-mongodb
  namespace: default
  labels:
    app: mongodb
    chart: mongodb-7.14.8
    release: "release-name"
    heritage: "Helm"
spec:
  strategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app: mongodb
      release: "release-name"
  template:
    metadata:
      labels:
        app: mongodb
        release: "release-name"
        chart: mongodb-7.14.8
    spec:
      serviceAccountName: ditto-mongodb      
      initContainers:
      containers:
        - name: ditto-mongodb
          image: docker.io/bitnami/mongodb:4.2.8-debian-10-r7
          imagePullPolicy: "IfNotPresent"
          env:
            - name: MONGODB_SYSTEM_LOG_VERBOSITY
              value: "0"
            - name: MONGODB_DISABLE_SYSTEM_LOG
              value: "no"
            - name: MONGODB_ENABLE_IPV6
              value: "no"
            - name: MONGODB_ENABLE_DIRECTORY_PER_DB
              value: "no"
          ports:
            - name: mongodb
              containerPort: 27017
          livenessProbe:
            exec:
              command:
                - mongo
                - --eval
                - "db.adminCommand('ping')"
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 6
          readinessProbe:
            exec:
              command:
                - mongo
                - --eval
                - "db.adminCommand('ping')"
            initialDelaySeconds: 5
            periodSeconds: 10
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 6
          volumeMounts:
            - name: data
              mountPath: /bitnami/mongodb
              subPath: 
          resources:
            {}
      volumes:
        - name: data
          emptyDir: {}
---
# Source: telemetry-e2e/charts/ditto/templates/concierge-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ditto-concierge
  labels:
    app.kubernetes.io/name: ditto-concierge
    helm.sh/chart: ditto-2.1.2
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "2.1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  strategy:
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
    type: RollingUpdate
  minReadySeconds: 45
  selector:
    matchLabels:
      app.kubernetes.io/name: ditto-concierge
      app.kubernetes.io/instance: release-name
  template:
    metadata:
      labels:
        app.kubernetes.io/name: ditto-concierge
        app.kubernetes.io/instance: release-name
        actorSystemName: ditto-cluster
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/path: "/"
        prometheus.io/port: "9095"
        checksum/mongodb-config: 4f8d7bc23474575732e8f75296113dd6479bbbca266a0e1bda310351ae4a9e86
    spec:
      serviceAccountName: ditto
      securityContext:
        runAsUser: 1000
        runAsGroup: 1000
        fsGroup: 1000
      containers:
        - name: ditto-concierge
          image: docker.io/eclipse/ditto-concierge:2.1.0
          imagePullPolicy: IfNotPresent
          args:
            - "java"
            - "-Dakka.cluster.failure-detector.threshold=15.0"
            - "-Dakka.cluster.failure-detector.expected-response-after=10s"
            - "-Dakka.cluster.failure-detector.acceptable-heartbeat-pause=30s"
            - "-Dakka.cluster.shutdown-after-unsuccessful-join-seed-nodes=120s"
            - "-jar"
            - "/opt/ditto/starter.jar"
          env:
            - name: DITTO_LOGGING_FILE_APPENDER
              value: "false"
            - name: POD_LABEL_SELECTOR
              value: "app.kubernetes.io/name=%s"
            - name: POD_NAMESPACE
              value: default
            - name: INSTANCE_INDEX
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.name
            - name: HOSTNAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: status.podIP
            - name: DISCOVERY_METHOD
              value: "kubernetes-api"
            - name: TZ
              value: "Europe/Berlin"
            - name: OPENJ9_JAVA_OPTIONS
              value: "-XX:+ExitOnOutOfMemoryError -Xtune:virtualized -Xss512k -XX:MaxRAMPercentage=80 -XX:InitialRAMPercentage=40 -Dakka.coordinated-shutdown.exit-jvm=on"
            - name: MONGO_DB_SSL_ENABLED
              value: "false"
            - name: MONGO_DB_URI
              valueFrom:
                secretKeyRef:
                  name: ditto-mongodb-secret
                  key: concierge-uri
            - name: PROMETHEUS_PORT
              value: "9095"
          ports:
            - name: remoting
              containerPort: 2551
              protocol: TCP
            - name: management
              containerPort: 8558
              protocol: TCP
          readinessProbe:
            httpGet:
              port: management
              path: /ready
            initialDelaySeconds: 90
            periodSeconds: 10
            timeoutSeconds: 1
            failureThreshold: 3
          livenessProbe:
            httpGet:
              port: management
              path: /alive
            initialDelaySeconds: 160
            periodSeconds: 10
            timeoutSeconds: 3
            failureThreshold: 4
          resources:
            limits:
              cpu: "1"
              memory: 384Mi
            requests:
              cpu: 100m
              memory: 256Mi
---
# Source: telemetry-e2e/charts/ditto/templates/connectivity-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ditto-connectivity
  labels:
    app.kubernetes.io/name: ditto-connectivity
    helm.sh/chart: ditto-2.1.2
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "2.1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  strategy:
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
    type: RollingUpdate
  minReadySeconds: 45
  selector:
    matchLabels:
      app.kubernetes.io/name: ditto-connectivity
      app.kubernetes.io/instance: release-name
  template:
    metadata:
      labels:
        app.kubernetes.io/name: ditto-connectivity
        app.kubernetes.io/instance: release-name
        actorSystemName: ditto-cluster
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/path: "/"
        prometheus.io/port: "9095"
        checksum/mongodb-config: 4f8d7bc23474575732e8f75296113dd6479bbbca266a0e1bda310351ae4a9e86
    spec:
      serviceAccountName: ditto
      securityContext:
        runAsUser: 1000
        runAsGroup: 1000
        fsGroup: 1000
      containers:
        - name: ditto-connectivity
          image: docker.io/eclipse/ditto-connectivity:2.1.0
          imagePullPolicy: IfNotPresent
          args:
            - "java"
            - "-Dakka.cluster.distributed-data.durable.lmdb.dir=/var/tmp/ddata"
            - "-Dakka.cluster.failure-detector.threshold=15.0"
            - "-Dakka.cluster.failure-detector.expected-response-after=10s"
            - "-Dakka.cluster.failure-detector.acceptable-heartbeat-pause=30s"
            - "-Dakka.cluster.shutdown-after-unsuccessful-join-seed-nodes=120s"
            - "-jar"
            - "/opt/ditto/starter.jar"
          env:
            - name: DITTO_LOGGING_FILE_APPENDER
              value: "false"
            - name: POD_LABEL_SELECTOR
              value: "app.kubernetes.io/name=%s"
            - name: POD_NAMESPACE
              value: default
            - name: INSTANCE_INDEX
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.name
            - name: HOSTNAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: status.podIP
            - name: DISCOVERY_METHOD
              value: "kubernetes-api"
            - name: TZ
              value: "Europe/Berlin"
            - name: OPENJ9_JAVA_OPTIONS
              value: "-XX:+ExitOnOutOfMemoryError -Xtune:virtualized -Xss512k -XX:MaxRAMPercentage=80 -XX:InitialRAMPercentage=40 -Dakka.coordinated-shutdown.exit-jvm=on"
            - name: MONGO_DB_SSL_ENABLED
              value: "false"
            - name: MONGO_DB_URI
              valueFrom:
                secretKeyRef:
                  name: ditto-mongodb-secret
                  key: connectivity-uri
            - name: PROMETHEUS_PORT
              value: "9095"
            - name: CONNECTIVITY_CONNECTION_BLOCKED_HOSTNAMES
              value: ""
          ports:
            - name: remoting
              containerPort: 2551
              protocol: TCP
            - name: management
              containerPort: 8558
              protocol: TCP
          readinessProbe:
            httpGet:
              port: management
              path: /ready
            initialDelaySeconds: 90
            periodSeconds: 10
            timeoutSeconds: 1
            failureThreshold: 3
          livenessProbe:
            httpGet:
              port: management
              path: /alive
            initialDelaySeconds: 160
            periodSeconds: 10
            timeoutSeconds: 3
            failureThreshold: 4
          resources:
            limits:
              cpu: "1"
              memory: 512Mi
            requests:
              cpu: 100m
              memory: 256Mi
---
# Source: telemetry-e2e/charts/ditto/templates/gateway-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ditto-gateway
  labels:
    app.kubernetes.io/name: ditto-gateway
    helm.sh/chart: ditto-2.1.2
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "2.1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  strategy:
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
    type: RollingUpdate
  minReadySeconds: 45
  selector:
    matchLabels:
      app.kubernetes.io/name: ditto-gateway
      app.kubernetes.io/instance: release-name
  template:
    metadata:
      labels:
        app.kubernetes.io/name: ditto-gateway
        app.kubernetes.io/instance: release-name
        actorSystemName: ditto-cluster
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/path: "/"
        prometheus.io/port: "9095"
        checksum/password-config: 41ae51b8add6a0322b6ba3b2561b5f86305148f5684e82ff7a4f09ac87b69108
        checksum/mongodb-config: 4f8d7bc23474575732e8f75296113dd6479bbbca266a0e1bda310351ae4a9e86
    spec:
      serviceAccountName: ditto
      securityContext:
        runAsUser: 1000
        runAsGroup: 1000
        fsGroup: 1000
      containers:
        - name: ditto-gateway
          image: docker.io/eclipse/ditto-gateway:2.1.0
          imagePullPolicy: IfNotPresent
          args:
            - "java"
            - "-Dakka.cluster.failure-detector.threshold=15.0"
            - "-Dakka.cluster.failure-detector.expected-response-after=10s"
            - "-Dakka.cluster.failure-detector.acceptable-heartbeat-pause=30s"
            - "-Dakka.cluster.shutdown-after-unsuccessful-join-seed-nodes=120s"
            - "-jar"
            - "/opt/ditto/starter.jar"
          env:
            - name: DITTO_LOGGING_FILE_APPENDER
              value: "false"
            - name: POD_LABEL_SELECTOR
              value: "app.kubernetes.io/name=%s"
            - name: POD_NAMESPACE
              value: default
            - name: ENABLE_DUMMY_AUTH
              value: "true"
            - name: INSTANCE_INDEX
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.name
            - name: HOSTNAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: status.podIP
            - name: DISCOVERY_METHOD
              value: "kubernetes-api"
            - name: TZ
              value: "Europe/Berlin"
            - name: OPENJ9_JAVA_OPTIONS
              value: "-XX:+ExitOnOutOfMemoryError -Xtune:virtualized -Xss512k -XX:MaxRAMPercentage=80 -XX:InitialRAMPercentage=40 -Dakka.coordinated-shutdown.exit-jvm=on"
            - name: DEVOPS_SECURE_STATUS
              value: "false"
            - name: DEVOPS_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: ditto-gateway-secret
                  key: devops-password
            - name: STATUS_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: ditto-gateway-secret
                  key: status-password
            - name: PROMETHEUS_PORT
              value: "9095"
          ports:
            - name: http
              containerPort: 8080
              protocol: TCP
            - name: remoting
              containerPort: 2551
              protocol: TCP
            - name: management
              containerPort: 8558
              protocol: TCP
          readinessProbe:
            httpGet:
              port: management
              path: /ready
            initialDelaySeconds: 90
            periodSeconds: 10
            timeoutSeconds: 1
            failureThreshold: 3
          livenessProbe:
            httpGet:
              port: management
              path: /alive
            initialDelaySeconds: 160
            periodSeconds: 10
            timeoutSeconds: 3
            failureThreshold: 4
          resources:
            limits:
              cpu: "1"
              memory: 384Mi
            requests:
              cpu: 100m
              memory: 256Mi
---
# Source: telemetry-e2e/charts/ditto/templates/nginx-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ditto-nginx
  labels:
    app.kubernetes.io/name: ditto-nginx
    helm.sh/chart: ditto-2.1.2
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "2.1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  strategy:
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/name: ditto-nginx
      app.kubernetes.io/instance: release-name
  template:
    metadata:
      labels:
        app.kubernetes.io/name: ditto-nginx
        app.kubernetes.io/instance: release-name
      annotations:
        checksum/nginx-conf: 81448098798ed99d83352e45e7195d7fa650b2bedb99ce580f18ece4415a81e7
        checksum/nginx-config: eba31b6c4e7cb8ef7e64043ff70b2b156df6fef280c5c2f3d13a1ae5a909c806
    spec:
      initContainers:
        - name: wait-for-gateway
          image: curlimages/curl:latest
          args:
            - /bin/sh
            - -c
            - >
              set -x;
              while [[ "$(curl -sL -w "%{http_code}\n" http://ditto-gateway:8080/health -o /dev/null)" != "200" ]]; do
                echo '.'
                sleep 15;
              done
      containers:
        - name: ditto-nginx
          image: "docker.io/nginx:1.20-alpine"
          imagePullPolicy: IfNotPresent
          env:
          ports:
            - name: http
              containerPort: 8080
              protocol: TCP
          resources:
            {}
          volumeMounts:
            - name: nginx-conf
              mountPath: /etc/nginx/nginx.conf
              subPath: nginx.conf
            - name: nginx-htpasswd
              mountPath: /etc/nginx/nginx.htpasswd
              subPath: nginx.htpasswd
            - name: nginx-cors
              mountPath: /etc/nginx/nginx-cors.conf
              subPath: nginx-cors.conf
            - name: nginx-index
              mountPath: /etc/nginx/html/index.html
              subPath: index.html
            - name: nginx-ditto-down
              mountPath: /etc/nginx/html/ditto-down.svg
              subPath: ditto-down.svg
            - name: nginx-ditto-up
              mountPath: /etc/nginx/html/ditto-up.svg
              subPath: ditto-up.svg
            - name: nginx-cache
              mountPath: /var/cache/nginx
            - name: nginx-run
              mountPath: /run/nginx
      volumes:
        - name: nginx-conf
          configMap:
            name: release-name-nginx-conf
        - name: nginx-htpasswd
          configMap:
            name: release-name-nginx-config-nginx-htpasswd
        - name: nginx-cors
          configMap:
            name: release-name-nginx-config-nginx-cors-conf
        - name: nginx-index
          configMap:
            name: release-name-nginx-config-index-html
        - name: nginx-ditto-down
          configMap:
            name: release-name-nginx-config-ditto-down-svg
        - name: nginx-ditto-up
          configMap:
            name: release-name-nginx-config-ditto-up-svg
        - name: nginx-cache
          emptyDir: {}
        - name: nginx-run
          emptyDir: {}
---
# Source: telemetry-e2e/charts/ditto/templates/policies-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ditto-policies
  labels:
    app.kubernetes.io/name: ditto-policies
    helm.sh/chart: ditto-2.1.2
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "2.1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  strategy:
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
    type: RollingUpdate
  minReadySeconds: 45
  selector:
    matchLabels:
      app.kubernetes.io/name: ditto-policies
      app.kubernetes.io/instance: release-name
  template:
    metadata:
      labels:
        app.kubernetes.io/name: ditto-policies
        app.kubernetes.io/instance: release-name
        actorSystemName: ditto-cluster
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/path: "/"
        prometheus.io/port: "9095"
        checksum/mongodb-config: 4f8d7bc23474575732e8f75296113dd6479bbbca266a0e1bda310351ae4a9e86
    spec:
      serviceAccountName: ditto
      securityContext:
        runAsUser: 1000
        runAsGroup: 1000
        fsGroup: 1000
      containers:
        - name: ditto-policies
          image: docker.io/eclipse/ditto-policies:2.1.0
          imagePullPolicy: IfNotPresent
          args:
            - "java"
            - "-Dakka.cluster.failure-detector.threshold=15.0"
            - "-Dakka.cluster.failure-detector.expected-response-after=10s"
            - "-Dakka.cluster.failure-detector.acceptable-heartbeat-pause=30s"
            - "-Dakka.cluster.shutdown-after-unsuccessful-join-seed-nodes=120s"
            - "-jar"
            - "/opt/ditto/starter.jar"
          env:
            - name: DITTO_LOGGING_FILE_APPENDER
              value: "false"
            - name: POD_LABEL_SELECTOR
              value: "app.kubernetes.io/name=%s"
            - name: POD_NAMESPACE
              value: default
            - name: INSTANCE_INDEX
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.name
            - name: HOSTNAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: status.podIP
            - name: DISCOVERY_METHOD
              value: "kubernetes-api"
            - name: TZ
              value: "Europe/Berlin"
            - name: OPENJ9_JAVA_OPTIONS
              value: "-XX:+ExitOnOutOfMemoryError -Xtune:virtualized -Xss512k -XX:MaxRAMPercentage=80 -XX:InitialRAMPercentage=40 -Dakka.coordinated-shutdown.exit-jvm=on"
            - name: MONGO_DB_SSL_ENABLED
              value: "false"
            - name: MONGO_DB_URI
              valueFrom:
                secretKeyRef:
                  name: ditto-mongodb-secret
                  key: policies-uri
            - name: PROMETHEUS_PORT
              value: "9095"
          ports:
            - name: http
              containerPort: 8080
              protocol: TCP
            - name: remoting
              containerPort: 2551
              protocol: TCP
            - name: management
              containerPort: 8558
              protocol: TCP
          readinessProbe:
            httpGet:
              port: management
              path: /ready
            initialDelaySeconds: 90
            periodSeconds: 10
            timeoutSeconds: 1
            failureThreshold: 3
          livenessProbe:
            httpGet:
              port: management
              path: /alive
            initialDelaySeconds: 160
            periodSeconds: 10
            timeoutSeconds: 3
            failureThreshold: 4
          resources:
            limits:
              cpu: "1"
              memory: 384Mi
            requests:
              cpu: 100m
              memory: 256Mi
---
# Source: telemetry-e2e/charts/ditto/templates/swaggerui-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ditto-swaggerui
  labels:
    app.kubernetes.io/name: ditto-swaggerui
    helm.sh/chart: ditto-2.1.2
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "2.1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  strategy:
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/name: ditto-swaggerui
      app.kubernetes.io/instance: release-name
  template:
    metadata:
      labels:
        app.kubernetes.io/name: ditto-swaggerui
        app.kubernetes.io/instance: release-name
      annotations:
    spec:
      initContainers:
        - name: ditto-init
          image: "docker.io/swaggerapi/swagger-ui:3.17.4"
          imagePullPolicy: IfNotPresent
          command:
            - sh
            - -ec
            - |
               cp -rv /etc/nginx/. /init-config/
               cp -rv /usr/share/nginx/html/. /init-content/
               mkdir /var/lib/nginx/logs
               mkdir /var/lib/nginx/tmp
          volumeMounts:
            - name: swagger-ui-config
              mountPath: /init-config
            - name: swagger-ui-content
              mountPath: /init-content
            - name: swagger-ui-work
              mountPath: /var/lib/nginx
      containers:
        - name: ditto-swaggerui
          image: "docker.io/swaggerapi/swagger-ui:3.17.4"
          imagePullPolicy: IfNotPresent
          env:
          ports:
            - name: http
              containerPort: 8080
              protocol: TCP
          volumeMounts:
            - name: swagger-ui-api
              mountPath: /usr/share/nginx/html/openapi
            - name: swagger-ui-cache
              mountPath: /var/cache/nginx
            - name: swagger-ui-work
              mountPath: /var/lib/nginx
            - name: swagger-ui-config
              mountPath: /etc/nginx
            - name: swagger-ui-content
              mountPath: /usr/share/nginx/html
            - name: swagger-ui-run
              mountPath: /run/nginx
      volumes:
        - name: swagger-ui-api
          configMap:
            name: ditto-swaggerui
        - name: swagger-ui-cache
          emptyDir: {}
        - name: swagger-ui-work
          emptyDir: {}
        - name: swagger-ui-config
          emptyDir: {}
        - name: swagger-ui-content
          emptyDir: {}
        - name: swagger-ui-run
          emptyDir: {}
---
# Source: telemetry-e2e/charts/ditto/templates/things-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ditto-things
  labels:
    app.kubernetes.io/name: ditto-things
    helm.sh/chart: ditto-2.1.2
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "2.1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  strategy:
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
    type: RollingUpdate
  minReadySeconds: 45
  selector:
    matchLabels:
      app.kubernetes.io/name: ditto-things
      app.kubernetes.io/instance: release-name
  template:
    metadata:
      labels:
        app.kubernetes.io/name: ditto-things
        app.kubernetes.io/instance: release-name
        actorSystemName: ditto-cluster
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/path: "/"
        prometheus.io/port: "9095"
        checksum/mongodb-config: 4f8d7bc23474575732e8f75296113dd6479bbbca266a0e1bda310351ae4a9e86
    spec:
      serviceAccountName: ditto
      securityContext:
        runAsUser: 1000
        runAsGroup: 1000
        fsGroup: 1000
      containers:
        - name: ditto-things
          image: docker.io/eclipse/ditto-things:2.1.0
          imagePullPolicy: IfNotPresent
          args:
            - "java"
            - "-Dakka.cluster.failure-detector.threshold=15.0"
            - "-Dakka.cluster.failure-detector.expected-response-after=10s"
            - "-Dakka.cluster.failure-detector.acceptable-heartbeat-pause=30s"
            - "-Dakka.cluster.shutdown-after-unsuccessful-join-seed-nodes=120s"
            - "-jar"
            - "/opt/ditto/starter.jar"
          env:
            - name: DITTO_LOGGING_FILE_APPENDER
              value: "false"
            - name: POD_LABEL_SELECTOR
              value: "app.kubernetes.io/name=%s"
            - name: POD_NAMESPACE
              value: default
            - name: INSTANCE_INDEX
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.name
            - name: HOSTNAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: status.podIP
            - name: DISCOVERY_METHOD
              value: "kubernetes-api"
            - name: TZ
              value: "Europe/Berlin"
            - name: OPENJ9_JAVA_OPTIONS
              value: "-XX:+ExitOnOutOfMemoryError -Xtune:virtualized -Xss512k -XX:MaxRAMPercentage=80 -XX:InitialRAMPercentage=40 -Dakka.coordinated-shutdown.exit-jvm=on"
            - name: MONGO_DB_SSL_ENABLED
              value: "false"
            - name: MONGO_DB_URI
              valueFrom:
                secretKeyRef:
                  name: ditto-mongodb-secret
                  key: things-uri
            - name: PROMETHEUS_PORT
              value: "9095"
          ports:
            - name: remoting
              containerPort: 2551
              protocol: TCP
            - name: management
              containerPort: 8558
              protocol: TCP
          readinessProbe:
            httpGet:
              port: management
              path: /ready
            initialDelaySeconds: 90
            periodSeconds: 10
            timeoutSeconds: 1
            failureThreshold: 3
          livenessProbe:
            httpGet:
              port: management
              path: /alive
            initialDelaySeconds: 160
            periodSeconds: 10
            timeoutSeconds: 3
            failureThreshold: 4
          resources:
            limits:
              cpu: "1"
              memory: 384Mi
            requests:
              cpu: 100m
              memory: 256Mi
---
# Source: telemetry-e2e/charts/ditto/templates/thingssearch-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ditto-thingssearch
  labels:
    app.kubernetes.io/name: ditto-thingssearch
    helm.sh/chart: ditto-2.1.2
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "2.1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  strategy:
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
    type: RollingUpdate
  minReadySeconds: 45
  selector:
    matchLabels:
      app.kubernetes.io/name: ditto-thingssearch
      app.kubernetes.io/instance: release-name
  template:
    metadata:
      labels:
        app.kubernetes.io/name: ditto-thingssearch
        app.kubernetes.io/instance: release-name
        actorSystemName: ditto-cluster
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/path: "/"
        prometheus.io/port: "9095"
        checksum/mongodb-config: 4f8d7bc23474575732e8f75296113dd6479bbbca266a0e1bda310351ae4a9e86
    spec:
      serviceAccountName: ditto
      securityContext:
        runAsUser: 1000
        runAsGroup: 1000
        fsGroup: 1000
      containers:
        - name: ditto-thingssearch
          image: docker.io/eclipse/ditto-things-search:2.1.0
          imagePullPolicy: IfNotPresent
          args:
            - "java"
            - "-Dakka.cluster.failure-detector.threshold=15.0"
            - "-Dakka.cluster.failure-detector.expected-response-after=10s"
            - "-Dakka.cluster.failure-detector.acceptable-heartbeat-pause=30s"
            - "-Dakka.cluster.shutdown-after-unsuccessful-join-seed-nodes=120s"
            - "-jar"
            - "/opt/ditto/starter.jar"
          env:
            - name: DITTO_LOGGING_FILE_APPENDER
              value: "false"
            - name: POD_LABEL_SELECTOR
              value: "app.kubernetes.io/name=%s"
            - name: POD_NAMESPACE
              value: default
            - name: INSTANCE_INDEX
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.name
            - name: HOSTNAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: status.podIP
            - name: DISCOVERY_METHOD
              value: "kubernetes-api"
            - name: TZ
              value: "Europe/Berlin"
            - name: OPENJ9_JAVA_OPTIONS
              value: "-XX:+ExitOnOutOfMemoryError -Xtune:virtualized -Xss512k -XX:MaxRAMPercentage=80 -XX:InitialRAMPercentage=40 -Dakka.coordinated-shutdown.exit-jvm=on"
            - name: MONGO_DB_SSL_ENABLED
              value: "false"
            - name: MONGO_DB_URI
              valueFrom:
                secretKeyRef:
                  name: ditto-mongodb-secret
                  key: searchDB-uri
            - name: PROMETHEUS_PORT
              value: "9095"
          ports:
            - name: remoting
              containerPort: 2551
              protocol: TCP
            - name: management
              containerPort: 8558
              protocol: TCP
          readinessProbe:
            httpGet:
              port: management
              path: /ready
            initialDelaySeconds: 90
            periodSeconds: 10
            timeoutSeconds: 1
            failureThreshold: 3
          livenessProbe:
            httpGet:
              port: management
              path: /alive
            initialDelaySeconds: 160
            periodSeconds: 10
            timeoutSeconds: 3
            failureThreshold: 4
          resources:
            limits:
              cpu: "1"
              memory: 384Mi
            requests:
              cpu: 100m
              memory: 256Mi
---
# Source: telemetry-e2e/charts/drogueCloud/templates/integration/mqtt/deployment.yaml
kind: Deployment
apiVersion: apps/v1
metadata:
  name: mqtt-integration
  labels:
    app.kubernetes.io/name: mqtt-integration
    app.kubernetes.io/component: integrations
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.7.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: drogue-iot
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: mqtt-integration
      app.kubernetes.io/component: integrations
      app.kubernetes.io/instance: release-name
  template:
    metadata:
      labels:
        app.kubernetes.io/name: mqtt-integration
        app.kubernetes.io/component: integrations
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/version: "0.7.0"
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/part-of: drogue-iot
    spec:
      initContainers:
        - name: wait-for-client-secret
          image: registry.access.redhat.com/ubi8-minimal:latest
          imagePullPolicy: IfNotPresent
          command:
            - bash
            - -c
            - |
              echo "Waiting for client secret to be populated (/etc/client-secret/CLIENT_SECRET)..."
              while test -z "$(cat /etc/client-secret/CLIENT_SECRET)"; do
                sleep 1
              done
          volumeMounts:
            - mountPath: /etc/client-secret
              name: client-secret-services
              readOnly: true
      containers:
        - name: service
          image: "ghcr.io/drogue-iot/mqtt-integration:0.7.0"
          imagePullPolicy: IfNotPresent
          env:
            - name: RUST_LOG
              value: debug
            - name: BIND_ADDR_MQTT
              value: "0.0.0.0:1883"
            - name: HEALTH__BIND_ADDR
              value: "0.0.0.0:9090"
            - name: INSTANCE
              valueFrom:
                configMapKeyRef:
                  name: configuration
                  key: instance
            - name: OAUTH__DROGUE__CLIENT_ID
              valueFrom:
                secretKeyRef:
                  name: keycloak-client-secret-drogue
                  key: CLIENT_ID
            - name: OAUTH__DROGUE__CLIENT_SECRET
              valueFrom:
                secretKeyRef:
                  name: keycloak-client-secret-drogue
                  key: CLIENT_SECRET
                  optional: true
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: USER_AUTH__CLIENT_ID
              valueFrom:
                secretKeyRef:
                  name: keycloak-client-secret-services
                  key: CLIENT_ID
            - name: USER_AUTH__CLIENT_SECRET
              valueFrom:
                secretKeyRef:
                  name: keycloak-client-secret-services
                  key: CLIENT_SECRET
            - name: REGISTRY__CLIENT_ID
              valueFrom:
                secretKeyRef:
                  name: keycloak-client-secret-services
                  key: CLIENT_ID
            - name: REGISTRY__CLIENT_SECRET
              valueFrom:
                secretKeyRef:
                  name: keycloak-client-secret-services
                  key: CLIENT_SECRET
            - name: SSO_URL
              value: http://sso.change.me
            - name: SERVICE__KAFKA__BOOTSTRAP_SERVERS
              value: drogue-iot-kafka-bootstrap.default.svc.cluster.local.:9092
            
            
            - name: SERVICE__KAFKA__PROPERTIES__SECURITY_PROTOCOL
              value: sasl_plaintext
            - name: SERVICE__KAFKA__PROPERTIES__SASL_MECHANISMS
              value: SCRAM-SHA-512
            - name: SERVICE__KAFKA__PROPERTIES__SASL_USERNAME
              value: drogue-iot
            - name: SERVICE__KAFKA__PROPERTIES__SASL_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: drogue-iot
                  key: password
            - name: COMMAND_KAFKA_SINK__TOPIC
              value: iot-commands
            - name: COMMAND_KAFKA_SINK__BOOTSTRAP_SERVERS
              value: drogue-iot-kafka-bootstrap.default.svc.cluster.local.:9092
            
            
            - name: COMMAND_KAFKA_SINK__PROPERTIES__SECURITY_PROTOCOL
              value: sasl_plaintext
            - name: COMMAND_KAFKA_SINK__PROPERTIES__SASL_MECHANISMS
              value: SCRAM-SHA-512
            - name: COMMAND_KAFKA_SINK__PROPERTIES__SASL_USERNAME
              value: drogue-iot
            - name: COMMAND_KAFKA_SINK__PROPERTIES__SASL_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: drogue-iot
                  key: password

            
            - name: DISABLE_TLS
              value: "true"
            

          ports:
            - containerPort: 1883
              name: service
              protocol: TCP
          resources:
            limits:
              memory: 64Mi

          readinessProbe:
            initialDelaySeconds: 2
            periodSeconds: 1
            timeoutSeconds: 1
            failureThreshold: 3
            httpGet:
              port: 9090
              path: /readiness
          livenessProbe:
            initialDelaySeconds: 2
            periodSeconds: 1
            timeoutSeconds: 1
            failureThreshold: 3
            httpGet:
              port: 9090
              path: /liveness

      volumes:

        - name: client-secret-services
          secret:
            secretName: keycloak-client-secret-services
---
# Source: telemetry-e2e/charts/drogueCloud/templates/integration/websocket/deployment.yaml
kind: Deployment
apiVersion: apps/v1
metadata:
  name: websocket-integration
  labels:
    app.kubernetes.io/name: websocket-integration
    app.kubernetes.io/component: integrations
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.7.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: drogue-iot
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: websocket-integration
      app.kubernetes.io/component: integrations
      app.kubernetes.io/instance: release-name
  template:
    metadata:
      labels:
        app.kubernetes.io/name: websocket-integration
        app.kubernetes.io/component: integrations
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/version: "0.7.0"
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/part-of: drogue-iot
    spec:
      initContainers:
        - name: wait-for-client-secret
          image: registry.access.redhat.com/ubi8-minimal:latest
          imagePullPolicy: IfNotPresent
          command:
            - bash
            - -c
            - |
              echo "Waiting for client secret to be populated (/etc/client-secret/CLIENT_SECRET)..."
              while test -z "$(cat /etc/client-secret/CLIENT_SECRET)"; do
                sleep 1
              done
          volumeMounts:
            - mountPath: /etc/client-secret
              name: client-secret-services
              readOnly: true
      containers:
        - name: service
          image: "ghcr.io/drogue-iot/websocket-integration:0.7.0"
          imagePullPolicy: IfNotPresent
          env:
            - name: RUST_LOG
              value: debug
            - name: BIND_ADDR
              value: "0.0.0.0:8080"
            - name: HEALTH__BIND_ADDR
              value: "0.0.0.0:9090"
            - name: INSTANCE
              valueFrom:
                configMapKeyRef:
                  name: configuration
                  key: instance
            - name: OAUTH__DROGUE__CLIENT_ID
              valueFrom:
                secretKeyRef:
                  name: keycloak-client-secret-drogue
                  key: CLIENT_ID
            - name: OAUTH__DROGUE__CLIENT_SECRET
              valueFrom:
                secretKeyRef:
                  name: keycloak-client-secret-drogue
                  key: CLIENT_SECRET
                  optional: true
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: USER_AUTH__CLIENT_ID
              valueFrom:
                secretKeyRef:
                  name: keycloak-client-secret-services
                  key: CLIENT_ID
            - name: USER_AUTH__CLIENT_SECRET
              valueFrom:
                secretKeyRef:
                  name: keycloak-client-secret-services
                  key: CLIENT_SECRET
            - name: REGISTRY__CLIENT_ID
              valueFrom:
                secretKeyRef:
                  name: keycloak-client-secret-services
                  key: CLIENT_ID
            - name: REGISTRY__CLIENT_SECRET
              valueFrom:
                secretKeyRef:
                  name: keycloak-client-secret-services
                  key: CLIENT_SECRET
            - name: SSO_URL
              value: http://sso.change.me
            - name: KAFKA__BOOTSTRAP_SERVERS
              value: drogue-iot-kafka-bootstrap.default.svc.cluster.local.:9092
            
            
            - name: KAFKA__PROPERTIES__SECURITY_PROTOCOL
              value: sasl_plaintext
            - name: KAFKA__PROPERTIES__SASL_MECHANISMS
              value: SCRAM-SHA-512
            - name: KAFKA__PROPERTIES__SASL_USERNAME
              value: drogue-iot
            - name: KAFKA__PROPERTIES__SASL_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: drogue-iot
                  key: password
            - name: COMMAND_KAFKA_SINK__TOPIC
              value: iot-commands
            - name: COMMAND_KAFKA_SINK__BOOTSTRAP_SERVERS
              value: drogue-iot-kafka-bootstrap.default.svc.cluster.local.:9092
            
            
            - name: COMMAND_KAFKA_SINK__PROPERTIES__SECURITY_PROTOCOL
              value: sasl_plaintext
            - name: COMMAND_KAFKA_SINK__PROPERTIES__SASL_MECHANISMS
              value: SCRAM-SHA-512
            - name: COMMAND_KAFKA_SINK__PROPERTIES__SASL_USERNAME
              value: drogue-iot
            - name: COMMAND_KAFKA_SINK__PROPERTIES__SASL_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: drogue-iot
                  key: password
          ports:
            - containerPort: 8080
              name: service
              protocol: TCP
          resources:
            limits:
              memory: 64Mi
          readinessProbe:
            initialDelaySeconds: 2
            periodSeconds: 1
            timeoutSeconds: 1
            failureThreshold: 3
            httpGet:
              port: 9090
              path: /readiness
          livenessProbe:
            initialDelaySeconds: 2
            periodSeconds: 1
            timeoutSeconds: 1
            failureThreshold: 3
            httpGet:
              port: 9090
              path: /liveness
      volumes:
        - name: client-secret-services
          secret:
            secretName: keycloak-client-secret-services
---
# Source: telemetry-e2e/charts/drogueCloud/templates/service/console/deployment-backend.yaml
kind: Deployment
apiVersion: apps/v1
metadata:
  name: console-backend
  labels:
    app.kubernetes.io/name: console-backend
    app.kubernetes.io/component: console
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.7.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: drogue-iot
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: console-backend
      app.kubernetes.io/component: console
      app.kubernetes.io/instance: release-name
  template:
    metadata:
      labels:
        app.kubernetes.io/name: console-backend
        app.kubernetes.io/component: console
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/version: "0.7.0"
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/part-of: drogue-iot
    spec:
      serviceAccountName: console-backend
      initContainers:
        - name: wait-for-client-secret
          image: registry.access.redhat.com/ubi8-minimal:latest
          imagePullPolicy: IfNotPresent
          command:
            - bash
            - -c
            - |
              echo "Waiting for client secret to be populated (/etc/client-secret/CLIENT_SECRET)..."
              while test -z "$(cat /etc/client-secret/CLIENT_SECRET)"; do
                sleep 1
              done
          volumeMounts:
            - mountPath: /etc/client-secret
              name: client-secret-services
              readOnly: true
      containers:
        - name: endpoint
          image: "ghcr.io/drogue-iot/console-backend:0.7.0"
          imagePullPolicy: IfNotPresent
          env:
            - name: RUST_LOG
              value: debug
            - name: BIND_ADDR
              value: "0.0.0.0:8080"
            - name: HEALTH__BIND_ADDR
              value: "0.0.0.0:9090"
            - name: ENABLE_AUTH
              value: "true"
            - name: KAFKA__BOOTSTRAP_SERVERS
              value: drogue-iot-kafka-bootstrap.default.svc.cluster.local.:9092
            
            
            - name: KAFKA__PROPERTIES__SECURITY_PROTOCOL
              value: sasl_plaintext
            - name: KAFKA__PROPERTIES__SASL_MECHANISMS
              value: SCRAM-SHA-512
            - name: KAFKA__PROPERTIES__SASL_USERNAME
              value: drogue-iot
            - name: KAFKA__PROPERTIES__SASL_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: drogue-iot
                  key: password
            - name: UI__CLIENT_ID
              valueFrom:
                secretKeyRef:
                  name: keycloak-client-secret-drogue
                  key: CLIENT_ID
            - name: UI__CLIENT_SECRET
              valueFrom:
                secretKeyRef:
                  name: keycloak-client-secret-drogue
                  key: CLIENT_SECRET
            - name: OAUTH__DROGUE__CLIENT_ID
              valueFrom:
                secretKeyRef:
                  name: keycloak-client-secret-drogue
                  key: CLIENT_ID
            - name: OAUTH__DROGUE__CLIENT_SECRET
              valueFrom:
                secretKeyRef:
                  name: keycloak-client-secret-drogue
                  key: CLIENT_SECRET
            - name: OAUTH__SERVICES__CLIENT_ID
              valueFrom:
                secretKeyRef:
                  name: keycloak-client-secret-services
                  key: CLIENT_ID
            - name: OAUTH__SERVICES__CLIENT_SECRET
              valueFrom:
                secretKeyRef:
                  name: keycloak-client-secret-services
                  key: CLIENT_SECRET
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: USER_AUTH__CLIENT_ID
              valueFrom:
                secretKeyRef:
                  name: keycloak-client-secret-services
                  key: CLIENT_ID
            - name: USER_AUTH__CLIENT_SECRET
              valueFrom:
                secretKeyRef:
                  name: keycloak-client-secret-services
                  key: CLIENT_SECRET
            - name: REGISTRY__CLIENT_ID
              valueFrom:
                secretKeyRef:
                  name: keycloak-client-secret-services
                  key: CLIENT_ID
            - name: REGISTRY__CLIENT_SECRET
              valueFrom:
                secretKeyRef:
                  name: keycloak-client-secret-services
                  key: CLIENT_SECRET
                  optional: true
            - name: KEYCLOAK__URL
              value: https://keycloak.$(NAMESPACE).svc.cluster.local.:8443
            - name: KEYCLOAK__ADMIN_USERNAME
              valueFrom:
                secretKeyRef:
                  key: ADMIN_USERNAME
                  name: credential-sso
            - name: KEYCLOAK__ADMIN_PASSWORD
              valueFrom:
                secretKeyRef:
                  key: ADMIN_PASSWORD
                  name: credential-sso
            
            - name: ENDPOINTS__LOCAL_CERTS
              value: "true"
            - name: "KEYCLOAK__TLS_NOVERIFY"
              value: "true"
            - name: SSO_URL
              value: http://sso.change.me
            - name: ENDPOINTS__API_URL
              value: http://api.change.me
            - name: ENDPOINTS__CONSOLE_URL
              value: http://console.change.me
            - name: ENDPOINTS__REDIRECT_URL
              value: http://console.change.me
            - name: ENDPOINTS__DEVICE_REGISTRY_URL
              value: http://api.change.me
            - name: ENDPOINTS__COMMAND_ENDPOINT_URL
              value: http://api.change.me
            - name: ENDPOINTS__COAP_ENDPOINT_URL
              value: coap://coap-endpoint.change.me:30003
            - name: ENDPOINTS__HTTP_ENDPOINT_URL
              value: http://http-endpoint.change.me:30443
            - name: ENDPOINTS__MQTT_ENDPOINT_HOST
              value: mqtt-endpoint.change.me
            - name: ENDPOINTS__MQTT_ENDPOINT_PORT
              value: "30001"
            - name: ENDPOINTS__MQTT_INTEGRATION_HOST
              value: mqtt-integration.change.me
            - name: ENDPOINTS__MQTT_INTEGRATION_PORT
              value: "30002"
            - name: ENDPOINTS__WEBSOCKET_INTEGRATION_URL
              value: ws://websocket-integration.change.me:30004
            - name: ENDPOINTS__KAFKA_BOOTSTRAP_SERVERS
              value: drogue-iot-kafka-bootstrap.default.svc.cluster.local.:9092
          ports:
            - containerPort: 8080
              name: endpoint
              protocol: TCP
          resources:
            limits:
              memory: 64Mi
          readinessProbe:
            initialDelaySeconds: 2
            periodSeconds: 1
            timeoutSeconds: 1
            failureThreshold: 3
            httpGet:
              port: 9090
              path: /readiness
          livenessProbe:
            initialDelaySeconds: 2
            periodSeconds: 1
            timeoutSeconds: 1
            failureThreshold: 3
            httpGet:
              port: 9090
              path: /liveness
      volumes:
        - name: client-secret-drogue
          secret:
            secretName: keycloak-client-secret-drogue
        - name: client-secret-services
          secret:
            secretName: keycloak-client-secret-services
---
# Source: telemetry-e2e/charts/drogueCloud/templates/service/console/deployment-frontend.yaml
kind: Deployment
apiVersion: apps/v1
metadata:
  name: console-frontend
  labels:
    app.kubernetes.io/name: console-frontend
    app.kubernetes.io/component: console
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.7.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: drogue-iot
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: console-frontend
      app.kubernetes.io/component: console
      app.kubernetes.io/instance: release-name
  template:
    metadata:
      labels:
        app.kubernetes.io/name: console-frontend
        app.kubernetes.io/component: console
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/version: "0.7.0"
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/part-of: drogue-iot
    spec:
      containers:
        - name: endpoint
          image: "ghcr.io/drogue-iot/console-frontend:0.7.0"
          imagePullPolicy: IfNotPresent
          env:
            - name: API_URL
              value: http://api.change.me
          ports:
            - containerPort: 8080
              name: endpoint
              protocol: TCP
          resources:
            limits:
              memory: 64Mi
          volumeMounts:
            - mountPath: /run
              name: run
            - mountPath: /endpoints
              name: endpoints
            - mountPath: /etc/config/login
              name: login-config
              readOnly: true
          readinessProbe:
            initialDelaySeconds: 2
            periodSeconds: 1
            timeoutSeconds: 1
            failureThreshold: 3
            httpGet:
              port: 8080
              path: /
      volumes:
        - name: run
          emptyDir: {}
        - name: endpoints
          emptyDir: {}
        - name: login-config
          configMap:
            optional: true
            name: login-config
---
# Source: telemetry-e2e/charts/drogueCloud/templates/service/registry/auth/deployment.yaml
kind: Deployment
apiVersion: apps/v1
metadata:
  name: authentication-service
  annotations:
    app.openshift.io/connects-to: '[{"apiVersion":"apps/v1","kind":"Deployment","name":"postgres"}]'
  labels:
    app.kubernetes.io/name: authentication-service
    app.kubernetes.io/component: device-registry
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.7.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: drogue-iot
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: authentication-service
      app.kubernetes.io/component: device-registry
      app.kubernetes.io/instance: release-name
  strategy:
    type: RollingUpdate
  template:
    metadata:
      labels:
        app.kubernetes.io/name: authentication-service
        app.kubernetes.io/component: device-registry
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/version: "0.7.0"
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/part-of: drogue-iot
    spec:
      initContainers:
        - name: wait-for-client-secret
          image: registry.access.redhat.com/ubi8-minimal:latest
          imagePullPolicy: IfNotPresent
          command:
            - bash
            - -c
            - |
              echo "Waiting for client secret to be populated (/etc/client-secret/CLIENT_SECRET)..."
              while test -z "$(cat /etc/client-secret/CLIENT_SECRET)"; do
                sleep 1
              done
          volumeMounts:
            - mountPath: /etc/client-secret
              name: client-secret-services
              readOnly: true
      containers:
        - name: service
          image: "ghcr.io/drogue-iot/authentication-service:0.7.0"
          imagePullPolicy: IfNotPresent
          env:
            - name: RUST_LOG
              value: debug
            - name: BIND_ADDR
              value: 0.0.0.0:8080
            - name: HEALTH__BIND_ADDR
              value: "0.0.0.0:9090"
            - name: PG__HOST
              value: postgres
            - name: PG__DBNAME
              valueFrom:
                configMapKeyRef:
                  name: postgres-config
                  key: databaseName
            - name: PG__USER
              valueFrom:
                secretKeyRef:
                  name: postgres-secret
                  key: admin.username
            - name: PG__PASSWORD
              valueFrom:
                secretKeyRef:
                  name: postgres-secret
                  key: admin.password
            - name: OAUTH__SERVICES__CLIENT_ID
              valueFrom:
                secretKeyRef:
                  name: keycloak-client-secret-services
                  key: CLIENT_ID
            - name: OAUTH__SERVICES__CLIENT_SECRET
              valueFrom:
                secretKeyRef:
                  name: keycloak-client-secret-services
                  key: CLIENT_SECRET
            - name: SSO_URL
              value: http://sso.change.me
          readinessProbe:
            initialDelaySeconds: 2
            periodSeconds: 1
            timeoutSeconds: 1
            failureThreshold: 3
            httpGet:
              port: 9090
              path: /readiness
          livenessProbe:
            initialDelaySeconds: 2
            periodSeconds: 1
            timeoutSeconds: 1
            failureThreshold: 3
            httpGet:
              port: 9090
              path: /liveness
          ports:
            - containerPort: 8080
              name: api
              protocol: TCP
          resources:
            limits:
              memory: 128Mi
      volumes:
        - name: client-secret-services
          secret:
            secretName: keycloak-client-secret-services
---
# Source: telemetry-e2e/charts/drogueCloud/templates/service/registry/outbox/deployment.yaml
kind: Deployment
apiVersion: apps/v1
metadata:
  name: outbox-controller
  labels:
    app.kubernetes.io/name: outbox-controller
    app.kubernetes.io/component: device-registry
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.7.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: drogue-iot
  annotations:
    app.openshift.io/connects-to: '[{"apiVersion":"apps/v1","kind":"Deployment","name":"postgres"}]'
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: outbox-controller
      app.kubernetes.io/component: device-registry
      app.kubernetes.io/instance: release-name
  template:
    metadata:
      labels:
        app.kubernetes.io/name: outbox-controller
        app.kubernetes.io/component: device-registry
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/version: "0.7.0"
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/part-of: drogue-iot
    spec:
      containers:
        - name: service
          image: "ghcr.io/drogue-iot/outbox-controller:0.7.0"
          imagePullPolicy: IfNotPresent
          env:
            - name: RUST_LOG
              value: debug
            - name: RUST_BACKTRACE
              value: "1"
            - name: HEALTH__BIND_ADDR
              value: "0.0.0.0:9090"
            - name: PG__HOST
              value: postgres
            - name: PG__DBNAME
              valueFrom:
                configMapKeyRef:
                  name: postgres-config
                  key: databaseName
            - name: PG__USER
              valueFrom:
                secretKeyRef:
                  name: postgres-secret
                  key: admin.username
            - name: PG__PASSWORD
              valueFrom:
                secretKeyRef:
                  name: postgres-secret
                  key: admin.password
            - name: KAFKA_SENDER__TOPIC
              value: registry
            - name: KAFKA_SENDER__QUEUE_TIMEOUT
              value: 15s
            
            
            - name: KAFKA_SENDER__PROPERTIES__SECURITY_PROTOCOL
              value: sasl_plaintext
            - name: KAFKA_SENDER__PROPERTIES__SASL_MECHANISMS
              value: SCRAM-SHA-512
            - name: KAFKA_SENDER__PROPERTIES__SASL_USERNAME
              value: drogue-iot
            - name: KAFKA_SENDER__PROPERTIES__SASL_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: drogue-iot
                  key: password
            - name: KAFKA_SOURCE__TOPIC
              value: registry
            - name: KAFKA_SOURCE__CONSUMER_GROUP
              value: outbox-controller
            
            
            - name: KAFKA_SOURCE__PROPERTIES__SECURITY_PROTOCOL
              value: sasl_plaintext
            - name: KAFKA_SOURCE__PROPERTIES__SASL_MECHANISMS
              value: SCRAM-SHA-512
            - name: KAFKA_SOURCE__PROPERTIES__SASL_USERNAME
              value: drogue-iot
            - name: KAFKA_SOURCE__PROPERTIES__SASL_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: drogue-iot
                  key: password
          readinessProbe:
            initialDelaySeconds: 2
            periodSeconds: 1
            timeoutSeconds: 1
            failureThreshold: 3
            httpGet:
              port: 9090
              path: /readiness
          livenessProbe:
            initialDelaySeconds: 2
            periodSeconds: 1
            timeoutSeconds: 1
            failureThreshold: 3
            httpGet:
              port: 9090
              path: /liveness
          ports:
            - containerPort: 8080
              name: api
              protocol: TCP
          resources:
            limits:
              memory: 128Mi
---
# Source: telemetry-e2e/charts/drogueCloud/templates/service/registry/postgres/deployment.yaml
kind: Deployment
apiVersion: apps/v1
metadata:
  name: postgres
  labels:
    app.kubernetes.io/name: postgres
    app.kubernetes.io/component: device-registry
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.7.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: drogue-iot
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: postgres
      app.kubernetes.io/component: device-registry
      app.kubernetes.io/instance: release-name
  strategy:
    type: Recreate
  template:
    metadata:
      labels:
        app.kubernetes.io/name: postgres
        app.kubernetes.io/component: device-registry
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/version: "0.7.0"
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/part-of: drogue-iot
    spec:
      containers:
        - name: postgres
          image: docker.io/bitnami/postgresql:13
          imagePullPolicy: IfNotPresent
          env:
            - name: POSTGRES_DB
              valueFrom:
                configMapKeyRef:
                  name: postgres-config
                  key: databaseName
            - name: POSTGRES_USER
              valueFrom:
                secretKeyRef:
                  name: postgres-secret
                  key: admin.username
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: postgres-secret
                  key: admin.password
            - name: PGPASSWORD # used in combination with psql
              valueFrom:
                secretKeyRef:
                  name: postgres-secret
                  key: admin.password
          readinessProbe:
            initialDelaySeconds: 5
            periodSeconds: 5
            tcpSocket:
              port: 5432
            timeoutSeconds: 1
          livenessProbe:
            initialDelaySeconds: 10
            periodSeconds: 5
            tcpSocket:
              port: 5432
            timeoutSeconds: 1
          ports:
            - containerPort: 5432
              name: postgres
              protocol: TCP
          resources:
            
            limits:
              cpu: 100m
              memory: 256Mi
            requests:
              cpu: 100m
              memory: 256Mi
          volumeMounts:
            - mountPath: /bitnami/postgresql
              name: storage
      volumes:
        - name: storage
          persistentVolumeClaim:
            claimName: postgres-pvc
---
# Source: telemetry-e2e/charts/drogueCloud/templates/service/registry/registry/deployment.yaml
kind: Deployment
apiVersion: apps/v1
metadata:
  name: device-management-service
  labels:
    app.kubernetes.io/name: device-management-service
    app.kubernetes.io/component: device-registry
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.7.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: drogue-iot
  annotations:
    app.openshift.io/connects-to: '[{"apiVersion":"apps/v1","kind":"Deployment","name":"postgres"}]'
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: device-management-service
      app.kubernetes.io/component: device-registry
      app.kubernetes.io/instance: release-name
  template:
    metadata:
      labels:
        app.kubernetes.io/name: device-management-service
        app.kubernetes.io/component: device-registry
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/version: "0.7.0"
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/part-of: drogue-iot
    spec:
      initContainers:
        - name: wait-for-client-secret
          image: registry.access.redhat.com/ubi8-minimal:latest
          imagePullPolicy: IfNotPresent
          command:
            - bash
            - -c
            - |
              echo "Waiting for client secret to be populated (/etc/client-secret/CLIENT_SECRET)..."
              while test -z "$(cat /etc/client-secret/CLIENT_SECRET)"; do
                sleep 1
              done
          volumeMounts:
            - mountPath: /etc/client-secret
              name: client-secret-services
              readOnly: true
      containers:
        - name: service
          image: "ghcr.io/drogue-iot/device-management-service:0.7.0"
          imagePullPolicy: IfNotPresent
          env:
            - name: RUST_LOG
              value: debug
            - name: RUST_BACKTRACE
              value: "1"
            - name: BIND_ADDR
              value: 0.0.0.0:8080
            - name: HEALTH__BIND_ADDR
              value: "0.0.0.0:9090"
            - name: PG__HOST
              value: postgres
            - name: PG__DBNAME
              valueFrom:
                configMapKeyRef:
                  name: postgres-config
                  key: databaseName
            - name: PG__USER
              valueFrom:
                secretKeyRef:
                  name: postgres-secret
                  key: admin.username
            - name: PG__PASSWORD
              valueFrom:
                secretKeyRef:
                  name: postgres-secret
                  key: admin.password
            - name: OAUTH__DROGUE__CLIENT_ID
              valueFrom:
                secretKeyRef:
                  name: keycloak-client-secret-drogue
                  key: CLIENT_ID
            - name: OAUTH__DROGUE__CLIENT_SECRET
              valueFrom:
                secretKeyRef:
                  name: keycloak-client-secret-drogue
                  key: CLIENT_SECRET
                  optional: true
            - name: OAUTH__SERVICES__CLIENT_ID
              valueFrom:
                secretKeyRef:
                  name: keycloak-client-secret-services
                  key: CLIENT_ID
            - name: OAUTH__SERVICES__CLIENT_SECRET
              valueFrom:
                secretKeyRef:
                  name: keycloak-client-secret-services
                  key: CLIENT_SECRET
            - name: INSTANCE
              valueFrom:
                configMapKeyRef:
                  name: configuration
                  key: instance
            - name: SSO_URL
              value: http://sso.change.me
            - name: KAFKA_SENDER__TOPIC
              value: registry
            - name: KAFKA_SENDER__QUEUE_TIMEOUT
              value: 15s
            
            
            - name: KAFKA_SENDER__PROPERTIES__SECURITY_PROTOCOL
              value: sasl_plaintext
            - name: KAFKA_SENDER__PROPERTIES__SASL_MECHANISMS
              value: SCRAM-SHA-512
            - name: KAFKA_SENDER__PROPERTIES__SASL_USERNAME
              value: drogue-iot
            - name: KAFKA_SENDER__PROPERTIES__SASL_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: drogue-iot
                  key: password
          readinessProbe:
            initialDelaySeconds: 2
            periodSeconds: 1
            timeoutSeconds: 1
            failureThreshold: 3
            httpGet:
              port: 9090
              path: /readiness
          livenessProbe:
            initialDelaySeconds: 2
            periodSeconds: 1
            timeoutSeconds: 1
            failureThreshold: 3
            httpGet:
              port: 9090
              path: /liveness
          ports:
            - containerPort: 8080
              name: api
              protocol: TCP
          resources:
            limits:
              memory: 128Mi
      volumes:
        - name: client-secret-drogue
          secret:
            secretName: keycloak-client-secret-drogue
        - name: client-secret-services
          secret:
            secretName: keycloak-client-secret-services
---
# Source: telemetry-e2e/charts/drogueCloud/templates/service/registry/topic-operator/deployment.yaml
kind: Deployment
apiVersion: apps/v1
metadata:
  name: topic-operator
  annotations:
    app.openshift.io/connects-to: '[{"apiVersion":"apps/v1","kind":"Deployment","name":"device-management-service"}]'
  labels:
    app.kubernetes.io/name: topic-operator
    app.kubernetes.io/component: device-registry
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.7.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: drogue-iot
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: topic-operator
      app.kubernetes.io/component: device-registry
      app.kubernetes.io/instance: release-name
  template:
    metadata:
      labels:
        app.kubernetes.io/name: topic-operator
        app.kubernetes.io/component: device-registry
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/version: "0.7.0"
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/part-of: drogue-iot
    spec:
      serviceAccountName: topic-operator
      initContainers:
        - name: wait-for-client-secret
          image: registry.access.redhat.com/ubi8-minimal:latest
          imagePullPolicy: IfNotPresent
          command:
            - bash
            - -c
            - |
              echo "Waiting for client secret to be populated (/etc/client-secret/CLIENT_SECRET)..."
              while test -z "$(cat /etc/client-secret/CLIENT_SECRET)"; do
                sleep 1
              done
          volumeMounts:
            - mountPath: /etc/client-secret
              name: client-secret-services
              readOnly: true
      containers:
        - name: service
          image: "ghcr.io/drogue-iot/topic-operator:0.7.0"
          imagePullPolicy: IfNotPresent
          env:
            - name: RUST_LOG
              value: debug
            - name: RUST_BACKTRACE
              value: "1"
            - name: HEALTH__BIND_ADDR
              value: "0.0.0.0:9090"
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: REGISTRY__CLIENT_ID
              valueFrom:
                secretKeyRef:
                  name: keycloak-client-secret-services
                  key: CLIENT_ID
            - name: REGISTRY__CLIENT_SECRET
              valueFrom:
                secretKeyRef:
                  name: keycloak-client-secret-services
                  key: CLIENT_SECRET
            - name: SSO_URL
              value: http://sso.change.me
            - name: CONTROLLER__TOPIC_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: CONTROLLER__CLUSTER_NAME
              value: drogue-iot
            - name: WORK_QUEUE__INSTANCE
              value: topic-operator
            - name: WORK_QUEUE__PG__HOST
              value: postgres
            - name: WORK_QUEUE__PG__DBNAME
              valueFrom:
                configMapKeyRef:
                  name: postgres-config
                  key: databaseName
            - name: WORK_QUEUE__PG__USER
              valueFrom:
                secretKeyRef:
                  name: postgres-secret
                  key: admin.username
            - name: WORK_QUEUE__PG__PASSWORD
              valueFrom:
                secretKeyRef:
                  name: postgres-secret
                  key: admin.password
            - name: KAFKA_SOURCE__TOPIC
              value: registry
            - name: KAFKA_SOURCE__CONSUMER_GROUP
              value: topic-operator
            
            
            - name: KAFKA_SOURCE__PROPERTIES__SECURITY_PROTOCOL
              value: sasl_plaintext
            - name: KAFKA_SOURCE__PROPERTIES__SASL_MECHANISMS
              value: SCRAM-SHA-512
            - name: KAFKA_SOURCE__PROPERTIES__SASL_USERNAME
              value: drogue-iot
            - name: KAFKA_SOURCE__PROPERTIES__SASL_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: drogue-iot
                  key: password
          readinessProbe:
            initialDelaySeconds: 2
            periodSeconds: 1
            timeoutSeconds: 1
            failureThreshold: 3
            httpGet:
              port: 9090
              path: /readiness
          livenessProbe:
            initialDelaySeconds: 2
            periodSeconds: 1
            timeoutSeconds: 1
            failureThreshold: 3
            httpGet:
              port: 9090
              path: /liveness
          resources:
            limits:
              memory: 128Mi
      volumes:
        - name: client-secret-services
          secret:
            secretName: keycloak-client-secret-services
---
# Source: telemetry-e2e/charts/drogueCloud/templates/service/registry/ttn-operator/deployment.yaml
kind: Deployment
apiVersion: apps/v1
metadata:
  name: ttn-operator
  annotations:
    app.openshift.io/connects-to: '[{"apiVersion":"apps/v1","kind":"Deployment","name":"device-management-service"}]'
  labels:
    app.kubernetes.io/name: ttn-operator
    app.kubernetes.io/component: device-registry
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.7.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: drogue-iot
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: ttn-operator
      app.kubernetes.io/component: device-registry
      app.kubernetes.io/instance: release-name
  template:
    metadata:
      labels:
        app.kubernetes.io/name: ttn-operator
        app.kubernetes.io/component: device-registry
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/version: "0.7.0"
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/part-of: drogue-iot
    spec:
      serviceAccountName: ttn-operator
      initContainers:
        - name: wait-for-client-secret
          image: registry.access.redhat.com/ubi8-minimal:latest
          imagePullPolicy: IfNotPresent
          command:
            - bash
            - -c
            - |
              echo "Waiting for client secret to be populated (/etc/client-secret/CLIENT_SECRET)..."
              while test -z "$(cat /etc/client-secret/CLIENT_SECRET)"; do
                sleep 1
              done
          volumeMounts:
            - mountPath: /etc/client-secret
              name: client-secret-services
              readOnly: true
      containers:
        - name: service
          image: "ghcr.io/drogue-iot/ttn-operator:0.7.0"
          imagePullPolicy: IfNotPresent
          env:
            - name: RUST_LOG
              value: debug
            - name: RUST_BACKTRACE
              value: "1"
            - name: HEALTH__BIND_ADDR
              value: "0.0.0.0:9090"
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: REGISTRY__CLIENT_ID
              valueFrom:
                secretKeyRef:
                  name: keycloak-client-secret-services
                  key: CLIENT_ID
            - name: REGISTRY__CLIENT_SECRET
              valueFrom:
                secretKeyRef:
                  name: keycloak-client-secret-services
                  key: CLIENT_SECRET
            - name: SSO_URL
              value: http://sso.change.me
            - name: ENDPOINTS__HTTP_ENDPOINT_URL
              value: http://http-endpoint.change.me:30443
            - name: WORK_QUEUE__INSTANCE
              value: ttn-operator
            - name: WORK_QUEUE__PG__HOST
              value: postgres
            - name: WORK_QUEUE__PG__DBNAME
              valueFrom:
                configMapKeyRef:
                  name: postgres-config
                  key: databaseName
            - name: WORK_QUEUE__PG__USER
              valueFrom:
                secretKeyRef:
                  name: postgres-secret
                  key: admin.username
            - name: WORK_QUEUE__PG__PASSWORD
              valueFrom:
                secretKeyRef:
                  name: postgres-secret
                  key: admin.password
            - name: KAFKA_SOURCE__TOPIC
              value: registry
            - name: KAFKA_SOURCE__CONSUMER_GROUP
              value: ttn-operator
            
            
            - name: KAFKA_SOURCE__PROPERTIES__SECURITY_PROTOCOL
              value: sasl_plaintext
            - name: KAFKA_SOURCE__PROPERTIES__SASL_MECHANISMS
              value: SCRAM-SHA-512
            - name: KAFKA_SOURCE__PROPERTIES__SASL_USERNAME
              value: drogue-iot
            - name: KAFKA_SOURCE__PROPERTIES__SASL_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: drogue-iot
                  key: password
          readinessProbe:
            initialDelaySeconds: 2
            periodSeconds: 1
            timeoutSeconds: 1
            failureThreshold: 3
            httpGet:
              port: 9090
              path: /readiness
          livenessProbe:
            initialDelaySeconds: 2
            periodSeconds: 1
            timeoutSeconds: 1
            failureThreshold: 3
            httpGet:
              port: 9090
              path: /liveness
          resources:
            limits:
              memory: 128Mi
      volumes:
        - name: client-secret-services
          secret:
            secretName: keycloak-client-secret-services
---
# Source: telemetry-e2e/charts/drogueCloud/templates/service/registry/user-auth/deployment.yaml
kind: Deployment
apiVersion: apps/v1
metadata:
  name: user-auth-service
  annotations:
    app.openshift.io/connects-to: '[{"apiVersion":"apps/v1","kind":"Deployment","name":"postgres"}]'
  labels:
    app.kubernetes.io/name: user-auth-service
    app.kubernetes.io/component: device-registry
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.7.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: drogue-iot

spec:

  replicas: 1

  selector:
    matchLabels:
      app.kubernetes.io/name: user-auth-service
      app.kubernetes.io/component: device-registry
      app.kubernetes.io/instance: release-name

  strategy:
    type: RollingUpdate

  template:
    metadata:
      labels:
        app.kubernetes.io/name: user-auth-service
        app.kubernetes.io/component: device-registry
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/version: "0.7.0"
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/part-of: drogue-iot

    spec:
      initContainers:
        - name: wait-for-client-secret
          image: registry.access.redhat.com/ubi8-minimal:latest
          imagePullPolicy: IfNotPresent
          command:
            - bash
            - -c
            - |
              echo "Waiting for client secret to be populated (/etc/client-secret/CLIENT_SECRET)..."
              while test -z "$(cat /etc/client-secret/CLIENT_SECRET)"; do
                sleep 1
              done
          volumeMounts:
            - mountPath: /etc/client-secret
              name: client-secret-services
              readOnly: true
      containers:
        - name: service
          image: "ghcr.io/drogue-iot/user-auth-service:0.7.0"
          imagePullPolicy: IfNotPresent
          env:
            - name: RUST_LOG
              value: debug
            - name: BIND_ADDR
              value: 0.0.0.0:8080
            - name: HEALTH__BIND_ADDR
              value: "0.0.0.0:9090"
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: SERVICE__PG__HOST
              value: postgres
            - name: SERVICE__PG__DBNAME
              valueFrom:
                configMapKeyRef:
                  name: postgres-config
                  key: databaseName
            - name: SERVICE__PG__USER
              valueFrom:
                secretKeyRef:
                  name: postgres-secret
                  key: admin.username
            - name: SERVICE__PG__PASSWORD
              valueFrom:
                secretKeyRef:
                  name: postgres-secret
                  key: admin.password
            - name: OAUTH__SERVICES__CLIENT_ID
              valueFrom:
                secretKeyRef:
                  name: keycloak-client-secret-services
                  key: CLIENT_ID
            - name: OAUTH__SERVICES__CLIENT_SECRET
              valueFrom:
                secretKeyRef:
                  name: keycloak-client-secret-services
                  key: CLIENT_SECRET
            - name: KEYCLOAK__URL
              value: https://keycloak.$(NAMESPACE).svc.cluster.local.:8443
            - name: KEYCLOAK__ADMIN_USERNAME
              valueFrom:
                secretKeyRef:
                  key: ADMIN_USERNAME
                  name: credential-sso
            - name: KEYCLOAK__ADMIN_PASSWORD
              valueFrom:
                secretKeyRef:
                  key: ADMIN_PASSWORD
                  name: credential-sso
            
            - name: "KEYCLOAK__TLS_NOVERIFY"
              value: "true"
            - name: SSO_URL
              value: http://sso.change.me
          readinessProbe:
            initialDelaySeconds: 2
            periodSeconds: 1
            timeoutSeconds: 1
            failureThreshold: 3
            httpGet:
              port: 9090
              path: /readiness
          livenessProbe:
            initialDelaySeconds: 2
            periodSeconds: 1
            timeoutSeconds: 1
            failureThreshold: 3
            httpGet:
              port: 9090
              path: /liveness
          ports:
            - containerPort: 8080
              name: api
              protocol: TCP
          resources:
            limits:
              memory: 128Mi
      volumes:
        - name: client-secret-services
          secret:
            secretName: keycloak-client-secret-services
---
# Source: telemetry-e2e/charts/drogueCloud/templates/source/coap/deployment.yaml
kind: Deployment
apiVersion: apps/v1
metadata:
  name: coap-endpoint
  labels:
    app.kubernetes.io/name: coap-endpoint
    app.kubernetes.io/component: endpoints
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.7.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: drogue-iot
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: coap-endpoint
      app.kubernetes.io/component: endpoints
      app.kubernetes.io/instance: release-name
  template:
    metadata:
      labels:
        app.kubernetes.io/name: coap-endpoint
        app.kubernetes.io/component: endpoints
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/version: "0.7.0"
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/part-of: drogue-iot
    spec:
      initContainers:
        - name: wait-for-client-secret
          image: registry.access.redhat.com/ubi8-minimal:latest
          imagePullPolicy: IfNotPresent
          command:
            - bash
            - -c
            - |
              echo "Waiting for client secret to be populated (/etc/client-secret/CLIENT_SECRET)..."
              while test -z "$(cat /etc/client-secret/CLIENT_SECRET)"; do
                sleep 1
              done
          volumeMounts:
            - mountPath: /etc/client-secret
              name: client-secret-services
              readOnly: true
      containers:
        - name: endpoint
          image: "ghcr.io/drogue-iot/coap-endpoint:0.7.0"
          imagePullPolicy: IfNotPresent
          env:
            - name: RUST_LOG
              value: debug
            - name: RUST_BACKTRACE
              value: "1"
            - name: BIND_ADDR_COAP
              value: "0.0.0.0:5683"
            - name: HEALTH__BIND_ADDR
              value: "0.0.0.0:9090"
            - name: INSTANCE
              valueFrom:
                configMapKeyRef:
                  name: configuration
                  key: instance
            - name: CLIENT_ID
              valueFrom:
                secretKeyRef:
                  name: keycloak-client-secret-services
                  key: CLIENT_ID
            - name: CLIENT_SECRET
              valueFrom:
                secretKeyRef:
                  name: keycloak-client-secret-services
                  key: CLIENT_SECRET
            - name: SSO_URL
              value: http://sso.change.me
            - name: COMMAND_SOURCE_KAFKA__TOPIC
              value: iot-commands
            - name: COMMAND_SOURCE_KAFKA__CONSUMER_GROUP
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: COMMAND_SOURCE_KAFKA__BOOTSTRAP_SERVERS
              value: drogue-iot-kafka-bootstrap.default.svc.cluster.local.:9092
            
            
            - name: COMMAND_SOURCE_KAFKA__PROPERTIES__SECURITY_PROTOCOL
              value: sasl_plaintext
            - name: COMMAND_SOURCE_KAFKA__PROPERTIES__SASL_MECHANISMS
              value: SCRAM-SHA-512
            - name: COMMAND_SOURCE_KAFKA__PROPERTIES__SASL_USERNAME
              value: drogue-iot
            - name: COMMAND_SOURCE_KAFKA__PROPERTIES__SASL_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: drogue-iot
                  key: password
            - name: DOWNSTREAM_KAFKA_SINK__BOOTSTRAP_SERVERS
              value: drogue-iot-kafka-bootstrap.default.svc.cluster.local.:9092
            
            
            - name: DOWNSTREAM_KAFKA_SINK__PROPERTIES__SECURITY_PROTOCOL
              value: sasl_plaintext
            - name: DOWNSTREAM_KAFKA_SINK__PROPERTIES__SASL_MECHANISMS
              value: SCRAM-SHA-512
            - name: DOWNSTREAM_KAFKA_SINK__PROPERTIES__SASL_USERNAME
              value: drogue-iot
            - name: DOWNSTREAM_KAFKA_SINK__PROPERTIES__SASL_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: drogue-iot
                  key: password

            
            - name: DISABLE_TLS
              value: "true"
            

          ports:
            - containerPort: 5683
              name: endpoint
              protocol: UDP

          readinessProbe:
            initialDelaySeconds: 2
            periodSeconds: 1
            timeoutSeconds: 1
            failureThreshold: 3
            httpGet:
              port: 9090
              path: /readiness
          livenessProbe:
            initialDelaySeconds: 2
            periodSeconds: 1
            timeoutSeconds: 1
            failureThreshold: 3
            httpGet:
              port: 9090
              path: /liveness

          

      volumes:

        

        - name: client-secret-services
          secret:
            secretName: keycloak-client-secret-services
---
# Source: telemetry-e2e/charts/drogueCloud/templates/source/command/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: command-endpoint
  labels:
    app.kubernetes.io/name: command-endpoint
    app.kubernetes.io/component: endpoints
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.7.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: drogue-iot
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: command-endpoint
      app.kubernetes.io/component: endpoints
      app.kubernetes.io/instance: release-name
  template:
    metadata:
      labels:
        app.kubernetes.io/name: command-endpoint
        app.kubernetes.io/component: endpoints
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/version: "0.7.0"
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/part-of: drogue-iot
    spec:
      initContainers:
        - name: wait-for-client-secret
          image: registry.access.redhat.com/ubi8-minimal:latest
          imagePullPolicy: IfNotPresent
          command:
            - bash
            - -c
            - |
              echo "Waiting for client secret to be populated (/etc/client-secret/CLIENT_SECRET)..."
              while test -z "$(cat /etc/client-secret/CLIENT_SECRET)"; do
                sleep 1
              done
          volumeMounts:
            - mountPath: /etc/client-secret
              name: client-secret-services
              readOnly: true
      containers:
        - name: endpoint
          image: "ghcr.io/drogue-iot/command-endpoint:0.7.0"
          imagePullPolicy: IfNotPresent
          env:
            - name: RUST_LOG
              value: debug
            - name: BIND_ADDR
              value: "0.0.0.0:8080"
            - name: HEALTH__BIND_ADDR
              value: "0.0.0.0:9090"
            - name: INSTANCE
              valueFrom:
                configMapKeyRef:
                  name: configuration
                  key: instance
            - name: OAUTH__DROGUE__CLIENT_ID
              valueFrom:
                secretKeyRef:
                  name: keycloak-client-secret-drogue
                  key: CLIENT_ID
            - name: OAUTH__DROGUE__CLIENT_SECRET
              valueFrom:
                secretKeyRef:
                  name: keycloak-client-secret-drogue
                  key: CLIENT_SECRET
                  optional: true
            - name: OAUTH__SERVICES__CLIENT_ID
              valueFrom:
                secretKeyRef:
                  name: keycloak-client-secret-services
                  key: CLIENT_ID
            - name: OAUTH__SERVICES__CLIENT_SECRET
              valueFrom:
                secretKeyRef:
                  name: keycloak-client-secret-services
                  key: CLIENT_SECRET
            - name: REGISTRY__CLIENT_ID
              valueFrom:
                secretKeyRef:
                  name: keycloak-client-secret-services
                  key: CLIENT_ID
            - name: REGISTRY__CLIENT_SECRET
              valueFrom:
                secretKeyRef:
                  name: keycloak-client-secret-services
                  key: CLIENT_SECRET
            - name: USER_AUTH__CLIENT_ID
              valueFrom:
                secretKeyRef:
                  name: keycloak-client-secret-services
                  key: CLIENT_ID
            - name: USER_AUTH__CLIENT_SECRET
              valueFrom:
                secretKeyRef:
                  name: keycloak-client-secret-services
                  key: CLIENT_SECRET
            - name: SSO_URL
              value: http://sso.change.me
            - name: COMMAND_KAFKA_SINK__TOPIC
              value: iot-commands
            - name: COMMAND_KAFKA_SINK__BOOTSTRAP_SERVERS
              value: drogue-iot-kafka-bootstrap.default.svc.cluster.local.:9092
            
            
            - name: COMMAND_KAFKA_SINK__PROPERTIES__SECURITY_PROTOCOL
              value: sasl_plaintext
            - name: COMMAND_KAFKA_SINK__PROPERTIES__SASL_MECHANISMS
              value: SCRAM-SHA-512
            - name: COMMAND_KAFKA_SINK__PROPERTIES__SASL_USERNAME
              value: drogue-iot
            - name: COMMAND_KAFKA_SINK__PROPERTIES__SASL_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: drogue-iot
                  key: password
          ports:
            - containerPort: 8080
              name: endpoint
              protocol: TCP
          readinessProbe:
            initialDelaySeconds: 2
            periodSeconds: 1
            timeoutSeconds: 1
            failureThreshold: 3
            httpGet:
              port: 9090
              path: /readiness
          livenessProbe:
            initialDelaySeconds: 2
            periodSeconds: 1
            timeoutSeconds: 1
            failureThreshold: 3
            httpGet:
              port: 9090
              path: /liveness
      volumes:
        - name: client-secret-services
          secret:
            secretName: keycloak-client-secret-services
---
# Source: telemetry-e2e/charts/drogueCloud/templates/source/http/deployment.yaml
kind: Deployment
apiVersion: apps/v1
metadata:
  name: http-endpoint
  labels:
    app.kubernetes.io/name: http-endpoint
    app.kubernetes.io/component: endpoints
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.7.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: drogue-iot
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: http-endpoint
      app.kubernetes.io/component: endpoints
      app.kubernetes.io/instance: release-name
  template:
    metadata:
      labels:
        app.kubernetes.io/name: http-endpoint
        app.kubernetes.io/component: endpoints
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/version: "0.7.0"
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/part-of: drogue-iot
    spec:
      initContainers:
        - name: wait-for-client-secret
          image: registry.access.redhat.com/ubi8-minimal:latest
          imagePullPolicy: IfNotPresent
          command:
            - bash
            - -c
            - |
              echo "Waiting for client secret to be populated (/etc/client-secret/CLIENT_SECRET)..."
              while test -z "$(cat /etc/client-secret/CLIENT_SECRET)"; do
                sleep 1
              done
          volumeMounts:
            - mountPath: /etc/client-secret
              name: client-secret-services
              readOnly: true
      containers:
        - name: endpoint
          image: "ghcr.io/drogue-iot/http-endpoint:0.7.0"
          imagePullPolicy: IfNotPresent
          env:
            - name: RUST_LOG
              value: debug
            - name: RUST_BACKTRACE
              value: "1"
            - name: BIND_ADDR
              value: "0.0.0.0:8080"
            - name: HEALTH__BIND_ADDR
              value: "0.0.0.0:9090"
            - name: INSTANCE
              valueFrom:
                configMapKeyRef:
                  name: configuration
                  key: instance
            - name: CLIENT_ID
              valueFrom:
                secretKeyRef:
                  name: keycloak-client-secret-services
                  key: CLIENT_ID
            - name: CLIENT_SECRET
              valueFrom:
                secretKeyRef:
                  name: keycloak-client-secret-services
                  key: CLIENT_SECRET
            - name: SSO_URL
              value: http://sso.change.me
            - name: COMMAND_SOURCE_KAFKA__TOPIC
              value: iot-commands
            - name: COMMAND_SOURCE_KAFKA__CONSUMER_GROUP
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: COMMAND_SOURCE_KAFKA__BOOTSTRAP_SERVERS
              value: drogue-iot-kafka-bootstrap.default.svc.cluster.local.:9092
            
            
            - name: COMMAND_SOURCE_KAFKA__PROPERTIES__SECURITY_PROTOCOL
              value: sasl_plaintext
            - name: COMMAND_SOURCE_KAFKA__PROPERTIES__SASL_MECHANISMS
              value: SCRAM-SHA-512
            - name: COMMAND_SOURCE_KAFKA__PROPERTIES__SASL_USERNAME
              value: drogue-iot
            - name: COMMAND_SOURCE_KAFKA__PROPERTIES__SASL_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: drogue-iot
                  key: password
            - name: DOWNSTREAM_KAFKA_SINK__BOOTSTRAP_SERVERS
              value: drogue-iot-kafka-bootstrap.default.svc.cluster.local.:9092
            
            
            - name: DOWNSTREAM_KAFKA_SINK__PROPERTIES__SECURITY_PROTOCOL
              value: sasl_plaintext
            - name: DOWNSTREAM_KAFKA_SINK__PROPERTIES__SASL_MECHANISMS
              value: SCRAM-SHA-512
            - name: DOWNSTREAM_KAFKA_SINK__PROPERTIES__SASL_USERNAME
              value: drogue-iot
            - name: DOWNSTREAM_KAFKA_SINK__PROPERTIES__SASL_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: drogue-iot
                  key: password

            
            - name: DISABLE_TLS
              value: "true"
            

          ports:
            - containerPort: 8080
              name: endpoint
              protocol: TCP

          readinessProbe:
            initialDelaySeconds: 2
            periodSeconds: 1
            timeoutSeconds: 1
            failureThreshold: 3
            httpGet:
              port: 9090
              path: /readiness
          livenessProbe:
            initialDelaySeconds: 2
            periodSeconds: 1
            timeoutSeconds: 1
            failureThreshold: 3
            httpGet:
              port: 9090
              path: /liveness

          

      volumes:

        

        - name: client-secret-services
          secret:
            secretName: keycloak-client-secret-services
---
# Source: telemetry-e2e/charts/drogueCloud/templates/source/mqtt/deployment.yaml
kind: Deployment
apiVersion: apps/v1
metadata:
  name: mqtt-endpoint
  labels:
    app.kubernetes.io/name: mqtt-endpoint
    app.kubernetes.io/component: endpoints
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.7.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: drogue-iot
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: mqtt-endpoint
      app.kubernetes.io/component: endpoints
      app.kubernetes.io/instance: release-name
  template:
    metadata:
      labels:
        app.kubernetes.io/name: mqtt-endpoint
        app.kubernetes.io/component: endpoints
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/version: "0.7.0"
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/part-of: drogue-iot
    spec:
      initContainers:
        - name: wait-for-client-secret
          image: registry.access.redhat.com/ubi8-minimal:latest
          imagePullPolicy: IfNotPresent
          command:
            - bash
            - -c
            - |
              echo "Waiting for client secret to be populated (/etc/client-secret/CLIENT_SECRET)..."
              while test -z "$(cat /etc/client-secret/CLIENT_SECRET)"; do
                sleep 1
              done
          volumeMounts:
            - mountPath: /etc/client-secret
              name: client-secret-services
              readOnly: true
      containers:
        - name: endpoint
          image: "ghcr.io/drogue-iot/mqtt-endpoint:0.7.0"
          imagePullPolicy: IfNotPresent
          env:
            - name: RUST_LOG
              value: debug
            - name: RUST_BACKTRACE
              value: "1"
            - name: BIND_ADDR_MQTT
              value: "0.0.0.0:1883"
            - name: BIND_ADDR_HTTP
              value: "0.0.0.0:8080"
            - name: HEALTH__BIND_ADDR
              value: "0.0.0.0:9090"
            - name: INSTANCE
              valueFrom:
                configMapKeyRef:
                  name: configuration
                  key: instance
            - name: CLIENT_ID
              valueFrom:
                secretKeyRef:
                  name: keycloak-client-secret-services
                  key: CLIENT_ID
            - name: CLIENT_SECRET
              valueFrom:
                secretKeyRef:
                  name: keycloak-client-secret-services
                  key: CLIENT_SECRET
            - name: SSO_URL
              value: http://sso.change.me
            - name: COMMAND_SOURCE_KAFKA__TOPIC
              value: iot-commands
            - name: COMMAND_SOURCE_KAFKA__CONSUMER_GROUP
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: COMMAND_SOURCE_KAFKA__BOOTSTRAP_SERVERS
              value: drogue-iot-kafka-bootstrap.default.svc.cluster.local.:9092
            
            
            - name: COMMAND_SOURCE_KAFKA__PROPERTIES__SECURITY_PROTOCOL
              value: sasl_plaintext
            - name: COMMAND_SOURCE_KAFKA__PROPERTIES__SASL_MECHANISMS
              value: SCRAM-SHA-512
            - name: COMMAND_SOURCE_KAFKA__PROPERTIES__SASL_USERNAME
              value: drogue-iot
            - name: COMMAND_SOURCE_KAFKA__PROPERTIES__SASL_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: drogue-iot
                  key: password
            - name: DOWNSTREAM_KAFKA_SINK__BOOTSTRAP_SERVERS
              value: drogue-iot-kafka-bootstrap.default.svc.cluster.local.:9092
            
            
            - name: DOWNSTREAM_KAFKA_SINK__PROPERTIES__SECURITY_PROTOCOL
              value: sasl_plaintext
            - name: DOWNSTREAM_KAFKA_SINK__PROPERTIES__SASL_MECHANISMS
              value: SCRAM-SHA-512
            - name: DOWNSTREAM_KAFKA_SINK__PROPERTIES__SASL_USERNAME
              value: drogue-iot
            - name: DOWNSTREAM_KAFKA_SINK__PROPERTIES__SASL_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: drogue-iot
                  key: password

            
            - name: DISABLE_TLS
              value: "true"
            

          ports:
            - containerPort: 1883
              name: endpoint
              protocol: TCP

          readinessProbe:
            initialDelaySeconds: 2
            periodSeconds: 1
            timeoutSeconds: 1
            failureThreshold: 3
            httpGet:
              port: 9090
              path: /readiness
          livenessProbe:
            initialDelaySeconds: 2
            periodSeconds: 1
            timeoutSeconds: 1
            failureThreshold: 3
            httpGet:
              port: 9090
              path: /liveness
          resources:
            limits:
              memory: 64Mi

      volumes:

        - name: client-secret-services
          secret:
            secretName: keycloak-client-secret-services
---
# Source: telemetry-e2e/charts/streamsheets/templates/gateway/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: streamsheets-gateway
  labels:
    
    helm.sh/chart: streamsheets-0.2.3
    app.kubernetes.io/name: streamsheets-gateway
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "2.4.0"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  strategy:
    type: Recreate
  selector:
    matchLabels:
      
      app.kubernetes.io/name: streamsheets-gateway
      app.kubernetes.io/instance: release-name
  template:
    metadata:
      labels:
        
        helm.sh/chart: streamsheets-0.2.3
        app.kubernetes.io/name: streamsheets-gateway
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/version: "2.4.0"
        app.kubernetes.io/managed-by: Helm
    spec:
      initContainers:
        - name: wait-for-database
          image: ghcr.io/ctron/streamsheets-base:latest
          imagePullPolicy: Always
          command:
            - bash
            - -ec
            - |
              until nc -z $MONGO_HOST $MONGO_PORT
              do
                echo "Waiting for MongoDB ($MONGO_HOST:$MONGO_PORT) to start..."
                sleep 1
              done
          env:
            - name: MONGO_HOST
              value: streamsheets-mongodb
            - name: MONGO_PORT
              value: "27017"
      containers:
        - name: gateway
          image: ghcr.io/ctron/streamsheets-gateway:latest
          imagePullPolicy: Always
          env:
            - name: NODE_ENV
              value: production
            - name: GATEWAY_SERVICE_LOG_LEVEL
              value: info
            - name: STREAMSHEETS_LOG_LEVEL
              value: info
            - name: MONGO_DATABASE
              value: streamsheets
            - name: MONGO_HOST
              value: streamsheets-mongodb
            - name: MONGO_PORT
              value: "27017"
            - name: MONGO_USERNAME
              value: streamsheets
            - name: MONGO_PASSWORD
              value: streamsheets123456
            - name: REDIS_HOST
              value: streamsheets-redis-master
            - name: REDIS_PORT
              value: "6379"
            - name: STREAMSHEETS_GATEWAY_CONFIGURATION_PATH
              value: /etc/streamsheets/config/gateway.json
            - name: MESSAGE_BROKER_URL
              value: mqtt://streamsheets-broker:1883
            - name: MESSAGE_BROKER_KEEP_ALIVE
              value: "20"
            - name: MESSAGE_BROKER_USERNAME
              valueFrom:
                secretKeyRef:
                  name: streamsheets-broker
                  key: USERNAME
            - name: MESSAGE_BROKER_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: streamsheets-broker
                  key: PASSWORD
            - name: DEPLOY_EXAMPLES_FROM
              value: /etc/streamsheets/init

          ports:
            - name: gateway
              containerPort: 8080
              protocol: TCP

          readinessProbe:
            httpGet:
              port: 8080

          livenessProbe:
            httpGet:
              port: 8080

          volumeMounts:
            - mountPath: /.logs
              name: logs
            - mountPath: /streamsheets/backups
              name: backup
            - mountPath: /streamsheets/plugins
              name: plugins
            - mountPath: /etc/streamsheets/config
              name: config
            - mountPath: /etc/streamsheets/init
              name: init

      volumes:
        - name: logs
          emptyDir: {}
        - name: backup
          emptyDir: {}
        - name: plugins
          emptyDir: {}
        - name: config
          configMap:
            name: streamsheets-gateway
        - name: init
          secret:
            secretName: streamsheets-init
---
# Source: telemetry-e2e/charts/streamsheets/templates/service-graphs/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: streamsheets-service-graphs
  labels:
    
    helm.sh/chart: streamsheets-0.2.3
    app.kubernetes.io/name: streamsheets-service-graphs
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "2.4.0"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  strategy:
    type: Recreate
  selector:
    matchLabels:
      
      app.kubernetes.io/name: streamsheets-service-graphs
      app.kubernetes.io/instance: release-name
  template:
    metadata:
      labels:
        
        helm.sh/chart: streamsheets-0.2.3
        app.kubernetes.io/name: streamsheets-service-graphs
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/version: "2.4.0"
        app.kubernetes.io/managed-by: Helm
    spec:
      initContainers:
        - name: wait-for-database
          image: ghcr.io/ctron/streamsheets-base:latest
          imagePullPolicy: Always
          command:
            - bash
            - -ec
            - |
              until nc -z $MONGO_HOST $MONGO_PORT
              do
                echo "Waiting for MongoDB ($MONGO_HOST:$MONGO_PORT) to start..."
                sleep 1
              done
          env:
            - name: MONGO_HOST
              value: streamsheets-mongodb
            - name: MONGO_PORT
              value: "27017"
      containers:
        - name: service
          image: ghcr.io/ctron/streamsheets-service-graphs:latest
          imagePullPolicy: Always
          env:
            - name: NODE_ENV
              value: production
            - name: GRAPH_SERVICE_LOG_LEVEL
              value: info
            - name: STREAMSHEETS_LOG_LEVEL
              value: info
            - name: MONGO_DATABASE
              value: streamsheets
            - name: MONGO_HOST
              value: streamsheets-mongodb
            - name: MONGO_PORT
              value: "27017"
            - name: MONGO_USERNAME
              value: streamsheets
            - name: MONGO_PASSWORD
              value: streamsheets123456
            - name: REDIS_HOST
              value: streamsheets-redis-master
            - name: REDIS_PORT
              value: "6379"
            - name: MESSAGE_BROKER_URL
              value: mqtt://streamsheets-broker:1883
            - name: MESSAGE_BROKER_KEEP_ALIVE
              value: "20"
            - name: MESSAGE_BROKER_USERNAME
              valueFrom:
                secretKeyRef:
                  name: streamsheets-broker
                  key: USERNAME
            - name: MESSAGE_BROKER_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: streamsheets-broker
                  key: PASSWORD
---
# Source: telemetry-e2e/charts/streamsheets/templates/service-machines/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: streamsheets-service-machines
  labels:
    
    helm.sh/chart: streamsheets-0.2.3
    app.kubernetes.io/name: streamsheets-service-machines
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "2.4.0"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  strategy:
    type: Recreate
  selector:
    matchLabels:
      
      app.kubernetes.io/name: streamsheets-service-machines
      app.kubernetes.io/instance: release-name
  template:
    metadata:
      labels:
        
        helm.sh/chart: streamsheets-0.2.3
        app.kubernetes.io/name: streamsheets-service-machines
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/version: "2.4.0"
        app.kubernetes.io/managed-by: Helm
    spec:
      initContainers:
        - name: wait-for-database
          image: ghcr.io/ctron/streamsheets-base:latest
          imagePullPolicy: Always
          command:
            - bash
            - -ec
            - |
              until nc -z $MONGO_HOST $MONGO_PORT
              do
                echo "Waiting for MongoDB ($MONGO_HOST:$MONGO_PORT) to start..."
                sleep 1
              done
          env:
            - name: MONGO_HOST
              value: streamsheets-mongodb
            - name: MONGO_PORT
              value: "27017"
      containers:
        - name: service
          image: ghcr.io/ctron/streamsheets-service-machines:latest
          imagePullPolicy: Always
          env:
            - name: NODE_ENV
              value: production
            - name: MACHINE_SERVICE_LOG_LEVEL
              value: info
            - name: STREAMSHEETS_LOG_LEVEL
              value: info
            - name: MONGO_DATABASE
              value: streamsheets
            - name: MONGO_HOST
              value: streamsheets-mongodb
            - name: MONGO_PORT
              value: "27017"
            - name: MONGO_USERNAME
              value: streamsheets
            - name: MONGO_PASSWORD
              value: streamsheets123456
            - name: REDIS_HOST
              value: streamsheets-redis-master
            - name: REDIS_PORT
              value: "6379"
            - name: MESSAGE_BROKER_URL
              value: mqtt://streamsheets-broker:1883
            - name: MESSAGE_BROKER_KEEP_ALIVE
              value: "20"
            - name: MESSAGE_BROKER_USERNAME
              valueFrom:
                secretKeyRef:
                  name: streamsheets-broker
                  key: USERNAME
            - name: MESSAGE_BROKER_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: streamsheets-broker
                  key: PASSWORD
---
# Source: telemetry-e2e/charts/streamsheets/templates/service-streams/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: streamsheets-service-streams
  labels:
    
    helm.sh/chart: streamsheets-0.2.3
    app.kubernetes.io/name: streamsheets-service-streams
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "2.4.0"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  strategy:
    type: Recreate
  selector:
    matchLabels:
      
      app.kubernetes.io/name: streamsheets-service-streams
      app.kubernetes.io/instance: release-name
  template:
    metadata:
      labels:
        
        helm.sh/chart: streamsheets-0.2.3
        app.kubernetes.io/name: streamsheets-service-streams
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/version: "2.4.0"
        app.kubernetes.io/managed-by: Helm
    spec:
      initContainers:
        - name: wait-for-database
          image: ghcr.io/ctron/streamsheets-base:latest
          imagePullPolicy: Always
          command:
            - bash
            - -ec
            - |
              until nc -z $MONGO_HOST $MONGO_PORT
              do
                echo "Waiting for MongoDB ($MONGO_HOST:$MONGO_PORT) to start..."
                sleep 1
              done
          env:
            - name: MONGO_HOST
              value: streamsheets-mongodb
            - name: MONGO_PORT
              value: "27017"
      containers:
        - name: service
          image: ghcr.io/ctron/streamsheets-service-streams:latest
          imagePullPolicy: Always
          env:
            - name: NODE_ENV
              value: production
            - name: STREAMSHEETS_STREAMS_SERVICE_LOG_LEVEL
              value: info
            - name: STREAMSHEETS_LOG_LEVEL
              value: info
            - name: MONGO_DATABASE
              value: streamsheets
            - name: MONGO_HOST
              value: streamsheets-mongodb
            - name: MONGO_PORT
              value: "27017"
            - name: MONGO_USERNAME
              value: streamsheets
            - name: MONGO_PASSWORD
              value: streamsheets123456
            - name: REDIS_HOST
              value: streamsheets-redis-master
            - name: REDIS_PORT
              value: "6379"
            - name: MESSAGE_BROKER_URL
              value: mqtt://streamsheets-broker:1883
            - name: MESSAGE_BROKER_KEEP_ALIVE
              value: "20"
            - name: MESSAGE_BROKER_USERNAME
              valueFrom:
                secretKeyRef:
                  name: streamsheets-broker
                  key: USERNAME
            - name: MESSAGE_BROKER_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: streamsheets-broker
                  key: PASSWORD

          volumeMounts:
            - mountPath: /.logs
              name: logs
      volumes:
        - name: logs
          emptyDir: {}
---
# Source: telemetry-e2e/charts/strimzi/templates/060-Deployment-strimzi-cluster-operator.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: strimzi-cluster-operator
  labels:
    app: strimzi
    chart: strimzi-0.25.0
    component: deployment
    release: release-name
    heritage: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      name: strimzi-cluster-operator
      strimzi.io/kind: cluster-operator
  template:
    metadata:
      labels:
        name: strimzi-cluster-operator
        strimzi.io/kind: cluster-operator
    spec:
      serviceAccountName: strimzi-cluster-operator
      volumes:
        - name: strimzi-tmp
          emptyDir:
            medium: Memory
            sizeLimit: 1Mi
        - name: co-config-volume
          configMap:
            name: strimzi-cluster-operator
      containers:
        - name: strimzi-cluster-operator
          image: quay.io/strimzi/operator:0.25.0
          ports:
            - containerPort: 8080
              name: http
          args:
            - /opt/strimzi/bin/cluster_operator_run.sh
          volumeMounts:
            - name: strimzi-tmp
              mountPath: /tmp
            - name: co-config-volume
              mountPath: /opt/strimzi/custom-config/
          env:
            - name: STRIMZI_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: STRIMZI_FULL_RECONCILIATION_INTERVAL_MS
              value: "120000"
            - name: STRIMZI_OPERATION_TIMEOUT_MS
              value: "300000"
            - name: STRIMZI_DEFAULT_TLS_SIDECAR_ENTITY_OPERATOR_IMAGE
              value: quay.io/strimzi/kafka:0.25.0-kafka-2.8.0
            - name: STRIMZI_DEFAULT_KAFKA_EXPORTER_IMAGE
              value: quay.io/strimzi/kafka:0.25.0-kafka-2.8.0
            - name: STRIMZI_DEFAULT_CRUISE_CONTROL_IMAGE
              value: quay.io/strimzi/kafka:0.25.0-kafka-2.8.0
            - name: STRIMZI_DEFAULT_TLS_SIDECAR_CRUISE_CONTROL_IMAGE
              value: quay.io/strimzi/kafka:0.25.0-kafka-2.8.0
            - name: STRIMZI_KAFKA_IMAGES
              value: |                 
                2.7.0=quay.io/strimzi/kafka:0.25.0-kafka-2.7.0
                2.7.1=quay.io/strimzi/kafka:0.25.0-kafka-2.7.1
                2.8.0=quay.io/strimzi/kafka:0.25.0-kafka-2.8.0
            - name: STRIMZI_KAFKA_CONNECT_IMAGES
              value: |                 
                2.7.0=quay.io/strimzi/kafka:0.25.0-kafka-2.7.0
                2.7.1=quay.io/strimzi/kafka:0.25.0-kafka-2.7.1
                2.8.0=quay.io/strimzi/kafka:0.25.0-kafka-2.8.0
            - name: STRIMZI_KAFKA_MIRROR_MAKER_IMAGES
              value: |                 
                2.7.0=quay.io/strimzi/kafka:0.25.0-kafka-2.7.0
                2.7.1=quay.io/strimzi/kafka:0.25.0-kafka-2.7.1
                2.8.0=quay.io/strimzi/kafka:0.25.0-kafka-2.8.0
            - name: STRIMZI_KAFKA_MIRROR_MAKER_2_IMAGES
              value: |                 
                2.7.0=quay.io/strimzi/kafka:0.25.0-kafka-2.7.0
                2.7.1=quay.io/strimzi/kafka:0.25.0-kafka-2.7.1
                2.8.0=quay.io/strimzi/kafka:0.25.0-kafka-2.8.0
            - name: STRIMZI_DEFAULT_TOPIC_OPERATOR_IMAGE
              value: quay.io/strimzi/operator:0.25.0
            - name: STRIMZI_DEFAULT_USER_OPERATOR_IMAGE
              value: quay.io/strimzi/operator:0.25.0
            - name: STRIMZI_DEFAULT_KAFKA_INIT_IMAGE
              value: quay.io/strimzi/operator:0.25.0
            - name: STRIMZI_DEFAULT_KAFKA_BRIDGE_IMAGE
              value: quay.io/strimzi/kafka-bridge:0.20.2
            - name: STRIMZI_DEFAULT_JMXTRANS_IMAGE
              value: quay.io/strimzi/jmxtrans:0.25.0
            - name: STRIMZI_DEFAULT_KANIKO_EXECUTOR_IMAGE
              value: quay.io/strimzi/kaniko-executor:0.25.0
            - name: STRIMZI_OPERATOR_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            
            - name: STRIMZI_FEATURE_GATES
              value: ""
          livenessProbe:
            httpGet:
              path: /healthy
              port: http
            initialDelaySeconds: 10
            periodSeconds: 30
          readinessProbe:
            httpGet:
              path: /ready
              port: http
            initialDelaySeconds: 10
            periodSeconds: 30
          resources:
            limits:
              cpu: 200m
              memory: 384Mi
            requests:
              cpu: 100m
              memory: 256Mi
  strategy:
    type: Recreate
---
# Source: telemetry-e2e/templates/keycloak/operator.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: keycloak-operator
  labels:
    app.kubernetes.io/name: keycloak-operator
    app.kubernetes.io/component: operator
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.1.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: sso

spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: keycloak-operator
      app.kubernetes.io/component: operator
      app.kubernetes.io/instance: release-name
  template:
    metadata:
      labels:
        app.kubernetes.io/name: keycloak-operator
        app.kubernetes.io/component: operator
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/version: "0.1.0"
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/part-of: sso
    spec:
      serviceAccountName: keycloak-operator
      containers:
        - name: keycloak-operator
          image: "quay.io/keycloak/keycloak-operator:15.0.1"
          imagePullPolicy: IfNotPresent
          command: [ "keycloak-operator" ]
          env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: OPERATOR_NAME
              value: "keycloak-operator"
            - name: WATCH_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
---
# Source: telemetry-e2e/charts/streamsheets/charts/mongodb/templates/standalone/dep-sts.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: streamsheets-mongodb
  namespace: default
  labels:
    app.kubernetes.io/name: mongodb
    helm.sh/chart: mongodb-10.25.2
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: mongodb
spec:
  replicas: 1
  serviceName: streamsheets-mongodb
  updateStrategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/name: mongodb
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/component: mongodb
  template:
    metadata:
      labels:
        app.kubernetes.io/name: mongodb
        helm.sh/chart: mongodb-10.25.2
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/component: mongodb
    spec:
      
      serviceAccountName: streamsheets-mongodb
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: mongodb
                    app.kubernetes.io/instance: release-name
                    app.kubernetes.io/component: mongodb
                namespaces:
                  - "default"
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      securityContext:
        fsGroup: 1001
        sysctls: []
      containers:
        - name: mongodb
          image: gcr.io/bitnami-containers/mongodb:4.4.8-debian-10-r31
          imagePullPolicy: "IfNotPresent"
          securityContext:
            runAsNonRoot: true
            runAsUser: 1001
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: MONGODB_USERNAME
              value: "streamsheets"
            - name: MONGODB_DATABASE
              value: "streamsheets"
            - name: MONGODB_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: streamsheets-mongodb
                  key: mongodb-password
            - name: MONGODB_ROOT_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: streamsheets-mongodb
                  key: mongodb-root-password
            - name: ALLOW_EMPTY_PASSWORD
              value: "no"
            - name: MONGODB_SYSTEM_LOG_VERBOSITY
              value: "0"
            - name: MONGODB_DISABLE_SYSTEM_LOG
              value: "no"
            - name: MONGODB_DISABLE_JAVASCRIPT
              value: "no"
            - name: MONGODB_ENABLE_JOURNAL
              value: "yes"
            - name: MONGODB_ENABLE_IPV6
              value: "no"
            - name: MONGODB_ENABLE_DIRECTORY_PER_DB
              value: "no"
          ports:
            - name: mongodb
              containerPort: 27017
          livenessProbe:
            exec:
              command:
                - mongo
                - --disableImplicitSessions
                - --eval
                - "db.adminCommand('ping')"
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 6
          readinessProbe:
            exec:
              command:
                - bash
                - -ec
                - |
                  # Run the proper check depending on the version
                  [[ $(mongo --version | grep "MongoDB shell") =~ ([0-9]+\.[0-9]+\.[0-9]+) ]] && VERSION=${BASH_REMATCH[1]}
                  . /opt/bitnami/scripts/libversion.sh
                  VERSION_MAJOR="$(get_sematic_version "$VERSION" 1)"
                  VERSION_MINOR="$(get_sematic_version "$VERSION" 2)"
                  VERSION_PATCH="$(get_sematic_version "$VERSION" 3)"
                  if [[ "$VERSION_MAJOR" -ge 4 ]] && [[ "$VERSION_MINOR" -ge 4 ]] && [[ "$VERSION_PATCH" -ge 2 ]]; then
                      mongo --disableImplicitSessions $TLS_OPTIONS --eval 'db.hello().isWritablePrimary || db.hello().secondary' | grep -q 'true'
                  else
                      mongo --disableImplicitSessions $TLS_OPTIONS --eval 'db.isMaster().ismaster || db.isMaster().secondary' | grep -q 'true'
                  fi
            initialDelaySeconds: 5
            periodSeconds: 10
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 6
          resources:
            limits: {}
            requests: {}
          volumeMounts:
            - name: datadir
              mountPath: /bitnami/mongodb
              subPath: 
      volumes:
  volumeClaimTemplates:
    - metadata:
        name: datadir
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: "8Gi"
---
# Source: telemetry-e2e/charts/streamsheets/charts/redis/templates/master/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: streamsheets-redis-master
  namespace: "default"
  labels:
    app.kubernetes.io/name: redis
    helm.sh/chart: redis-14.8.11
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: master
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: redis
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/component: master
  serviceName: streamsheets-redis-headless
  updateStrategy:
    rollingUpdate: {}
    type: RollingUpdate
  template:
    metadata:
      labels:
        app.kubernetes.io/name: redis
        helm.sh/chart: redis-14.8.11
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/component: master
      annotations:
        checksum/configmap: fb1d112d17d7acc0802bccb96facce256fdcbd27beb5871925bb145ceee9e32b
        checksum/health: 0fa075da6deefcc68d8025e18c92b4393316c96807e9eab9885dc9c80a9f04ac
        checksum/scripts: fc931881b52ea86f8f0205430934d377fcf6222987697abd69caf7473cef4fc8
        checksum/secret: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855
    spec:
      
      securityContext:
        fsGroup: 1001
      serviceAccountName: streamsheets-redis
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: redis
                    app.kubernetes.io/instance: release-name
                    app.kubernetes.io/component: master
                namespaces:
                  - "default"
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      terminationGracePeriodSeconds: 30
      containers:
        - name: redis
          image: gcr.io/bitnami-containers/redis:6.2.5-debian-10-r11
          imagePullPolicy: "IfNotPresent"
          securityContext:
            runAsUser: 1001
          command:
            - /bin/bash
          args:
            - -c
            - /opt/bitnami/scripts/start-scripts/start-master.sh
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: REDIS_REPLICATION_MODE
              value: master
            - name: ALLOW_EMPTY_PASSWORD
              value: "yes"
            - name: REDIS_TLS_ENABLED
              value: "no"
            - name: REDIS_PORT
              value: "6379"
          ports:
            - name: redis
              containerPort: 6379
          livenessProbe:
            initialDelaySeconds: 20
            periodSeconds: 5
            # One second longer than command timeout should prevent generation of zombie processes.
            timeoutSeconds: 6
            successThreshold: 1
            failureThreshold: 5
            exec:
              command:
                - sh
                - -c
                - /health/ping_liveness_local.sh 5
          readinessProbe:
            initialDelaySeconds: 20
            periodSeconds: 5
            timeoutSeconds: 2
            successThreshold: 1
            failureThreshold: 5
            exec:
              command:
                - sh
                - -c
                - /health/ping_readiness_local.sh 1
          resources:
            limits: {}
            requests: {}
          volumeMounts:
            - name: start-scripts
              mountPath: /opt/bitnami/scripts/start-scripts
            - name: health
              mountPath: /health
            - name: redis-data
              mountPath: /data
              subPath: 
            - name: config
              mountPath: /opt/bitnami/redis/mounted-etc
            - name: redis-tmp-conf
              mountPath: /opt/bitnami/redis/etc/
            - name: tmp
              mountPath: /tmp
      volumes:
        - name: start-scripts
          configMap:
            name: streamsheets-redis-scripts
            defaultMode: 0755
        - name: health
          configMap:
            name: streamsheets-redis-health
            defaultMode: 0755
        - name: config
          configMap:
            name: streamsheets-redis-configuration
        - name: redis-tmp-conf
          emptyDir: {}
        - name: tmp
          emptyDir: {}
  volumeClaimTemplates:
    - metadata:
        name: redis-data
        labels:
          app.kubernetes.io/name: redis
          app.kubernetes.io/instance: release-name
          app.kubernetes.io/component: master
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: "8Gi"
---
# Source: telemetry-e2e/charts/streamsheets/templates/broker/statefulset.yaml
# FIXME: should be a stateful set

apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: streamsheets-broker
  labels:
    
    helm.sh/chart: streamsheets-0.2.3
    app.kubernetes.io/name: streamsheets-broker
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "2.4.0"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  serviceName: streamsheets-broker
  selector:
    matchLabels:
      
      app.kubernetes.io/name: streamsheets-broker
      app.kubernetes.io/instance: release-name
  template:
    metadata:
      labels:
        
        helm.sh/chart: streamsheets-0.2.3
        app.kubernetes.io/name: streamsheets-broker
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/version: "2.4.0"
        app.kubernetes.io/managed-by: Helm
    spec:
      initContainers:
        - name: create-pw-file
          image: docker.io/eclipse-mosquitto:2
          imagePullPolicy: IfNotPresent
          env:
            - name: USERNAME
              valueFrom:
                secretKeyRef:
                  name: streamsheets-broker
                  key: USERNAME
            - name: PASSWORD
              valueFrom:
                secretKeyRef:
                  name: streamsheets-broker
                  key: PASSWORD
          command:
            - mosquitto_passwd
            - -c
            - -b
            - /mosquitto/secrets/pw.txt
            - $(USERNAME)
            - $(PASSWORD)
          volumeMounts:
            - mountPath: /mosquitto/secrets
              name: secrets

      containers:
        - name: gateway
          image: docker.io/eclipse-mosquitto:2
          imagePullPolicy: IfNotPresent
          ports:
            - name: mqtt
              containerPort: 1883
              protocol: TCP
          volumeMounts:
            - mountPath: /mosquitto/config
              name: config
            - mountPath: /mosquitto/secrets
              name: secrets
      volumes:
        - name: config
          configMap:
            name: streamsheets-broker
        - name: secrets
          emptyDir: {}
---
# Source: telemetry-e2e/charts/drogueCloud/templates/api/ingress.yaml
kind: Ingress
apiVersion: networking.k8s.io/v1
metadata:
  name: api
  annotations:
    
  labels:
    app.kubernetes.io/name: api
    app.kubernetes.io/component: api
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.7.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: drogue-iot
spec:
  
  ingressClassName: nginx
  rules:
    - host: api.change.me
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: console-backend
                port:
                  name: endpoint
          - path: /api
            pathType: Prefix
            backend:
              service:
                name: console-backend
                port:
                  name: endpoint
          - path: /.well-known/
            pathType: Prefix
            backend:
              service:
                name: console-backend
                port:
                  name: endpoint
          - path: /api/console/
            pathType: Prefix
            backend:
              service:
                name: console-backend
                port:
                  name: endpoint
          - path: /api/keys/
            pathType: Prefix
            backend:
              service:
                name: console-backend
                port:
                  name: endpoint
          - path: /api/admin/v1alpha1/user
            pathType: Prefix
            backend:
              service:
                name: console-backend
                port:
                  name: endpoint
          - path: /api/admin/v1alpha1/apps
            pathType: Prefix
            backend:
              service:
                name: device-management-service
                port:
                  name: api
          - path: /api/registry/
            pathType: Prefix
            backend:
              service:
                name: device-management-service
                port:
                  name: api
          - path: /api/command/
            pathType: Prefix
            backend:
              service:
                name: command-endpoint
                port:
                  name: endpoint
---
# Source: telemetry-e2e/charts/drogueCloud/templates/service/console/ingress.yaml
kind: Ingress
apiVersion: networking.k8s.io/v1
metadata:
  name: console
  annotations:
    
  labels:
    app.kubernetes.io/name: console
    app.kubernetes.io/component: console
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.7.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: drogue-iot
spec:
  
  ingressClassName: nginx
  rules:
    - host: console.change.me
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: console
                port:
                  name: endpoint
---
# Source: telemetry-e2e/charts/drogueCloud/templates/sso/ingress.yaml
kind: Ingress
apiVersion: networking.k8s.io/v1
metadata:
  name: keycloak
  annotations:
    nginx.ingress.kubernetes.io/backend-protocol: HTTPS
    nginx.ingress.kubernetes.io/server-snippet: |2-
                        location ~* "^/auth/realms/master/metrics" {
                            return 301 /auth/realms/master;
                        }
  labels:
    app.kubernetes.io/name: sso
    app.kubernetes.io/component: sso
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.7.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: drogue-iot
spec:
  
  ingressClassName: nginx
  rules:
    - host: sso.change.me
      http:
        paths:
          - path: /
            pathType: ImplementationSpecific
            backend:
              service:
                name: keycloak
                port:
                  number: 8443
---
# Source: telemetry-e2e/charts/streamsheets/templates/ingress/ingress.yaml
kind: Ingress
apiVersion: networking.k8s.io/v1
metadata:
  name: streamsheets
  labels:
    helm.sh/chart: streamsheets-0.2.3
    app.kubernetes.io/name: streamsheets
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "2.4.0"
    app.kubernetes.io/managed-by: Helm
  annotations:
    kubernetes.io/ingress.class: nginx
spec:
  rules:
    - host: streamsheets-default.change.me
      http:
        paths:
          - path: /request
            pathType: Prefix
            backend:
              service:
                 name: streamsheets-service-stream
                 port:
                   name: webui
          - path: /
            pathType: Prefix
            backend:
              service:
                  name: streamsheets-gateway
                  port:
                    name: gateway
---
# Source: telemetry-e2e/templates/ditto/ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: ditto-ingress
  labels:
    app.kubernetes.io/name: ditto-ingress
spec:
  rules:
    - host: "ditto-default.change.me"
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: ditto-nginx
                port:
                  name: http
---
# Source: telemetry-e2e/charts/ditto/templates/concierge-deployment.yaml
# Copyright (c) 2019 Contributors to the Eclipse Foundation
#
# See the NOTICE file(s) distributed with this work for additional
# information regarding copyright ownership.
#
# This program and the accompanying materials are made available under the
# terms of the Eclipse Public License 2.0 which is available at
# http://www.eclipse.org/legal/epl-2.0
#
# SPDX-License-Identifier: EPL-2.0
---
# Source: telemetry-e2e/charts/ditto/templates/concierge-networkpolicy.yaml
# Copyright (c) 2019 Contributors to the Eclipse Foundation
#
# See the NOTICE file(s) distributed with this work for additional
# information regarding copyright ownership.
#
# This program and the accompanying materials are made available under the
# terms of the Eclipse Public License 2.0 which is available at
# http://www.eclipse.org/legal/epl-2.0
#
# SPDX-License-Identifier: EPL-2.0
---
# Source: telemetry-e2e/charts/ditto/templates/concierge-pdb.yaml
# Copyright (c) 2019 Contributors to the Eclipse Foundation
#
# See the NOTICE file(s) distributed with this work for additional
# information regarding copyright ownership.
#
# This program and the accompanying materials are made available under the
# terms of the Eclipse Public License 2.0 which is available at
# http://www.eclipse.org/legal/epl-2.0
#
# SPDX-License-Identifier: EPL-2.0
---
# Source: telemetry-e2e/charts/ditto/templates/connectivity-deployment.yaml
# Copyright (c) 2019 Contributors to the Eclipse Foundation
#
# See the NOTICE file(s) distributed with this work for additional
# information regarding copyright ownership.
#
# This program and the accompanying materials are made available under the
# terms of the Eclipse Public License 2.0 which is available at
# http://www.eclipse.org/legal/epl-2.0
#
# SPDX-License-Identifier: EPL-2.0
---
# Source: telemetry-e2e/charts/ditto/templates/connectivity-networkpolicy.yaml
# Copyright (c) 2019 Contributors to the Eclipse Foundation
#
# See the NOTICE file(s) distributed with this work for additional
# information regarding copyright ownership.
#
# This program and the accompanying materials are made available under the
# terms of the Eclipse Public License 2.0 which is available at
# http://www.eclipse.org/legal/epl-2.0
#
# SPDX-License-Identifier: EPL-2.0
---
# Source: telemetry-e2e/charts/ditto/templates/connectivity-pdb.yaml
# Copyright (c) 2019 Contributors to the Eclipse Foundation
#
# See the NOTICE file(s) distributed with this work for additional
# information regarding copyright ownership.
#
# This program and the accompanying materials are made available under the
# terms of the Eclipse Public License 2.0 which is available at
# http://www.eclipse.org/legal/epl-2.0
#
# SPDX-License-Identifier: EPL-2.0
---
# Source: telemetry-e2e/charts/ditto/templates/gateway-deployment.yaml
# Copyright (c) 2019 Contributors to the Eclipse Foundation
#
# See the NOTICE file(s) distributed with this work for additional
# information regarding copyright ownership.
#
# This program and the accompanying materials are made available under the
# terms of the Eclipse Public License 2.0 which is available at
# http://www.eclipse.org/legal/epl-2.0
#
# SPDX-License-Identifier: EPL-2.0
---
# Source: telemetry-e2e/charts/ditto/templates/gateway-networkpolicy.yaml
# Copyright (c) 2019 Contributors to the Eclipse Foundation
#
# See the NOTICE file(s) distributed with this work for additional
# information regarding copyright ownership.
#
# This program and the accompanying materials are made available under the
# terms of the Eclipse Public License 2.0 which is available at
# http://www.eclipse.org/legal/epl-2.0
#
# SPDX-License-Identifier: EPL-2.0
---
# Source: telemetry-e2e/charts/ditto/templates/gateway-pdb.yaml
# Copyright (c) 2019 Contributors to the Eclipse Foundation
#
# See the NOTICE file(s) distributed with this work for additional
# information regarding copyright ownership.
#
# This program and the accompanying materials are made available under the
# terms of the Eclipse Public License 2.0 which is available at
# http://www.eclipse.org/legal/epl-2.0
#
# SPDX-License-Identifier: EPL-2.0
---
# Source: telemetry-e2e/charts/ditto/templates/gateway-secret.yaml
# Copyright (c) 2019 Contributors to the Eclipse Foundation
#
# See the NOTICE file(s) distributed with this work for additional
# information regarding copyright ownership.
#
# This program and the accompanying materials are made available under the
# terms of the Eclipse Public License 2.0 which is available at
# http://www.eclipse.org/legal/epl-2.0
#
# SPDX-License-Identifier: EPL-2.0
---
# Source: telemetry-e2e/charts/ditto/templates/gateway-service.yaml
# Copyright (c) 2019 Contributors to the Eclipse Foundation
#
# See the NOTICE file(s) distributed with this work for additional
# information regarding copyright ownership.
#
# This program and the accompanying materials are made available under the
# terms of the Eclipse Public License 2.0 which is available at
# http://www.eclipse.org/legal/epl-2.0
#
# SPDX-License-Identifier: EPL-2.0
---
# Source: telemetry-e2e/charts/ditto/templates/mongodb-secret.yaml
# Copyright (c) 2019 Contributors to the Eclipse Foundation
#
# See the NOTICE file(s) distributed with this work for additional
# information regarding copyright ownership.
#
# This program and the accompanying materials are made available under the
# terms of the Eclipse Public License 2.0 which is available at
# http://www.eclipse.org/legal/epl-2.0
#
# SPDX-License-Identifier: EPL-2.0
---
# Source: telemetry-e2e/charts/ditto/templates/nginx-config.yaml
# Copyright (c) 2019 Contributors to the Eclipse Foundation
#
# See the NOTICE file(s) distributed with this work for additional
# information regarding copyright ownership.
#
# This program and the accompanying materials are made available under the
# terms of the Eclipse Public License 2.0 which is available at
# http://www.eclipse.org/legal/epl-2.0
#
# SPDX-License-Identifier: EPL-2.0
---
# Source: telemetry-e2e/charts/ditto/templates/nginx-configmap.yaml
# Copyright (c) 2019 Contributors to the Eclipse Foundation
#
# See the NOTICE file(s) distributed with this work for additional
# information regarding copyright ownership.
#
# This program and the accompanying materials are made available under the
# terms of the Eclipse Public License 2.0 which is available at
# http://www.eclipse.org/legal/epl-2.0
#
# SPDX-License-Identifier: EPL-2.0
---
# Source: telemetry-e2e/charts/ditto/templates/nginx-deployment.yaml
# Copyright (c) 2019 Contributors to the Eclipse Foundation
#
# See the NOTICE file(s) distributed with this work for additional
# information regarding copyright ownership.
#
# This program and the accompanying materials are made available under the
# terms of the Eclipse Public License 2.0 which is available at
# http://www.eclipse.org/legal/epl-2.0
#
# SPDX-License-Identifier: EPL-2.0
---
# Source: telemetry-e2e/charts/ditto/templates/nginx-ingress.yaml
# Copyright (c) 2019 Contributors to the Eclipse Foundation
#
# See the NOTICE file(s) distributed with this work for additional
# information regarding copyright ownership.
#
# This program and the accompanying materials are made available under the
# terms of the Eclipse Public License 2.0 which is available at
# http://www.eclipse.org/legal/epl-2.0
#
# SPDX-License-Identifier: EPL-2.0
---
# Source: telemetry-e2e/charts/ditto/templates/nginx-route.yaml
# Copyright (c) 2019 Contributors to the Eclipse Foundation
#
# See the NOTICE file(s) distributed with this work for additional
# information regarding copyright ownership.
#
# This program and the accompanying materials are made available under the
# terms of the Eclipse Public License 2.0 which is available at
# http://www.eclipse.org/legal/epl-2.0
#
# SPDX-License-Identifier: EPL-2.0
---
# Source: telemetry-e2e/charts/ditto/templates/nginx-service.yaml
# Copyright (c) 2019 Contributors to the Eclipse Foundation
#
# See the NOTICE file(s) distributed with this work for additional
# information regarding copyright ownership.
#
# This program and the accompanying materials are made available under the
# terms of the Eclipse Public License 2.0 which is available at
# http://www.eclipse.org/legal/epl-2.0
#
# SPDX-License-Identifier: EPL-2.0
---
# Source: telemetry-e2e/charts/ditto/templates/policies-deployment.yaml
# Copyright (c) 2019 Contributors to the Eclipse Foundation
#
# See the NOTICE file(s) distributed with this work for additional
# information regarding copyright ownership.
#
# This program and the accompanying materials are made available under the
# terms of the Eclipse Public License 2.0 which is available at
# http://www.eclipse.org/legal/epl-2.0
#
# SPDX-License-Identifier: EPL-2.0
---
# Source: telemetry-e2e/charts/ditto/templates/policies-networkpolicy.yaml
# Copyright (c) 2019 Contributors to the Eclipse Foundation
#
# See the NOTICE file(s) distributed with this work for additional
# information regarding copyright ownership.
#
# This program and the accompanying materials are made available under the
# terms of the Eclipse Public License 2.0 which is available at
# http://www.eclipse.org/legal/epl-2.0
#
# SPDX-License-Identifier: EPL-2.0
---
# Source: telemetry-e2e/charts/ditto/templates/policies-pdb.yaml
# Copyright (c) 2019 Contributors to the Eclipse Foundation
#
# See the NOTICE file(s) distributed with this work for additional
# information regarding copyright ownership.
#
# This program and the accompanying materials are made available under the
# terms of the Eclipse Public License 2.0 which is available at
# http://www.eclipse.org/legal/epl-2.0
#
# SPDX-License-Identifier: EPL-2.0
---
# Source: telemetry-e2e/charts/ditto/templates/role.yaml
# Copyright (c) 2019 Contributors to the Eclipse Foundation
#
# See the NOTICE file(s) distributed with this work for additional
# information regarding copyright ownership.
#
# This program and the accompanying materials are made available under the
# terms of the Eclipse Public License 2.0 which is available at
# http://www.eclipse.org/legal/epl-2.0
#
# SPDX-License-Identifier: EPL-2.0
---
# Source: telemetry-e2e/charts/ditto/templates/rolebinding.yaml
# Copyright (c) 2019 Contributors to the Eclipse Foundation
#
# See the NOTICE file(s) distributed with this work for additional
# information regarding copyright ownership.
#
# This program and the accompanying materials are made available under the
# terms of the Eclipse Public License 2.0 which is available at
# http://www.eclipse.org/legal/epl-2.0
#
# SPDX-License-Identifier: EPL-2.0
---
# Source: telemetry-e2e/charts/ditto/templates/serviceaccount.yaml
# Copyright (c) 2019 Contributors to the Eclipse Foundation
#
# See the NOTICE file(s) distributed with this work for additional
# information regarding copyright ownership.
#
# This program and the accompanying materials are made available under the
# terms of the Eclipse Public License 2.0 which is available at
# http://www.eclipse.org/legal/epl-2.0
#
# SPDX-License-Identifier: EPL-2.0
---
# Source: telemetry-e2e/charts/ditto/templates/swaggerui-config.yaml
# Copyright (c) 2019 Contributors to the Eclipse Foundation
#
# See the NOTICE file(s) distributed with this work for additional
# information regarding copyright ownership.
#
# This program and the accompanying materials are made available under the
# terms of the Eclipse Public License 2.0 which is available at
# http://www.eclipse.org/legal/epl-2.0
#
# SPDX-License-Identifier: EPL-2.0
---
# Source: telemetry-e2e/charts/ditto/templates/swaggerui-deployment.yaml
# Copyright (c) 2019, 2020 Contributors to the Eclipse Foundation
#
# See the NOTICE file(s) distributed with this work for additional
# information regarding copyright ownership.
#
# This program and the accompanying materials are made available under the
# terms of the Eclipse Public License 2.0 which is available at
# http://www.eclipse.org/legal/epl-2.0
#
# SPDX-License-Identifier: EPL-2.0
---
# Source: telemetry-e2e/charts/ditto/templates/swaggerui-networkpolicy.yaml
# Copyright (c) 2019 Contributors to the Eclipse Foundation
#
# See the NOTICE file(s) distributed with this work for additional
# information regarding copyright ownership.
#
# This program and the accompanying materials are made available under the
# terms of the Eclipse Public License 2.0 which is available at
# http://www.eclipse.org/legal/epl-2.0
#
# SPDX-License-Identifier: EPL-2.0
---
# Source: telemetry-e2e/charts/ditto/templates/swaggerui-pdb.yaml
# Copyright (c) 2019 Contributors to the Eclipse Foundation
#
# See the NOTICE file(s) distributed with this work for additional
# information regarding copyright ownership.
#
# This program and the accompanying materials are made available under the
# terms of the Eclipse Public License 2.0 which is available at
# http://www.eclipse.org/legal/epl-2.0
#
# SPDX-License-Identifier: EPL-2.0
---
# Source: telemetry-e2e/charts/ditto/templates/swaggerui-service.yaml
# Copyright (c) 2019 Contributors to the Eclipse Foundation
#
# See the NOTICE file(s) distributed with this work for additional
# information regarding copyright ownership.
#
# This program and the accompanying materials are made available under the
# terms of the Eclipse Public License 2.0 which is available at
# http://www.eclipse.org/legal/epl-2.0
#
# SPDX-License-Identifier: EPL-2.0
---
# Source: telemetry-e2e/charts/ditto/templates/things-deployment.yaml
# Copyright (c) 2019 Contributors to the Eclipse Foundation
#
# See the NOTICE file(s) distributed with this work for additional
# information regarding copyright ownership.
#
# This program and the accompanying materials are made available under the
# terms of the Eclipse Public License 2.0 which is available at
# http://www.eclipse.org/legal/epl-2.0
#
# SPDX-License-Identifier: EPL-2.0
---
# Source: telemetry-e2e/charts/ditto/templates/things-networkpolicy.yaml
# Copyright (c) 2019 Contributors to the Eclipse Foundation
#
# See the NOTICE file(s) distributed with this work for additional
# information regarding copyright ownership.
#
# This program and the accompanying materials are made available under the
# terms of the Eclipse Public License 2.0 which is available at
# http://www.eclipse.org/legal/epl-2.0
#
# SPDX-License-Identifier: EPL-2.0
---
# Source: telemetry-e2e/charts/ditto/templates/things-pdb.yaml
# Copyright (c) 2019 Contributors to the Eclipse Foundation
#
# See the NOTICE file(s) distributed with this work for additional
# information regarding copyright ownership.
#
# This program and the accompanying materials are made available under the
# terms of the Eclipse Public License 2.0 which is available at
# http://www.eclipse.org/legal/epl-2.0
#
# SPDX-License-Identifier: EPL-2.0
---
# Source: telemetry-e2e/charts/ditto/templates/thingssearch-deployment.yaml
# Copyright (c) 2019 Contributors to the Eclipse Foundation
#
# See the NOTICE file(s) distributed with this work for additional
# information regarding copyright ownership.
#
# This program and the accompanying materials are made available under the
# terms of the Eclipse Public License 2.0 which is available at
# http://www.eclipse.org/legal/epl-2.0
#
# SPDX-License-Identifier: EPL-2.0
---
# Source: telemetry-e2e/charts/ditto/templates/thingssearch-networkpolicy.yaml
# Copyright (c) 2019 Contributors to the Eclipse Foundation
#
# See the NOTICE file(s) distributed with this work for additional
# information regarding copyright ownership.
#
# This program and the accompanying materials are made available under the
# terms of the Eclipse Public License 2.0 which is available at
# http://www.eclipse.org/legal/epl-2.0
#
# SPDX-License-Identifier: EPL-2.0
---
# Source: telemetry-e2e/charts/ditto/templates/thingssearch-pdb.yaml
# Copyright (c) 2019 Contributors to the Eclipse Foundation
#
# See the NOTICE file(s) distributed with this work for additional
# information regarding copyright ownership.
#
# This program and the accompanying materials are made available under the
# terms of the Eclipse Public License 2.0 which is available at
# http://www.eclipse.org/legal/epl-2.0
#
# SPDX-License-Identifier: EPL-2.0
---
# Source: telemetry-e2e/charts/drogueCloud/templates/kafka/kafka.yaml
kind: Kafka
apiVersion: kafka.strimzi.io/v1beta2
metadata:
  name: drogue-iot
  labels:
    app.kubernetes.io/name: drogue-iot
    app.kubernetes.io/component: kafka
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.7.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: drogue-iot
spec:

  kafka:
    authorization:
      type: simple
      superUsers:
        - drogue-iot
    config:
      log.message.format.version: "2.8"
      offsets.topic.replication.factor: 1
      transaction.state.log.min.isr: 1
      transaction.state.log.replication.factor: 1
      auto.create.topics.enable: false
    listeners:
      - name: plain
        tls: false
        port: 9092
        type: internal
        authentication:
          type: scram-sha-512
      - name: tls
        tls: true
        port: 9093
        type: internal
        authentication:
          type: scram-sha-512
      - name: external
        port: 9094
        type: nodeport
        authentication:
          type: scram-sha-512
        tls: true
    resources:
      limits:
        cpu: "1"
        memory: 1Gi
      requests:
        cpu: 200m
        memory: 128Mi

    replicas: 1
    storage:
      deleteClaim: true
      size: 10Gi
      type: persistent-claim
    version: 2.8.0
    template:
      pod:
        {}

  zookeeper:
    replicas: 1
    storage:
      deleteClaim: true
      size: 1Gi
      type: persistent-claim
    resources:
      limits:
        cpu: 500m
        memory: 512Mi
      requests:
        cpu: 50m
        memory: 128Mi
    template:
      pod:
        {}

  entityOperator:

    topicOperator:
      watchedNamespace: default
      resources:
        limits:
          cpu: 250m
          memory: 256Mi
        requests:
          cpu: 50m
          memory: 128Mi

    userOperator:
      watchedNamespace: default
      resources:
        limits:
          cpu: 250m
          memory: 256Mi
        requests:
          cpu: 50m
          memory: 128Mi
    tlsSidecar:
      resources:
        limits: {}
        requests: {}
---
# Source: telemetry-e2e/charts/drogueCloud/templates/kafka/topics.yaml
apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaTopic
metadata:
  name: iot-commands
  labels:
    strimzi.io/cluster: drogue-iot
    app.kubernetes.io/name: iot-commands
    app.kubernetes.io/component: kafka
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.7.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: drogue-iot
spec:
  config: {}
  partitions: 3
  replicas: 1
  topicName: iot-commands
---
# Source: telemetry-e2e/charts/drogueCloud/templates/kafka/topics.yaml
apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaTopic
metadata:
  name: registry
  labels:
    strimzi.io/cluster: drogue-iot
    app.kubernetes.io/name: registry
    app.kubernetes.io/component: kafka
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.7.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: drogue-iot
spec:
  config: {}
  partitions: 3
  replicas: 1
  topicName: registry
---
# Source: telemetry-e2e/charts/drogueCloud/templates/kafka/kafka-user.yaml
apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaUser
metadata:
  name: drogue-iot
  labels:
    strimzi.io/cluster: drogue-iot
    app.kubernetes.io/name: drogue-iot
    app.kubernetes.io/component: kafka
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.7.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: drogue-iot
spec:
  authentication:
    type: scram-sha-512
  authorization:
    type: simple
    acls: []
---
# Source: telemetry-e2e/templates/kafka/kafka-user.yaml
apiVersion: kafka.strimzi.io/v1beta2
kind: KafkaUser
metadata:
  name: ditto-kafka-user
  labels:
    strimzi.io/cluster: drogue-iot
spec:
  authentication:
    type: scram-sha-512
    password:
      valueFrom:
        secretKeyRef:
          name: ditto-kafka-user-credentials
          key: password
  authorization:
    type: simple
    acls:
      - resource:
          type: topic
          name: "events-eclipse"
          patternType: literal
        operation: Read
        host: "*"

      - resource:
          type: group
          name: "*"
          patternType: literal
        operation: Read
        host: "*"
---
# Source: telemetry-e2e/charts/drogueCloud/templates/sso/instance.yaml
apiVersion: keycloak.org/v1alpha1
kind: Keycloak
metadata:
  name: sso
  labels:
    app.kubernetes.io/name: keycloak
    app.kubernetes.io/component: sso
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.7.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: drogue-iot
spec:
  instances: 1

  externalAccess:
    # External Access must be disabled. It is broken for OpenShift for KeyCloak 12+ and also causes issues
    # with the nginx ingress controller. The controller sets the ingressClass to "nginx" and the keycloak
    # operator removes this again. Resulting in constant updates and failures of the Ingress resource.
    enabled: false
  externalDatabase:
    enabled: true

  keycloakDeploymentSpec:
    resources:
      
        limits:
          cpu: "1"
          memory: 2048Mi
        requests:
          cpu: 200m
          memory: 1536Mi
---
# Source: telemetry-e2e/charts/drogueCloud/templates/sso/client-drogue.yaml
apiVersion: keycloak.org/v1alpha1
kind: KeycloakClient
metadata:
  name: client
  labels:
    app.kubernetes.io/name: client-drogue
    app.kubernetes.io/component: sso
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.7.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: drogue-iot
spec:
  realmSelector:
    matchLabels:
      app.kubernetes.io/name: drogue
      app.kubernetes.io/component: sso
      app.kubernetes.io/instance: release-name
  client:
    clientId: drogue
    clientAuthenticatorType: client-secret
    enabled: true
    rootUrl: ""
    publicClient: true
    implicitFlowEnabled: true
    standardFlowEnabled: true
    directAccessGrantsEnabled: false
    serviceAccountsEnabled: false
    fullScopeAllowed: true
    redirectUris:
      - http://console.change.me
      - http://console.change.me/*
      - "http://localhost:*" 
    defaultClientScopes:
      - "email"
      - "profile"
      - "roles"
      - "web-origins"
    optionalClientScopes:
      - "address"
      - "microprofile-jwt"
      - "offline_access"
      - "phone"
    defaultRoles:
      - "drogue-user"
    protocolMappers:
      - name: add-audience
        protocol: openid-connect
        protocolMapper: oidc-audience-mapper
        consentRequired: false
        config:
          "included.client.audience": "drogue"
          "id.token.claim": "false"
          "access.token.claim": "true"
---
# Source: telemetry-e2e/charts/drogueCloud/templates/sso/client-services.yaml
apiVersion: keycloak.org/v1alpha1
kind: KeycloakClient
metadata:
  name: client-services
  labels:
    app.kubernetes.io/name: client-services
    app.kubernetes.io/component: sso
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.7.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: drogue-iot
spec:
  realmSelector:
    matchLabels:
      app.kubernetes.io/name: drogue
      app.kubernetes.io/component: sso
      app.kubernetes.io/instance: release-name
  client:
    clientId: services
    clientAuthenticatorType: client-secret
    enabled: true
    rootUrl: ""
    publicClient: false
    implicitFlowEnabled: false
    standardFlowEnabled: false
    directAccessGrantsEnabled: false
    serviceAccountsEnabled: true
    fullScopeAllowed: true
    defaultClientScopes:
      - "email"
      - "profile"
      - "roles"
      - "web-origins"
    optionalClientScopes:
      - "address"
      - "microprofile-jwt"
      - "offline_access"
      - "phone"
    defaultRoles:
      - "drogue-user"
      - "drogue-admin"
    protocolMappers:
      - name: add-audience
        protocol: openid-connect
        protocolMapper: oidc-audience-mapper
        consentRequired: false
        config:
          "included.client.audience": "services"
          "id.token.claim": "false"
          "access.token.claim": "true"
---
# Source: telemetry-e2e/charts/drogueCloud/templates/sso/realm.yaml
apiVersion: keycloak.org/v1alpha1
kind: KeycloakRealm
metadata:
  name: drogue
  labels:
    app.kubernetes.io/name: drogue
    app.kubernetes.io/component: sso
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.7.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: drogue-iot
spec:
  instanceSelector:
    matchLabels:
      app.kubernetes.io/name: keycloak
      app.kubernetes.io/component: sso
      app.kubernetes.io/instance: release-name
  realm:
    realm: "drogue"
    enabled: true
    displayName: "Drogue IoT cloud"
    registrationAllowed: true
    resetPasswordAllowed: true
    loginWithEmailAllowed: false
    roles:
      realm:
      - name: "drogue-user"
      - name: "drogue-admin"
    identityProviders:
      []
---
# Source: telemetry-e2e/charts/drogueCloud/templates/sso/user.yaml
apiVersion: keycloak.org/v1alpha1
kind: KeycloakUser
metadata:
  name: admin
  labels:
    app.kubernetes.io/name: admin
    app.kubernetes.io/component: sso
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.7.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: drogue-iot
spec:
  realmSelector:
    matchLabels:
      app.kubernetes.io/name: drogue
      app.kubernetes.io/component: sso
      app.kubernetes.io/instance: release-name
  user:
    username: "admin"
    firstName: "System"
    lastName: "Admin"
    email: "user@example.com"
    enabled: true
    emailVerified: false
    credentials:
      - type: password
        value: admin123456
        temporary: false
    realmRoles:
      - "drogue-admin"
      - "drogue-user"
      - "offline_access"
    clientRoles:
      grafana:
        - "grafana-admin"
        - "grafana-editor"
      account:
        - "manage-account"
      realm-management:
        - "manage-users"
---
# Source: telemetry-e2e/charts/drogueCloud/templates/service/registry/postgres/migrate.yaml
kind: Job
apiVersion: batch/v1
metadata:
  name: migrate-database
  annotations:
    argocd.argoproj.io/hook: PostSync
    argocd.argoproj.io/hook-delete-policy: BeforeHookCreation
    helm.sh/hook: post-install,post-upgrade
    helm.sh/hook-delete-policy: before-hook-creation
  labels:
    app.kubernetes.io/name: migrate-database
    app.kubernetes.io/component: device-registry
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.7.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: drogue-iot
spec:
  backoffLimit: 1000
  completions: 1
  parallelism: 1
  ttlSecondsAfterFinished: 600
  template:
    spec:
      restartPolicy: OnFailure
      containers:
        - name: diesel-migrate
          image: "ghcr.io/drogue-iot/database-migration:0.7.0"
          imagePullPolicy: IfNotPresent
          env:
            - name: POSTGRES_DB
              valueFrom:
                configMapKeyRef:
                  name: postgres-config
                  key: databaseName
            - name: POSTGRES_USER
              valueFrom:
                secretKeyRef:
                  name: postgres-secret
                  key: admin.username
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: postgres-secret
                  key: admin.password
            - name: DATABASE_URL
              value: postgres://$(POSTGRES_USER):$(POSTGRES_PASSWORD)@postgres/$(POSTGRES_DB)
---
# Source: telemetry-e2e/charts/drogueCloud/templates/sso/post-install.yaml
kind: Job
apiVersion: batch/v1
metadata:
  name: post-install-keycloak
  annotations:
    argocd.argoproj.io/hook: PostSync
    argocd.argoproj.io/hook-delete-policy: BeforeHookCreation
    helm.sh/hook: post-install,post-upgrade
    helm.sh/hook-delete-policy: before-hook-creation
  labels:
    app.kubernetes.io/name: migrate-database
    app.kubernetes.io/component: device-registry
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.7.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: drogue-iot
spec:
  backoffLimit: 1000
  completions: 1
  parallelism: 1
  ttlSecondsAfterFinished: 600
  template:
    spec:
      restartPolicy: OnFailure
      containers:
        - name: post-install
          image: quay.io/keycloak/keycloak:15.0.1
          imagePullPolicy: IfNotPresent

          env:
            - name: ADMIN_USERNAME
              valueFrom:
                secretKeyRef:
                  name: credential-sso
                  key: ADMIN_USERNAME
            - name: ADMIN_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: credential-sso
                  key: ADMIN_PASSWORD
            - name: KEYCLOAK_URL
              value: http://sso.change.me

          command:
            - bash
            - -exc
            - |
              # log in to keycloak
              /opt/jboss/keycloak/bin/kcadm.sh config credentials config --config /tmp/kcadm.config --server "$KEYCLOAK_URL/auth" --realm master --user "$ADMIN_USERNAME" --password "$ADMIN_PASSWORD"

              # add drogue-user to default roles

              # get realm
              /opt/jboss/keycloak/bin/kcadm.sh get --config /tmp/kcadm.config realms/drogue
              # get composite default role
              /opt/jboss/keycloak/bin/kcadm.sh get --config /tmp/kcadm.config -r drogue roles/default-roles-drogue
              # list default roles
              /opt/jboss/keycloak/bin/kcadm.sh get-roles --config /tmp/kcadm.config -r drogue --rname default-roles-drogue
              # add drogue-user to default roles
              /opt/jboss/keycloak/bin/kcadm.sh add-roles --config /tmp/kcadm.config -r drogue --rname default-roles-drogue --rolename drogue-user
              # list again
              /opt/jboss/keycloak/bin/kcadm.sh get-roles --config /tmp/kcadm.config -r drogue --rname default-roles-drogue

              # add drogue-admin to service account roles

              # get all client (we don't know the ID)
              /opt/jboss/keycloak/bin/kcadm.sh get --config /tmp/kcadm.config -r drogue clients
              # get client roles
              /opt/jboss/keycloak/bin/kcadm.sh get-roles --config /tmp/kcadm.config -r drogue --uusername service-account-services
              # add drogue-admin to service account roles
              /opt/jboss/keycloak/bin/kcadm.sh add-roles --config /tmp/kcadm.config -r drogue --uusername service-account-services --rolename drogue-admin
              # list again
              /opt/jboss/keycloak/bin/kcadm.sh get-roles --config /tmp/kcadm.config -r drogue --uusername service-account-services
---
# Source: telemetry-e2e/templates/post-install/job.yaml
kind: Job
apiVersion: batch/v1
metadata:
  name: post-install-ditto
  labels:
    app.kubernetes.io/name: post-install-ditto
    app.kubernetes.io/component: post-install
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.1.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: deployment
  annotations:
    helm.sh/hook: post-install,post-upgrade
    helm.sh/hook-delete-policy: before-hook-creation
spec:
  backoffLimit: 1000
  completions: 1
  parallelism: 1
  ttlSecondsAfterFinished: 600
  template:
    metadata:
      labels:
        app.kubernetes.io/name: post-install-ditto
        app.kubernetes.io/component: post-install
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/version: "0.1.0"
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/part-of: deployment
    spec:
      restartPolicy: OnFailure
      containers:
        - name: "post-install"
          image: "ghcr.io/ctron/kubectl:1.19"
          env:
            - name: SSO_URL
              value: http://sso.change.me
            - name: DROGUE_CLIENT_ID
              valueFrom:
                secretKeyRef:
                  name: keycloak-client-secret-services
                  key: CLIENT_ID
            - name: DROGUE_CLIENT_SECRET
              valueFrom:
                secretKeyRef:
                  name: keycloak-client-secret-services
                  key: CLIENT_SECRET
            - name: DITTO_PWD
              valueFrom:
                secretKeyRef:
                  name: ditto-gateway-secret
                  key: devops-password
            - name: DROGUE_REGISTRY_URL
              value: http://device-management-service:80
            - name: DITTO_URL
              value: http://ditto-nginx:8080
          command:
            - /bin/bash
            - -exc
            - |
              # get bearer token for client
              DROGUE_TOKEN="$(curl -sL -k -o - -X POST -H "Content-Type: application/x-www-form-urlencoded" -d "client_id=$DROGUE_CLIENT_ID" -d "client_secret=$DROGUE_CLIENT_SECRET" -d "grant_type=client_credentials" ${SSO_URL}/auth/realms/drogue/protocol/openid-connect/token | jq -r .access_token)"
              echo

              # test access
              curl -svL -f -X GET -H "Authorization: Bearer $DROGUE_TOKEN" -H "Content-Type: application/json" ${DROGUE_REGISTRY_URL}/api/registry/v1alpha1/apps
              echo

              # create Drogue Cloud application
              curl -svL -f -X POST -H "Authorization: Bearer $DROGUE_TOKEN" -H "Content-Type: application/json" --data-binary @/etc/config/post-install-data/drogue-cloud-application.json ${DROGUE_REGISTRY_URL}/api/registry/v1alpha1/apps || true
              echo

              # create Drogue Cloud device
              curl -svL -f -X POST -H "Authorization: Bearer $DROGUE_TOKEN" -H "Content-Type: application/json" --data-binary @/etc/config/post-install-data/drogue-cloud-device.json ${DROGUE_REGISTRY_URL}/api/registry/v1alpha1/apps/eclipse/devices || true
              echo

              # delete and re-create a thing
              curl -svL -X DELETE -u ditto:ditto "${DITTO_URL}/api/2/things/eclipse%3Adevice-1"
              echo
              curl -svL -X DELETE -u ditto:ditto "${DITTO_URL}/api/2/policies/eclipse%3Adevice-1"
              echo
              curl -svL -f -X PUT -u ditto:ditto -H 'Content-Type: application/json' --data-binary @/etc/config/post-install-data/thing-definition.json "${DITTO_URL}/api/2/things/eclipse:device-1"
              echo

              # drop and re-create connection between Drogue Cloud and Ditto
              curl -svL -f -X POST -u devops:$DITTO_PWD -H 'Content-Type: application/json' --data-binary @/etc/config/post-install-data/drogue-cloud-delete-connection.json ${DITTO_URL}/devops/piggyback/connectivity
              echo
              curl -svL -f -X POST -u devops:$DITTO_PWD -H 'Content-Type: application/json' --data-binary @/etc/config/post-install-data/drogue-cloud-create-connection.json ${DITTO_URL}/devops/piggyback/connectivity
              echo

              # drop and re-create connection between Ditto and Streamsheets
              curl -svL -f -X POST -u devops:$DITTO_PWD -H 'Content-Type: application/json' --data-binary @/etc/config/post-install-data/streamsheets-delete-connection.json ${DITTO_URL}/devops/piggyback/connectivity
              echo
              curl -svL -f -X POST -u devops:$DITTO_PWD -H 'Content-Type: application/json' --data-binary @/etc/config/post-install-data/streamsheets-create-connection.json ${DITTO_URL}/devops/piggyback/connectivity
              echo

          volumeMounts:
            - name: post-install-data
              mountPath: "/etc/config/post-install-data"
              readOnly: true
      volumes:
        - name: post-install-data
          secret:
            secretName: "post-install-data"
