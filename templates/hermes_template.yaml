---
# Source: hermes/charts/apicurio-registry/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: release-name-apicurio-registry
  labels:
    helm.sh/chart: apicurio-registry-0.1.3
    app.kubernetes.io/name: apicurio-registry
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "2.1.0.Final"
    app.kubernetes.io/managed-by: Helm
---
# Source: hermes/charts/kafka/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: release-name-kafka
  namespace: "default"
  labels:
    app.kubernetes.io/name: kafka
    helm.sh/chart: kafka-20.0.4
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: kafka
  annotations:
automountServiceAccountToken: true
---
# Source: hermes/templates/consumers-serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: release-name-hermes-consumers
  labels:
    component: "consumers"
    helm.sh/chart: hermes-0.6.0
    app.kubernetes.io/name: hermes
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "2.2.8"
    app.kubernetes.io/managed-by: Helm
---
# Source: hermes/templates/frontend-serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: release-name-hermes-frontend
  labels:
    component: "frontend"
    helm.sh/chart: hermes-0.6.0
    app.kubernetes.io/name: hermes
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "2.2.8"
    app.kubernetes.io/managed-by: Helm
---
# Source: hermes/templates/management-serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: release-name-hermes-management
  labels:
    component: "management"
    helm.sh/chart: hermes-0.6.0
    app.kubernetes.io/name: hermes
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "2.2.8"
    app.kubernetes.io/managed-by: Helm
---
# Source: hermes/templates/consumers-secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: release-name-hermes-consumers-secret
data: 
  consumers-secret.yaml: |-
      bnVsbA==
---
# Source: hermes/templates/frontend-secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: release-name-hermes-frontend-secret
data: 
  frontend-secret.yaml: |-
      bnVsbA==
---
# Source: hermes/templates/management-secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: release-name-hermes-management-secret
data: 
  management-secret.yaml: |-
      bnVsbA==
---
# Source: hermes/charts/kafka/charts/zookeeper/templates/scripts-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-zookeeper-scripts
  namespace: default
  labels:
    app.kubernetes.io/name: zookeeper
    helm.sh/chart: zookeeper-11.0.3
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: zookeeper
data:
  init-certs.sh: |-
    #!/bin/bash
  setup.sh: |-
    #!/bin/bash

    # Execute entrypoint as usual after obtaining ZOO_SERVER_ID
    # check ZOO_SERVER_ID in persistent volume via myid
    # if not present, set based on POD hostname
    if [[ -f "/bitnami/zookeeper/data/myid" ]]; then
        export ZOO_SERVER_ID="$(cat /bitnami/zookeeper/data/myid)"
    else
        HOSTNAME="$(hostname -s)"
        if [[ $HOSTNAME =~ (.*)-([0-9]+)$ ]]; then
            ORD=${BASH_REMATCH[2]}
            export ZOO_SERVER_ID="$((ORD + 1 ))"
        else
            echo "Failed to get index from hostname $HOST"
            exit 1
        fi
    fi
    exec /entrypoint.sh /run.sh
---
# Source: hermes/charts/kafka/templates/scripts-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-kafka-scripts
  namespace: "default"
  labels:
    app.kubernetes.io/name: kafka
    helm.sh/chart: kafka-20.0.4
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
data:
  setup.sh: |-
    #!/bin/bash

    ID="${MY_POD_NAME#"release-name-kafka-"}"
    if [[ -f "/bitnami/kafka/data/meta.properties" ]]; then
        export KAFKA_CFG_BROKER_ID="$(grep "broker.id" "/bitnami/kafka/data/meta.properties" | awk -F '=' '{print $2}')"
    else
        export KAFKA_CFG_BROKER_ID="$((ID + 0))"
    fi

    # Configure zookeeper client

    exec /entrypoint.sh /run.sh
---
# Source: hermes/templates/consumers-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-hermes-consumers
  labels:
    component: "consumers"
    helm.sh/chart: hermes-0.6.0
    app.kubernetes.io/name: hermes
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "2.2.8"
    app.kubernetes.io/managed-by: Helm
data:
  consumers.yaml: |-
    consumer:
      zookeeper:
        clusters:
          - datacenter: "dc"
            root: "/hermes"
            connectionString: "release-name-zookeeper:2181"
            connectionTimeout: 5000
            sessionTimeout: 7000
      kafka:
        clusters:
          - datacenter: "dc"
            brokerList: "release-name-kafka:9092"
      schema:
        repository:
          serverUrl: "http://release-name-apicurio-registry:80/apis/ccompat/v6/"
          subjectSuffixEnabled: true
          subjectNamespaceEnabled: true
      metrics:
        graphiteReporterEnabled: false
      workload:
        consumersPerSubscription:1
  logback.xml: |-
    <?xml version="1.0" encoding="UTF-8"?>
    <configuration scan="true" scanPeriod="5 seconds">

        <appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender">
            <encoder class="ch.qos.logback.classic.encoder.PatternLayoutEncoder">
                <Pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} %-5level %logger{36} - %msg%n</Pattern>
            </encoder>
        </appender>

        <logger name="org.apache.zookeeper" level="ERROR" />
        <logger name="kafka" level="WARN"/>

        <root level="INFO">
            <appender-ref ref="STDOUT" />
        </root>

    </configuration>
---
# Source: hermes/templates/frontend-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-hermes-frontend
  labels:
    component: "frontend"
    helm.sh/chart: hermes-0.6.0
    app.kubernetes.io/name: hermes
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "2.2.8"
    app.kubernetes.io/managed-by: Helm
data:
  frontend.yaml: |-
    frontend:
      zookeeper:
        clusters:
          - datacenter: "dc"
            root: "/hermes"
            connectionString: "release-name-zookeeper:2181"
      kafka:
        clusters:
          - datacenter: "dc"
            brokerList: "release-name-kafka:9092"
      metrics:
        graphiteReporterEnabled: false
      schema:
        repository:
          serverUrl: "http://release-name-apicurio-registry:80/apis/ccompat/v6/"
          subjectSuffixEnabled: true
          subjectNamespaceEnabled: true
      message:
        preview:
          enabled: true
  logback.xml: |-
    <?xml version="1.0" encoding="UTF-8"?>
    <configuration scan="true" scanPeriod="5 seconds">

        <appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender">
            <encoder class="ch.qos.logback.classic.encoder.PatternLayoutEncoder">
                <Pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} %-5level %logger{36} - %msg%n</Pattern>
            </encoder>
        </appender>

        <logger name="org.apache.zookeeper" level="ERROR" />

        <!--Selector spams ERROR level messages every 100ms on IOException-->
        <logger name="org.apache.kafka.common.network.Selector" level="OFF"/>

        <logger name="kafka" level="WARN"/>

        <root level="INFO">
            <appender-ref ref="STDOUT" />
        </root>

    </configuration>
---
# Source: hermes/templates/management-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-hermes-management
  labels:
    component: "management"
    helm.sh/chart: hermes-0.6.0
    app.kubernetes.io/name: hermes
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "2.2.8"
    app.kubernetes.io/managed-by: Helm
data:
  management.yaml: |-
    application:
      name: hermes-management

    logging.config: /etc/hermes/logback.xml

    zookeeper:
      enabled: false

    storage:
      pathPrefix: /hermes
      clusters:
        -
          datacenter: dc
          clusterName: zk
          connectionString: "release-name-zookeeper:2181"

    kafka:
      clusters:
        -
          datacenter: dc
          clusterName: primary
          connectionTimeoutMillis: 10000
          bootstrapKafkaServer: "release-name-kafka:9092"
          kafkaServerRequestTimeoutMillis: 10000

    metrics:
      graphiteHttpUri: graphite:8082
      graphite:
        enabled: true

    server:
      port: 8080

    spring:
      jersey:
        type: filter

    management:
      endpoints:
        web:
          base-path: /
      rest-template:
        connect-timeout: 2000
        read-timeout: 2000
      server:
        servlet:
          context-path: /
      health:
        periodSeconds: 30
        enabled: true
      consumer-groups:
        create-manually: true

    audit.enabled: false

    topicOwnerCache:
      refreshRateInSeconds: 300 # 5 minutes

    subscriptionOwnerCache:
      refreshRateInSeconds: 300

    schema:
      repository:
        type: schema_registry
        serverUrl: http://release-name-apicurio-registry:80/apis/ccompat/v6/
        subjectSuffixEnabled: true
        subjectNamespaceEnabled: true
        validationEnabled: true

    console:
      configurationLocation: console/config-local.json
      configurationType: classpath_resource
    topic: {"defaultSchemaIdAwareSerializationEnabled":true,"partitions":4,"replicationFactor":1}
  logback.xml: |-
    <?xml version="1.0" encoding="UTF-8"?>
    <configuration scan="true" scanPeriod="5 seconds">

        <appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender">
            <encoder class="ch.qos.logback.classic.encoder.PatternLayoutEncoder">
                <Pattern>%d{yyyy-MM-dd HH:mm:ss.SSS} %-5level %logger{36} - %msg%n</Pattern>
            </encoder>
        </appender>


        <!-- Selector spams ERROR level messages every 100ms on IOException -->
        <logger name="org.apache.kafka.common.network.Selector" level="OFF"/>
        <logger name="org.apache.zookeeper" level="WARN" />
        <logger name="org.apache.kafka" level="INFO" />
        <logger name="kafka" level="INFO"/>

        <root level="INFO">
            <appender-ref ref="STDOUT" />
        </root>

    </configuration>
---
# Source: hermes/templates/tests/test-scripts.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-hermes-test-scripts
data:
  main-wrapper.sh: |-
    #!/bin/sh
    ($*) &
    MAIN_PID=$!
    echo $MAIN_PID > /var/run/sidecars/main.pid
    wait $MAIN_PID
  sidecar-wrapper.sh: |-
    #!/bin/sh
    ($*) &
    MAIN_PID=$(until cat /var/run/sidecars/main.pid; do sleep 1; done)
    tail --pid $MAIN_PID -f /dev/null
---
# Source: hermes/templates/tests/test-suites.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-hermes-test-suites
data:
  main.bats: "#!/usr/bin/env bats\n\n: \"${MANAGEMENT_URL:?required environment value
    not set}\"\n: \"${FRONTEND_URL:?required environment value not set}\"\n: \"${WIREMOCK_URL:?required
    environment value not set}\"\n\nGROUP=testgroup\nTOPIC=testtopic\nSCHEMA=$(cat <<
    _END | sed -e 's/$/\\\\n/g' -e 's/\"/\\\\\"/g'\n{\n  \"namespace\": \"${GROUP}\",\n
    \ \"name\": \"${TOPIC}\",\n  \"type\": \"record\",\n  \"doc\": \"This is a sample
    schema definition for some Hermes message\",\n  \"fields\": [\n    {\n      \"name\":
    \"id\",\n      \"type\": \"string\",\n      \"doc\": \"Message id\"\n    },\n    {\n
    \     \"name\": \"content\",\n      \"type\": \"string\",\n      \"doc\": \"Message
    content\"\n    },\n    {\n      \"name\": \"tags\",\n      \"type\": { \"type\":
    \"array\", \"items\": \"string\" },\n      \"doc\": \"Message tags\"\n    }\n  ]\n}\n_END\n)\n\nfunction
    curl_get() {\n  curl -f -k -v -X GET \"$@\"\n}\n\nfunction curl_delete() {\n  curl
    -f -k -v -X DELETE \"$@\"\n}\n\nfunction curl_post() {\n  curl -f -k -v -H \"Content-type:
    application/json\" -X POST \"$@\"\n}\n\n# timeout command has different syntax in
    Ubuntu and BusyBox\nif [[ $(realpath $(which timeout)) =~ \"busybox\" ]]; then\n
    \ function timeout() {\n    $(which timeout) -t \"$@\"\n  }\nfi\n\nfunction setup()
    {\n  # given a group\n  curl_get ${MANAGEMENT_URL%/}/groups/${GROUP} ||\n    curl_post
    -d \"{\\\"groupName\\\": \\\"${GROUP}\\\"}\" ${MANAGEMENT_URL%/}/groups\n\n  # and
    a topic\n  curl_get ${MANAGEMENT_URL%/}/topics/${GROUP}.${TOPIC} ||\n    cat  <<
    _END | curl_post -d @- ${MANAGEMENT_URL%/}/topics/\n{\n    \"name\": \"${GROUP}.${TOPIC}\",\n
    \   \"description\": \"This is a test topic\",\n    \"contentType\": \"AVRO\",\n
    \   \"retentionTime\": {\n        \"duration\": 1\n    },\n    \"owner\": {\n        \"source\":
    \"Plaintext\",\n        \"id\": \"Test\"\n    },\n    \"schema\":\t\"$SCHEMA\"\n}\n_END\n
    \ timeout 10 /bin/sh -c \"until curl --output /dev/null --silent --fail ${WIREMOCK_URL%/}/__admin/;
    do sleep 1 && echo -n .; done;\"\n\n  # and a subscriber\n  SUBSCRIBER_NAME=$(head
    /dev/urandom | tr -dc a-z | head -c 16)\n  SUBSCRIBER_URL=${WIREMOCK_URL%/}/${SUBSCRIBER_NAME}\n
    \ cat << _END | curl_post -d @- ${WIREMOCK_URL%/}/__admin/mappings\n{\n  \"request\":
    {\n    \"method\": \"POST\",\n    \"url\": \"/${SUBSCRIBER_NAME}\"\n  },\n  \"response\":
    {\n    \"status\": 202\n  }\n}\n_END\n  cat << _END | curl_post -d @- ${MANAGEMENT_URL%/}/topics/${GROUP}.${TOPIC}/subscriptions\n{\n
    \   \"contentType\": \"JSON\",\n    \"description\": \"test\",\n    \"endpoint\":
    \"${SUBSCRIBER_URL%/}\",\n    \"name\": \"${SUBSCRIBER_NAME}\",\n    \"owner\":
    { \"id\": \"test\", \"source\": \"Plaintext\" },\n    \"topicName\": \"${GROUP}.${TOPIC}\"\n}\n_END\n}\n\nfunction
    teardown() {\n  # afterwards remove the subscription\n  curl_delete ${MANAGEMENT_URL%/}/topics/${GROUP}.${TOPIC}/subscriptions/${SUBSCRIBER_NAME}\n
    \ # the group and topic are left as an example\n}\n\n@test \"message should be sent
    to subscriber\" {\n  # when a message has been posted on the topic\n  cat << _END
    | curl_post -d @- ${FRONTEND_URL%/}/topics/${GROUP}.${TOPIC}\n{\n  \"id\": \"an
    id\",\n  \"content\": \"a content\",\n  \"tags\": []\n}\n_END\n\n  # then the message
    is received by the subscriber\n  export -f curl_post\n  cat << _END | timeout 90
    bash -c \"until curl_post -d '$(cat)' ${WIREMOCK_URL%/}/__admin/requests/count |
    grep '\\\"count\\\" : 1'; do sleep 10; done\"\n{\n    \"method\": \"POST\",\n    \"url\":
    \"/${SUBSCRIBER_NAME}\"\n}\n_END\n\n}\n"
---
# Source: hermes/charts/apicurio-registry/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-apicurio-registry
  labels:
    helm.sh/chart: apicurio-registry-0.1.3
    app.kubernetes.io/name: apicurio-registry
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "2.1.0.Final"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 80
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/name: apicurio-registry
    app.kubernetes.io/instance: release-name
---
# Source: hermes/charts/kafka/charts/zookeeper/templates/svc-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-zookeeper-headless
  namespace: default
  labels:
    app.kubernetes.io/name: zookeeper
    helm.sh/chart: zookeeper-11.0.3
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: zookeeper
spec:
  type: ClusterIP
  clusterIP: None
  publishNotReadyAddresses: true
  ports:
    - name: tcp-client
      port: 2181
      targetPort: client
    - name: tcp-follower
      port: 2888
      targetPort: follower
    - name: tcp-election
      port: 3888
      targetPort: election
  selector:
    app.kubernetes.io/name: zookeeper
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/component: zookeeper
---
# Source: hermes/charts/kafka/charts/zookeeper/templates/svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-zookeeper
  namespace: default
  labels:
    app.kubernetes.io/name: zookeeper
    helm.sh/chart: zookeeper-11.0.3
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: zookeeper
spec:
  type: ClusterIP
  sessionAffinity: None
  ports:
    - name: tcp-client
      port: 2181
      targetPort: client
      nodePort: null
    - name: tcp-follower
      port: 2888
      targetPort: follower
    - name: tcp-election
      port: 3888
      targetPort: election
  selector:
    app.kubernetes.io/name: zookeeper
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/component: zookeeper
---
# Source: hermes/charts/kafka/templates/svc-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-kafka-headless
  namespace: "default"
  labels:
    app.kubernetes.io/name: kafka
    helm.sh/chart: kafka-20.0.4
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: kafka
spec:
  type: ClusterIP
  clusterIP: None
  publishNotReadyAddresses: false
  ports:
    - name: tcp-client
      port: 9092
      protocol: TCP
      targetPort: kafka-client
    - name: tcp-internal
      port: 9093
      protocol: TCP
      targetPort: kafka-internal
  selector:
    app.kubernetes.io/name: kafka
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/component: kafka
---
# Source: hermes/charts/kafka/templates/svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-kafka
  namespace: "default"
  labels:
    app.kubernetes.io/name: kafka
    helm.sh/chart: kafka-20.0.4
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: kafka
spec:
  type: ClusterIP
  sessionAffinity: None
  ports:
    - name: tcp-client
      port: 9092
      protocol: TCP
      targetPort: kafka-client
      nodePort: null
  selector:
    app.kubernetes.io/name: kafka
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/component: kafka
---
# Source: hermes/templates/frontend-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-hermes-frontend
  labels:
    component: "frontend"
    helm.sh/chart: hermes-0.6.0
    app.kubernetes.io/name: hermes
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "2.2.8"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 8080
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/name: hermes
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/name: frontend
---
# Source: hermes/templates/management-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-hermes-management
  labels:
    component: "management"
    helm.sh/chart: hermes-0.6.0
    app.kubernetes.io/name: hermes
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "2.2.8"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 8080
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/name: hermes
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/name: management
---
# Source: hermes/charts/apicurio-registry/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-apicurio-registry
  labels:
    helm.sh/chart: apicurio-registry-0.1.3
    app.kubernetes.io/name: apicurio-registry
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "2.1.0.Final"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: apicurio-registry
      app.kubernetes.io/instance: release-name
  template:
    metadata:
      labels:
        app.kubernetes.io/name: apicurio-registry
        app.kubernetes.io/instance: release-name
    spec:
      serviceAccountName: release-name-apicurio-registry
      securityContext:
        {}
      containers:
        - name: apicurio-registry
          securityContext:
            {}
          image: "apicurio/apicurio-registry-kafkasql:2.1.0.Final"
          imagePullPolicy: IfNotPresent
          ports:
            - name: http
              containerPort: 8080
              protocol: TCP
          livenessProbe:
            httpGet:
              path: /
              port: http
          readinessProbe:
            httpGet:
              path: /
              port: http
          env:
            - name: KAFKA_BOOTSTRAP_SERVERS
              value: release-name-kafka:9092
          resources:
            {}
---
# Source: hermes/templates/consumers-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-hermes-consumers
  labels:
    component: "consumers"
    helm.sh/chart: hermes-0.6.0
    app.kubernetes.io/name: hermes
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "2.2.8"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: hermes
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/name: consumers
  template:
    metadata:
      annotations:
        checksum/config: 40787b4728330159bce1727c7c41f2ec6d40c0a91db56ef80cdd0876ff8a9d52
      labels:
        app.kubernetes.io/name: hermes
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/name: consumers
    spec:
      serviceAccountName: release-name-hermes-consumers
      securityContext:
        fsGroup: 2000
      containers:
        - name: hermes-consumers
          securityContext:
            runAsUser: 1000
          image: "allegro/hermes-consumers:hermes-2.2.8"
          imagePullPolicy: IfNotPresent
          volumeMounts:
            - name: config
              mountPath: /etc/hermes
          env:
            - name: HERMES_CONSUMERS_OPTS
              value: -Dspring.config.location=file:///etc/hermes/consumers.yaml,file:///etc/hermes/consumers-secret.yaml -Dlogging.config=/etc/hermes/logback.xml
            - name: JAVA_OPTS
              value: -Xms200m -Xmx200m
          envFrom:
            - configMapRef:
                optional: true
                name: release-name-hermes-consumers-env
          ports:
            - name: http
              containerPort: 8000
              protocol: TCP
          livenessProbe:
            httpGet:
              path: /status/health
              port: http
            periodSeconds: 5
            failureThreshold: 3
          startupProbe:
            httpGet:
              path: /status/health
              port: http
            periodSeconds: 3
            failureThreshold: 40
          resources:
            {}
      volumes:
        - name: config
          projected: 
            sources:
            - configMap:
                name: release-name-hermes-consumers
            - secret:
                name: release-name-hermes-consumers-secret
---
# Source: hermes/templates/frontend-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-hermes-frontend
  labels:
    component: "frontend"
    helm.sh/chart: hermes-0.6.0
    app.kubernetes.io/name: hermes
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "2.2.8"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: hermes
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/name: frontend
  template:
    metadata:
      annotations:
        checksum/config: 517fe3c8c5b81e19243ea59ffd6ea192283a2d18e4a43a4c745fbd8458d0ed5c
      labels:
        app.kubernetes.io/name: hermes
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/name: frontend
    spec:
      serviceAccountName: release-name-hermes-frontend
      securityContext:
        fsGroup: 1001
      containers:
        - name: hermes-frontend
          securityContext:
            runAsUser: 1001
          image: "allegro/hermes-frontend:hermes-2.2.8"
          imagePullPolicy: IfNotPresent
          volumeMounts:
            - name: config
              mountPath: /etc/hermes
          envFrom:
            - configMapRef:
                optional: true
                name: release-name-hermes-frontend-env
          env:
            - name: HERMES_FRONTEND_OPTS
              value: -Dspring.config.location=file:///etc/hermes/frontend.yaml,file:///etc/hermes/frontend-secret.yaml -Dlogging.config=/etc/hermes/logback.xml
            - name: JAVA_OPTS
              value: -Xms150m -Xmx150m
          ports:
            - name: http
              containerPort: 8080
              protocol: TCP
          livenessProbe:
            httpGet:
              path: /
              port: http
            periodSeconds: 5
            failureThreshold: 3
          startupProbe:
            httpGet:
              path: /
              port: http
            periodSeconds: 3
            failureThreshold: 40
          resources:
            {}
      volumes:
        - name: config
          projected: 
            sources:
            - configMap:
                name: release-name-hermes-frontend
            - secret:
                name: release-name-hermes-frontend-secret
---
# Source: hermes/templates/management-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-hermes-management
  labels:
    component: "management"
    helm.sh/chart: hermes-0.6.0
    app.kubernetes.io/name: hermes
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "2.2.8"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: hermes
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/name: management
  template:
    metadata:
      annotations:
        checksum/config: 92d5df55e8c0c94daa26d9234c3db953574657bc338d9a496ad4d7b19246d232
      labels:
        app.kubernetes.io/name: hermes
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/name: management
    spec:
      serviceAccountName: release-name-hermes-management
      securityContext:
        fsGroup: 1001
      containers:
        - name: hermes-management
          securityContext:
            runAsUser: 1001
          image: "allegro/hermes-management:hermes-2.2.8"
          imagePullPolicy: IfNotPresent
          volumeMounts:
            - name: config
              mountPath: /etc/hermes
          env:
            - name: SERVER_USE_FORWARD_HEADERS
              value: "true"
            - name: SPRING_CONFIG_LOCATION
              value: "file:///etc/hermes/management.yaml,file:///etc/hermes/management-secret.yaml"
            - name: JAVA_OPTS
              value: -Xms100m -Xmx100m
          envFrom:
            - configMapRef:
                optional: true
                name: release-name-hermes-management-env
          ports:
            - name: http
              containerPort: 8080
              protocol: TCP

          livenessProbe:
            tcpSocket:
              port: http
            periodSeconds: 5
            failureThreshold: 3
          startupProbe:
            tcpSocket:
              port: http
            periodSeconds: 3
            failureThreshold: 40
          resources:
            {}
      volumes:
        - name: config
          projected: 
            sources:
            - configMap:
                name: release-name-hermes-management
            - secret:
                name: release-name-hermes-management-secret
---
# Source: hermes/charts/kafka/charts/zookeeper/templates/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: release-name-zookeeper
  namespace: default
  labels:
    app.kubernetes.io/name: zookeeper
    helm.sh/chart: zookeeper-11.0.3
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: zookeeper
    role: zookeeper
spec:
  replicas: 1
  podManagementPolicy: Parallel
  selector:
    matchLabels:
      app.kubernetes.io/name: zookeeper
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/component: zookeeper
  serviceName: release-name-zookeeper-headless
  updateStrategy:
    rollingUpdate: {}
    type: RollingUpdate
  template:
    metadata:
      annotations:
      labels:
        app.kubernetes.io/name: zookeeper
        helm.sh/chart: zookeeper-11.0.3
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/component: zookeeper
    spec:
      serviceAccountName: default
      
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: zookeeper
                    app.kubernetes.io/instance: release-name
                    app.kubernetes.io/component: zookeeper
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      securityContext:
        fsGroup: 1001
      initContainers:
      containers:
        - name: zookeeper
          image: docker.io/bitnami/zookeeper:3.8.0-debian-11-r74
          imagePullPolicy: "IfNotPresent"
          securityContext:
            allowPrivilegeEscalation: false
            runAsNonRoot: true
            runAsUser: 1001
          command:
            - /scripts/setup.sh
          resources:
            limits: {}
            requests:
              cpu: 250m
              memory: 256Mi
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: ZOO_DATA_LOG_DIR
              value: ""
            - name: ZOO_PORT_NUMBER
              value: "2181"
            - name: ZOO_TICK_TIME
              value: "2000"
            - name: ZOO_INIT_LIMIT
              value: "10"
            - name: ZOO_SYNC_LIMIT
              value: "5"
            - name: ZOO_PRE_ALLOC_SIZE
              value: "65536"
            - name: ZOO_SNAPCOUNT
              value: "100000"
            - name: ZOO_MAX_CLIENT_CNXNS
              value: "60"
            - name: ZOO_4LW_COMMANDS_WHITELIST
              value: "srvr, mntr, ruok"
            - name: ZOO_LISTEN_ALLIPS_ENABLED
              value: "no"
            - name: ZOO_AUTOPURGE_INTERVAL
              value: "0"
            - name: ZOO_AUTOPURGE_RETAIN_COUNT
              value: "3"
            - name: ZOO_MAX_SESSION_TIMEOUT
              value: "40000"
            - name: ZOO_SERVERS
              value: release-name-zookeeper-0.release-name-zookeeper-headless.default.svc.cluster.local:2888:3888::1 
            - name: ZOO_ENABLE_AUTH
              value: "no"
            - name: ZOO_ENABLE_QUORUM_AUTH
              value: "no"
            - name: ZOO_HEAP_SIZE
              value: "1024"
            - name: ZOO_LOG_LEVEL
              value: "ERROR"
            - name: ALLOW_ANONYMOUS_LOGIN
              value: "yes"
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.name
          ports:
            - name: client
              containerPort: 2181
            - name: follower
              containerPort: 2888
            - name: election
              containerPort: 3888
          livenessProbe:
            failureThreshold: 6
            initialDelaySeconds: 30
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            exec:
              command: ['/bin/bash', '-c', 'echo "ruok" | timeout 2 nc -w 2 localhost 2181 | grep imok']
          readinessProbe:
            failureThreshold: 6
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            exec:
              command: ['/bin/bash', '-c', 'echo "ruok" | timeout 2 nc -w 2 localhost 2181 | grep imok']
          volumeMounts:
            - name: scripts
              mountPath: /scripts/setup.sh
              subPath: setup.sh
            - name: data
              mountPath: /bitnami/zookeeper
      volumes:
        - name: scripts
          configMap:
            name: release-name-zookeeper-scripts
            defaultMode: 0755
  volumeClaimTemplates:
    - metadata:
        name: data
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: "8Gi"
---
# Source: hermes/charts/kafka/templates/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: release-name-kafka
  namespace: "default"
  labels:
    app.kubernetes.io/name: kafka
    helm.sh/chart: kafka-20.0.4
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: kafka
spec:
  podManagementPolicy: Parallel
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: kafka
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/component: kafka
  serviceName: release-name-kafka-headless
  updateStrategy:
    rollingUpdate: {}
    type: RollingUpdate
  template:
    metadata:
      labels:
        app.kubernetes.io/name: kafka
        helm.sh/chart: kafka-20.0.4
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/component: kafka
      annotations:
    spec:
      
      hostNetwork: false
      hostIPC: false
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: kafka
                    app.kubernetes.io/instance: release-name
                    app.kubernetes.io/component: kafka
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      securityContext:
        fsGroup: 1001
      serviceAccountName: release-name-kafka
      containers:
        - name: kafka
          image: docker.io/bitnami/kafka:3.3.1-debian-11-r34
          imagePullPolicy: "IfNotPresent"
          securityContext:
            allowPrivilegeEscalation: false
            runAsNonRoot: true
            runAsUser: 1001
          command:
            - /scripts/setup.sh
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: MY_POD_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
            - name: MY_POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: KAFKA_CFG_ZOOKEEPER_CONNECT
              value: "release-name-zookeeper"
            - name: KAFKA_INTER_BROKER_LISTENER_NAME
              value: "INTERNAL"
            - name: KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP
              value: "INTERNAL:PLAINTEXT,CLIENT:PLAINTEXT"
            - name: KAFKA_CFG_LISTENERS
              value: "INTERNAL://:9093,CLIENT://:9092"
            - name: KAFKA_CFG_ADVERTISED_LISTENERS
              value: "INTERNAL://$(MY_POD_NAME).release-name-kafka-headless.default.svc.cluster.local:9093,CLIENT://$(MY_POD_NAME).release-name-kafka-headless.default.svc.cluster.local:9092"
            - name: ALLOW_PLAINTEXT_LISTENER
              value: "yes"
            - name: KAFKA_ZOOKEEPER_PROTOCOL
              value: PLAINTEXT
            - name: KAFKA_VOLUME_DIR
              value: "/bitnami/kafka"
            - name: KAFKA_LOG_DIR
              value: "/opt/bitnami/kafka/logs"
            - name: KAFKA_CFG_DELETE_TOPIC_ENABLE
              value: "false"
            - name: KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE
              value: "true"
            - name: KAFKA_HEAP_OPTS
              value: "-Xmx1024m -Xms1024m"
            - name: KAFKA_CFG_LOG_FLUSH_INTERVAL_MESSAGES
              value: "10000"
            - name: KAFKA_CFG_LOG_FLUSH_INTERVAL_MS
              value: "1000"
            - name: KAFKA_CFG_LOG_RETENTION_BYTES
              value: "1073741824"
            - name: KAFKA_CFG_LOG_RETENTION_CHECK_INTERVAL_MS
              value: "300000"
            - name: KAFKA_CFG_LOG_RETENTION_HOURS
              value: "168"
            - name: KAFKA_CFG_MESSAGE_MAX_BYTES
              value: "1000012"
            - name: KAFKA_CFG_LOG_SEGMENT_BYTES
              value: "1073741824"
            - name: KAFKA_CFG_LOG_DIRS
              value: "/bitnami/kafka/data"
            - name: KAFKA_CFG_DEFAULT_REPLICATION_FACTOR
              value: "1"
            - name: KAFKA_CFG_OFFSETS_TOPIC_REPLICATION_FACTOR
              value: "1"
            - name: KAFKA_CFG_TRANSACTION_STATE_LOG_REPLICATION_FACTOR
              value: "1"
            - name: KAFKA_CFG_TRANSACTION_STATE_LOG_MIN_ISR
              value: "1"
            - name: KAFKA_CFG_NUM_IO_THREADS
              value: "8"
            - name: KAFKA_CFG_NUM_NETWORK_THREADS
              value: "3"
            - name: KAFKA_CFG_NUM_PARTITIONS
              value: "1"
            - name: KAFKA_CFG_NUM_RECOVERY_THREADS_PER_DATA_DIR
              value: "1"
            - name: KAFKA_CFG_SOCKET_RECEIVE_BUFFER_BYTES
              value: "102400"
            - name: KAFKA_CFG_SOCKET_REQUEST_MAX_BYTES
              value: "104857600"
            - name: KAFKA_CFG_SOCKET_SEND_BUFFER_BYTES
              value: "102400"
            - name: KAFKA_CFG_ZOOKEEPER_CONNECTION_TIMEOUT_MS
              value: "6000"
            - name: KAFKA_CFG_AUTHORIZER_CLASS_NAME
              value: ""
            - name: KAFKA_CFG_ALLOW_EVERYONE_IF_NO_ACL_FOUND
              value: "true"
            - name: KAFKA_CFG_SUPER_USERS
              value: "User:admin"
          ports:
            - name: kafka-client
              containerPort: 9092
            - name: kafka-internal
              containerPort: 9093
          livenessProbe:
            failureThreshold: 3
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            tcpSocket:
              port: kafka-client
          readinessProbe:
            failureThreshold: 6
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            tcpSocket:
              port: kafka-client
          resources:
            limits: {}
            requests: {}
          volumeMounts:
            - name: data
              mountPath: /bitnami/kafka
            - name: logs
              mountPath: /opt/bitnami/kafka/logs
            - name: scripts
              mountPath: /scripts/setup.sh
              subPath: setup.sh
      volumes:
        - name: scripts
          configMap:
            name: release-name-kafka-scripts
            defaultMode: 0755
        - name: logs
          emptyDir: {}
  volumeClaimTemplates:
    - metadata:
        name: data
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: "8Gi"
---
# Source: hermes/charts/apicurio-registry/templates/tests/test-connection.yaml
apiVersion: v1
kind: Pod
metadata:
  name: "release-name-apicurio-registry-test-connection"
  labels:
    helm.sh/chart: apicurio-registry-0.1.3
    app.kubernetes.io/name: apicurio-registry
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "2.1.0.Final"
    app.kubernetes.io/managed-by: Helm
  annotations:
    "helm.sh/hook": test
spec:
  containers:
    - name: wget
      image: busybox
      command: ['wget']
      args: ['release-name-apicurio-registry:80']
  restartPolicy: Never
---
# Source: hermes/templates/tests/test-job.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: "release-name-hermes-test-job"
  annotations:
    "helm.sh/hook": test
spec:
  activeDeadlineSeconds: 240
  backoffLimit: 0
  template:
    spec:
      shareProcessNamespace: true
      containers:
        - name: test-job
          image: touk/bats
          command:
            - /main-wrapper.sh
            - /usr/sbin/bats
          args:
            - -t
            - /suites
          env:
            - name: MANAGEMENT_URL
              value: "http://release-name-hermes-management:8080"
            - name: FRONTEND_URL
              value: "http://release-name-hermes-frontend:8080"
            - name: POD_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
            - name: WIREMOCK_URL
              value: "http://$(POD_IP):8080"
          volumeMounts:
            - name: suites
              mountPath: /suites
            - name: scripts
              mountPath: /main-wrapper.sh
              subPath: main-wrapper.sh
            - name: pids
              mountPath: /var/run/sidecars
        - name: test-wiremock
          image: rodolpheche/wiremock
          command:
            - /sidecar-wrapper.sh
            - /docker-entrypoint.sh
          args: ["java", "-cp", "/var/wiremock/lib/*:/var/wiremock/extensions/*", "com.github.tomakehurst.wiremock.standalone.WireMockServerRunner", "--verbose"]
          volumeMounts:
            - name: scripts
              mountPath: /sidecar-wrapper.sh
              subPath: sidecar-wrapper.sh
            - name: pids
              mountPath: /var/run/sidecars
      restartPolicy: Never
      volumes:
        - name: pids
          emptyDir: {}
        - name: suites
          configMap:
            name: release-name-hermes-test-suites
        - name: scripts
          configMap:
            name: release-name-hermes-test-scripts
            defaultMode: 0744
