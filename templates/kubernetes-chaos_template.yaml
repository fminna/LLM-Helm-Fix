---
# Source: kubernetes-chaos/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: k8s-chaos-admin
  labels:    
    app.kubernetes.io/component: kubernetes-chaos
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: k8s
    app.kubernetes.io/part-of: k8s 
    app.kubernetes.io/version: "3.6.0"
    helm.sh/chart: kubernetes-chaos-3.6.0 
    litmuschaos.io/version: 3.6.0
---
# Source: kubernetes-chaos/templates/clusterrole.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: k8s-chaos-admin
  labels:    
    app.kubernetes.io/component: kubernetes-chaos
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: k8s
    app.kubernetes.io/part-of: k8s 
    app.kubernetes.io/version: "3.6.0"
    helm.sh/chart: kubernetes-chaos-3.6.0 
    litmuschaos.io/version: 3.6.0
rules:
- apiGroups:
  - ""
  - "apps"
  - "batch"
  - "extensions"
  - "apps.openshift.io"
  - "argoproj.io"
  - "litmuschaos.io"
  resources:
  - "jobs"
  - "pods"
  - "pods/exec"
  - "pods/log"
  - "pods/eviction"
  - "daemonsets"
  - "replicasets"
  - "deployments"
  - "statefulsets"
  - "services"
  - "events"
  - "configmaps"
  - "secrets"
  - "networkpolicies"
  - "replicationcontrollers"
  - "deploymentconfigs"
  - "rollouts"
  - "chaosengines"
  - "chaosexperiments"
  - "chaosresults"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "deletecollection"
- apiGroups:
  - ""
  resources:
  - "nodes"
  verbs:
  - "get"
  - "list"
  - "patch"
  - "update"
---
# Source: kubernetes-chaos/templates/clusterrolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: k8s-chaos-admin 
  labels:    
    app.kubernetes.io/component: kubernetes-chaos
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: k8s
    app.kubernetes.io/part-of: k8s 
    app.kubernetes.io/version: "3.6.0"
    helm.sh/chart: kubernetes-chaos-3.6.0 
    litmuschaos.io/version: 3.6.0
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: k8s-chaos-admin
subjects:
- kind: ServiceAccount
  name: k8s-chaos-admin
  namespace: default
---
# Source: kubernetes-chaos/templates/container-kill.yaml
apiVersion: litmuschaos.io/v1alpha1
description:
  message: "Kills a container belonging to an application pod \n"
kind: ChaosExperiment
metadata:
  name: container-kill
  labels:    
    app.kubernetes.io/component: kubernetes-chaos
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: k8s
    app.kubernetes.io/part-of: k8s 
    app.kubernetes.io/version: "3.6.0"
    helm.sh/chart: kubernetes-chaos-3.6.0 
    litmuschaos.io/version: 3.6.0
spec:
  definition:
    scope: Namespaced
    permissions:
      - apiGroups:
          - ""
          - "apps"
          - "batch"
          - "apps.openshift.io"
          - "argoproj.io"
          - "litmuschaos.io"
        resources:
          - "jobs"
          - "pods"
          - "pods/log"
          - "events"
          - "replicationcontrollers"
          - "deployments"
          - "statefulsets"
          - "daemonsets"
          - "replicasets"
          - "deploymentconfigs"
          - "rollouts"
          - "pods/exec"
          - "chaosengines"
          - "chaosexperiments"
          - "chaosresults"
        verbs:
          - "create"
          - "list"
          - "get"
          - "update"
          - "patch"
          - "delete"
          - "deletecollection"
    image: "litmuschaos.docker.scarf.sh/litmuschaos/go-runner:3.6.0"
    imagePullPolicy: Always
    args:
    - -c
    - ./experiments -name container-kill
    command:
    - /bin/bash
    env:

    - name: TARGET_CONTAINER
      value: ''

    # Period to wait before injection of chaos in sec
    - name: RAMP_TIME
      value: ''

    # provide the chaos interval
    - name: CHAOS_INTERVAL
      value: '10'

    - name: SIGNAL
      value: 'SIGKILL'

    # provide the total chaos duration
    - name: TOTAL_CHAOS_DURATION
      value: '20'

    # provide the socket file path
    - name: SOCKET_PATH
      value: "/run/containerd/containerd.sock"

    # provide the name of container runtime
    # it supports docker, containerd, crio
    - name: CONTAINER_RUNTIME
      value: "containerd"

    - name: LIB_IMAGE
      value: "litmuschaos.docker.scarf.sh/litmuschaos/go-runner:3.6.0"

    - name: TARGET_PODS
      value: ''

    - name: PODS_AFFECTED_PERC
      value: ''

    ## it defines the sequence of chaos execution for multiple target pods
    ## supported values: serial, parallel
    - name: SEQUENCE
      value: 'parallel'

    labels:
      name: container-kill
      app.kubernetes.io/part-of: litmus
      app.kubernetes.io/runtime-api-usage: "true"
---
# Source: kubernetes-chaos/templates/disk-fill.yaml
apiVersion: litmuschaos.io/v1alpha1
description:
  message: |
    Fillup Ephemeral Storage of a Resource
kind: ChaosExperiment
metadata:
  name: disk-fill
  labels:    
    app.kubernetes.io/component: kubernetes-chaos
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: k8s
    app.kubernetes.io/part-of: k8s 
    app.kubernetes.io/version: "3.6.0"
    helm.sh/chart: kubernetes-chaos-3.6.0 
    litmuschaos.io/version: 3.6.0
spec:
  definition:
    scope: Namespaced
    permissions:
      - apiGroups:
          - ""
          - "apps"
          - "batch"
          - "apps.openshift.io"
          - "argoproj.io"
          - "litmuschaos.io"
        resources:
          - "jobs"
          - "pods"
          - "pods/exec"
          - "pods/log"
          - "replicationcontrollers"
          - "deployments"
          - "statefulsets"
          - "daemonsets"
          - "replicasets"
          - "deploymentconfigs"
          - "rollouts"
          - "events"
          - "chaosengines"
          - "chaosexperiments"
          - "chaosresults"
        verbs:
          - "create"
          - "list"
          - "get"
          - "patch"
          - "update"
          - "delete"
          - "deletecollection"
    image: "litmuschaos.docker.scarf.sh/litmuschaos/go-runner:3.6.0"
    imagePullPolicy: Always
    args:
    - -c
    - ./experiments -name disk-fill
    command:
    - /bin/bash
    env:

    - name: TARGET_CONTAINER
      value: ''

    - name: FILL_PERCENTAGE
      value: '80'

    - name: TOTAL_CHAOS_DURATION
      value: '60'

    # Period to wait before injection of chaos in sec
    - name: RAMP_TIME
      value: ''

    - name: LIB_IMAGE
      value: "litmuschaos.docker.scarf.sh/litmuschaos/go-runner:3.6.0"

    # provide the data block size
    # supported unit is KB
    - name: DATA_BLOCK_SIZE
      value: '256'

    - name: TARGET_PODS
      value: ''

    - name: EPHEMERAL_STORAGE_MEBIBYTES
      value: ''

    - name: PODS_AFFECTED_PERC
      value: ''

    ## it defines the sequence of chaos execution for multiple target pods
    ## supported values: serial, parallel
    - name: SEQUENCE
      value: 'parallel'

      # provide the socket file path
    - name: SOCKET_PATH
      value: "/run/containerd/containerd.sock"

      # provide the name of container runtime
      # it supports docker, containerd, crio
    - name: CONTAINER_RUNTIME
      value: "containerd"

    labels:
      name: disk-fill
      app.kubernetes.io/part-of: litmus
      app.kubernetes.io/host-path-usage: "true"
---
# Source: kubernetes-chaos/templates/disk-loss.yaml
apiVersion: litmuschaos.io/v1alpha1
description:
  message: |
    Detaching a persistent disk from a node/instance. Supports only for AWS and GCP
kind: ChaosExperiment
metadata:
  name: disk-loss
  labels:    
    app.kubernetes.io/component: kubernetes-chaos
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: k8s
    app.kubernetes.io/part-of: k8s 
    app.kubernetes.io/version: "3.6.0"
    helm.sh/chart: kubernetes-chaos-3.6.0 
    litmuschaos.io/version: 3.6.0
spec:
  definition:
    scope: Cluster
    permissions:
      - apiGroups:
          - ""
          - "batch"
          - "litmuschaos.io"
        resources:
          - "jobs"
          - "pods"
          - "events"
          - "pods/log"
          - "secrets"
          - "chaosengines"
          - "chaosexperiments"
          - "chaosresults"
        verbs:
          - "create"
          - "list"
          - "get"
          - "patch"
          - "update"
          - "delete"
    image: "litmuschaos.docker.scarf.sh/litmuschaos/ansible-runner:3.6.0"
    imagePullPolicy: Always
    args:
    - -c
    - ansible-playbook ./experiments/generic/disk_loss/disk_loss_ansible_logic.yml -i /etc/ansible/hosts -vv; exit 0
    command:
    - /bin/bash
    env:
    - name: ANSIBLE_STDOUT_CALLBACK
      value: 'default'

    - name: TOTAL_CHAOS_DURATION
      value: '15'

    # Period to wait before injection of chaos in sec
    - name: RAMP_TIME
      value: ''

    - name: APP_CHECK
      value: 'true'

    # GKE and AWS supported
    - name: CLOUD_PLATFORM
      value: 'GKE'

    - name: PROJECT_ID
      value: ''

    # provide the LIB
    # only litmus supported
    - name: LIB
      value: 'litmus'

    - name: NODE_NAME
      value: ''

    - name: DISK_NAME
      value: ''

    - name: ZONE_NAME
      value: ''

    - name: DEVICE_NAME
      value: ''

    labels:
      name: disk-loss
      app.kubernetes.io/part-of: litmus
    secrets:
    - name: cloud-secret
      mountPath: /tmp/
---
# Source: kubernetes-chaos/templates/docker-service-kill.yaml
apiVersion: litmuschaos.io/v1alpha1
description:
  message: |
    Kills the docker service on the application node to check the resiliency.
kind: ChaosExperiment
metadata:
  name: docker-service-kill
  labels:    
    app.kubernetes.io/component: kubernetes-chaos
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: k8s
    app.kubernetes.io/part-of: k8s 
    app.kubernetes.io/version: "3.6.0"
    helm.sh/chart: kubernetes-chaos-3.6.0 
    litmuschaos.io/version: 3.6.0
spec:
  definition:
    scope: Cluster
    permissions:
      - apiGroups:
          - ""
          - "batch"
          - "apps"
          - "litmuschaos.io"
        resources:
          - "jobs"
          - "pods"
          - "pods/log"
          - "events"
          - "chaosengines"
          - "chaosexperiments"
          - "chaosresults"
        verbs:
          - "create"
          - "list"
          - "get"
          - "patch"
          - "update"
          - "delete"
      - apiGroups:
          - ""
        resources:
          - "nodes"
        verbs:
          - "get"
          - "list"
    image: "litmuschaos.docker.scarf.sh/litmuschaos/go-runner:3.6.0"
    imagePullPolicy: Always
    args:
    - -c
    - ./experiments -name docker-service-kill
    command:
    - /bin/bash
    env:
    - name: TOTAL_CHAOS_DURATION
      value: '90' # in seconds

    # Period to wait before injection of chaos in sec
    - name: RAMP_TIME
      value: ''

    - name: NODE_LABEL
      value: ''

    # provide lib image
    - name: LIB_IMAGE
      value: 'ubuntu:16.04'

    # provide the target node name
    - name: TARGET_NODE
      value: ''

    labels:
      name: docker-service-kill
      app.kubernetes.io/part-of: litmus
      app.kubernetes.io/host-path-usage: "true"
---
# Source: kubernetes-chaos/templates/kubelet-service-kill.yaml
apiVersion: litmuschaos.io/v1alpha1
description:
  message: |
    Kills the kubelet service on the application node to check the resiliency.
kind: ChaosExperiment
metadata:
  name: kubelet-service-kill
  labels:    
    app.kubernetes.io/component: kubernetes-chaos
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: k8s
    app.kubernetes.io/part-of: k8s 
    app.kubernetes.io/version: "3.6.0"
    helm.sh/chart: kubernetes-chaos-3.6.0 
    litmuschaos.io/version: 3.6.0
spec:
  definition:
    scope: Cluster
    permissions:
      - apiGroups:
          - ""
          - "batch"
          - "litmuschaos.io"
        resources:
          - "jobs"
          - "pods"
          - "pods/log"
          - "pods/exec"
          - "events"
          - "chaosengines"
          - "chaosexperiments"
          - "chaosresults"
        verbs:
          - "create"
          - "list"
          - "get"
          - "patch"
          - "update"
          - "delete"
          - "deletecollection"
      - apiGroups:
          - ""
        resources:
          - "nodes"
        verbs:
          - "get"
          - "list"
    image: "litmuschaos.docker.scarf.sh/litmuschaos/go-runner:3.6.0"
    imagePullPolicy: Always
    args:
    - -c
    - ./experiments -name kubelet-service-kill
    command:
    - /bin/bash
    env:

    - name: TOTAL_CHAOS_DURATION
      value: '90' # in seconds

    # Period to wait before and after injection of chaos in sec
    - name: RAMP_TIME
      value: ''

    - name: NODE_LABEL
      value: ''

    - name: LIB_IMAGE
      value: 'ubuntu:16.04'

    # provide node name
    - name: TARGET_NODE
      value: ''

    labels:
      name: kubelet-service-kill
      app.kubernetes.io/part-of: litmus
      app.kubernetes.io/host-path-usage: "true"
---
# Source: kubernetes-chaos/templates/node-cpu-hog.yaml
apiVersion: litmuschaos.io/v1alpha1
description:
  message: |
    Give a cpu spike on a node belonging to a deployment
kind: ChaosExperiment
metadata:
  name: node-cpu-hog
  labels:    
    app.kubernetes.io/component: kubernetes-chaos
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: k8s
    app.kubernetes.io/part-of: k8s 
    app.kubernetes.io/version: "3.6.0"
    helm.sh/chart: kubernetes-chaos-3.6.0 
    litmuschaos.io/version: 3.6.0
spec:
  definition:
    scope: Cluster
    permissions:
      - apiGroups:
          - ""
          - "batch"
          - "litmuschaos.io"
        resources:
          - "jobs"
          - "pods"
          - "pods/log"
          - "pods/exec"
          - "events"
          - "chaosengines"
          - "chaosexperiments"
          - "chaosresults"
        verbs:
          - "create"
          - "list"
          - "get"
          - "patch"
          - "update"
          - "delete"
          - "deletecollection"
      - apiGroups:
          - ""
        resources:
          - "nodes"
        verbs:
          - "get"
          - "list"
    image: "litmuschaos.docker.scarf.sh/litmuschaos/go-runner:3.6.0"
    imagePullPolicy: Always
    args:
    - -c
    - ./experiments -name node-cpu-hog
    command:
    - /bin/bash
    env:

    - name: TOTAL_CHAOS_DURATION
      value: '60'

    # Period to wait before injection of chaos in sec
    - name: RAMP_TIME
      value: ''

    # Enter the number of CPU cores
    - name: NODE_CPU_CORE
      value: '1'

    - name: CPU_LOAD
      value: '0'

    # ENTER THE COMMA SEPARATED TARGET NODES NAME
    - name: TARGET_NODES
      value: ''

    - name: NODE_LABEL
      value: ''

    ##TODO: Sync w/ linuxStressNG values
    - name: LIB_IMAGE
      value: "litmuschaos.docker.scarf.sh/litmuschaos/go-runner:3.6.0"

    ## percentage of total nodes to target
    - name: NODES_AFFECTED_PERC
      value: ''

    ## it defines the sequence of chaos execution for multiple target nodes
    ## supported values: serial, parallel
    - name: SEQUENCE
      value: 'parallel'

    labels:
      name: node-cpu-hog
      app.kubernetes.io/part-of: litmus
---
# Source: kubernetes-chaos/templates/node-drain.yaml
apiVersion: litmuschaos.io/v1alpha1
description:
  message: |
    Drain the node where application pod is scheduled
kind: ChaosExperiment
metadata:
  name: node-drain
  labels:    
    app.kubernetes.io/component: kubernetes-chaos
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: k8s
    app.kubernetes.io/part-of: k8s 
    app.kubernetes.io/version: "3.6.0"
    helm.sh/chart: kubernetes-chaos-3.6.0 
    litmuschaos.io/version: 3.6.0
spec:
  definition:
    scope: Cluster
    permissions:
      - apiGroups:
          - ""
          - "batch"
          - "litmuschaos.io"
          - "apps"
        resources:
          - "jobs"
          - "pods"
          - "events"
          - "pods/log"
          - "pods/exec"
          - "daemonsets"
          - "pods/eviction"
          - "chaosengines"
          - "chaosexperiments"
          - "chaosresults"
        verbs:
          - "create"
          - "list"
          - "get"
          - "patch"
          - "update"
          - "delete"
          - "deletecollection"
      - apiGroups:
          - ""
        resources:
          - "nodes"
        verbs:
          - "get"
          - "list"
          - "patch"
    image: "litmuschaos.docker.scarf.sh/litmuschaos/go-runner:3.6.0"
    imagePullPolicy: Always
    args:
    - -c
    - ./experiments -name node-drain
    command:
    - /bin/bash
    env:

    - name: TARGET_NODE
      value: ''

    - name: NODE_LABEL
      value: ''

    - name: TOTAL_CHAOS_DURATION
      value: '60'

    # Period to wait before injection of chaos in sec
    - name: RAMP_TIME
      value: ''

    labels:
      name: node-drain
      app.kubernetes.io/part-of: litmus
---
# Source: kubernetes-chaos/templates/node-io-stress.yaml
apiVersion: litmuschaos.io/v1alpha1
description:
  message: |
    Give IO disk stress on a node belonging to a deployment
kind: ChaosExperiment
metadata:
  name: node-io-stress
  labels:    
    app.kubernetes.io/component: kubernetes-chaos
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: k8s
    app.kubernetes.io/part-of: k8s 
    app.kubernetes.io/version: "3.6.0"
    helm.sh/chart: kubernetes-chaos-3.6.0 
    litmuschaos.io/version: 3.6.0
spec:
  definition:
    scope: Cluster
    permissions:
      - apiGroups:
          - ""
          - "batch"
          - "litmuschaos.io"
        resources:
          - "jobs"
          - "pods"
          - "pods/log"
          - "pods/exec"
          - "events"
          - "chaosengines"
          - "chaosexperiments"
          - "chaosresults"
        verbs:
          - "create"
          - "list"
          - "get"
          - "patch"
          - "update"
          - "delete"
          - "deletecollection"
      - apiGroups:
          - ""
        resources:
          - "nodes"
        verbs:
          - "get"
          - "list"
    image: "litmuschaos.docker.scarf.sh/litmuschaos/go-runner:3.6.0"
    imagePullPolicy: Always
    args:
    - -c
    - ./experiments -name node-io-stress
    command:
    - /bin/bash
    env:

    - name: TOTAL_CHAOS_DURATION
      value: '120'

    # specify the size as percentage of free space on the file system
    # default value 90 (in percentage)
    - name: FILESYSTEM_UTILIZATION_PERCENTAGE
      value: '10'

    # we can specify the size in Gigabyte (Gb) also in place of percentage of free space
    # NOTE: for selecting this option FILESYSTEM_UTILIZATION_PERCENTAGE should be empty
    - name: FILESYSTEM_UTILIZATION_BYTES
      value: ''

    ## Number of core of CPU
    - name: CPU
      value: '1'

    # Total number of workers default value is 4
    - name: NUMBER_OF_WORKERS
      value: '4'

    ## Total number of vm workers
    - name: VM_WORKERS
      value: '1'

    ## enter the comma separated target nodes name
    - name: TARGET_NODES
      value: ''

    - name: NODE_LABEL
      value: ''

    # Period to wait before and after injection of chaos in sec
    - name: RAMP_TIME
      value: ''

    # provide lib image
    - name: LIB_IMAGE
      value: "litmuschaos.docker.scarf.sh/litmuschaos/go-runner:3.6.0"

    ## percentage of total nodes to target
    - name: NODES_AFFECTED_PERC
      value: ''

    ## it defines the sequence of chaos execution for multiple target nodes
    ## supported values: serial, parallel
    - name: SEQUENCE
      value: 'parallel'

    labels:
      name: node-io-stress
      app.kubernetes.io/part-of: litmus
---
# Source: kubernetes-chaos/templates/node-memory-hog.yaml
apiVersion: litmuschaos.io/v1alpha1
description:
  message: |
    Give a memory hog on a node belonging to a deployment
kind: ChaosExperiment
metadata:
  name: node-memory-hog
  labels:    
    app.kubernetes.io/component: kubernetes-chaos
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: k8s
    app.kubernetes.io/part-of: k8s 
    app.kubernetes.io/version: "3.6.0"
    helm.sh/chart: kubernetes-chaos-3.6.0 
    litmuschaos.io/version: 3.6.0
spec:
  definition:
    scope: Cluster
    permissions:
      - apiGroups:
          - ""
          - "batch"
          - "litmuschaos.io"
        resources:
          - "jobs"
          - "pods"
          - "pods/log"
          - "pods/exec"
          - "events"
          - "chaosengines"
          - "chaosexperiments"
          - "chaosresults"
        verbs:
          - "create"
          - "list"
          - "get"
          - "patch"
          - "update"
          - "delete"
          - "deletecollection"
      - apiGroups:
          - ""
        resources:
          - "nodes"
        verbs:
          - "get"
          - "list"
    image: "litmuschaos.docker.scarf.sh/litmuschaos/go-runner:3.6.0"
    imagePullPolicy: Always
    args:
    - -c
    - ./experiments -name node-memory-hog
    command:
    - /bin/bash
    env:

    - name: TOTAL_CHAOS_DURATION
      value: '120'

    ## Specify the size as percent of total node capacity Ex: '30'
    ## NOTE: for selecting this option keep MEMORY_CONSUMPTION_MEBIBYTES is 0
    - name: MEMORY_CONSUMPTION_PERCENTAGE
      value: '0'

    ## Specify the amount of memory to be consumed in mebibytes
    ## NOTE: for selecting this option keep MEMORY_CONSUMPTION_PERCENTAGE empty
    - name: MEMORY_CONSUMPTION_MEBIBYTES
      value: '0'

    - name: NUMBER_OF_WORKERS
      value: '1'

     ## enter the comma separated target nodes name
    - name: TARGET_NODES
      value: ''

    - name: NODE_LABEL
      value: ''

    # Period to wait before injection of chaos in sec
    - name: RAMP_TIME
      value: ''

    # provide lib image
    - name: LIB_IMAGE
      value: "litmuschaos.docker.scarf.sh/litmuschaos/go-runner:3.6.0"

    ## percentage of total nodes to target
    - name: NODES_AFFECTED_PERC
      value: ''

    ## it defines the sequence of chaos execution for multiple target nodes
    ## supported values: serial, parallel
    - name: SEQUENCE
      value: 'parallel'

    labels:
      name: node-memory-hog
      app.kubernetes.io/part-of: litmus
---
# Source: kubernetes-chaos/templates/node-taint.yaml
apiVersion: litmuschaos.io/v1alpha1
description:
  message: |
    Taint the node where application pod is scheduled
kind: ChaosExperiment
metadata:
  name: node-taint
  labels:    
    app.kubernetes.io/component: kubernetes-chaos
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: k8s
    app.kubernetes.io/part-of: k8s 
    app.kubernetes.io/version: "3.6.0"
    helm.sh/chart: kubernetes-chaos-3.6.0 
    litmuschaos.io/version: 3.6.0
spec:
  definition:
    scope: Cluster
    permissions:
      - apiGroups:
          - ""
          - "batch"
          - "apps"
          - "litmuschaos.io"
        resources:
          - "jobs"
          - "pods"
          - "events"
          - "pods/log"
          - "pods/exec"
          - "daemonsets"
          - "pods/eviction"
          - "chaosengines"
          - "chaosexperiments"
          - "chaosresults"
        verbs:
          - "create"
          - "list"
          - "get"
          - "patch"
          - "update"
          - "delete"
          - "deletecollection"
      - apiGroups:
          - ""
        resources:
          - "nodes"
        verbs:
          - "get"
          - "list"
          - "patch"
          - "update"
    image: "litmuschaos.docker.scarf.sh/litmuschaos/go-runner:3.6.0"
    imagePullPolicy: Always
    args:
    - -c
    - ./experiments -name node-taint
    command:
    - /bin/bash
    env:

    - name: TARGET_NODE
      value: ''

    - name: NODE_LABEL
      value: ''

    - name: TOTAL_CHAOS_DURATION
      value: '60'

    # Period to wait before and after injection of chaos in sec
    - name: RAMP_TIME
      value: ''

    # set taint label & effect
    # key=value:effect or key:effect
    - name: TAINTS
      value: ''

    labels:
      name: node-taint
      app.kubernetes.io/part-of: litmus
---
# Source: kubernetes-chaos/templates/pod-autoscaler.yaml
apiVersion: litmuschaos.io/v1alpha1
description:
  message: |
    Scale the application replicas and test the node autoscaling on cluster
kind: ChaosExperiment
metadata:
  name: pod-autoscaler
  labels:    
    app.kubernetes.io/component: kubernetes-chaos
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: k8s
    app.kubernetes.io/part-of: k8s 
    app.kubernetes.io/version: "3.6.0"
    helm.sh/chart: kubernetes-chaos-3.6.0 
    litmuschaos.io/version: 3.6.0
spec:
  definition:
    scope: Cluster
    permissions:
      - apiGroups:
          - ""
          - "batch"
          - "apps"
          - "litmuschaos.io"
        resources:
          - "jobs"
          - "pods"
          - "pods/log"
          - "pods/exec"
          - "deployments"
          - "statefulsets"
          - "events"
          - "chaosengines"
          - "chaosexperiments"
          - "chaosresults"
        verbs:
          - "create"
          - "list"
          - "get"
          - "patch"
          - "update"
          - "delete"
          - "deletecollection"
      - apiGroups:
          - ""
        resources:
          - "nodes"
        verbs:
          - "get"
          - "list"
          - "create"
          - "patch"
          - "update"
    image: "litmuschaos.docker.scarf.sh/litmuschaos/go-runner:3.6.0"
    imagePullPolicy: Always
    args:
    - -c
    - ./experiments -name pod-autoscaler
    command:
    - /bin/bash
    env:

    - name: TOTAL_CHAOS_DURATION
      value: '60'

    # Period to wait before and after injection of chaos in sec
    - name: RAMP_TIME
      value: ''

    # Number of replicas to scale
    - name: REPLICA_COUNT
      value: '5'

    labels:
      name: pod-autoscaler
      app.kubernetes.io/part-of: litmus
---
# Source: kubernetes-chaos/templates/pod-cpu-hog-exec.yaml
apiVersion: litmuschaos.io/v1alpha1
description:
  message: |
    Injects cpu consumption on pods belonging to an app deployment
kind: ChaosExperiment
metadata:
  name: pod-cpu-hog-exec
  labels:    
    app.kubernetes.io/component: kubernetes-chaos
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: k8s
    app.kubernetes.io/part-of: k8s 
    app.kubernetes.io/version: "3.6.0"
    helm.sh/chart: kubernetes-chaos-3.6.0 
    litmuschaos.io/version: 3.6.0
spec:
  definition:
    scope: Namespaced
    permissions:
      - apiGroups:
          - ""
          - "batch"
          - "apps"
          - "apps.openshift.io"
          - "argoproj.io"
          - "litmuschaos.io"
        resources:
          - "jobs"
          - "pods"
          - "pods/log"
          - "events"
          - "replicationcontrollers"
          - "deployments"
          - "statefulsets"
          - "daemonsets"
          - "replicasets"
          - "deploymentconfigs"
          - "rollouts"
          - "pods/exec"
          - "chaosengines"
          - "chaosexperiments"
          - "chaosresults"
        verbs:
          - "create"
          - "list"
          - "get"
          - "patch"
          - "update"
          - "delete"
          - "deletecollection"
    image: "litmuschaos.docker.scarf.sh/litmuschaos/go-runner:3.6.0"
    imagePullPolicy: Always
    args:
    - -c
    - ./experiments -name pod-cpu-hog-exec
    command:
    - /bin/bash
    env:

    - name: TOTAL_CHAOS_DURATION
      value: '60'

    - name: CPU_CORES
      value: '1'

    # Percentage of total pods to target
    - name: PODS_AFFECTED_PERC
      value: ''

    # Period to wait before injection of chaos in sec
    - name: RAMP_TIME
      value: ''

    ## it defines the sequence of chaos execution for multiple target pods
    ## supported values: serial, parallel
    - name: SEQUENCE
      value: 'parallel'

    - name: TARGET_PODS
      value: ''

    labels:
      name: pod-cpu-hog-exec
      app.kubernetes.io/part-of: litmus
---
# Source: kubernetes-chaos/templates/pod-cpu-hog.yaml
apiVersion: litmuschaos.io/v1alpha1
description:
  message: |
    Injects cpu consumption on pods belonging to an app deployment
kind: ChaosExperiment
metadata:
  name: pod-cpu-hog
  labels:    
    app.kubernetes.io/component: kubernetes-chaos
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: k8s
    app.kubernetes.io/part-of: k8s 
    app.kubernetes.io/version: "3.6.0"
    helm.sh/chart: kubernetes-chaos-3.6.0 
    litmuschaos.io/version: 3.6.0
spec:
  definition:
    scope: Namespaced
    permissions:
      - apiGroups:
          - ""
          - "batch"
          - "apps"
          - "apps.openshift.io"
          - "argoproj.io"
          - "litmuschaos.io"
        resources:
          - "jobs"
          - "pods"
          - "pods/log"
          - "events"
          - "replicationcontrollers"
          - "deployments"
          - "statefulsets"
          - "daemonsets"
          - "replicasets"
          - "deploymentconfigs"
          - "rollouts"
          - "pods/exec"
          - "chaosengines"
          - "chaosexperiments"
          - "chaosresults"
        verbs:
          - "create"
          - "list"
          - "get"
          - "patch"
          - "update"
          - "delete"
          - "deletecollection"
    image: "litmuschaos.docker.scarf.sh/litmuschaos/go-runner:3.6.0"
    imagePullPolicy: Always
    args:
    - -c
    - ./experiments -name pod-cpu-hog
    command:
    - /bin/bash
    env:

    - name: TOTAL_CHAOS_DURATION
      value: '60'

    - name: CPU_CORES
      value: '1'

    - name: CPU_LOAD
      value: '100'

    # Percentage of total pods to target
    - name: PODS_AFFECTED_PERC
      value: ''

    # Period to wait before injection of chaos in sec
    - name: RAMP_TIME
      value: ''

    ## it defines the sequence of chaos execution for multiple target pods
    ## supported values: serial, parallel
    - name: SEQUENCE
      value: 'parallel'

    - name: LIB_IMAGE
      value: "litmuschaos.docker.scarf.sh/litmuschaos/go-runner:3.6.0"

    - name: TARGET_PODS
      value: ''

      # provide the socket file path
    - name: SOCKET_PATH
      value: "/run/containerd/containerd.sock"

      # provide the name of container runtime
      # it supports docker, containerd, crio
    - name: CONTAINER_RUNTIME
      value: "containerd"

    labels:
      name: pod-cpu-hog
      app.kubernetes.io/part-of: litmus
      app.kubernetes.io/runtime-api-usage: "true"
---
# Source: kubernetes-chaos/templates/pod-delete.yaml
apiVersion: litmuschaos.io/v1alpha1
description:
  message: |
    Deletes a pod belonging to a deployment/statefulset/daemonset
kind: ChaosExperiment
metadata:
  name: pod-delete
  labels:    
    app.kubernetes.io/component: kubernetes-chaos
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: k8s
    app.kubernetes.io/part-of: k8s 
    app.kubernetes.io/version: "3.6.0"
    helm.sh/chart: kubernetes-chaos-3.6.0 
    litmuschaos.io/version: 3.6.0
spec:
  definition:
    scope: Namespaced
    permissions:
      - apiGroups:
          - ""
          - "apps"
          - "apps.openshift.io"
          - "argoproj.io"
          - "batch"
          - "litmuschaos.io"
        resources:
          - "deployments"
          - "jobs"
          - "pods"
          - "pods/log"
          - "replicationcontrollers"
          - "deployments"
          - "statefulsets"
          - "daemonsets"
          - "replicasets"
          - "deploymentconfigs"
          - "rollouts"
          - "pods/exec"
          - "events"
          - "chaosengines"
          - "chaosexperiments"
          - "chaosresults"
        verbs:
          - "create"
          - "list"
          - "get"
          - "patch"
          - "update"
          - "delete"
          - "deletecollection"
    image: "litmuschaos.docker.scarf.sh/litmuschaos/go-runner:3.6.0"
    imagePullPolicy: Always
    args:
    - -c
    - ./experiments -name pod-delete
    command:
    - /bin/bash
    env:

    - name: TOTAL_CHAOS_DURATION
      value: '15'

    # Period to wait before injection of chaos in sec
    - name: RAMP_TIME
      value: ''

    - name: FORCE
      value: 'true'

    - name: CHAOS_INTERVAL
      value: '5'

    # Percentage of total pods to target
    - name: PODS_AFFECTED_PERC
      value: ''

    - name: TARGET_PODS
      value: ''

    ## it defines the sequence of chaos execution for multiple target pods
    ## supported values: serial, parallel
    - name: SEQUENCE
      value: 'parallel'

    labels:
      name: pod-delete
      app.kubernetes.io/part-of: litmus
---
# Source: kubernetes-chaos/templates/pod-dns-error.yaml
apiVersion: litmuschaos.io/v1alpha1
description:
  message: |
    Pod DNS Error injects dns failure/error in target pod containers
kind: ChaosExperiment
metadata:
  name: pod-dns-error
  labels:    
    app.kubernetes.io/component: kubernetes-chaos
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: k8s
    app.kubernetes.io/part-of: k8s 
    app.kubernetes.io/version: "3.6.0"
    helm.sh/chart: kubernetes-chaos-3.6.0 
    litmuschaos.io/version: 3.6.0
spec:
  definition:
    scope: Namespaced
    permissions:
      - apiGroups:
          - ""
          - "batch"
          - "apps"
          - "apps.openshift.io"
          - "argoproj.io"
          - "litmuschaos.io"
        resources:
          - "jobs"
          - "pods"
          - "pods/log"
          - "events"
          - "replicationcontrollers"
          - "deployments"
          - "statefulsets"
          - "daemonsets"
          - "replicasets"
          - "deploymentconfigs"
          - "rollouts"
          - "pods/exec"
          - "chaosengines"
          - "chaosexperiments"
          - "chaosresults"
        verbs:
          - "create"
          - "list"
          - "get"
          - "patch"
          - "update"
          - "delete"
          - "deletecollection"
    image: "litmuschaos.docker.scarf.sh/litmuschaos/go-runner:3.6.0"
    imagePullPolicy: Always
    args:
    - -c
    - ./experiments -name pod-dns-error
    command:
    - /bin/bash
    env:

    - name: TARGET_CONTAINER
      value: ""

    # provide lib image
    - name: LIB_IMAGE
      value: "litmuschaos.docker.scarf.sh/litmuschaos/go-runner:3.6.0"

    - name: TOTAL_CHAOS_DURATION
      value: "60" # in seconds

    # Time period to wait before and after injection of chaos in sec
    - name: RAMP_TIME
      value: ""

    ## percentage of total pods to target
    - name: PODS_AFFECTED_PERC
      value: ""

    - name: TARGET_PODS
      value: ""

    # provide the name of container runtime, it supports docker, containerd, crio
    - name: CONTAINER_RUNTIME
      value: "containerd"

    # provide the socket file path
    - name: SOCKET_PATH
      value: "/run/containerd/containerd.sock"

    ## it defines the sequence of chaos execution for multiple target pods
    ## supported values: serial, parallel
    - name: SEQUENCE
      value: "parallel"

    # list of the target hostnames or kewywords eg. '["litmuschaos","chaosnative.io"]' . If empty all hostnames are targets
    - name: TARGET_HOSTNAMES
      value: ""

    # can be either exact or substring, determines whether the dns query has to match exactly with one of the targets or can have any of the targets as substring
    - name: MATCH_SCHEME
      value: "exact"
            
    labels:
      name: pod-dns-error
      app.kubernetes.io/part-of: litmus
      app.kubernetes.io/runtime-api-usage: "true"
---
# Source: kubernetes-chaos/templates/pod-dns-spoof.yaml
apiVersion: litmuschaos.io/v1alpha1
description:
  message: |
    Pod DNS Spoof can spoof particular dns requests in target pod container to desired target hostnames
kind: ChaosExperiment
metadata:
  name: pod-dns-spoof
  labels:    
    app.kubernetes.io/component: kubernetes-chaos
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: k8s
    app.kubernetes.io/part-of: k8s 
    app.kubernetes.io/version: "3.6.0"
    helm.sh/chart: kubernetes-chaos-3.6.0 
    litmuschaos.io/version: 3.6.0
spec:
  definition:
    scope: Namespaced
    permissions:
      - apiGroups:
          - ""
          - "batch"
          - "apps"
          - "apps.openshift.io"
          - "argoproj.io"
          - "litmuschaos.io"
        resources:
          - "jobs"
          - "pods"
          - "pods/log"
          - "events"
          - "replicationcontrollers"
          - "deployments"
          - "statefulsets"
          - "daemonsets"
          - "replicasets"
          - "deploymentconfigs"
          - "rollouts"
          - "pods/exec"
          - "chaosengines"
          - "chaosexperiments"
          - "chaosresults"
        verbs:
          - "create"
          - "list"
          - "get"
          - "patch"
          - "update"
          - "delete"
          - "deletecollection"
    image: "litmuschaos.docker.scarf.sh/litmuschaos/go-runner:3.6.0"
    imagePullPolicy: Always
    args:
    - -c
    - ./experiments -name pod-dns-spoof
    command:
    - /bin/bash
    env:

    - name: TARGET_CONTAINER
      value: ""

    # provide lib image
    - name: LIB_IMAGE
      value: "litmuschaos.docker.scarf.sh/litmuschaos/go-runner:3.6.0"

    - name: TOTAL_CHAOS_DURATION
      value: "60" # in seconds

    # Time period to wait before and after injection of chaos in sec
    - name: RAMP_TIME
      value: ""

    ## percentage of total pods to target
    - name: PODS_AFFECTED_PERC
      value: ""

    - name: TARGET_PODS
      value: ""

    # provide the name of container runtime, it supports docker, containerd, crio
    - name: CONTAINER_RUNTIME
      value: "containerd"

    # provide the socket file path
    - name: SOCKET_PATH
      value: "/run/containerd/containerd.sock"

    ## it defines the sequence of chaos execution for multiple target pods
    ## supported values: serial, parallel
    - name: SEQUENCE
      value: "parallel"

    # map of the target hostnames eg. '{"abc.com":"spoofabc.com"}' . If empty no queries will be spoofed
    - name: SPOOF_MAP
      value: ""
            
    labels:
      name: pod-dns-spoof
      app.kubernetes.io/part-of: litmus
      app.kubernetes.io/runtime-api-usage: "true"
---
# Source: kubernetes-chaos/templates/pod-http-latency.yaml
apiVersion: litmuschaos.io/v1alpha1
description:
  message: |
    Injects http request latency on pods belonging to an app deployment
kind: ChaosExperiment
metadata:
  name: pod-http-latency
  labels:    
    app.kubernetes.io/component: kubernetes-chaos
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: k8s
    app.kubernetes.io/part-of: k8s 
    app.kubernetes.io/version: "3.6.0"
    helm.sh/chart: kubernetes-chaos-3.6.0 
    litmuschaos.io/version: 3.6.0
spec:
  definition:
    scope: Namespaced
    permissions:
      # Create and monitor the experiment & helper pods
      - apiGroups: [""]
        resources: ["pods"]
        verbs: ["create","delete","get","list","patch","update", "deletecollection"]
      # Performs CRUD operations on the events inside chaosengine and chaosresult
      - apiGroups: [""]
        resources: ["events"]
        verbs: ["create","get","list","patch","update"]
      # Fetch configmaps details and mount it to the experiment pod (if specified)
      - apiGroups: [""]
        resources: ["configmaps"]
        verbs: ["get","list",]
      # Track and get the runner, experiment, and helper pods log
      - apiGroups: [""]
        resources: ["pods/log"]
        verbs: ["get","list","watch"]
      # for creating and managing to execute comands inside target container
      - apiGroups: [""]
        resources: ["pods/exec"]
        verbs: ["get","list","create"]
      # deriving the parent/owner details of the pod(if parent is anyof {deployment, statefulset, daemonsets})
      - apiGroups: ["apps"]
        resources: ["deployments","statefulsets","replicasets", "daemonsets"]
        verbs: ["list","get"]
      # deriving the parent/owner details of the pod(if parent is deploymentConfig)
      - apiGroups: ["apps.openshift.io"]
        resources: ["deploymentconfigs"]
        verbs: ["list","get"]
      # deriving the parent/owner details of the pod(if parent is deploymentConfig)
      - apiGroups: [""]
        resources: ["replicationcontrollers"]
        verbs: ["get","list"]
      # deriving the parent/owner details of the pod(if parent is argo-rollouts)
      - apiGroups: ["argoproj.io"]
        resources: ["rollouts"]
        verbs: ["list","get"]
      # for configuring and monitor the experiment job by the chaos-runner pod
      - apiGroups: ["batch"]
        resources: ["jobs"]
        verbs: ["create","list","get","delete","deletecollection"]
      # for creation, status polling and deletion of litmus chaos resources used within a chaos workflow
      - apiGroups: ["litmuschaos.io"]
        resources: ["chaosengines","chaosexperiments","chaosresults"]
        verbs: ["create","list","get","patch","update","delete"]
    image: "litmuschaos.docker.scarf.sh/litmuschaos/go-runner:3.6.0"
    imagePullPolicy: Always
    args:
    - -c
    - ./experiments -name pod-http-latency
    command:
    - /bin/bash
    env:

    - name: TARGET_CONTAINER
      value: ''

    # provide lib image
    - name: LIB_IMAGE
      value: "litmuschaos.docker.scarf.sh/litmuschaos/go-runner:3.6.0"

    - name: LATENCY
      value: '2000' #in ms

    # port of the target service
    - name: TARGET_SERVICE_PORT
      value: "80"

    # port on which the proxy will listen
    - name: PROXY_PORT
      value: "20000"

    # toxicity is the probability of the request to be affected
    # provide the percentage value in the range of 0-100
    # 0 means no request will be affected and 100 means all
    - name: TOXICITY
      value: "100"

    # network interface on which the proxy will listen
    - name: NETWORK_INTERFACE
      value: "eth0"

    - name: TOTAL_CHAOS_DURATION
      value: '60' # in seconds

    # Time period to wait before and after injection of chaos in sec
    - name: RAMP_TIME
      value: ''

    # percentage of total pods to target
    - name: PODS_AFFECTED_PERC
      value: ''

    - name: TARGET_PODS
      value: ''

      # provide the socket file path
    - name: SOCKET_PATH
      value: "/run/containerd/containerd.sock"

      # provide the name of container runtime
      # it supports docker, containerd, crio
    - name: CONTAINER_RUNTIME
      value: "containerd"

    # To select pods on specific node(s)
    - name: NODE_LABEL
      value: ''

    ## it defines the sequence of chaos execution for multiple target pods
    ## supported values: serial, parallel
    - name: SEQUENCE
      value: 'parallel'

    labels:
      name: pod-http-latency
      app.kubernetes.io/part-of: litmus
---
# Source: kubernetes-chaos/templates/pod-http-modify-body.yaml
apiVersion: litmuschaos.io/v1alpha1
description:
  message: |
    It injects the chaos inside the pod which modifies the body of the response from the provided application server to the body string provided by the user and reverts after a specified duration
kind: ChaosExperiment
metadata:
  name: pod-http-modify-body
  labels:    
    app.kubernetes.io/component: kubernetes-chaos
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: k8s
    app.kubernetes.io/part-of: k8s 
    app.kubernetes.io/version: "3.6.0"
    helm.sh/chart: kubernetes-chaos-3.6.0 
    litmuschaos.io/version: 3.6.0
spec:
  definition:
    scope: Namespaced
    permissions:
      # Create and monitor the experiment & helper pods
      - apiGroups: [""]
        resources: ["pods"]
        verbs: ["create","delete","get","list","patch","update", "deletecollection"]
      # Performs CRUD operations on the events inside chaosengine and chaosresult
      - apiGroups: [""]
        resources: ["events"]
        verbs: ["create","get","list","patch","update"]
      # Fetch configmaps details and mount it to the experiment pod (if specified)
      - apiGroups: [""]
        resources: ["configmaps"]
        verbs: ["get","list",]
      # Track and get the runner, experiment, and helper pods log
      - apiGroups: [""]
        resources: ["pods/log"]
        verbs: ["get","list","watch"]
      # for creating and managing to execute comands inside target container
      - apiGroups: [""]
        resources: ["pods/exec"]
        verbs: ["get","list","create"]
      # deriving the parent/owner details of the pod(if parent is anyof {deployment, statefulset, daemonsets})
      - apiGroups: ["apps"]
        resources: ["deployments","statefulsets","replicasets", "daemonsets"]
        verbs: ["list","get"]
      # deriving the parent/owner details of the pod(if parent is deploymentConfig)
      - apiGroups: ["apps.openshift.io"]
        resources: ["deploymentconfigs"]
        verbs: ["list","get"]
      # deriving the parent/owner details of the pod(if parent is deploymentConfig)
      - apiGroups: [""]
        resources: ["replicationcontrollers"]
        verbs: ["get","list"]
      # deriving the parent/owner details of the pod(if parent is argo-rollouts)
      - apiGroups: ["argoproj.io"]
        resources: ["rollouts"]
        verbs: ["list","get"]
      # for configuring and monitor the experiment job by the chaos-runner pod
      - apiGroups: ["batch"]
        resources: ["jobs"]
        verbs: ["create","list","get","delete","deletecollection"]
      # for creation, status polling and deletion of litmus chaos resources used within a chaos workflow
      - apiGroups: ["litmuschaos.io"]
        resources: ["chaosengines","chaosexperiments","chaosresults"]
        verbs: ["create","list","get","patch","update","delete"]
    image: "litmuschaos.docker.scarf.sh/litmuschaos/go-runner:3.6.0"
    imagePullPolicy: Always
    args:
    - -c
    - ./experiments -name pod-http-modify-body
    command:
    - /bin/bash
    env:

    - name: TARGET_CONTAINER
      value: ''

    # provide lib image
    - name: LIB_IMAGE
      value: "litmuschaos.docker.scarf.sh/litmuschaos/go-runner:3.6.0"

    # provide the body string to overwrite the response body
    # if no value is provided, response will be an empty body.
    - name: RESPONSE_BODY
      value: ''

    # port of the target service
    - name: TARGET_SERVICE_PORT
      value: "80"

    # port on which the proxy will listen
    - name: PROXY_PORT
      value: "20000"

    # toxicity is the probability of the request to be affected
    # provide the percentage value in the range of 0-100
    # 0 means no request will be affected and 100 means all
    - name: TOXICITY
      value: "100"

    # provide the encoding type for the response body
    # currently supported value are gzip, deflate
    # if empty no encoding will be applied
    - name: CONTENT_ENCODING
      value: ''

    # provide the content type for the response body
    - name: CONTENT_TYPE
      value: 'text/plain'

    # network interface on which the proxy will listen
    - name: NETWORK_INTERFACE
      value: "eth0"

    - name: TOTAL_CHAOS_DURATION
      value: '60' # in seconds

    # Time period to wait before and after injection of chaos in sec
    - name: RAMP_TIME
      value: ''

    # percentage of total pods to target
    - name: PODS_AFFECTED_PERC
      value: ''

    - name: TARGET_PODS
      value: ''

      # provide the socket file path
    - name: SOCKET_PATH
      value: "/run/containerd/containerd.sock"

      # provide the name of container runtime
      # it supports docker, containerd, crio
    - name: CONTAINER_RUNTIME
      value: "containerd"

    # To select pods on specific node(s)
    - name: NODE_LABEL
      value: ''

    ## it defines the sequence of chaos execution for multiple target pods
    ## supported values: serial, parallel
    - name: SEQUENCE
      value: 'parallel'

    labels:
      name: pod-http-modify-body
      app.kubernetes.io/part-of: litmus
---
# Source: kubernetes-chaos/templates/pod-http-modify-header.yaml
apiVersion: litmuschaos.io/v1alpha1
description:
  message: |
    It injects the chaos inside the pod which modifies the header of the request/response from the provided application server to the headers provided by the user and reverts after a specified duration
kind: ChaosExperiment
metadata:
  name: pod-http-modify-header
  labels:    
    app.kubernetes.io/component: kubernetes-chaos
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: k8s
    app.kubernetes.io/part-of: k8s 
    app.kubernetes.io/version: "3.6.0"
    helm.sh/chart: kubernetes-chaos-3.6.0 
    litmuschaos.io/version: 3.6.0
spec:
  definition:
    scope: Namespaced
    permissions:
      # Create and monitor the experiment & helper pods
      - apiGroups: [""]
        resources: ["pods"]
        verbs: ["create","delete","get","list","patch","update", "deletecollection"]
      # Performs CRUD operations on the events inside chaosengine and chaosresult
      - apiGroups: [""]
        resources: ["events"]
        verbs: ["create","get","list","patch","update"]
      # Fetch configmaps details and mount it to the experiment pod (if specified)
      - apiGroups: [""]
        resources: ["configmaps"]
        verbs: ["get","list",]
      # Track and get the runner, experiment, and helper pods log
      - apiGroups: [""]
        resources: ["pods/log"]
        verbs: ["get","list","watch"]
      # for creating and managing to execute comands inside target container
      - apiGroups: [""]
        resources: ["pods/exec"]
        verbs: ["get","list","create"]
      # deriving the parent/owner details of the pod(if parent is anyof {deployment, statefulset, daemonsets})
      - apiGroups: ["apps"]
        resources: ["deployments","statefulsets","replicasets", "daemonsets"]
        verbs: ["list","get"]
      # deriving the parent/owner details of the pod(if parent is deploymentConfig)
      - apiGroups: ["apps.openshift.io"]
        resources: ["deploymentconfigs"]
        verbs: ["list","get"]
      # deriving the parent/owner details of the pod(if parent is deploymentConfig)
      - apiGroups: [""]
        resources: ["replicationcontrollers"]
        verbs: ["get","list"]
      # deriving the parent/owner details of the pod(if parent is argo-rollouts)
      - apiGroups: ["argoproj.io"]
        resources: ["rollouts"]
        verbs: ["list","get"]
      # for configuring and monitor the experiment job by the chaos-runner pod
      - apiGroups: ["batch"]
        resources: ["jobs"]
        verbs: ["create","list","get","delete","deletecollection"]
      # for creation, status polling and deletion of litmus chaos resources used within a chaos workflow
      - apiGroups: ["litmuschaos.io"]
        resources: ["chaosengines","chaosexperiments","chaosresults"]
        verbs: ["create","list","get","patch","update","delete"]
    image: "litmuschaos.docker.scarf.sh/litmuschaos/go-runner:3.6.0"
    imagePullPolicy: Always
    args:
    - -c
    - ./experiments -name pod-http-modify-header
    command:
    - /bin/bash
    env:

    - name: TARGET_CONTAINER
      value: ''

    # provide lib image
    - name: LIB_IMAGE
      value: "litmuschaos.docker.scarf.sh/litmuschaos/go-runner:3.6.0"

    # map of headers to modify/add; Eg: {"X-Litmus-Test-Header": "X-Litmus-Test-Value"}
    # to remove a header, just set the value to ""; Eg: {"X-Litmus-Test-Header": ""}
    - name: HEADERS_MAP
      value: '{}'

    # whether to modify response headers or request headers. Accepted values: request, response
    - name: HEADER_MODE
      value: 'response'

    # port of the target service
    - name: TARGET_SERVICE_PORT
      value: "80"

    # port on which the proxy will listen
    - name: PROXY_PORT
      value: "20000"

    # network interface on which the proxy will listen
    - name: NETWORK_INTERFACE
      value: "eth0"

    # toxicity is the probability of the request to be affected
    # provide the percentage value in the range of 0-100
    # 0 means no request will be affected and 100 means all
    - name: TOXICITY
      value: "100"

    - name: TOTAL_CHAOS_DURATION
      value: '60' # in seconds

    # Time period to wait before and after injection of chaos in sec
    - name: RAMP_TIME
      value: ''

    # percentage of total pods to target
    - name: PODS_AFFECTED_PERC
      value: ''

    - name: TARGET_PODS
      value: ''

      # provide the socket file path
    - name: SOCKET_PATH
      value: "/run/containerd/containerd.sock"

      # provide the name of container runtime
      # it supports docker, containerd, crio
    - name: CONTAINER_RUNTIME
      value: "containerd"

    # To select pods on specific node(s)
    - name: NODE_LABEL
      value: ''

    ## it defines the sequence of chaos execution for multiple target pods
    ## supported values: serial, parallel
    - name: SEQUENCE
      value: 'parallel'

    labels:
      name: pod-http-modify-header
      app.kubernetes.io/part-of: litmus
---
# Source: kubernetes-chaos/templates/pod-http-reset-peer.yaml
apiVersion: litmuschaos.io/v1alpha1
description:
  message: |
    it injects chaos into the pod which stops outgoing http requests by resetting the TCP connection and then reverts back to the original state after a specified duration
kind: ChaosExperiment
metadata:
  name: pod-http-reset-peer
  labels:    
    app.kubernetes.io/component: kubernetes-chaos
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: k8s
    app.kubernetes.io/part-of: k8s 
    app.kubernetes.io/version: "3.6.0"
    helm.sh/chart: kubernetes-chaos-3.6.0 
    litmuschaos.io/version: 3.6.0
spec:
  definition:
    scope: Namespaced
    permissions:
      # Create and monitor the experiment & helper pods
      - apiGroups: [""]
        resources: ["pods"]
        verbs: ["create","delete","get","list","patch","update", "deletecollection"]
      # Performs CRUD operations on the events inside chaosengine and chaosresult
      - apiGroups: [""]
        resources: ["events"]
        verbs: ["create","get","list","patch","update"]
      # Fetch configmaps details and mount it to the experiment pod (if specified)
      - apiGroups: [""]
        resources: ["configmaps"]
        verbs: ["get","list",]
      # Track and get the runner, experiment, and helper pods log
      - apiGroups: [""]
        resources: ["pods/log"]
        verbs: ["get","list","watch"]
      # for creating and managing to execute comands inside target container
      - apiGroups: [""]
        resources: ["pods/exec"]
        verbs: ["get","list","create"]
      # deriving the parent/owner details of the pod(if parent is anyof {deployment, statefulset, daemonsets})
      - apiGroups: ["apps"]
        resources: ["deployments","statefulsets","replicasets", "daemonsets"]
        verbs: ["list","get"]
      # deriving the parent/owner details of the pod(if parent is deploymentConfig)
      - apiGroups: ["apps.openshift.io"]
        resources: ["deploymentconfigs"]
        verbs: ["list","get"]
      # deriving the parent/owner details of the pod(if parent is deploymentConfig)
      - apiGroups: [""]
        resources: ["replicationcontrollers"]
        verbs: ["get","list"]
      # deriving the parent/owner details of the pod(if parent is argo-rollouts)
      - apiGroups: ["argoproj.io"]
        resources: ["rollouts"]
        verbs: ["list","get"]
      # for configuring and monitor the experiment job by the chaos-runner pod
      - apiGroups: ["batch"]
        resources: ["jobs"]
        verbs: ["create","list","get","delete","deletecollection"]
      # for creation, status polling and deletion of litmus chaos resources used within a chaos workflow
      - apiGroups: ["litmuschaos.io"]
        resources: ["chaosengines","chaosexperiments","chaosresults"]
        verbs: ["create","list","get","patch","update","delete"]
    image: "litmuschaos.docker.scarf.sh/litmuschaos/go-runner:3.6.0"
    imagePullPolicy: Always
    args:
    - -c
    - ./experiments -name pod-http-reset-peer
    command:
    - /bin/bash
    env:

    - name: TARGET_CONTAINER
      value: ''

    # provide lib image
    - name: LIB_IMAGE
      value: "litmuschaos.docker.scarf.sh/litmuschaos/go-runner:3.6.0"

    # reset timeout specifies after how much duration to reset the connection
    - name: RESET_TIMEOUT
      value: '0' #in ms

    # port of the target service
    - name: TARGET_SERVICE_PORT
      value: "80"

    # port on which the proxy will listen
    - name: PROXY_PORT
      value: "20000"

    # toxicity is the probability of the request to be affected
    # provide the percentage value in the range of 0-100
    # 0 means no request will be affected and 100 means all
    - name: TOXICITY
      value: "100"

    # network interface on which the proxy will listen
    - name: NETWORK_INTERFACE
      value: "eth0"

    - name: TOTAL_CHAOS_DURATION
      value: '60' # in seconds

    # Time period to wait before and after injection of chaos in sec
    - name: RAMP_TIME
      value: ''

    # percentage of total pods to target
    - name: PODS_AFFECTED_PERC
      value: ''

    - name: TARGET_PODS
      value: ''

      # provide the socket file path
    - name: SOCKET_PATH
      value: "/run/containerd/containerd.sock"

      # provide the name of container runtime
      # it supports docker, containerd, crio
    - name: CONTAINER_RUNTIME
      value: "containerd"

    # To select pods on specific node(s)
    - name: NODE_LABEL
      value: ''

    ## it defines the sequence of chaos execution for multiple target pods
    ## supported values: serial, parallel
    - name: SEQUENCE
      value: 'parallel'

    labels:
      name: pod-http-reset-peer
      app.kubernetes.io/part-of: litmus
---
# Source: kubernetes-chaos/templates/pod-http-status-code.yaml
apiVersion: litmuschaos.io/v1alpha1
description:
  message: |
    It injects chaos inside the pod which modifies the status code of the response from the provided application server to desired status code provided by the user and reverts after a specified duration
kind: ChaosExperiment
metadata:
  name: pod-http-status-code
  labels:    
    app.kubernetes.io/component: kubernetes-chaos
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: k8s
    app.kubernetes.io/part-of: k8s 
    app.kubernetes.io/version: "3.6.0"
    helm.sh/chart: kubernetes-chaos-3.6.0 
    litmuschaos.io/version: 3.6.0
spec:
  definition:
    scope: Namespaced
    permissions:
      # Create and monitor the experiment & helper pods
      - apiGroups: [""]
        resources: ["pods"]
        verbs: ["create","delete","get","list","patch","update", "deletecollection"]
      # Performs CRUD operations on the events inside chaosengine and chaosresult
      - apiGroups: [""]
        resources: ["events"]
        verbs: ["create","get","list","patch","update"]
      # Fetch configmaps details and mount it to the experiment pod (if specified)
      - apiGroups: [""]
        resources: ["configmaps"]
        verbs: ["get","list",]
      # Track and get the runner, experiment, and helper pods log
      - apiGroups: [""]
        resources: ["pods/log"]
        verbs: ["get","list","watch"]
      # for creating and managing to execute comands inside target container
      - apiGroups: [""]
        resources: ["pods/exec"]
        verbs: ["get","list","create"]
      # deriving the parent/owner details of the pod(if parent is anyof {deployment, statefulset, daemonsets})
      - apiGroups: ["apps"]
        resources: ["deployments","statefulsets","replicasets", "daemonsets"]
        verbs: ["list","get"]
      # deriving the parent/owner details of the pod(if parent is deploymentConfig)
      - apiGroups: ["apps.openshift.io"]
        resources: ["deploymentconfigs"]
        verbs: ["list","get"]
      # deriving the parent/owner details of the pod(if parent is deploymentConfig)
      - apiGroups: [""]
        resources: ["replicationcontrollers"]
        verbs: ["get","list"]
      # deriving the parent/owner details of the pod(if parent is argo-rollouts)
      - apiGroups: ["argoproj.io"]
        resources: ["rollouts"]
        verbs: ["list","get"]
      # for configuring and monitor the experiment job by the chaos-runner pod
      - apiGroups: ["batch"]
        resources: ["jobs"]
        verbs: ["create","list","get","delete","deletecollection"]
      # for creation, status polling and deletion of litmus chaos resources used within a chaos workflow
      - apiGroups: ["litmuschaos.io"]
        resources: ["chaosengines","chaosexperiments","chaosresults"]
        verbs: ["create","list","get","patch","update","delete"]
    image: "litmuschaos.docker.scarf.sh/litmuschaos/go-runner:3.6.0"
    imagePullPolicy: Always
    args:
    - -c
    - ./experiments -name pod-http-status-code
    command:
    - /bin/bash
    env:

    - name: TARGET_CONTAINER
      value: ''

    # provide lib image
    - name: LIB_IMAGE
      value: "litmuschaos.docker.scarf.sh/litmuschaos/go-runner:3.6.0"

    # modified status code for the http response
    # if no value is provided, a random status code from the supported code list will selected
    # if an invalid status code is provided, the experiment will fail
    # supported status code list: [200, 201, 202, 204, 300, 301, 302, 304, 307, 400, 401, 403, 404, 500, 501, 502, 503, 504]
    - name: STATUS_CODE
      value: ''

    #  whether to modify the body as per the status code provided
    - name: "MODIFY_RESPONSE_BODY"
      value: "true"

    # port of the target service
    - name: TARGET_SERVICE_PORT
      value: "80"

    # port on which the proxy will listen
    - name: PROXY_PORT
      value: "20000"

    # toxicity is the probability of the request to be affected
    # provide the percentage value in the range of 0-100
    # 0 means no request will be affected and 100 means all
    - name: TOXICITY
      value: "100"

    # network interface on which the proxy will listen
    - name: NETWORK_INTERFACE
      value: "eth0"

    # provide the body string to overwrite the response body. This will be used only if MODIFY_RESPONSE_BODY is set to true
    - name: RESPONSE_BODY
      value: ''

    # provide the encoding type for the response body
    # currently supported value are gzip, deflate
    # if empty no encoding will be applied
    - name: CONTENT_ENCODING
      value: ''

    # provide the content type for the response body
    - name: CONTENT_TYPE
      value: 'text/plain'

    - name: TOTAL_CHAOS_DURATION
      value: '60' # in seconds

    # Time period to wait before and after injection of chaos in sec
    - name: RAMP_TIME
      value: ''

    # percentage of total pods to target
    - name: PODS_AFFECTED_PERC
      value: ''

    - name: TARGET_PODS
      value: ''

      # provide the socket file path
    - name: SOCKET_PATH
      value: "/run/containerd/containerd.sock"

      # provide the name of container runtime
      # it supports docker, containerd, crio
    - name: CONTAINER_RUNTIME
      value: "containerd"

    # To select pods on specific node(s)
    - name: NODE_LABEL
      value: ''

    ## it defines the sequence of chaos execution for multiple target pods
    ## supported values: serial, parallel
    - name: SEQUENCE
      value: 'parallel'

    labels:
      name: pod-http-status-code
      app.kubernetes.io/part-of: litmus
---
# Source: kubernetes-chaos/templates/pod-io-stress.yaml
apiVersion: litmuschaos.io/v1alpha1
description:
  message: |
    IO stress on a app pods belonging to an app deployment
kind: ChaosExperiment
metadata:
  name: pod-io-stress
  labels:    
    app.kubernetes.io/component: kubernetes-chaos
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: k8s
    app.kubernetes.io/part-of: k8s 
    app.kubernetes.io/version: "3.6.0"
    helm.sh/chart: kubernetes-chaos-3.6.0 
    litmuschaos.io/version: 3.6.0
spec:
  definition:
    scope: Namespaced
    permissions:
      - apiGroups:
          - ""
          - "batch"
          - "apps"
          - "apps.openshift.io"
          - "argoproj.io"
          - "litmuschaos.io"
        resources:
          - "jobs"
          - "pods"
          - "pods/log"
          - "replicationcontrollers"
          - "deployments"
          - "statefulsets"
          - "daemonsets"
          - "replicasets"
          - "deploymentconfigs"
          - "rollouts"
          - "pods/exec"
          - "events"
          - "chaosengines"
          - "chaosexperiments"
          - "chaosresults"
        verbs:
          - "create"
          - "list"
          - "get"
          - "patch"
          - "update"
          - "delete"
          - "deletecollection"
    image: "litmuschaos.docker.scarf.sh/litmuschaos/go-runner:3.6.0"
    imagePullPolicy: Always
    args:
    - -c
    - ./experiments -name pod-io-stress
    command:
    - /bin/bash
    env:
      - name: TOTAL_CHAOS_DURATION
        value: '120'

      # specify the size as percentage of free space on the file system
      # default value 90 (in percentage)
      - name: FILESYSTEM_UTILIZATION_PERCENTAGE
        value: '10'

      # we can specify the size in Gigabyte (Gb) also in place of percentage of free space
      # NOTE: for selecting this option FILESYSTEM_UTILIZATION_PERCENTAGE should be empty
      - name: FILESYSTEM_UTILIZATION_BYTES
        value: ''

      # Total number of workers default value is 4
      - name: NUMBER_OF_WORKERS
        value: '4'

      # Percentage of total pods to target
      - name: PODS_AFFECTED_PERC
        value: ''

      # provide volume mount path
      - name: VOLUME_MOUNT_PATH
        value: ''

       ## specify the comma separated target pods
      - name: TARGET_PODS
        value: ''

      # Period to wait before and after injection of chaos in sec
      - name: RAMP_TIME
        value: ''

      ## it defines the sequence of chaos execution for multiple target pods
      ## supported values: serial, parallel
      - name: SEQUENCE
        value: 'parallel'

      # provide lib image
      - name: LIB_IMAGE
        value: "litmuschaos.docker.scarf.sh/litmuschaos/go-runner:3.6.0"

      - name: SOCKET_PATH
        value: "/run/containerd/containerd.sock"

    labels:
      name: pod-io-stress
      app.kubernetes.io/part-of: litmus
      app.kubernetes.io/runtime-api-usage: "true"
---
# Source: kubernetes-chaos/templates/pod-memory-hog-exec.yaml
apiVersion: litmuschaos.io/v1alpha1
description:
  message: |
    Injects memory consumption on pods belonging to an app deployment
kind: ChaosExperiment
metadata:
  name: pod-memory-hog-exec
  labels:    
    app.kubernetes.io/component: kubernetes-chaos
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: k8s
    app.kubernetes.io/part-of: k8s 
    app.kubernetes.io/version: "3.6.0"
    helm.sh/chart: kubernetes-chaos-3.6.0 
    litmuschaos.io/version: 3.6.0
spec:
  definition:
    scope: Namespaced
    permissions:
      - apiGroups:
          - ""
          - "batch"
          - "apps"
          - "apps.openshift.io"
          - "argoproj.io"
          - "litmuschaos.io"
        resources:
          - "jobs"
          - "pods"
          - "pods/log"
          - "replicationcontrollers"
          - "deployments"
          - "statefulsets"
          - "daemonsets"
          - "replicasets"
          - "deploymentconfigs"
          - "rollouts"
          - "pods/exec"
          - "events"
          - "chaosengines"
          - "chaosexperiments"
          - "chaosresults"
        verbs:
          - "create"
          - "list"
          - "get"
          - "patch"
          - "update"
          - "delete"
          - "deletecollection"
    image: "litmuschaos.docker.scarf.sh/litmuschaos/go-runner:3.6.0"
    imagePullPolicy: Always
    args:
    - -c
    - ./experiments -name pod-memory-hog-exec
    command:
    - /bin/bash
    env:

    - name: TOTAL_CHAOS_DURATION
      value: '60'

    # Enter the amount of memory in megabytes to be consumed by the application pod
    # default: 500 (Megabytes)
    - name: MEMORY_CONSUMPTION
      value: '500'

    # Percentage of total pods to target
    - name: PODS_AFFECTED_PERC
      value: ''

    # Period to wait before injection of chaos in sec
    - name: RAMP_TIME
      value: ''

    - name: CHAOS_KILL_COMMAND
      value: "kill $(find /proc -name exe -lname '*/dd' 2>&1 | grep -v 'Permission denied' | awk -F/ '{print $(NF-1)}' | head -n 1)"

    - name: TARGET_PODS
      value: ''

    ## it defines the sequence of chaos execution for multiple target pods
    ## supported values: serial, parallel
    - name: SEQUENCE
      value: 'parallel'

    labels:
      name: pod-memory-hog-exec
      app.kubernetes.io/part-of: litmus
---
# Source: kubernetes-chaos/templates/pod-memory-hog.yaml
apiVersion: litmuschaos.io/v1alpha1
description:
  message: |
    Injects memory consumption on pods belonging to an app deployment
kind: ChaosExperiment
metadata:
  name: pod-memory-hog
  labels:    
    app.kubernetes.io/component: kubernetes-chaos
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: k8s
    app.kubernetes.io/part-of: k8s 
    app.kubernetes.io/version: "3.6.0"
    helm.sh/chart: kubernetes-chaos-3.6.0 
    litmuschaos.io/version: 3.6.0
spec:
  definition:
    scope: Namespaced
    permissions:
      - apiGroups:
          - ""
          - "batch"
          - "apps"
          - "apps.openshift.io"
          - "argoproj.io"
          - "litmuschaos.io"
        resources:
          - "jobs"
          - "pods"
          - "pods/log"
          - "replicationcontrollers"
          - "deployments"
          - "statefulsets"
          - "daemonsets"
          - "replicasets"
          - "deploymentconfigs"
          - "rollouts"
          - "pods/exec"
          - "events"
          - "chaosengines"
          - "chaosexperiments"
          - "chaosresults"
        verbs:
          - "create"
          - "list"
          - "get"
          - "patch"
          - "update"
          - "delete"
          - "deletecollection"
    image: "litmuschaos.docker.scarf.sh/litmuschaos/go-runner:3.6.0"
    imagePullPolicy: Always
    args:
    - -c
    - ./experiments -name pod-memory-hog
    command:
    - /bin/bash
    env:

    - name: TOTAL_CHAOS_DURATION
      value: '60'

    # Enter the amount of memory in megabytes to be consumed by the application pod
    # default: 500 (Megabytes)
    - name: MEMORY_CONSUMPTION
      value: '500'

    # Percentage of total pods to target
    - name: PODS_AFFECTED_PERC
      value: ''

    # Period to wait before injection of chaos in sec
    - name: RAMP_TIME
      value: ''

    - name: LIB_IMAGE
      value: "litmuschaos.docker.scarf.sh/litmuschaos/go-runner:3.6.0"

    - name: TARGET_PODS
      value: ''

    ## it defines the sequence of chaos execution for multiple target pods
    ## supported values: serial, parallel
    - name: SEQUENCE
      value: 'parallel'

      # provide the socket file path
    - name: SOCKET_PATH
      value: "/run/containerd/containerd.sock"

      # provide the name of container runtime
      # it supports docker, containerd, crio
    - name: CONTAINER_RUNTIME
      value: "containerd"

    labels:
      name: pod-memory-hog
      app.kubernetes.io/part-of: litmus
      app.kubernetes.io/runtime-api-usage: "true"
---
# Source: kubernetes-chaos/templates/pod-network-corruption.yaml
apiVersion: litmuschaos.io/v1alpha1
description:
  message: |
    Inject network packet corruption into application pod
kind: ChaosExperiment
metadata:
  name: pod-network-corruption
  labels:    
    app.kubernetes.io/component: kubernetes-chaos
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: k8s
    app.kubernetes.io/part-of: k8s 
    app.kubernetes.io/version: "3.6.0"
    helm.sh/chart: kubernetes-chaos-3.6.0 
    litmuschaos.io/version: 3.6.0
spec:
  definition:
    scope: Namespaced
    permissions:
      - apiGroups:
          - ""
          - "batch"
          - "apps"
          - "apps.openshift.io"
          - "argoproj.io"
          - "litmuschaos.io"
        resources:
          - "jobs"
          - "pods"
          - "pods/log"
          - "replicationcontrollers"
          - "deployments"
          - "statefulsets"
          - "daemonsets"
          - "replicasets"
          - "deploymentconfigs"
          - "rollouts"
          - "pods/exec"
          - "events"
          - "chaosengines"
          - "chaosexperiments"
          - "chaosresults"
        verbs:
          - "create"
          - "delete"
          - "list"
          - "patch"
          - "update"
          - "get"
          - "deletecollection"
    image: "litmuschaos.docker.scarf.sh/litmuschaos/go-runner:3.6.0"
    imagePullPolicy: Always
    args:
    - -c
    - ./experiments -name pod-network-corruption
    command:
    - /bin/bash
    env:

    - name: TARGET_CONTAINER
      value: ''

    # provide lib image
    - name: LIB_IMAGE
      value: "litmuschaos.docker.scarf.sh/litmuschaos/go-runner:3.6.0"

    - name: NETWORK_INTERFACE
      value: 'eth0'

    - name: NETWORK_PACKET_CORRUPTION_PERCENTAGE
      value: '100' #in PERCENTAGE

    - name: TOTAL_CHAOS_DURATION
      value: '60' # in seconds

    # Time period to wait before injection of chaos in sec
    - name: RAMP_TIME
      value: ''

    # percentage of total pods to target
    - name: PODS_AFFECTED_PERC
      value: ''

    - name: TARGET_PODS
      value: ''

    ## it defines the sequence of chaos execution for multiple target pods
    ## supported values: serial, parallel
    - name: SEQUENCE
      value: 'parallel'

    # provide the destination ips
    # chaos injection will be triggered for these destination ips
    - name: DESTINATION_IPS
      value: ''

    # provide the destination hosts
    # chaos injection will be triggered for these destination hosts
    - name: DESTINATION_HOSTS
      value: ''

      # provide the socket file path
    - name: SOCKET_PATH
      value: "/run/containerd/containerd.sock"

      # provide the name of container runtime
      # it supports docker, containerd, crio
    - name: CONTAINER_RUNTIME
      value: "containerd"

    labels:
      name: pod-network-corruption
      app.kubernetes.io/part-of: litmus
      app.kubernetes.io/runtime-api-usage: "true"
---
# Source: kubernetes-chaos/templates/pod-network-duplication.yaml
apiVersion: litmuschaos.io/v1alpha1
description:
  message: |
    Injects network packet duplication on pods belonging to an app deployment
kind: ChaosExperiment
metadata:
  name: pod-network-duplication
  labels:    
    app.kubernetes.io/component: kubernetes-chaos
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: k8s
    app.kubernetes.io/part-of: k8s 
    app.kubernetes.io/version: "3.6.0"
    helm.sh/chart: kubernetes-chaos-3.6.0 
    litmuschaos.io/version: 3.6.0
spec:
  definition:
    scope: Namespaced
    permissions:
    - apiGroups:
        - ""
        - "batch"
        - "apps"
        - "apps.openshift.io"
        - "argoproj.io"
        - "litmuschaos.io"
      resources:
        - "jobs"
        - "pods"
        - "pods/log"
        - "replicationcontrollers"
        - "deployments"
        - "statefulsets"
        - "daemonsets"
        - "replicasets"
        - "deploymentconfigs"
        - "rollouts"
        - "pods/exec"
        - "events"
        - "chaosengines"
        - "chaosexperiments"
        - "chaosresults"
      verbs:
        - "get"
        - "list"
        - "patch"
        - "create"
        - "update"
        - "delete"
        - "deletecollection"
    image: "litmuschaos.docker.scarf.sh/litmuschaos/go-runner:3.6.0"
    imagePullPolicy: Always
    args:
    - -c
    - ./experiments -name pod-network-duplication
    command:
    - /bin/bash
    env:
    - name: TOTAL_CHAOS_DURATION
      value: '60'

    - name: RAMP_TIME
      value: ''

    - name: TARGET_CONTAINER
      value: ''

    - name: NETWORK_INTERFACE
      value: 'eth0'

    - name: NETWORK_PACKET_DUPLICATION_PERCENTAGE
      value: '100' # in percentage

    - name: LIB_IMAGE
      value: "litmuschaos.docker.scarf.sh/litmuschaos/go-runner:3.6.0"

    # percentage of total pods to target
    - name: PODS_AFFECTED_PERC
      value: ''

    - name: TARGET_PODS
      value: ''

    ## it defines the sequence of chaos execution for multiple target pods
    ## supported values: serial, parallel
    - name: SEQUENCE
      value: 'parallel'

    # provide the destination ips
    # chaos injection will be triggered for these destination ips
    - name: DESTINATION_IPS
      value: ''

    # provide the destination hosts
    # chaos injection will be triggered for these destination hosts
    - name: DESTINATION_HOSTS
      value: ''

      # provide the socket file path
    - name: SOCKET_PATH
      value: "/run/containerd/containerd.sock"

      # provide the name of container runtime
      # it supports docker, containerd, crio
    - name: CONTAINER_RUNTIME
      value: "containerd"

    labels:
      name: pod-network-duplication
      app.kubernetes.io/part-of: litmus
      app.kubernetes.io/runtime-api-usage: "true"
---
# Source: kubernetes-chaos/templates/pod-network-latency.yaml
apiVersion: litmuschaos.io/v1alpha1
description:
  message: |
    Injects network latency on pods belonging to an app deployment
kind: ChaosExperiment
metadata:
  name: pod-network-latency
  labels:    
    app.kubernetes.io/component: kubernetes-chaos
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: k8s
    app.kubernetes.io/part-of: k8s 
    app.kubernetes.io/version: "3.6.0"
    helm.sh/chart: kubernetes-chaos-3.6.0 
    litmuschaos.io/version: 3.6.0
spec:
  definition:
    scope: Namespaced
    permissions:
      - apiGroups:
          - ""
          - "batch"
          - "apps"
          - "apps.openshift.io"
          - "argoproj.io"
          - "litmuschaos.io"
        resources:
          - "jobs"
          - "pods"
          - "pods/log"
          - "replicationcontrollers"
          - "deployments"
          - "statefulsets"
          - "daemonsets"
          - "replicasets"
          - "deploymentconfigs"
          - "rollouts"
          - "pods/exec"
          - "events"
          - "chaosengines"
          - "chaosexperiments"
          - "chaosresults"
        verbs:
          - "create"
          - "list"
          - "get"
          - "patch"
          - "update"
          - "delete"
          - "deletecollection"
    image: "litmuschaos.docker.scarf.sh/litmuschaos/go-runner:3.6.0"
    imagePullPolicy: Always
    args:
    - -c
    - ./experiments -name pod-network-latency
    command:
    - /bin/bash
    env:

    - name: TARGET_CONTAINER
      value: ''

    - name: NETWORK_INTERFACE
      value: 'eth0'

    # provide lib image
    - name: LIB_IMAGE
      value: "litmuschaos.docker.scarf.sh/litmuschaos/go-runner:3.6.0"

    - name: NETWORK_LATENCY
      value: '2000' #in ms

    - name: TOTAL_CHAOS_DURATION
      value: '60' # in seconds

    # Time period to wait before injection of chaos in sec
    - name: RAMP_TIME
      value: ''

    - name: JITTER
      value: '0'

    # percentage of total pods to target
    - name: PODS_AFFECTED_PERC
      value: ''

    - name: TARGET_PODS
      value: ''

    ## it defines the sequence of chaos execution for multiple target pods
    ## supported values: serial, parallel
    - name: SEQUENCE
      value: 'parallel'

    # provide the destination ips
    # chaos injection will be triggered for these destination ips
    - name: DESTINATION_IPS
      value: ''

    # provide the destination hosts
    # chaos injection will be triggered for these destination hosts
    - name: DESTINATION_HOSTS
      value: ''

      # provide the socket file path
    - name: SOCKET_PATH
      value: "/run/containerd/containerd.sock"

      # provide the name of container runtime
      # it supports docker, containerd, crio
    - name: CONTAINER_RUNTIME
      value: "containerd"

    labels:
      name: pod-network-latency
      app.kubernetes.io/part-of: litmus
      app.kubernetes.io/runtime-api-usage: "true"
---
# Source: kubernetes-chaos/templates/pod-network-loss.yaml
apiVersion: litmuschaos.io/v1alpha1
description:
  message: |
    Injects network packet loss on pods belonging to an app deployment
kind: ChaosExperiment
metadata:
  name: pod-network-loss
  labels:    
    app.kubernetes.io/component: kubernetes-chaos
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: k8s
    app.kubernetes.io/part-of: k8s 
    app.kubernetes.io/version: "3.6.0"
    helm.sh/chart: kubernetes-chaos-3.6.0 
    litmuschaos.io/version: 3.6.0
spec:
  definition:
    scope: Namespaced
    permissions:
    - apiGroups:
        - ""
        - "batch"
        - "apps"
        - "apps.openshift.io"
        - "argoproj.io"
        - "litmuschaos.io"
      resources:
        - "jobs"
        - "pods"
        - "pods/log"
        - "replicationcontrollers"
        - "deployments"
        - "statefulsets"
        - "daemonsets"
        - "replicasets"
        - "deploymentconfigs"
        - "rollouts"
        - "pods/exec"
        - "events"
        - "chaosengines"
        - "chaosexperiments"
        - "chaosresults"
      verbs:
        - "get"
        - "list"
        - "patch"
        - "create"
        - "update"
        - "delete"
        - "deletecollection"
    image: "litmuschaos.docker.scarf.sh/litmuschaos/go-runner:3.6.0"
    imagePullPolicy: Always
    args:
    - -c
    - ./experiments -name pod-network-loss
    command:
    - /bin/bash
    env:

    - name: TARGET_CONTAINER
      value: ''

    # provide lib image
    - name: LIB_IMAGE
      value: "litmuschaos.docker.scarf.sh/litmuschaos/go-runner:3.6.0"

    - name: NETWORK_INTERFACE
      value: 'eth0'

    - name: NETWORK_PACKET_LOSS_PERCENTAGE
      value: '100' #in PERCENTAGE

    - name: TOTAL_CHAOS_DURATION
      value: '60' # in seconds

    # time period to wait before injection of chaos in sec
    - name: RAMP_TIME
      value: ''

    # percentage of total pods to target
    - name: PODS_AFFECTED_PERC
      value: ''

    - name: TARGET_PODS
      value: ''

    ## it defines the sequence of chaos execution for multiple target pods
    ## supported values: serial, parallel
    - name: SEQUENCE
      value: 'parallel'

    # provide the destination ips
    # chaos injection will be triggered for these destination ips
    - name: DESTINATION_IPS
      value: ''

    # provide the destination hosts
    # chaos injection will be triggered for these destination hosts
    - name: DESTINATION_HOSTS
      value: ''

      # provide the socket file path
    - name: SOCKET_PATH
      value: "/run/containerd/containerd.sock"

      # provide the name of container runtime
      # it supports docker, containerd, crio
    - name: CONTAINER_RUNTIME
      value: "containerd"

    labels:
      name: pod-network-loss
      app.kubernetes.io/part-of: litmus
      app.kubernetes.io/runtime-api-usage: "true"
---
# Source: kubernetes-chaos/templates/pod-network-partition.yaml
apiVersion: litmuschaos.io/v1alpha1
description:
  message: |
    Injects 100% network packet loss on pods belonging to an app deployment
kind: ChaosExperiment
metadata:
  name: pod-network-partition
  labels:    
    app.kubernetes.io/component: kubernetes-chaos
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: k8s
    app.kubernetes.io/part-of: k8s 
    app.kubernetes.io/version: "3.6.0"
    helm.sh/chart: kubernetes-chaos-3.6.0 
    litmuschaos.io/version: 3.6.0
spec:
  definition:
    scope: Namespaced
    permissions:
    - apiGroups:
        - ""
        - "batch"
        - "networking.k8s.io"
        - "litmuschaos.io"
      resources:
        - "jobs"
        - "pods"
        - "pods/log"
        - networkpolicies
        - "pods/exec"
        - "events"
        - "chaosengines"
        - "chaosexperiments"
        - "chaosresults"
      verbs:
        - "get"
        - "list"
        - "patch"
        - "create"
        - "update"
        - "delete"
        - "deletecollection"
    image: "litmuschaos.docker.scarf.sh/litmuschaos/go-runner:3.6.0"
    imagePullPolicy: Always
    args:
    - -c
    - ./experiments -name pod-network-partition
    command:
    - /bin/bash
    env:

    - name: TOTAL_CHAOS_DURATION
      value: '60' # in seconds

    # ime period to wait before and after injection of chaos in sec
    - name: RAMP_TIME
      value: ''

    # provide the destination ips
    # chaos injection will be triggered for these destination ips
    - name: DESTINATION_IPS
      value: ''

    # provide the destination hosts
    # chaos injection will be triggered for these destination hosts
    - name: DESTINATION_HOSTS
      value: ''

    # provide network policy type
    # support ingress, egress, all values
    - name: POLICY_TYPES
      value: 'all'

    # provide labels of the destination pods
    - name: POD_SELECTOR
      value: ''

    # provide labels the destination namespaces
    - name: NAMESPACE_SELECTOR
      value: ''

    # provide comma separated ports
    - name: PORTS
      value: ''

    labels:
      name: pod-network-partition
      app.kubernetes.io/part-of: litmus
