---
# Source: infinispan/templates/secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: release-name-generated-secret
  labels:
    app: infinispan-secret-identities
    clusterName: release-name
    helm.sh/chart: infinispan-0.4.0
    meta.helm.sh/release-name: release-name
    meta.helm.sh/release-namespace: default
    app.kubernetes.io/version: "15.0"
    app.kubernetes.io/managed-by: Helm
  annotations:
    meta.helm.sh/release-name: release-name
    meta.helm.sh/release-namespace: default
    "helm.sh/resource-policy": keep
type: Opaque
stringData:
  username: monitor
  password: RAY0wgSR
  identities-batch: |-
    user create developer -p RAY0wgSR -g admin
    user create monitor -p RAY0wgSR --users-file metrics-users.properties --groups-file metrics-groups.properties
---
# Source: infinispan/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-configuration
  annotations:
    meta.helm.sh/release-name: release-name
    meta.helm.sh/release-namespace: default
  labels:
    app: infinispan-configmap-configuration
    clusterName: release-name
    helm.sh/chart: infinispan-0.4.0
    meta.helm.sh/release-name: release-name
    meta.helm.sh/release-namespace: default
    app.kubernetes.io/version: "15.0"
    app.kubernetes.io/managed-by: Helm
data:
  infinispan.yml: |-
    infinispan:
      cacheContainer:
        globalState:
          uncleanShutdownAction: IGNORE
        name: default
        security:
          authorization: {}
        transport:
          cluster: ${infinispan.cluster.name:cluster}
          node-name: ${infinispan.node.name:}
          stack: kubernetes
      server:
        endpoints:
        - connectors:
            hotrod:
              hotrodConnector: null
            rest:
              restConnector: null
          securityRealm: default
          socketBinding: default
        - connectors:
            rest:
              restConnector:
                authentication:
                  mechanisms: BASIC
          securityRealm: metrics
          socketBinding: metrics
        interfaces:
        - inetAddress:
            value: ${infinispan.bind.address:127.0.0.1}
          name: public
        security:
          credentialStores:
          - clearTextCredential:
              clearText: secret
            name: credentials
            path: credentials.pfx
          securityRealms:
          - name: default
            propertiesRealm:
              groupProperties:
                path: groups.properties
              groupsAttribute: Roles
              userProperties:
                path: users.properties
          - name: metrics
            propertiesRealm:
              groupProperties:
                path: metrics-groups.properties
                relativeTo: infinispan.server.config.path
              groupsAttribute: Roles
              userProperties:
                path: metrics-users.properties
                relativeTo: infinispan.server.config.path
        socketBindings:
          defaultInterface: public
          portOffset: ${infinispan.socket.binding.port-offset:0}
          socketBinding:
          - name: default
            port: 11222
          - name: metrics
            port: 11223
  log4j2.xml: |-
    <Configuration name="InfinispanServerConfig" monitorInterval="60" shutdownHook="disable">
      <Properties>
        <Property name="path">${sys:infinispan.server.log.path}</Property>
        <Property name="accessLogPattern">%X{address} %X{user} [%d{dd/MMM/yyyy:HH:mm:ss Z}] &quot;%X{method} %m %X{protocol}&quot; %X{status} %X{requestSize} %X{responseSize} %X{duration}%n</Property>
      </Properties>
      <Appenders>
        <!-- Colored output on the console -->
        <Console name="STDOUT">
          <PatternLayout pattern="%highlight{%d{yyyy-MM-dd HH:mm:ss,SSS} %-5p (%t) [%c] %m%throwable}{INFO=normal, DEBUG=normal, TRACE=normal}%n"/>
        </Console>
    
        <!-- Rolling file -->
        <RollingFile name="FILE" createOnDemand="true"
                     fileName="${path}/server.log"
                     filePattern="${path}/server.log.%d{yyyy-MM-dd}-%i">
          <Policies>
            <OnStartupTriggeringPolicy />
            <SizeBasedTriggeringPolicy size="100 MB" />
            <TimeBasedTriggeringPolicy />
          </Policies>
          <PatternLayout pattern="%d{yyyy-MM-dd HH:mm:ss,SSS} %-5p (%t) [%c] %m%throwable%n"/>
        </RollingFile>
    
        <!-- Rolling file -->
        <RollingFile name="AUDIT-FILE" createOnDemand="true"
                     fileName="${path}/audit.log"
                     filePattern="${path}/audit.log.%d{yyyy-MM-dd}-%i">
          <Policies>
            <OnStartupTriggeringPolicy />
            <SizeBasedTriggeringPolicy size="100 MB" />
            <TimeBasedTriggeringPolicy />
          </Policies>
          <PatternLayout pattern="%d{yyyy-MM-dd HH:mm:ss,SSS} %m%n"/>
        </RollingFile>
    
        <!-- Rolling JSON file, disabled by default -->
        <RollingFile name="JSON-FILE" createOnDemand="true"
                     fileName="${path}/server.log.json"
                     filePattern="${path}/server.log.json.%d{yyyy-MM-dd}-%i">
          <Policies>
            <OnStartupTriggeringPolicy />
            <SizeBasedTriggeringPolicy size="100 MB" />
            <TimeBasedTriggeringPolicy />
          </Policies>
          <JsonLayout compact="true" eventEol="true" stacktraceAsString="true">
            <KeyValuePair key="time" value="$${date:yyyy-MM-dd'T'HH:mm:ss.SSSZ}" />
          </JsonLayout>
        </RollingFile>
    
        <!-- Rolling HotRod access log, disabled by default -->
        <RollingFile name="HR-ACCESS-FILE" createOnDemand="true"
                     fileName="${path}/hotrod-access.log"
                     filePattern="${path}/hotrod-access.log.%i">
          <Policies>
            <SizeBasedTriggeringPolicy size="100 MB" />
          </Policies>
          <PatternLayout pattern="${accessLogPattern}"/>
        </RollingFile>
        <!-- Rolling REST access log, disabled by default -->
        <RollingFile name="REST-ACCESS-FILE" createOnDemand="true"
                     fileName="${path}/rest-access.log"
                     filePattern="${path}/rest-access.log.%i">
          <Policies>
            <SizeBasedTriggeringPolicy size="100 MB" />
          </Policies>
          <PatternLayout pattern="${accessLogPattern}"/>
        </RollingFile>
      </Appenders>
    
      <Loggers>
        <Root level="INFO">
          <AppenderRef ref="STDOUT"/>
    
          <!-- Uncomment just one of the two lines bellow to use alternatively JSON logging or plain-text logging to file-->
          <AppenderRef ref="FILE"/>
    <!--      <AppenderRef ref="JSON-FILE"/>-->
        </Root>
    
        <!-- Set to INFO to enable audit logging -->
        <Logger name="org.infinispan.AUDIT" additivity="false" level="ERROR">
          <AppenderRef ref="AUDIT-FILE"/>
        </Logger>
    
        <!-- Set to TRACE to enable access logging for Hot Rod requests -->
        <Logger name="org.infinispan.HOTROD_ACCESS_LOG" additivity="false" level="INFO">
          <AppenderRef ref="HR-ACCESS-FILE"/>
        </Logger>
    
        <!-- Set to TRACE to enable access logging for REST requests -->
        <Logger name="org.infinispan.REST_ACCESS_LOG" additivity="false" level="INFO">
          <AppenderRef ref="REST-ACCESS-FILE"/>
        </Logger>
        <Logger name="com.arjuna" level="WARN" />
        <Logger name="io.netty.handler.ssl.ApplicationProtocolNegotiationHandler" level="ERROR" />
    
      </Loggers>
    </Configuration>
---
# Source: infinispan/templates/metrics-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-metrics
  annotations:
    meta.helm.sh/release-name: release-name
    meta.helm.sh/release-namespace: default
  labels:
    app: infinispan-service-metrics
    clusterName: release-name
    helm.sh/chart: infinispan-0.4.0
    meta.helm.sh/release-name: release-name
    meta.helm.sh/release-namespace: default
    app.kubernetes.io/version: "15.0"
    app.kubernetes.io/managed-by: Helm
    
spec:
  type: ClusterIP
  clusterIP: None
  ports:
    - port: 11223
      protocol: TCP
      name: infinispan-met
  selector:
    clusterName: release-name
    app: infinispan-pod
---
# Source: infinispan/templates/ping-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-ping
  annotations:
    meta.helm.sh/release-name: release-name
    meta.helm.sh/release-namespace: default
  labels:
    app: infinispan-service-ping
    clusterName: release-name
    helm.sh/chart: infinispan-0.4.0
    meta.helm.sh/release-name: release-name
    meta.helm.sh/release-namespace: default
    app.kubernetes.io/version: "15.0"
    app.kubernetes.io/managed-by: Helm
    
spec:
  publishNotReadyAddresses: true
  type: ClusterIP
  clusterIP: None
  ports:
    - port: 8888
      protocol: TCP
      name: infinispan
  selector:
    clusterName: release-name
    app: infinispan-pod
---
# Source: infinispan/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name
  annotations:
    meta.helm.sh/release-name: release-name
    meta.helm.sh/release-namespace: default
  labels:
    app: infinispan-service
    clusterName: release-name
    helm.sh/chart: infinispan-0.4.0
    meta.helm.sh/release-name: release-name
    meta.helm.sh/release-namespace: default
    app.kubernetes.io/version: "15.0"
    app.kubernetes.io/managed-by: Helm
    
spec:
  type: ClusterIP
  ports:
    - port: 11222
      protocol: TCP
      name: infinispan
  selector:
    clusterName: release-name
    app: infinispan-pod
---
# Source: infinispan/templates/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: release-name
  labels:
    clusterName: release-name
    helm.sh/chart: infinispan-0.4.0
    meta.helm.sh/release-name: release-name
    meta.helm.sh/release-namespace: default
    app.kubernetes.io/version: "15.0"
    app.kubernetes.io/managed-by: Helm
  annotations:
    meta.helm.sh/release-name: release-name
    meta.helm.sh/release-namespace: default
    "openshift.io/display-name": "Infinispan Cluster"
    "openshift.io/documentation-url": "http://infinispan.org/documentation/"
spec:
  serviceName: ""
  replicas: 1
  selector:
    matchLabels:
      app: infinispan-pod
      clusterName: release-name
  template:
    metadata:
      annotations:
        checksum/config: ec91387fe1818ae55b5aa8bcdbc2ed87048ee891249ece8f2fd5d09e3e0f2810
        checksum/identities: 975a088c8e4b485b80f4d1662d0d735480dca6df4ebfcd4516a5dfbd4d405e7d
      labels:
        app: infinispan-pod
        clusterName: release-name
        
    spec:
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    clusterName: release-name
                    app: infinispan-pod
                topologyKey: kubernetes.io/hostname
              weight: 100
      
      containers:
        - env:
            - name: JAVA_OPTIONS
              value: 
            - name: IDENTITIES_BATCH
              value: /etc/security/identities-batch
            - name: SERVER_LIBS
              value: 
          image: quay.io/infinispan/server:15.0
          imagePullPolicy: Always
          args:
            - --cluster-name=release-name
            - --server-config=/etc/config/infinispan.yml
            - --logging-config=/etc/config/log4j2.xml
            - --bind-address=0.0.0.0
            - -Djgroups.dns.query=release-name-ping.default.svc.cluster.local
          ports:
            - containerPort: 8888
              name: ping
              protocol: TCP
            - containerPort: 11222
              name: infinispan
              protocol: TCP
            - containerPort: 11223
              name: infinispan-met
              protocol: TCP
          livenessProbe:
            failureThreshold: 5
            httpGet:
              path: rest/v2/cache-managers/default/health/status
              port: 11222
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 80
          name: infinispan
          readinessProbe:
            failureThreshold: 5
            httpGet:
              path: rest/v2/cache-managers/default/health/status
              port: 11222
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 80
          startupProbe:
            failureThreshold: 60
            httpGet:
              path: rest/v2/cache-managers/default/health/status
              port: 11222
              scheme: HTTP
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 80
          resources:
            limits:
              cpu: 500m
              memory: 512Mi
            requests:
              cpu: 500m
              memory: 512Mi
          volumeMounts:
            - mountPath: /etc/config
              name: config-volume
            - mountPath: /opt/infinispan/server/data
              name: data-volume
            - mountPath: /etc/security
              name: identities-volume
      volumes:
        - configMap:
            name: release-name-configuration
          name: config-volume
        - name: identities-volume
          secret:
            secretName: release-name-generated-secret
  updateStrategy:
    type: RollingUpdate
  volumeClaimTemplates:
    - apiVersion: v1
      kind: PersistentVolumeClaim
      metadata:
        name: data-volume
      spec:
        accessModes:
          - ReadWriteOnce
        resources:
          requests:
            storage: 1Gi
---
# Source: infinispan/templates/tests/test-connection.yaml
apiVersion: v1
kind: Pod
metadata:
  name: "release-name-test-connection"
  labels:
    clusterName: release-name
    helm.sh/chart: infinispan-0.4.0
    meta.helm.sh/release-name: release-name
    meta.helm.sh/release-namespace: default
    app.kubernetes.io/version: "15.0"
    app.kubernetes.io/managed-by: Helm
    
  annotations:
    meta.helm.sh/release-name: release-name
    meta.helm.sh/release-namespace: default
    "helm.sh/hook": test
    "helm.sh/hook-delete-policy": before-hook-creation
spec:
  containers:
    - name: wget
      image: quay.io/quay/busybox:latest
      command: ['wget']
      args: ['release-name:11222/console']
  restartPolicy: Never
