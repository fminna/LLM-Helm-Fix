---
# Source: librephotos/charts/redis/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
automountServiceAccountToken: true
metadata:
  name: release-name-redis
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: redis
    app.kubernetes.io/version: 7.2.1
    helm.sh/chart: redis-18.1.0
---
# Source: librephotos/templates/cronjob-native/serviceaccount-cronjob.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: librephotos-scan-cron
---
# Source: librephotos/charts/postgresql/templates/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: release-name-postgresql
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: 16.0.0
    helm.sh/chart: postgresql-13.0.0
type: Opaque
data:
  postgres-password: "ckh5NkhRRVNoSg=="
  password: "ZEtWVEMwVW1LRw=="
  # We don't auto-generate LDAP password when it's not provided as we do for other passwords
---
# Source: librephotos/charts/redis/templates/secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: release-name-redis
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: redis
    app.kubernetes.io/version: 7.2.1
    helm.sh/chart: redis-18.1.0
type: Opaque
data:
  redis-password: "ekdXdXZ3VVNpYg=="
---
# Source: librephotos/templates/secretAuth.yaml
apiVersion: v1
kind: Secret
metadata:
  name: release-name-creds
  labels:
    helm.sh/chart: librephotos-0.202337.0
    app.kubernetes.io/name: librephotos
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "2023w37p2"
    app.kubernetes.io/managed-by: Helm
type: Opaque
stringData:
  ADMIN_EMAIL: admin@mydomain.com
  ADMIN_PASSWORD: password
  ADMIN_USERNAME: admin
  MAPBOX_API_KEY: ""
---
# Source: librephotos/templates/secretSecrets.yaml
apiVersion: v1
kind: Secret
type: Opaque
metadata:
  name: release-name-secrets
data:
  SECRET_KEY: UkhocTBKM3NvRVVDb0NzZExHOXVDUDE4dlBReDJwMFY=
---
# Source: librephotos/charts/redis/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-redis-configuration
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: redis
    app.kubernetes.io/version: 7.2.1
    helm.sh/chart: redis-18.1.0
data:
  redis.conf: |-
    # User-supplied common configuration:
    # Enable AOF https://redis.io/topics/persistence#append-only-file
    appendonly yes
    # Disable RDB persistence, AOF persistence already enabled.
    save ""
    # End of common configuration
  master.conf: |-
    dir /data
    # User-supplied master configuration:
    rename-command FLUSHALL ""
    # End of master configuration
  replica.conf: |-
    dir /data
    # User-supplied replica configuration:
    rename-command FLUSHDB ""
    rename-command FLUSHALL ""
    # End of replica configuration
---
# Source: librephotos/charts/redis/templates/health-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-redis-health
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: redis
    app.kubernetes.io/version: 7.2.1
    helm.sh/chart: redis-18.1.0
data:
  ping_readiness_local.sh: |-
    #!/bin/bash

    [[ -f $REDIS_PASSWORD_FILE ]] && export REDIS_PASSWORD="$(< "${REDIS_PASSWORD_FILE}")"
    [[ -n "$REDIS_PASSWORD" ]] && export REDISCLI_AUTH="$REDIS_PASSWORD"
    response=$(
      timeout -s 15 $1 \
      redis-cli \
        -h localhost \
        -p $REDIS_PORT \
        ping
    )
    if [ "$?" -eq "124" ]; then
      echo "Timed out"
      exit 1
    fi
    if [ "$response" != "PONG" ]; then
      echo "$response"
      exit 1
    fi
  ping_liveness_local.sh: |-
    #!/bin/bash

    [[ -f $REDIS_PASSWORD_FILE ]] && export REDIS_PASSWORD="$(< "${REDIS_PASSWORD_FILE}")"
    [[ -n "$REDIS_PASSWORD" ]] && export REDISCLI_AUTH="$REDIS_PASSWORD"
    response=$(
      timeout -s 15 $1 \
      redis-cli \
        -h localhost \
        -p $REDIS_PORT \
        ping
    )
    if [ "$?" -eq "124" ]; then
      echo "Timed out"
      exit 1
    fi
    responseFirstWord=$(echo $response | head -n1 | awk '{print $1;}')
    if [ "$response" != "PONG" ] && [ "$responseFirstWord" != "LOADING" ] && [ "$responseFirstWord" != "MASTERDOWN" ]; then
      echo "$response"
      exit 1
    fi
  ping_readiness_master.sh: |-
    #!/bin/bash

    [[ -f $REDIS_MASTER_PASSWORD_FILE ]] && export REDIS_MASTER_PASSWORD="$(< "${REDIS_MASTER_PASSWORD_FILE}")"
    [[ -n "$REDIS_MASTER_PASSWORD" ]] && export REDISCLI_AUTH="$REDIS_MASTER_PASSWORD"
    response=$(
      timeout -s 15 $1 \
      redis-cli \
        -h $REDIS_MASTER_HOST \
        -p $REDIS_MASTER_PORT_NUMBER \
        ping
    )
    if [ "$?" -eq "124" ]; then
      echo "Timed out"
      exit 1
    fi
    if [ "$response" != "PONG" ]; then
      echo "$response"
      exit 1
    fi
  ping_liveness_master.sh: |-
    #!/bin/bash

    [[ -f $REDIS_MASTER_PASSWORD_FILE ]] && export REDIS_MASTER_PASSWORD="$(< "${REDIS_MASTER_PASSWORD_FILE}")"
    [[ -n "$REDIS_MASTER_PASSWORD" ]] && export REDISCLI_AUTH="$REDIS_MASTER_PASSWORD"
    response=$(
      timeout -s 15 $1 \
      redis-cli \
        -h $REDIS_MASTER_HOST \
        -p $REDIS_MASTER_PORT_NUMBER \
        ping
    )
    if [ "$?" -eq "124" ]; then
      echo "Timed out"
      exit 1
    fi
    responseFirstWord=$(echo $response | head -n1 | awk '{print $1;}')
    if [ "$response" != "PONG" ] && [ "$responseFirstWord" != "LOADING" ]; then
      echo "$response"
      exit 1
    fi
  ping_readiness_local_and_master.sh: |-
    script_dir="$(dirname "$0")"
    exit_status=0
    "$script_dir/ping_readiness_local.sh" $1 || exit_status=$?
    "$script_dir/ping_readiness_master.sh" $1 || exit_status=$?
    exit $exit_status
  ping_liveness_local_and_master.sh: |-
    script_dir="$(dirname "$0")"
    exit_status=0
    "$script_dir/ping_liveness_local.sh" $1 || exit_status=$?
    "$script_dir/ping_liveness_master.sh" $1 || exit_status=$?
    exit $exit_status
---
# Source: librephotos/charts/redis/templates/scripts-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-redis-scripts
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: redis
    app.kubernetes.io/version: 7.2.1
    helm.sh/chart: redis-18.1.0
data:
  start-master.sh: |
    #!/bin/bash

    [[ -f $REDIS_PASSWORD_FILE ]] && export REDIS_PASSWORD="$(< "${REDIS_PASSWORD_FILE}")"
    if [[ -f /opt/bitnami/redis/mounted-etc/master.conf ]];then
        cp /opt/bitnami/redis/mounted-etc/master.conf /opt/bitnami/redis/etc/master.conf
    fi
    if [[ -f /opt/bitnami/redis/mounted-etc/redis.conf ]];then
        cp /opt/bitnami/redis/mounted-etc/redis.conf /opt/bitnami/redis/etc/redis.conf
    fi
    ARGS=("--port" "${REDIS_PORT}")
    ARGS+=("--requirepass" "${REDIS_PASSWORD}")
    ARGS+=("--masterauth" "${REDIS_PASSWORD}")
    ARGS+=("--include" "/opt/bitnami/redis/etc/redis.conf")
    ARGS+=("--include" "/opt/bitnami/redis/etc/master.conf")
    exec redis-server "${ARGS[@]}"
---
# Source: librephotos/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-nginx-config
  labels:
    helm.sh/chart: librephotos-0.202337.0
    app.kubernetes.io/name: librephotos
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "2023w37p2"
    app.kubernetes.io/managed-by: Helm
data:
  nginx-config: |-
    user  nginx;
    worker_processes  1;

    error_log  /var/log/nginx/error.log debug;

    events {
        worker_connections  1024;
    }

    http {
      server {
        listen 80;
        location / {
          # React routes are entirely on the App side in the web broswer
          # Always proxy to root with the same page request when nginx 404s
          error_page 404 /;
          proxy_intercept_errors on;
          proxy_set_header Host $host;
          proxy_pass http://release-name-frontend/;
          proxy_cookie_path / "/; secure; HttpOnly; SameSite=None";
        }
        location ~ ^/(api|media)/ {
          proxy_set_header X-Forwarded-Proto $scheme;
          proxy_set_header X-Real-IP $remote_addr;
          proxy_set_header Host release-name-backend;
          include uwsgi_params;
          proxy_pass http://release-name-backend;
          proxy_cookie_path / "/; secure; HttpOnly; SameSite=None";
        }
        # Django media
        location /protected_media  {
            internal;
            alias /protected_media/;
        }

        location /static/drf-yasg {
            proxy_pass http://release-name-backend;
        }

        location /data  {
            internal;
            alias /data/;
        }

        # Original Photos
        location /original  {
            internal;
            alias /data/;
        }
        # Nextcloud Original Photos
        location /nextcloud_original  {
            internal;
            alias /data/nextcloud_media/;
        }
      }
    }
---
# Source: librephotos/templates/cronjob-native/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: librephotos-scan-cron
data:
  cronjob.sh: |
    POD=$(kubectl get pods -l app.kubernetes.io/name=librephotos,app.kubernetes.io/instance=release-name,app.kubernetes.io/app=backend --no-headers -o custom-columns=NAME:.metadata.name |head)
    kubectl exec $POD -ti -- /bin/sh -c "cd /code; python3 manage.py scan"
---
# Source: librephotos/templates/pvc.yaml
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: release-name
  labels:
    helm.sh/chart: librephotos-0.202337.0
    app.kubernetes.io/name: librephotos
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "2023w37p2"
    app.kubernetes.io/managed-by: Helm
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: "100Gi"
---
# Source: librephotos/templates/cronjob-native/role-cronjob.yaml
kind: Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: librephotos-scan-cron
rules:
- apiGroups: [""]
  resources: ["pods"]
  verbs: ["get", "list"]
- apiGroups: [""]
  resources: ["pods/exec"]
  verbs: ["create"]
---
# Source: librephotos/templates/cronjob-native/rolebinding-cronjob.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: librephotos-scan-cron
subjects:
- kind: ServiceAccount
  name: librephotos-scan-cron
roleRef:
  kind: Role
  name:  librephotos-scan-cron
  apiGroup: rbac.authorization.k8s.io
---
# Source: librephotos/charts/postgresql/templates/primary/svc-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-postgresql-hl
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: 16.0.0
    helm.sh/chart: postgresql-13.0.0
    app.kubernetes.io/component: primary
  annotations:
    # Use this annotation in addition to the actual publishNotReadyAddresses
    # field below because the annotation will stop being respected soon but the
    # field is broken in some versions of Kubernetes:
    # https://github.com/kubernetes/kubernetes/issues/58662
    service.alpha.kubernetes.io/tolerate-unready-endpoints: "true"
spec:
  type: ClusterIP
  clusterIP: None
  # We want all pods in the StatefulSet to have their addresses published for
  # the sake of the other Postgresql pods even before they're ready, since they
  # have to be able to talk to each other in order to become ready.
  publishNotReadyAddresses: true
  ports:
    - name: tcp-postgresql
      port: 5432
      targetPort: tcp-postgresql
  selector:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/component: primary
---
# Source: librephotos/charts/postgresql/templates/primary/svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-postgresql
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: 16.0.0
    helm.sh/chart: postgresql-13.0.0
    app.kubernetes.io/component: primary
spec:
  type: ClusterIP
  sessionAffinity: None
  ports:
    - name: tcp-postgresql
      port: 5432
      targetPort: tcp-postgresql
      nodePort: null
  selector:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/component: primary
---
# Source: librephotos/charts/redis/templates/headless-svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-redis-headless
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: redis
    app.kubernetes.io/version: 7.2.1
    helm.sh/chart: redis-18.1.0
  annotations:
    
spec:
  type: ClusterIP
  clusterIP: None
  ports:
    - name: tcp-redis
      port: 6379
      targetPort: redis
  selector:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/name: redis
---
# Source: librephotos/charts/redis/templates/master/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-redis-master
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: redis
    app.kubernetes.io/version: 7.2.1
    helm.sh/chart: redis-18.1.0
    app.kubernetes.io/component: master
spec:
  type: ClusterIP
  internalTrafficPolicy: Cluster
  sessionAffinity: None
  ports:
    - name: tcp-redis
      port: 6379
      targetPort: redis
      nodePort: null
  selector:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/name: redis
    app.kubernetes.io/component: master
---
# Source: librephotos/templates/serviceBackend.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-backend
  labels:
    helm.sh/chart: librephotos-0.202337.0
    app.kubernetes.io/name: librephotos
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "2023w37p2"
    app.kubernetes.io/managed-by: Helm
  annotations:
    {}
spec:
  type: ClusterIP
  ports:
    - name: backend
      port: 80
      protocol: TCP
      targetPort: 8001
  selector:
    app.kubernetes.io/app: backend
    app.kubernetes.io/name: librephotos
    app.kubernetes.io/instance: release-name
---
# Source: librephotos/templates/serviceFrontend.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-frontend
  labels:
    helm.sh/chart: librephotos-0.202337.0
    app.kubernetes.io/name: librephotos
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "2023w37p2"
    app.kubernetes.io/managed-by: Helm
  annotations:
    {}
spec:
  type: ClusterIP
  ports:
    - name: backend
      port: 80
      protocol: TCP
      targetPort: 3000
  selector:
    app.kubernetes.io/app: frontend
    app.kubernetes.io/name: librephotos
    app.kubernetes.io/instance: release-name
---
# Source: librephotos/templates/serviceProxy.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-proxy
  labels:
    helm.sh/chart: librephotos-0.202337.0
    app.kubernetes.io/name: librephotos
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "2023w37p2"
    app.kubernetes.io/managed-by: Helm
  annotations:
    {}
spec:
  type: ClusterIP
  ports:
    - name: backend
      port: 80
      protocol: TCP
      targetPort: 80
  selector:
    app.kubernetes.io/app: proxy
    app.kubernetes.io/name: librephotos
    app.kubernetes.io/instance: release-name
---
# Source: librephotos/templates/deploymentBackend.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-backend
  labels:
    app.kubernetes.io/app: backend
    helm.sh/chart: librephotos-0.202337.0
    app.kubernetes.io/name: librephotos
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "2023w37p2"
    app.kubernetes.io/managed-by: Helm
  annotations:
    {}
spec:
  revisionHistoryLimit: 3
  replicas: 1
  strategy:
    type: Recreate
  selector:
    matchLabels:
      app.kubernetes.io/app: backend
      app.kubernetes.io/name: librephotos
      app.kubernetes.io/instance: release-name
  template:
    metadata:
      annotations:
        {}
      labels:
        app.kubernetes.io/app: backend
        app.kubernetes.io/name: librephotos
        app.kubernetes.io/instance: release-name
    spec:
      terminationGracePeriodSeconds: 30
      initContainers:
      - name: check-postgres-ready
        image: postgres:9.6.5
        command: ['sh', '-c', 
          'until pg_isready -h release-name-postgresql -p 5432; 
          do echo waiting for database; sleep 2; done;']
      containers:
        - name: photos-librephotos
          image: "reallibrephotos/librephotos:2023w37p2"
          imagePullPolicy: IfNotPresent
          tty: false
          stdin: false
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              add: []
              drop: []
            privileged: false
            readOnlyRootFilesystem: false
            runAsNonRoot: false
          env:
            - name: "ALLOW_UPLOAD"
              value: "false"
            - name: "DEBUG"
              value: "0"
            - name: "HEAVYWEIGHT_PROCESS"
              value: "2"
            - name: "SKIP_PATTERNS"
              value: ""
            - name: "WEB_CONCURRENCY"
              value: "4"
            - name: "DB_BACKEND"
              value: postgresql
            - name: "DB_NAME"
              value: librephotos
            - name: "DB_PORT"
              value: "5432"
            - name: "DB_USER"
              value: librephotos
            - name: DB_HOST
              value: release-name-postgresql
            - name: DB_PASS
              valueFrom:
                secretKeyRef:
                  name: release-name-postgresql
                  key: "password"
            - name: "REDIS_PORT"
              value: "6379"
            - name: "BACKEND_HOST"
              value: "release-name-backend"
            - name: REDIS_HOST
              value: release-name-redis-master
            - name: REDIS_PASS
              valueFrom:
                secretKeyRef:
                  name: release-name-redis
                  key: "redis-password"
          envFrom:
            - secretRef:
                name: "release-name-secrets"
            - secretRef:
               name:  "release-name-creds"
          ports:
            - name: backend
              containerPort: 8001
              protocol: TCP
          volumeMounts:
            - mountPath: /root/.cache
              name: data
              subPath: cache
            - mountPath: /etc/nginx/nginx.conf
              name: config
              readOnly: true
              subPath: nginx-config
            - mountPath: /logs
              name: data
              subPath: logs
            - mountPath: /data
              name: data
              subPath: data
            - mountPath: /protected_media
              name: data
              subPath: protected-media
            - mountPath: /shared
              name: data
              subPath: shared
            - mountPath: /tmp
              name: temp
            - mountPath: /var/logs
              name: varlogs
          livenessProbe:
            failureThreshold: 5
            initialDelaySeconds: 10
            periodSeconds: 120
            tcpSocket:
              port: 8001
            timeoutSeconds: 5
          readinessProbe:
            failureThreshold: 5
            initialDelaySeconds: 10
            periodSeconds: 120
            tcpSocket:
              port: 8001
            timeoutSeconds: 5
          startupProbe:
            failureThreshold: 60
            initialDelaySeconds: 10
            periodSeconds: 5
            tcpSocket:
              port: 8001
            timeoutSeconds: 2
          resources:
            limits:
              memory: 8Gi
            requests:
              cpu: 10m
              memory: 50Mi
      volumes:
        - emptyDir: {}
          name: shared
        - emptyDir:
            medium: Memory
          name: temp
        - emptyDir: {}
          name: varlogs
        - name: config
          configMap:
            defaultMode: 420
            name: release-name-nginx-config
        - name: data
          persistentVolumeClaim:
            claimName: release-name
---
# Source: librephotos/templates/deploymentFrontend.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-frontend
  labels:
    helm.sh/chart: librephotos-0.202337.0
    app.kubernetes.io/name: librephotos
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "2023w37p2"
    app.kubernetes.io/managed-by: Helm
  annotations:
    {}
spec:
  revisionHistoryLimit: 3
  replicas: 1
  strategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/app: frontend
      app.kubernetes.io/name: librephotos
      app.kubernetes.io/instance: release-name
  template:
    metadata:
      annotations:
        {}
      labels:
        app.kubernetes.io/app: frontend
        app.kubernetes.io/name: librephotos
        app.kubernetes.io/instance: release-name
    spec:
      terminationGracePeriodSeconds: 30
      
      affinity:
        podAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: "app.kubernetes.io/instance"
                operator: In
                values:
                - release-name
            topologyKey: "kubernetes.io/hostname"
      
      containers:
        - name: frontend
          image: "reallibrephotos/librephotos-frontend:2023w37p2"
          imagePullPolicy: IfNotPresent
          tty: false
          stdin: false
          livenessProbe:
            failureThreshold: 5
            initialDelaySeconds: 10
            periodSeconds: 120
            tcpSocket:
              port: 3000
            timeoutSeconds: 5
          readinessProbe:
            failureThreshold: 5
            initialDelaySeconds: 10
            periodSeconds: 120
            tcpSocket:
              port: 3000
            timeoutSeconds: 5
          startupProbe:
            failureThreshold: 60
            initialDelaySeconds: 10
            periodSeconds: 5
            tcpSocket:
              port: 3000
            timeoutSeconds: 2
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              add: []
              drop: []
            privileged: false
            readOnlyRootFilesystem: false
            runAsNonRoot: false
          ports:
            - name: frontend
              containerPort: 3000
              protocol: TCP
---
# Source: librephotos/templates/deploymentProxy.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-proxy
  labels:
    helm.sh/chart: librephotos-0.202337.0
    app.kubernetes.io/name: librephotos
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "2023w37p2"
    app.kubernetes.io/managed-by: Helm
  annotations:
    {}
spec:
  revisionHistoryLimit: 3
  replicas: 1
  strategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/app: proxy
      app.kubernetes.io/name: librephotos
      app.kubernetes.io/instance: release-name
  template:
    metadata:
      annotations:
        {}
      labels:
        app.kubernetes.io/app: proxy
        app.kubernetes.io/name: librephotos
        app.kubernetes.io/instance: release-name
    spec:
      
      affinity:
        podAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions:
              - key: "app.kubernetes.io/instance"
                operator: In
                values:
                - release-name
            topologyKey: "kubernetes.io/hostname"
      
      terminationGracePeriodSeconds: 30
      containers:
        - name: proxy
          image: "reallibrephotos/librephotos-proxy:2023w37p2"
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 5
            initialDelaySeconds: 10
            periodSeconds: 60
            tcpSocket:
              port: 80
            timeoutSeconds: 5
          readinessProbe:
            failureThreshold: 5
            httpGet:
              path: /
              port: 80
            initialDelaySeconds: 10
            periodSeconds: 60
            timeoutSeconds: 5
          startupProbe:
            failureThreshold: 60
            initialDelaySeconds: 10
            periodSeconds: 5
            tcpSocket:
              port: 80
            timeoutSeconds: 2
          tty: false
          stdin: false
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              add: []
              drop: []
            privileged: false
            readOnlyRootFilesystem: false
            runAsNonRoot: false
          ports:
            - name: main
              containerPort: 80
              protocol: TCP
          volumeMounts:
            - mountPath: /root/.cache
              name: data
              subPath: cache
            - mountPath: /etc/nginx/nginx.conf
              name: config
              subPath: nginx-config
              readOnly: true
            - mountPath: /data
              name: data
              subPath: data
            - mountPath: /protected_media
              name: data
              subPath: protected-media
      volumes:
        - name: data
          persistentVolumeClaim:
            claimName: release-name
        - name: config
          configMap:
            defaultMode: 420
            name: release-name-nginx-config
---
# Source: librephotos/charts/postgresql/templates/primary/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: release-name-postgresql
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: 16.0.0
    helm.sh/chart: postgresql-13.0.0
    app.kubernetes.io/component: primary
spec:
  replicas: 1
  serviceName: release-name-postgresql-hl
  updateStrategy:
    rollingUpdate: {}
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/name: postgresql
      app.kubernetes.io/component: primary
  template:
    metadata:
      name: release-name-postgresql
      labels:
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: postgresql
        app.kubernetes.io/version: 16.0.0
        helm.sh/chart: postgresql-13.0.0
        app.kubernetes.io/component: primary
    spec:
      serviceAccountName: default
      
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/instance: release-name
                    app.kubernetes.io/name: postgresql
                    app.kubernetes.io/component: primary
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      securityContext:
        fsGroup: 1001
      hostNetwork: false
      hostIPC: false
      containers:
        - name: postgresql
          image: docker.io/bitnami/postgresql:16.0.0-debian-11-r3
          imagePullPolicy: "IfNotPresent"
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            runAsGroup: 0
            runAsNonRoot: true
            runAsUser: 1001
            seccompProfile:
              type: RuntimeDefault
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: POSTGRESQL_PORT_NUMBER
              value: "5432"
            - name: POSTGRESQL_VOLUME_DIR
              value: "/bitnami/postgresql"
            - name: PGDATA
              value: "/bitnami/postgresql/data"
            # Authentication
            - name: POSTGRES_USER
              value: "librephotos"
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: release-name-postgresql
                  key: password
            - name: POSTGRES_POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: release-name-postgresql
                  key: postgres-password
            - name: POSTGRES_DATABASE
              value: "librephotos"
            # Replication
            # Initdb
            # Standby
            # LDAP
            - name: POSTGRESQL_ENABLE_LDAP
              value: "no"
            # TLS
            - name: POSTGRESQL_ENABLE_TLS
              value: "no"
            # Audit
            - name: POSTGRESQL_LOG_HOSTNAME
              value: "false"
            - name: POSTGRESQL_LOG_CONNECTIONS
              value: "false"
            - name: POSTGRESQL_LOG_DISCONNECTIONS
              value: "false"
            - name: POSTGRESQL_PGAUDIT_LOG_CATALOG
              value: "off"
            # Others
            - name: POSTGRESQL_CLIENT_MIN_MESSAGES
              value: "error"
            - name: POSTGRESQL_SHARED_PRELOAD_LIBRARIES
              value: "pgaudit"
          ports:
            - name: tcp-postgresql
              containerPort: 5432
          livenessProbe:
            failureThreshold: 6
            initialDelaySeconds: 30
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            exec:
              command:
                - /bin/sh
                - -c
                - exec pg_isready -U "librephotos" -d "dbname=librephotos" -h 127.0.0.1 -p 5432
          readinessProbe:
            failureThreshold: 6
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            exec:
              command:
                - /bin/sh
                - -c
                - -e
                - |
                  exec pg_isready -U "librephotos" -d "dbname=librephotos" -h 127.0.0.1 -p 5432
                  [ -f /opt/bitnami/postgresql/tmp/.initialized ] || [ -f /bitnami/postgresql/.initialized ]
          resources:
            limits: {}
            requests:
              cpu: 250m
              memory: 256Mi
          volumeMounts:
            - name: dshm
              mountPath: /dev/shm
            - name: data
              mountPath: /bitnami/postgresql
      volumes:
        - name: dshm
          emptyDir:
            medium: Memory
  volumeClaimTemplates:
    - apiVersion: v1
      kind: PersistentVolumeClaim
      metadata:
        name: data
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: "8Gi"
---
# Source: librephotos/charts/redis/templates/master/application.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: release-name-redis-master
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: redis
    app.kubernetes.io/version: 7.2.1
    helm.sh/chart: redis-18.1.0
    app.kubernetes.io/component: master
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/name: redis
      app.kubernetes.io/component: master
  serviceName: release-name-redis-headless
  updateStrategy:
    type: RollingUpdate
  template:
    metadata:
      labels:
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: redis
        app.kubernetes.io/version: 7.2.1
        helm.sh/chart: redis-18.1.0
        app.kubernetes.io/component: master
      annotations:
        checksum/configmap: bea27d8c96777c27fc5814e9c6a07819e291720ae4b63f8144e22ee332d21cfa
        checksum/health: aff24913d801436ea469d8d374b2ddb3ec4c43ee7ab24663d5f8ff1a1b6991a9
        checksum/scripts: 560c33ff34d845009b51830c332aa05fa211444d1877d3526d3599be7543aaa5
        checksum/secret: cc26bdd3bb9423ac181210e300d51f45bd3a131161683f3e1b364a01543501ef
    spec:
      
      securityContext:
        fsGroup: 1001
      serviceAccountName: release-name-redis
      automountServiceAccountToken: true
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/instance: release-name
                    app.kubernetes.io/name: redis
                    app.kubernetes.io/component: master
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      enableServiceLinks: true
      terminationGracePeriodSeconds: 30
      containers:
        - name: redis
          image: docker.io/bitnami/redis:7.2.1-debian-11-r0
          imagePullPolicy: "IfNotPresent"
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            runAsGroup: 0
            runAsNonRoot: true
            runAsUser: 1001
            seccompProfile:
              type: RuntimeDefault
          command:
            - /bin/bash
          args:
            - -c
            - /opt/bitnami/scripts/start-scripts/start-master.sh
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: REDIS_REPLICATION_MODE
              value: master
            - name: ALLOW_EMPTY_PASSWORD
              value: "no"
            - name: REDIS_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: release-name-redis
                  key: redis-password
            - name: REDIS_TLS_ENABLED
              value: "no"
            - name: REDIS_PORT
              value: "6379"
          ports:
            - name: redis
              containerPort: 6379
          livenessProbe:
            initialDelaySeconds: 20
            periodSeconds: 5
            # One second longer than command timeout should prevent generation of zombie processes.
            timeoutSeconds: 6
            successThreshold: 1
            failureThreshold: 5
            exec:
              command:
                - sh
                - -c
                - /health/ping_liveness_local.sh 5
          readinessProbe:
            initialDelaySeconds: 20
            periodSeconds: 5
            timeoutSeconds: 2
            successThreshold: 1
            failureThreshold: 5
            exec:
              command:
                - sh
                - -c
                - /health/ping_readiness_local.sh 1
          resources:
            limits: {}
            requests: {}
          volumeMounts:
            - name: start-scripts
              mountPath: /opt/bitnami/scripts/start-scripts
            - name: health
              mountPath: /health
            - name: redis-data
              mountPath: /data
            - name: config
              mountPath: /opt/bitnami/redis/mounted-etc
            - name: redis-tmp-conf
              mountPath: /opt/bitnami/redis/etc/
            - name: tmp
              mountPath: /tmp
      volumes:
        - name: start-scripts
          configMap:
            name: release-name-redis-scripts
            defaultMode: 0755
        - name: health
          configMap:
            name: release-name-redis-health
            defaultMode: 0755
        - name: config
          configMap:
            name: release-name-redis-configuration
        - name: redis-tmp-conf
          emptyDir: {}
        - name: tmp
          emptyDir: {}
  volumeClaimTemplates:
    - apiVersion: v1
      kind: PersistentVolumeClaim
      metadata:
        name: redis-data
        labels:
          app.kubernetes.io/instance: release-name
          app.kubernetes.io/name: redis
          app.kubernetes.io/component: master
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: "8Gi"
---
# Source: librephotos/templates/cronjob-native/cronjob.yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: librephotos-scan-cron
  labels:
    app.kubernetes.io/app: scan-cron
    helm.sh/chart: librephotos-0.202337.0
    app.kubernetes.io/name: librephotos
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "2023w37p2"
    app.kubernetes.io/managed-by: Helm
  annotations:
        {}
spec:
  schedule: "0 * * * *"
  concurrencyPolicy: Forbid
  failedJobsHistoryLimit: 10
  successfulJobsHistoryLimit: 
  jobTemplate:
    metadata:
      labels:
        app.kubernetes.io/app: scan-cron
        app.kubernetes.io/name: librephotos
        app.kubernetes.io/instance: release-name
    spec:
      template:
        metadata:
          labels:
            app.kubernetes.io/app: scan-cron
            app.kubernetes.io/name: librephotos
            app.kubernetes.io/instance: release-name
        spec:
          restartPolicy: Never
          containers:
            - name: librephotos
              image: alpine/k8s:1.22.6
              imagePullPolicy: 
              volumeMounts:
              - name: backend-cj-script
                mountPath: /opt
              command:  [ "/bin/sh", "/opt/cronjob.sh"]
          serviceAccountName: release-name-scan-cron
          volumes:
          - name: backend-cj-script
            configMap:
              name: release-name-scan-cron
