---
# Source: mission-control/charts/canary-checker/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: release-name-canary-checker-sa
  labels:
    helm.sh/chart: canary-checker-1.0.260-beta.26
    app.kubernetes.io/version: "1.0.260-beta.26"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: canary-checker
    app.kubernetes.io/instance: release-name
    control-plane: canary-checker
---
# Source: mission-control/charts/config-db/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name:  config-db-sa
  labels:
    helm.sh/chart: config-db-0.0.263
    app.kubernetes.io/name: config-db
    app.kubernetes.io/instance: release-name
    control-plane: config-db
    app.kubernetes.io/version: "0.0.263"
    app.kubernetes.io/managed-by: Helm
---
# Source: mission-control/charts/flanksource-ui/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: incident-manager-ui
  labels:
    helm.sh/chart: flanksource-ui-1.0.636
    app.kubernetes.io/version: "1.0.636"
    app.kubernetes.io/managed-by: Helm
---
# Source: mission-control/charts/kratos/templates/rbac.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: kratos
  namespace: default
  labels:
    app.kubernetes.io/name: kratos
    helm.sh/chart: kratos-0.32.0
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "v0.13.0"
    app.kubernetes.io/managed-by: Helm
---
# Source: mission-control/templates/rbac.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: mission-control-sa
  labels:
    helm.sh/chart: mission-control-0.1.123
    app.kubernetes.io/name: mission-control
    app.kubernetes.io/instance: release-name
    control-plane: incident-commander
    app.kubernetes.io/version: "0.1.123"
    app.kubernetes.io/managed-by: Helm
---
# Source: mission-control/templates/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: incident-commander-postgres
type: Opaque
stringData:
  POSTGRES_USER: "postgres"
  POSTGRES_PASSWORD: "gt0kXg5HCeM5P1xbvpN5IsLe6DcyUzgK"
  POSTGRES_HOST: "postgres.default.svc.cluster.local"
  POSTGRES_PORT: "5432"
  SSLMODE: "disable"
  DB_URL:  "postgres://postgres:gt0kXg5HCeM5P1xbvpN5IsLe6DcyUzgK@postgres.default.svc.cluster.local/mission_control?sslmode=disable"
  DATABASE: "mission_control"
---
# Source: mission-control/templates/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: kratos
  namespace: default
type: Opaque
data:
  dsn: "cG9zdGdyZXM6Ly9wb3N0Z3JlczpndDBrWGc1SENlTTVQMXhidnBONUlzTGU2RGN5VXpnS0Bwb3N0Z3Jlcy5kZWZhdWx0LnN2Yy5jbHVzdGVyLmxvY2FsL21pc3Npb25fY29udHJvbA=="
  # Generate a random secret if the user doesn't give one. User given secret has priority
  secretsDefault: "InlldCBhbm90aGVyIHNlY3JldCIsImxvcmVtIGlwc3VtIGRvbG9yZXMiLCJqdXN0IGEgcmFuZG9tIGEgc3RyaW5nIHNlY3JldCI="
  secretsCookie: "ZUREdGZtc3ExenNocWVIaHNubmgyTFNkM1FSVllHN3c="
  secretsCipher: "bVdFSFdnaTRzamxrdlFPTFN2eGwya1ZHS1Q4WFNsaDQ="
  smtpConnectionURI: "c210cDovL3dyb25nLXVybA=="
---
# Source: mission-control/templates/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: incident-commander-postgrest-jwt
type: Opaque
stringData:
  PGRST_JWT_SECRET: "XgdzxI8iw1wL77WL4ZsPb2kwzbohkwLY"
---
# Source: mission-control/charts/canary-checker/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: canary-checker
  labels:
    helm.sh/chart: canary-checker-1.0.260-beta.26
    app.kubernetes.io/version: "1.0.260-beta.26"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: canary-checker
    app.kubernetes.io/instance: release-name
    control-plane: canary-checker
data:
  canary-checker.properties: |
---
# Source: mission-control/charts/kratos/templates/configmap-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: kratos-config
  namespace: default
  labels:
    app.kubernetes.io/name: kratos
    helm.sh/chart: kratos-0.32.0
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "v0.13.0"
    app.kubernetes.io/managed-by: Helm
  annotations:
data:
  # Render the kratos config:
  "kratos.yaml": |
    courier:
      smtp: {}
    log:
      level: warning
    serve:
      admin:
        port: 4434
      public:
        port: 4433
    session:
      lifespan: 336h
  # Render the identity schemas to disk:
---
# Source: mission-control/templates/kratos-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: mission-control-kratos-config
  labels:
    helm.sh/chart: mission-control-0.1.123
    app.kubernetes.io/name: mission-control
    app.kubernetes.io/instance: release-name
    control-plane: incident-commander
    app.kubernetes.io/version: "0.1.123"
    app.kubernetes.io/managed-by: Helm
data:
  "kratos.yaml": |
    courier:
      smtp:
        connection_uri: smtp://wrong-url
    identity:
      schemas:
      - id: default
        url: base64://ewogICIkaWQiOiAiaHR0cHM6Ly9zY2hlbWFzLm9yeS5zaC9wcmVzZXRzL2tyYXRvcy9xdWlja3N0YXJ0L2VtYWlsLXBhc3N3b3JkL2lkZW50aXR5LnNjaGVtYS5qc29uIiwKICAiJHNjaGVtYSI6ICJodHRwOi8vanNvbi1zY2hlbWEub3JnL2RyYWZ0LTA3L3NjaGVtYSMiLAogICJ0aXRsZSI6ICJQZXJzb24iLAogICJ0eXBlIjogIm9iamVjdCIsCiAgInByb3BlcnRpZXMiOiB7CiAgICAidHJhaXRzIjogewogICAgICAidHlwZSI6ICJvYmplY3QiLAogICAgICAicHJvcGVydGllcyI6IHsKICAgICAgICAiZW1haWwiOiB7CiAgICAgICAgICAidHlwZSI6ICJzdHJpbmciLAogICAgICAgICAgImZvcm1hdCI6ICJlbWFpbCIsCiAgICAgICAgICAidGl0bGUiOiAiRS1NYWlsIiwKICAgICAgICAgICJtaW5MZW5ndGgiOiAzLAogICAgICAgICAgIm9yeS5zaC9rcmF0b3MiOiB7CiAgICAgICAgICAgICJjcmVkZW50aWFscyI6IHsKICAgICAgICAgICAgICAicGFzc3dvcmQiOiB7CiAgICAgICAgICAgICAgICAiaWRlbnRpZmllciI6IHRydWUKICAgICAgICAgICAgICB9CiAgICAgICAgICAgIH0sCiAgICAgICAgICAgICJ2ZXJpZmljYXRpb24iOiB7CiAgICAgICAgICAgICAgInZpYSI6ICJlbWFpbCIKICAgICAgICAgICAgfSwKICAgICAgICAgICAgInJlY292ZXJ5IjogewogICAgICAgICAgICAgICJ2aWEiOiAiZW1haWwiCiAgICAgICAgICAgIH0KICAgICAgICAgIH0KICAgICAgICB9LAogICAgICAgICJuYW1lIjogewogICAgICAgICAgInR5cGUiOiAib2JqZWN0IiwKICAgICAgICAgICJwcm9wZXJ0aWVzIjogewogICAgICAgICAgICAiZmlyc3QiOiB7CiAgICAgICAgICAgICAgInRpdGxlIjogIkZpcnN0IE5hbWUiLAogICAgICAgICAgICAgICJ0eXBlIjogInN0cmluZyIKICAgICAgICAgICAgfSwKICAgICAgICAgICAgImxhc3QiOiB7CiAgICAgICAgICAgICAgInRpdGxlIjogIkxhc3QgTmFtZSIsCiAgICAgICAgICAgICAgInR5cGUiOiAic3RyaW5nIgogICAgICAgICAgICB9CiAgICAgICAgICB9CiAgICAgICAgfSwKICAgICAgICAiZ3JvdXBzIjogewogICAgICAgICAgInR5cGUiOiAiYXJyYXkiLAogICAgICAgICAgInRpdGxlIjogIkdyb3VwcyIsCiAgICAgICAgICAiaXRlbXMiOiB7CiAgICAgICAgICAgICJ0eXBlIjogInN0cmluZyIKICAgICAgICAgIH0KICAgICAgICB9CiAgICAgIH0sCiAgICAgICJyZXF1aXJlZCI6IFsiZW1haWwiXSwKICAgICAgImFkZGl0aW9uYWxQcm9wZXJ0aWVzIjogZmFsc2UKICAgIH0KICB9Cn0K
    log:
      leak_sensitive_values: false
      level: warning
    secrets:
      default:
      - yet another secret
      - lorem ipsum dolores
      - just a random a string secret
    selfservice:
      allowed_return_urls:
      - https://mission-control-ui.local
      default_browser_return_url: https://mission-control-ui.local/
      flows:
        error:
          ui_url: https://mission-control-ui.local/error
        login:
          lifespan: 10m
          ui_url: https://mission-control-ui.local/login
        logout:
          after:
            default_browser_return_url: https://mission-control-ui.local/login
        recovery:
          enabled: true
          ui_url: https://mission-control-ui.local/recovery
        registration:
          after:
            password:
              hooks:
              - hook: session
          enabled: false
          lifespan: 10m
          ui_url: https://mission-control-ui.local/registration
        settings:
          privileged_session_max_age: 15m
          ui_url: https://mission-control-ui.local/profile-settings
        verification:
          enabled: true
          ui_url: https://mission-control-ui.local/verification
      methods:
        link:
          enabled: true
        password:
          enabled: true
    serve:
      admin:
        port: 4434
      public:
        base_url: https://mission-control-ui.local/api/.ory
        cors:
          enabled: true
        port: 4433
    session:
      lifespan: 336h
---
# Source: mission-control/templates/properties-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: mission-control-properties-config
  labels:
    helm.sh/chart: mission-control-0.1.123
    app.kubernetes.io/name: mission-control
    app.kubernetes.io/instance: release-name
    control-plane: incident-commander
    app.kubernetes.io/version: "0.1.123"
    app.kubernetes.io/managed-by: Helm
data:
  mission-control.properties: |
    incidents.disable=true
    logs.disable=true
---
# Source: mission-control/charts/canary-checker/templates/clusterrole.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: "ClusterRole"
metadata:
  name: canary-checker-role
rules:
  - apiGroups:
      - ""
    resources:
      - secrets
    verbs:
      - get
      - list
  - apiGroups:
      - ""
    resources:
      - configmaps
    verbs:
      - get
      - list
  - apiGroups:
      - authentication.k8s.io
    resources:
      - serviceaccounts/token
    verbs:
      - create
  - apiGroups:
      - "*"
    resources:
      - "*"
    verbs:
      - list
      - get
      - watch
  - apiGroups:
      - canaries.flanksource.com
    resources:
      - canaries
      - topologies
    verbs:
      - create
      - delete
      - get
      - list
      - patch
      - update
      - watch
  - apiGroups:
      - canaries.flanksource.com
    resources:
      - canaries/status
      - topologies/status
    verbs:
      - get
      - patch
      - update
  # for creating and destroying pods during the pod canary test
  - apiGroups:
      - ""
    resources:
      - pods
      - namespaces
      - services
    verbs:
      - "*"
  - apiGroups:
      - "networking.k8s.io"
    resources:
      - ingresses
    verbs:
      - "*"
  - apiGroups:
      - "extensions"
    resources:
      - ingresses
    verbs:
      - "*"
  - apiGroups:
      - ""
    resources:
      - namespaces
    verbs:
      - "*"
  - apiGroups:
      - "metrics.k8s.io"
    resources:
      - pods
      - nodes
    verbs:
      - "*"
  - apiGroups:
      - ""
    resources:
      - nodes
    verbs:
      - get
      - list
  - apiGroups:
      - ""
    resources:
      - events
    verbs:
      - create
      - patch
  # for leader election
  - apiGroups:
      - ""
    resources:
      - configmaps
    verbs:
      - get
      - list
      - watch
      - create
      - update
      - patch
      - delete
  - apiGroups:
      - ""
    resources:
      - configmaps/status
    verbs:
      - get
      - update
      - patch
---
# Source: mission-control/charts/config-db/templates/serviceaccount.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: "ClusterRole"
metadata:
  name: config-db-sa-role
  labels:
    helm.sh/chart: config-db-0.0.263
    app.kubernetes.io/name: config-db
    app.kubernetes.io/instance: release-name
    control-plane: config-db
    app.kubernetes.io/version: "0.0.263"
    app.kubernetes.io/managed-by: Helm
rules:
- apiGroups: 
    - v1
  resources: 
    - secrets
  verbs:
    - get
    - list
- apiGroups: 
    - v1
  resources: 
    - configmaps
  verbs:
    - get
    - list
- apiGroups: [""]
  resources:
    - pods/attach
    - pods/exec
    - pods/log
  verbs:
    - '*'
- apiGroups: ['authentication.k8s.io/v1']
  resources: ['serviceaccounts/token']
  verbs: ['create']
- apiGroups:
  - '*'
  resources:
  - '*'
  verbs:
  - "list"
  - "get"
  - "watch"
- apiGroups:
  - configs.flanksource.com
  resources:
  - scrapeconfigs
  verbs:
  - create
  - delete
  - get
  - list
  - patch
  - update
  - watch
- apiGroups:
  - configs.flanksource.com
  resources:
  - scrapeconfigs/finalizers
  verbs:
  - update
- apiGroups:
  - configs.flanksource.com
  resources:
  - scrapeconfigs/status
  verbs:
  - get
  - patch
  - update
# Leader election
- apiGroups:
  - ""
  resources:
  - configmaps
  verbs:
  - get
  - list
  - watch
  - create
  - update
  - patch
  - delete
- apiGroups:
  - coordination.k8s.io
  resources:
  - leases
  verbs:
  - get
  - list
  - watch
  - create
  - update
  - patch
  - delete
- apiGroups:
  - ""
  resources:
  - events
  verbs:
  - create
  - patch
- apiGroups:
  - ""
  resources:
  - pods/exec
  verbs:
  - create
---
# Source: mission-control/templates/rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  creationTimestamp: null
  name: mission-control-role
rules:
- apiGroups:
  - mission-control.flanksource.com
  resources:
  - connections
  - incidentrules
  - playbooks
  - notifications
  verbs:
  - create
  - delete
  - get
  - list
  - patch
  - update
  - watch
- apiGroups:
  - mission-control.flanksource.com
  resources:
  - connections/finalizers
  - incidentrules/finalizers
  - playbooks/finalizers
  - notifications/finalizers
  verbs:
  - update
- apiGroups:
  - mission-control.flanksource.com
  resources:
  - connections/status
  - incidentrules/status
  - playbooks/status
  - notifications/status
  verbs:
  - get
  - patch
  - update
- apiGroups:
    - v1
  resources:
    - secrets
  verbs:
    - get
    - list
- apiGroups:
    - v1
  resources:
    - configmaps
  verbs:
    - get
    - list
- apiGroups: [""]
  resources:
    - pods/attach
    - pods/exec
    - pods/log
  verbs:
    - '*'
- apiGroups: [""]
  resources:
    - pods/attach
    - pods/exec
    - pods/log
    - pods
  verbs:
    - '*'
- apiGroups:
    - authentication.k8s.io/v1
  resources:
    - serviceaccounts/token
  verbs:
    - create
- apiGroups:
    - "*"
  resources:
    - "*"
  verbs:
    - list
    - get
    - watch
---
# Source: mission-control/charts/canary-checker/templates/clusterrolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: "ClusterRoleBinding"
metadata:
  name: release-name-canary-checker-rolebinding
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: "ClusterRole"
  name: canary-checker-role
subjects:
  - kind: ServiceAccount
    name: release-name-canary-checker-sa
    namespace: default
---
# Source: mission-control/charts/config-db/templates/serviceaccount.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: "ClusterRoleBinding"
metadata:
  name: config-db-sa-rolebinding
  labels:
    helm.sh/chart: config-db-0.0.263
    app.kubernetes.io/name: config-db
    app.kubernetes.io/instance: release-name
    control-plane: config-db
    app.kubernetes.io/version: "0.0.263"
    app.kubernetes.io/managed-by: Helm
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: "ClusterRole"
  name: config-db-sa-role
subjects:
  - kind: ServiceAccount
    name: config-db-sa
    namespace: default
---
# Source: mission-control/templates/rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: mission-control-rolebinding
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: mission-control-role
subjects:
  - kind: ServiceAccount
    name: mission-control-sa
    namespace: default
---
# Source: mission-control/charts/canary-checker/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: canary-checker
  labels:
    helm.sh/chart: canary-checker-1.0.260-beta.26
    app.kubernetes.io/version: "1.0.260-beta.26"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: canary-checker
    app.kubernetes.io/instance: release-name
    control-plane: canary-checker
spec:
  ports:
    - port: 8080
      targetPort: 8080
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/name: canary-checker
    app.kubernetes.io/instance: release-name
    control-plane: canary-checker
---
# Source: mission-control/charts/config-db/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: config-db
  labels:
    helm.sh/chart: config-db-0.0.263
    app.kubernetes.io/name: config-db
    app.kubernetes.io/instance: release-name
    control-plane: config-db
    app.kubernetes.io/version: "0.0.263"
    app.kubernetes.io/managed-by: Helm
spec:
  ports:
    - port: 8080
      targetPort: 8080
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/name: config-db
    app.kubernetes.io/instance: release-name
    control-plane: config-db
---
# Source: mission-control/charts/flanksource-ui/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: incident-manager-ui
  labels:
    helm.sh/chart: flanksource-ui-1.0.636
    app.kubernetes.io/version: "1.0.636"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 80
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/name: incident-manager-ui
    app.kubernetes.io/instance: release-name
---
# Source: mission-control/charts/kratos/templates/service-admin.yaml
apiVersion: v1
kind: Service
metadata:
  name: kratos-admin
  namespace: default
  labels:
    app.kubernetes.io/component: admin
    app.kubernetes.io/name: kratos
    helm.sh/chart: kratos-0.32.0
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "v0.13.0"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 80
      targetPort: http-admin
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/name: kratos
    app.kubernetes.io/instance: release-name
---
# Source: mission-control/charts/kratos/templates/service-public.yaml
apiVersion: v1
kind: Service
metadata:
  name: kratos-public
  namespace: default
  labels:
    app.kubernetes.io/component: public
    app.kubernetes.io/name: kratos
    helm.sh/chart: kratos-0.32.0
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "v0.13.0"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 80
      targetPort: http-public
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/name: kratos
    app.kubernetes.io/instance: release-name
---
# Source: mission-control/templates/postgres.yaml
apiVersion: v1
kind: Service
metadata:
  name: postgres
spec:
  selector:
    app: postgresql
  ports:
  - port: 5432
    targetPort: 5432
---
# Source: mission-control/templates/postgrest.yaml
apiVersion: v1
kind: Service
metadata:
  name: postgrest
  labels:
    app: postgrest
spec:
  ports:
    - port: 3000
      targetPort: 3000
      protocol: TCP
  selector:
    app: postgrest
    chart: "mission-control"
---
# Source: mission-control/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: mission-control
  labels:
    helm.sh/chart: mission-control-0.1.123
    app.kubernetes.io/name: mission-control
    app.kubernetes.io/instance: release-name
    control-plane: incident-commander
    app.kubernetes.io/version: "0.1.123"
    app.kubernetes.io/managed-by: Helm
spec:
  ports:
    - port: 8080
      targetPort: 8080
      protocol: TCP
  selector:
    app.kubernetes.io/name: mission-control
    app.kubernetes.io/instance: release-name
    control-plane: incident-commander
---
# Source: mission-control/charts/canary-checker/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: canary-checker
  labels:
    helm.sh/chart: canary-checker-1.0.260-beta.26
    app.kubernetes.io/version: "1.0.260-beta.26"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: canary-checker
    app.kubernetes.io/instance: release-name
    control-plane: canary-checker
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: canary-checker
      app.kubernetes.io/instance: release-name
      control-plane: canary-checker
  template:
    metadata:
      labels:
        app.kubernetes.io/name: canary-checker
        app.kubernetes.io/instance: release-name
        control-plane: canary-checker
    spec:
      serviceAccountName: release-name-canary-checker-sa
      volumes:
        - name: podinfo
          downwardAPI:
            items:
              - path: "labels"
                fieldRef:
                  fieldPath: metadata.labels
        - name: config
          configMap:
            name: canary-checker
      securityContext:
        fsGroup: 1000
        sysctls:
          - name: net.ipv4.ping_group_range
            value: "0 2147483647"
      containers:
        - name: canary-checker
          image: docker.io/flanksource/canary-checker-full:v1.0.260-beta.26
          imagePullPolicy: "IfNotPresent"
          env:
            - name: PING_MODE
              value:  "unprivileged"
            - name: DB_URL
              valueFrom:
                secretKeyRef:
                  name: incident-commander-postgres
                  key: DB_URL
          volumeMounts:
            - mountPath: /etc/podinfo
              name: podinfo
            - mountPath: /app/canary-checker.properties
              name: config
              subPath: canary-checker.properties
          command:
            - /app/canary-checker
          args:
            - operator
            - -v
            - --httpPort
            - "8080"
            - --disable-postgrest=true
            - --db-migrations=false
            - --cache-timeout=90
            - --default-window=1h
            - --otel-service-name=canary-checker
          resources:
            limits:
              memory: 2Gi
            requests:
              cpu: 200m
              memory: 200Mi
          livenessProbe:
            httpGet:
              path: /health
              port: 8080
          readinessProbe:
            httpGet:
              path: /health
              port: 8080
---
# Source: mission-control/charts/config-db/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: config-db
  labels:
    helm.sh/chart: config-db-0.0.263
    app.kubernetes.io/name: config-db
    app.kubernetes.io/instance: release-name
    control-plane: config-db
    app.kubernetes.io/version: "0.0.263"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: config-db
      app.kubernetes.io/instance: release-name
      control-plane: config-db
  template:
    metadata:
      labels:
        app.kubernetes.io/name: config-db
        app.kubernetes.io/instance: release-name
        control-plane: config-db
    spec:
      serviceAccountName: config-db-sa
      securityContext:
        fsGroup: 1000
      containers:
        - name: config-db
          image: "docker.io/flanksource/config-db:v0.0.263"
          imagePullPolicy: IfNotPresent
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /live
              port: 8080
              scheme: HTTP
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /ready
              port: 8080
              scheme: HTTP
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
          command:
            - /app/config-db
          args:
            - operator
            - -v
            - --disable-postgrest=true
            - --change-retention-days=60
            - --analysis-retention-days=60
          env:
            - name: DB_URL
              valueFrom:
                secretKeyRef:
                  name: "incident-commander-postgres"
                  key: "DB_URL"
            - name: NAMESPACE
              value: default
          resources:
            limits:
              cpu: 500m
              memory: 4Gi
            requests:
              cpu: 200m
              memory: 1Gi
          volumeMounts:
---
# Source: mission-control/charts/flanksource-ui/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: incident-manager-ui
  labels:
    helm.sh/chart: flanksource-ui-1.0.636
    app.kubernetes.io/version: "1.0.636"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: incident-manager-ui
      app.kubernetes.io/instance: release-name
  template:
    metadata:
      labels:
        app.kubernetes.io/name: incident-manager-ui
        app.kubernetes.io/instance: release-name
    spec:
      serviceAccountName: incident-manager-ui
      securityContext:
        {}
      containers:
        - name: flanksource-ui
          securityContext:
            {}
          image: docker.io/flanksource/incident-manager-ui:v1.0.636
          env:
          - name: HOSTNAME
            value: "0.0.0.0"
          - name: ORY_KRATOS_URL
            value: http://mission-control-ui.local/api/.ory
          - name: BACKEND_URL
            value: "http://mission-control:8080"
          imagePullPolicy: IfNotPresent
          ports:
            - name: http
              containerPort: 3000 # TODO(infra): application port. Make configurable.
              protocol: TCP
          livenessProbe:
            httpGet:
              path: /api/_health
              port: http
          readinessProbe:
            httpGet:
              path: /api/_health
              port: http
          resources:
            {}
---
# Source: mission-control/charts/kratos/templates/deployment-kratos.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: kratos
  namespace: default
  labels:
    app.kubernetes.io/name: kratos
    helm.sh/chart: kratos-0.32.0
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "v0.13.0"
    app.kubernetes.io/managed-by: Helm
  annotations:
spec:
  progressDeadlineSeconds: 3600
  replicas: 1
  strategy:
    rollingUpdate:
      maxSurge: 30%
      maxUnavailable: 0
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/name: kratos
      app.kubernetes.io/instance: release-name
  template:
    metadata:
      labels:
        app.kubernetes.io/name: kratos
        helm.sh/chart: kratos-0.32.0
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/version: "v0.13.0"
        app.kubernetes.io/managed-by: Helm
      annotations:        
    spec:
      initContainers:
        - name: kratos-automigrate
          image: oryd/kratos:v0.13.0
          imagePullPolicy: IfNotPresent
          command: ["kratos"]
          args: ["migrate", "sql", "-e", "--yes", "--config", "/etc/config/kratos.yaml"]
          volumeMounts:
            - name: kratos-config-volume
              mountPath: /etc/config
              readOnly: true
            - mountPath: /etc/custom/config
              name: kratos-custom-config-volume
              readOnly: true
          env:
            - name: DSN
              valueFrom:
                secretKeyRef:
                  name: kratos
                  key: dsn
      volumes:
        - configMap:
            name: mission-control-kratos-config
          name: kratos-custom-config-volume
        - name: kratos-config-volume
          configMap:
            name: kratos-config
      automountServiceAccountToken: true
      serviceAccountName: kratos
      containers:
        - name: kratos
          image: oryd/kratos:v0.13.0
          imagePullPolicy: IfNotPresent
          command:
            - kratos
          args:
            - serve
            - all
            - --config
            - /etc/config/kratos.yaml
            - --watch-courier
            - --config
            - /etc/custom/config/kratos.yaml
          volumeMounts:
            - mountPath: /etc/custom/config
              name: kratos-custom-config-volume
              readOnly: true
            - name: kratos-config-volume
              mountPath: /etc/config
              readOnly: true
          env:
            - name: DSN
              valueFrom:
                secretKeyRef:
                  name: kratos
                  key: dsn
            - name: SECRETS_DEFAULT
              valueFrom:
                secretKeyRef:
                  name: kratos
                  key: secretsDefault
                  optional: true
            - name: SECRETS_COOKIE
              valueFrom:
                secretKeyRef:
                  name: kratos
                  key: secretsCookie
                  optional: true
            - name: SECRETS_CIPHER
              valueFrom:
                secretKeyRef:
                  name: kratos
                  key: secretsCipher
                  optional: true
            - name: COURIER_SMTP_CONNECTION_URI
              valueFrom:
                secretKeyRef:
                  name: kratos
                  key: smtpConnectionURI
          ports:
            - name: http-admin
              containerPort: 4434
              protocol: TCP
            - name: http-public
              containerPort: 4433
              protocol: TCP
          lifecycle:
            {}
          livenessProbe:
            httpGet:
              path: /admin/health/ready
              port: 4434
              httpHeaders:
                - name: Host
                  value: '127.0.0.1'
            failureThreshold: 5
            initialDelaySeconds: 5
            periodSeconds: 10
          readinessProbe:
            httpGet:
              path: /admin/health/ready
              port: 4434
              httpHeaders:
                - name: Host
                  value: '127.0.0.1'
            failureThreshold: 5
            initialDelaySeconds: 5
            periodSeconds: 10
          startupProbe:
            httpGet:
              path: /admin/health/ready
              port: 4434
              httpHeaders:
                - name: Host
                  value: '127.0.0.1'
            failureThreshold: 60
            periodSeconds: 1
            successThreshold: 1
            timeoutSeconds: 1
          resources:
            {}
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            privileged: false
            readOnlyRootFilesystem: true
            runAsNonRoot: true
            runAsUser: 100
            seccompProfile:
              type: RuntimeDefault
---
# Source: mission-control/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: mission-control
  labels:
    helm.sh/chart: mission-control-0.1.123
    app.kubernetes.io/name: mission-control
    app.kubernetes.io/instance: release-name
    control-plane: incident-commander
    app.kubernetes.io/version: "0.1.123"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: mission-control
      app.kubernetes.io/instance: release-name
      control-plane: incident-commander
  template:
    metadata:
      labels:
        app.kubernetes.io/name: mission-control
        app.kubernetes.io/instance: release-name
        control-plane: incident-commander
    spec:
      serviceAccountName: mission-control-sa
      volumes:
        - name: properties-config
          configMap:
            name: mission-control-properties-config
      containers:
        - name: mission-control
          image: "docker.io/flanksource/incident-commander:v0.0.530"
          imagePullPolicy: IfNotPresent
          env:
            - name: DB_URL
              valueFrom:
                secretKeyRef:
                  name: incident-commander-postgres
                  key: DB_URL
            - name: PGRST_JWT_SECRET
              valueFrom:
                secretKeyRef:
                  name: incident-commander-postgrest-jwt
                  key: PGRST_JWT_SECRET
            - name: ADMIN_PASSWORD
              value: admin
          envFrom:
            - secretRef:
                name: incident-commander-smtp
                optional: true
          command:
            - /app/incident-commander
          args:
            - serve
            - --public-endpoint=https://
            - --apm-hub=http://apm-hub:8080
            - --canary-checker=http://canary-checker:8080
            - --config-db=http://config-db:8080
            - --auth=kratos
            - --kratos-api=http://kratos-public:80
            - --postgrest-uri=http://postgrest:3000
            - --otel-service-name=mission-control
          resources:
            limits:
              cpu: 500m
              memory: 1024Mi
            requests:
              cpu: 100m
              memory: 768Mi
          startupProbe:
              periodSeconds: 10
              failureThreshold: 120 # 20 minutes for any migration scripts to run
              httpGet:
                path: /health
                port: 8080
          livenessProbe:
            httpGet:
              path: /health
              port: 8080
          readinessProbe:
            httpGet:
              path: /health
              port: 8080
          volumeMounts:
            - mountPath: /app/mission-control.properties
              name: properties-config
              subPath: mission-control.properties
---
# Source: mission-control/templates/postgrest.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: postgrest-mission-control
  labels:
    app: postgrest
    chart: "mission-control"
spec:
  replicas: 1
  selector:
    matchLabels:
      app: postgrest
      chart: "mission-control"
  template:
    metadata:
      labels:
        app: postgrest
        chart: "mission-control"
    spec:
      containers:
        - name: postgrest
          image: docker.io/postgrest/postgrest:v10.1.0
          imagePullPolicy: IfNotPresent
          env:
            - name: PGRST_DB_URI
              valueFrom:
                secretKeyRef:
                  name: incident-commander-postgres
                  key: DB_URL
            - name: PGRST_JWT_SECRET
              valueFrom:
                secretKeyRef:
                  name: incident-commander-postgrest-jwt
                  key: PGRST_JWT_SECRET
            - name: PGRST_DB_SCHEMA
              value: public
            - name: PGRST_DB_ANON_ROLE
              value: postgrest_anon
            - name: PGRST_LOG_LEVEL
              value: info
            - name: PGRST_DB_MAX_ROWS
              value: '2000'
            - name: PGRST_OPENAPI_SERVER_PROXY_URI
              value: http://mission-control/db
---
# Source: mission-control/templates/postgres.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: postgresql
spec:
  serviceName: postgresql
  selector:
    matchLabels:
      app: postgresql
  replicas: 1
  template:
    metadata:
      labels:
        app: postgresql
    spec:
      volumes:
        - name: dshm
          emptyDir:
            medium: Memory
            sizeLimit: "256Mi"
        - name: conf
          configMap:
            name: postgresql-conf
            optional: true
        - name: logs
          emptyDir: {}

      initContainers:
        - command:
          - sh
          - -c
          - mkdir -p /postgres && chmod -R 0750 /postgres && chown 999:999 -R /postgres &&  chmod -R 777 /dev/shm
          image: busybox
          name: postgres-perms
          volumeMounts:
          - mountPath: /postgres
            name: postgresql
          - name: dshm
            mountPath: /dev/shm
      containers:
      - name: postgresql
        image: docker.io/supabase/postgres:14.1.0.21
        command:
          - /usr/local/bin/docker-entrypoint.sh
          - -D
          - /var/lib/postgresql/data
          - --config-file=/etc/postgresql/postgresql.conf
          - '--db_user_namespace=false'
          - '--effective_cache_size=3GB'
          - '--effective_io_concurrency=200'
          - '--extra_float_digits=0'
          - '--log_autovacuum_min_duration=0'
          - '--log_connections=true'
          - '--log_destination=stderr'
          - '--log_directory=/var/log/postgresql'
          - '--log_file_mode=420'
          - '--log_filename=postgresql.log'
          - '--log_line_prefix=%m [%p] %q[user=%u,db=%d,app=%a] '
          - '--log_lock_waits=true'
          - '--log_min_duration_statement=1s'
          - '--log_rotation_age=0'
          - '--log_rotation_size=0'
          - '--log_statement=all'
          - '--log_temp_files=0'
          - '--log_timezone=UTC'
          - '--logging_collector=true'
          - '--maintenance_work_mem=256MB'
          - '--max_connections=200'
          - '--max_wal_size=4GB'
          - '--password_encryption=scram-sha-256'
          - '--shared_buffers=1GB'
          - '--ssl=false'
          - '--timezone=UTC'
          - '--wal_buffers=16MB'
          - '--work_mem=10MB'
        resources:
            requests:
              memory: 4Gi
        env:
          - name: PGDATA
            value: /var/lib/postgresql/data
          - name: POSTGRES_DB
            value: mission_control
        volumeMounts:
          - name: dshm
            mountPath: /dev/shm
          - name: postgresql
            mountPath: /var/lib/postgresql/data
            subPath: postgres
          - name: logs
            mountPath: /var/log/postgresql
        envFrom:
          - secretRef:
              name: incident-commander-postgres

  volumeClaimTemplates:
  - metadata:
      name: postgresql
    spec:
      accessModes: ["ReadWriteOnce"]
      
      resources:
        requests:
          storage: 20Gi
---
# Source: mission-control/charts/flanksource-ui/templates/ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: incident-manager-ui
  labels:
    helm.sh/chart: flanksource-ui-1.0.636
    app.kubernetes.io/version: "1.0.636"
    app.kubernetes.io/managed-by: Helm
spec:
  tls:
    - hosts:
        - "mission-control-ui.local"
      secretName: mission-control-ui-tls
  rules:
    - host: "mission-control-ui.local"
      http:
        paths:
          - path: /
            pathType: ImplementationSpecific
            backend:
              service:
                name: incident-manager-ui
                port:
                  number: 80
---
# Source: mission-control/charts/kratos/templates/statefulset-svc.yaml
# Headless Service for StatefulSet. See https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#limitations 
# and https://kubernetes.io/docs/concepts/services-networking/service/#headless-services for details.
---
# Source: mission-control/charts/kratos/templates/job-rbac.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: kratos-job
  namespace: default
  labels:
    app.kubernetes.io/name: kratos
    helm.sh/chart: kratos-0.32.0
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "v0.13.0"
    app.kubernetes.io/managed-by: Helm
  annotations:
    helm.sh/hook: pre-install, pre-upgrade
    helm.sh/hook-delete-policy: before-hook-creation
    helm.sh/hook-weight: "0"
---
# Source: mission-control/charts/flanksource-ui/templates/tests/test-connection.yaml
apiVersion: v1
kind: Pod
metadata:
  name: "incident-manager-ui-test-connection"
  labels:
    helm.sh/chart: flanksource-ui-1.0.636
    app.kubernetes.io/version: "1.0.636"
    app.kubernetes.io/managed-by: Helm
  annotations:
    "helm.sh/hook": test
spec:
  containers:
    - name: wget
      image: busybox
      command: ['wget']
      args: ['incident-manager-ui:80']
  restartPolicy: Never
---
# Source: mission-control/charts/kratos/templates/tests/test-connection.yaml
apiVersion: v1
kind: Pod
metadata:
  name: "kratos-test-connection"
  namespace: default
  labels:
    app.kubernetes.io/name: kratos
    helm.sh/chart: kratos-0.32.0
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "v0.13.0"
    app.kubernetes.io/managed-by: Helm
  annotations:
    "helm.sh/hook": test-success
spec:
  containers:
    - name: wget
      image: busybox
      command: ['wget']
      args:  ['kratos-admin:80/admin/health/ready']
  restartPolicy: Never
