---
# Source: logstash/templates/poddisruptionbudget.yaml
apiVersion: policy/v1beta1
kind: PodDisruptionBudget
metadata:
  name: release-name-logstash
  labels:
    app: logstash
    chart: logstash-1.10.0
    release: release-name
    heritage: Helm
spec:
  selector:
    matchLabels:
      app: logstash
      release: release-name
  maxUnavailable: 1
---
# Source: logstash/templates/files-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-logstash-files
  labels:
    app: logstash
    chart: logstash-1.10.0
    release: release-name
    heritage: Helm
data:
binaryData:
---
# Source: logstash/templates/patterns-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-logstash-patterns
  labels:
    app: logstash
    chart: logstash-1.10.0
    release: release-name
    heritage: Helm
data:
---
# Source: logstash/templates/pipeline-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-logstash-pipeline
  labels:
    app: logstash
    chart: logstash-1.10.0
    release: release-name
    heritage: Helm
data:
  input_main: |-
    input {
      # udp {
      #   port => 1514
      #   type => syslog
      # }
      # tcp {
      #   port => 1514
      #   type => syslog
      # }
      beats {
        port => 5044
      }
      # http {
      #   port => 8080
      # }
      # kafka {
      #   ## ref: https://www.elastic.co/guide/en/logstash/current/plugins-inputs-kafka.html
      #   bootstrap_servers => "kafka-input:9092"
      #   codec => json { charset => "UTF-8" }
      #   consumer_threads => 1
      #   topics => ["source"]
      #   type => "example"
      # }
    }
  output_main: |-
    output {
      # stdout { codec => rubydebug }
      elasticsearch {
        hosts => ["${ELASTICSEARCH_HOST}:${ELASTICSEARCH_PORT}"]
        manage_template => false
        index => "%{[@metadata][beat]}-%{+YYYY.MM.dd}"
        document_type => "%{[@metadata][type]}"
      }
      # kafka {
      #   ## ref: https://www.elastic.co/guide/en/logstash/current/plugins-outputs-kafka.html
      #   bootstrap_servers => "kafka-output:9092"
      #   codec => json { charset => "UTF-8" }
      #   compression_type => "lz4"
      #   topic_id => "destination"
      # }
    }
---
# Source: logstash/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-logstash
  labels:
    app: logstash
    chart: logstash-1.10.0
    release: release-name
    heritage: Helm
  annotations:
spec:
  type: ClusterIP
  ports:
    - name: beats
      port: 5044
      protocol: TCP
      targetPort: beats
  selector:
    app: logstash
    release: release-name
---
# Source: logstash/templates/statefulset.yaml
apiVersion: apps/v1beta2
kind: StatefulSet
metadata:
  name: release-name-logstash
  labels:
    app: logstash
    chart: logstash-1.10.0
    release: release-name
    heritage: Helm
spec:
  serviceName: release-name-logstash
  replicas: 1
  selector:
    matchLabels:
      app: logstash
      release: release-name
  template:
    metadata:
      labels:
        app: logstash
        release: release-name
      annotations:
        checksum/patterns: ba7a750b699de5015d34b26e3da16fc3d817a8f5b1889b2cb05830b15d25876b
        checksum/templates: 8af5239b6b02e797636c8a8117f202e2625a1b840f57b977e4f82841f3be528f
        checksum/pipeline: 83ce8ad8440919ceeb5e87ec45c74d52863afd55965bad5f294c3a94d74a311c
    spec:
      securityContext:
        runAsUser: 1000
        fsGroup: 1000
      containers:

        ## logstash
        - name: logstash
          image: "docker.elastic.co/logstash/logstash-oss:6.7.0"
          imagePullPolicy: IfNotPresent
          ports:
            - name: monitor
              containerPort: 9600
              protocol: TCP
            - containerPort: 5044
              name: beats
              protocol: TCP
          livenessProbe:
            httpGet:
              path: /
              port: monitor
            initialDelaySeconds: 20
          readinessProbe:
            httpGet:
              path: /
              port: monitor
            initialDelaySeconds: 20
          env:
            ## Logstash monitoring API host and port env vars
            - name: HTTP_HOST
              value: "0.0.0.0"
            - name: HTTP_PORT
              value: "9600"
            ## Elasticsearch output
            - name: ELASTICSEARCH_HOST
              value: "elasticsearch-client.default.svc.cluster.local"
            - name: ELASTICSEARCH_PORT
              value: "9200"
            # Logstash Java Options
            - name: LS_JAVA_OPTS
              value: -Xmx1g -Xms1g
            ## Additional env vars
            - name: CONFIG_RELOAD_AUTOMATIC
              value: "true"
            - name: PATH_CONFIG
              value: "/usr/share/logstash/pipeline"
            - name: PATH_DATA
              value: "/usr/share/logstash/data"
            - name: QUEUE_CHECKPOINT_WRITES
              value: "1"
            - name: QUEUE_DRAIN
              value: "true"
            - name: QUEUE_MAX_BYTES
              value: "1gb"
            - name: QUEUE_TYPE
              value: "persisted"
          resources:
            {}
          volumeMounts:
            - mountPath: /usr/share/logstash/data
              name: data
            - mountPath: /usr/share/logstash/patterns
              name: patterns
            - mountPath: /usr/share/logstash/files
              name: files
            - mountPath: /usr/share/logstash/pipeline
              name: pipeline
      terminationGracePeriodSeconds: 30
      volumes:
        - name: patterns
          configMap:
            name: release-name-logstash-patterns
        - name: files
          configMap:
            name: release-name-logstash-files
        - name: pipeline
          configMap:
            name: release-name-logstash-pipeline
  volumeClaimTemplates:
    - metadata:
        name: data
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: "2Gi"
