---
# Source: system/charts/kafka/templates/networkpolicy.yaml
kind: NetworkPolicy
apiVersion: networking.k8s.io/v1
metadata:
  name: kafka
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: kafka
    app.kubernetes.io/version: 3.7.0
    helm.sh/chart: kafka-28.0.4
spec:
  podSelector:
    matchLabels:
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/name: kafka
  policyTypes:
    - Ingress
    - Egress
  egress:
    - {}
  ingress:
    # Allow client connections
    - ports:
        - port: 9092
        - port: 9094
        - port: 9093
---
# Source: system/charts/redis/templates/networkpolicy.yaml
kind: NetworkPolicy
apiVersion: networking.k8s.io/v1
metadata:
  name: redis
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: redis
    app.kubernetes.io/version: 7.2.4
    helm.sh/chart: redis-19.1.3
spec:
  podSelector:
    matchLabels:
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/name: redis
  policyTypes:
    - Ingress
    - Egress
  egress:
    - {}
  ingress:
    # Allow inbound connections
    - ports:
        - port: 6379
---
# Source: system/charts/access-control-srv/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: access-control-srv
  labels:
    helm.sh/chart: access-control-srv-0.1.29
    app.kubernetes.io/name: access-control-srv
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.4.2"
    app.kubernetes.io/managed-by: Helm
---
# Source: system/charts/catalog-srv/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: catalog-srv
  labels:
    helm.sh/chart: catalog-srv-0.1.17
    app.kubernetes.io/name: catalog-srv
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.4.5"
    app.kubernetes.io/managed-by: Helm
---
# Source: system/charts/facade-srv/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: facade-srv
  labels:
    helm.sh/chart: facade-srv-0.1.28
    app.kubernetes.io/name: facade-srv
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.5.8"
    app.kubernetes.io/managed-by: Helm
---
# Source: system/charts/fulfillment-srv/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: fulfillment-srv
  labels:
    helm.sh/chart: fulfillment-srv-0.1.18
    app.kubernetes.io/name: fulfillment-srv
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.2.6"
    app.kubernetes.io/managed-by: Helm
---
# Source: system/charts/identity-srv/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: identity-srv
  labels:
    helm.sh/chart: identity-srv-0.1.30
    app.kubernetes.io/name: identity-srv
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.6.12"
    app.kubernetes.io/managed-by: Helm
---
# Source: system/charts/invoicing-srv/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: invoicing-srv
  labels:
    helm.sh/chart: invoicing-srv-0.1.18
    app.kubernetes.io/name: invoicing-srv
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.3.8"
    app.kubernetes.io/managed-by: Helm
---
# Source: system/charts/kafka/templates/provisioning/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: kafka-provisioning
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: kafka
    app.kubernetes.io/version: 3.7.0
    helm.sh/chart: kafka-28.0.4
automountServiceAccountToken: false
---
# Source: system/charts/kafka/templates/rbac/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: kafka
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: kafka
    app.kubernetes.io/version: 3.7.0
    helm.sh/chart: kafka-28.0.4
    app.kubernetes.io/component: kafka
automountServiceAccountToken: false
---
# Source: system/charts/notification-srv/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: notification-srv
  labels:
    helm.sh/chart: notification-srv-0.1.24
    app.kubernetes.io/name: notification-srv
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.3.6"
    app.kubernetes.io/managed-by: Helm
---
# Source: system/charts/ordering-srv/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: ordering-srv
  labels:
    helm.sh/chart: ordering-srv-0.1.19
    app.kubernetes.io/name: ordering-srv
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.2.9"
    app.kubernetes.io/managed-by: Helm
---
# Source: system/charts/ostorage-srv/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: ostorage-srv
  labels:
    helm.sh/chart: ostorage-srv-0.1.24
    app.kubernetes.io/name: ostorage-srv
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.3.7"
    app.kubernetes.io/managed-by: Helm
---
# Source: system/charts/payment-srv/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: payment-srv
  labels:
    helm.sh/chart: payment-srv-0.1.16
    app.kubernetes.io/name: payment-srv
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.3.3"
    app.kubernetes.io/managed-by: Helm
---
# Source: system/charts/pdf-rendering-srv/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: pdf-rendering-srv
  labels:
    helm.sh/chart: pdf-rendering-srv-0.2.4
    app.kubernetes.io/name: pdf-rendering-srv
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.0.6"
    app.kubernetes.io/managed-by: Helm
---
# Source: system/charts/redis/templates/master/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
automountServiceAccountToken: false
metadata:
  name: redis-master
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: redis
    app.kubernetes.io/version: 7.2.4
    helm.sh/chart: redis-19.1.3
---
# Source: system/charts/rendering-srv/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: rendering-srv
  labels:
    helm.sh/chart: rendering-srv-0.1.27
    app.kubernetes.io/name: rendering-srv
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.3.9"
    app.kubernetes.io/managed-by: Helm
---
# Source: system/charts/resource-srv/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: resource-srv
  labels:
    helm.sh/chart: resource-srv-0.1.18
    app.kubernetes.io/name: resource-srv
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.5.6"
    app.kubernetes.io/managed-by: Helm
---
# Source: system/charts/scheduling-srv/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: scheduling-srv
  labels:
    helm.sh/chart: scheduling-srv-0.1.20
    app.kubernetes.io/name: scheduling-srv
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.2.7"
    app.kubernetes.io/managed-by: Helm
---
# Source: system/templates/job-1-migrations.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: release-name-system-1-migrations
  labels:
    helm.sh/chart: system-0.1.75
    app.kubernetes.io/name: system
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
---
# Source: system/charts/kafka/templates/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: kafka-user-passwords
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: kafka
    app.kubernetes.io/version: 3.7.0
    helm.sh/chart: kafka-28.0.4
type: Opaque
data:
  client-passwords: "QnNpdFRrZW12Rw=="
  system-user-password: "QnNpdFRrZW12Rw=="
  inter-broker-password: "REdZekZNRUVtMg=="
  controller-password: "OFJHV1JKOGI4NA=="
---
# Source: system/charts/kafka/templates/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: kafka-kraft-cluster-id
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: kafka
    app.kubernetes.io/version: 3.7.0
    helm.sh/chart: kafka-28.0.4
type: Opaque
data:
  kraft-cluster-id: "RnJkQTlyODBtQ2lPSGVwNE1RcGNXOA=="
---
# Source: system/charts/kafka/templates/controller-eligible/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: kafka-controller-configuration
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: kafka
    app.kubernetes.io/version: 3.7.0
    helm.sh/chart: kafka-28.0.4
    app.kubernetes.io/component: controller-eligible
    app.kubernetes.io/part-of: kafka
data:
  server.properties: |-
    # Listeners configuration
    listeners=CLIENT://:9092,INTERNAL://:9094,CONTROLLER://:9093
    advertised.listeners=CLIENT://advertised-address-placeholder:9092,INTERNAL://advertised-address-placeholder:9094
    listener.security.protocol.map=CLIENT:SASL_PLAINTEXT,INTERNAL:SASL_PLAINTEXT,CONTROLLER:SASL_PLAINTEXT
    # KRaft process roles
    process.roles=controller,broker
    #node.id=
    controller.listener.names=CONTROLLER
    controller.quorum.voters=0@kafka-controller-0.kafka-controller-headless.default.svc.cluster.local:9093,1@kafka-controller-1.kafka-controller-headless.default.svc.cluster.local:9093,2@kafka-controller-2.kafka-controller-headless.default.svc.cluster.local:9093
    # Kraft Controller listener SASL settings
    sasl.mechanism.controller.protocol=PLAIN
    listener.name.controller.sasl.enabled.mechanisms=PLAIN
    listener.name.controller.plain.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username="controller_user" password="controller-password-placeholder" user_controller_user="controller-password-placeholder";
    # Kafka data logs directory
    log.dir=/bitnami/kafka/data
    # Kafka application logs directory
    logs.dir=/opt/bitnami/kafka/logs
    
    sasl.enabled.mechanisms=PLAIN,SCRAM-SHA-256,SCRAM-SHA-512
    # Interbroker configuration
    inter.broker.listener.name=INTERNAL
    sasl.mechanism.inter.broker.protocol=PLAIN
    # Listeners SASL JAAS configuration
    listener.name.client.plain.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required user_user1="password-placeholder-0";
    listener.name.client.scram-sha-256.sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required;
    listener.name.client.scram-sha-512.sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required;
    listener.name.internal.plain.sasl.jaas.config=org.apache.kafka.common.security.plain.PlainLoginModule required username="inter_broker_user" password="interbroker-password-placeholder" user_inter_broker_user="interbroker-password-placeholder" user_user1="password-placeholder-0";
    listener.name.internal.scram-sha-256.sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required username="inter_broker_user" password="interbroker-password-placeholder";
    listener.name.internal.scram-sha-512.sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required username="inter_broker_user" password="interbroker-password-placeholder";
    # End of SASL JAAS configuration
---
# Source: system/charts/kafka/templates/scripts-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: kafka-scripts
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: kafka
    app.kubernetes.io/version: 3.7.0
    helm.sh/chart: kafka-28.0.4
data:
  kafka-init.sh: |-
    #!/bin/bash

    set -o errexit
    set -o nounset
    set -o pipefail

    error(){
      local message="${1:?missing message}"
      echo "ERROR: ${message}"
      exit 1
    }

    retry_while() {
        local -r cmd="${1:?cmd is missing}"
        local -r retries="${2:-12}"
        local -r sleep_time="${3:-5}"
        local return_value=1

        read -r -a command <<< "$cmd"
        for ((i = 1 ; i <= retries ; i+=1 )); do
            "${command[@]}" && return_value=0 && break
            sleep "$sleep_time"
        done
        return $return_value
    }

    replace_in_file() {
        local filename="${1:?filename is required}"
        local match_regex="${2:?match regex is required}"
        local substitute_regex="${3:?substitute regex is required}"
        local posix_regex=${4:-true}

        local result

        # We should avoid using 'sed in-place' substitutions
        # 1) They are not compatible with files mounted from ConfigMap(s)
        # 2) We found incompatibility issues with Debian10 and "in-place" substitutions
        local -r del=$'\001' # Use a non-printable character as a 'sed' delimiter to avoid issues
        if [[ $posix_regex = true ]]; then
            result="$(sed -E "s${del}${match_regex}${del}${substitute_regex}${del}g" "$filename")"
        else
            result="$(sed "s${del}${match_regex}${del}${substitute_regex}${del}g" "$filename")"
        fi
        echo "$result" > "$filename"
    }

    kafka_conf_set() {
        local file="${1:?missing file}"
        local key="${2:?missing key}"
        local value="${3:?missing value}"

        # Check if the value was set before
        if grep -q "^[#\\s]*$key\s*=.*" "$file"; then
            # Update the existing key
            replace_in_file "$file" "^[#\\s]*${key}\s*=.*" "${key}=${value}" false
        else
            # Add a new key
            printf '\n%s=%s' "$key" "$value" >>"$file"
        fi
    }

    replace_placeholder() {
      local placeholder="${1:?missing placeholder value}"
      local password="${2:?missing password value}"
      sed -i "s/$placeholder/$password/g" "$KAFKA_CONFIG_FILE"
    }

    append_file_to_kafka_conf() {
        local file="${1:?missing source file}"
        local conf="${2:?missing kafka conf file}"

        cat "$1" >> "$2"
    }

    configure_external_access() {
      # Configure external hostname
      if [[ -f "/shared/external-host.txt" ]]; then
        host=$(cat "/shared/external-host.txt")
      elif [[ -n "${EXTERNAL_ACCESS_HOST:-}" ]]; then
        host="$EXTERNAL_ACCESS_HOST"
      elif [[ -n "${EXTERNAL_ACCESS_HOSTS_LIST:-}" ]]; then
        read -r -a hosts <<<"$(tr ',' ' ' <<<"${EXTERNAL_ACCESS_HOSTS_LIST}")"
        host="${hosts[$POD_ID]}"
      elif [[ "$EXTERNAL_ACCESS_HOST_USE_PUBLIC_IP" =~ ^(yes|true)$ ]]; then
        host=$(curl -s https://ipinfo.io/ip)
      else
        error "External access hostname not provided"
      fi

      # Configure external port
      if [[ -f "/shared/external-port.txt" ]]; then
        port=$(cat "/shared/external-port.txt")
      elif [[ -n "${EXTERNAL_ACCESS_PORT:-}" ]]; then
        if [[ "${EXTERNAL_ACCESS_PORT_AUTOINCREMENT:-}" =~ ^(yes|true)$ ]]; then
          port="$((EXTERNAL_ACCESS_PORT + POD_ID))"
        else
          port="$EXTERNAL_ACCESS_PORT"
        fi
      elif [[ -n "${EXTERNAL_ACCESS_PORTS_LIST:-}" ]]; then
        read -r -a ports <<<"$(tr ',' ' ' <<<"${EXTERNAL_ACCESS_PORTS_LIST}")"
        port="${ports[$POD_ID]}"
      else
        error "External access port not provided"
      fi
      # Configure Kafka advertised listeners
      sed -i -E "s|^(advertised\.listeners=\S+)$|\1,EXTERNAL://${host}:${port}|" "$KAFKA_CONFIG_FILE"
    }
    configure_kafka_sasl() {

      # Replace placeholders with passwords
      replace_placeholder "interbroker-password-placeholder" "$KAFKA_INTER_BROKER_PASSWORD"
      replace_placeholder "controller-password-placeholder" "$KAFKA_CONTROLLER_PASSWORD"
      read -r -a passwords <<<"$(tr ',;' ' ' <<<"${KAFKA_CLIENT_PASSWORDS:-}")"
      for ((i = 0; i < ${#passwords[@]}; i++)); do
          replace_placeholder "password-placeholder-${i}\"" "${passwords[i]}\""
      done
    }

    export KAFKA_CONFIG_FILE=/config/server.properties
    cp /configmaps/server.properties $KAFKA_CONFIG_FILE

    # Get pod ID and role, last and second last fields in the pod name respectively
    POD_ID=$(echo "$MY_POD_NAME" | rev | cut -d'-' -f 1 | rev)
    POD_ROLE=$(echo "$MY_POD_NAME" | rev | cut -d'-' -f 2 | rev)

    # Configure node.id and/or broker.id
    if [[ -f "/bitnami/kafka/data/meta.properties" ]]; then
        if grep -q "broker.id" /bitnami/kafka/data/meta.properties; then
          ID="$(grep "broker.id" /bitnami/kafka/data/meta.properties | awk -F '=' '{print $2}')"
          kafka_conf_set "$KAFKA_CONFIG_FILE" "node.id" "$ID"
        else
          ID="$(grep "node.id" /bitnami/kafka/data/meta.properties | awk -F '=' '{print $2}')"
          kafka_conf_set "$KAFKA_CONFIG_FILE" "node.id" "$ID"
        fi
    else
        ID=$((POD_ID + KAFKA_MIN_ID))
        kafka_conf_set "$KAFKA_CONFIG_FILE" "node.id" "$ID"
    fi
    replace_placeholder "advertised-address-placeholder" "${MY_POD_NAME}.kafka-${POD_ROLE}-headless.default.svc.cluster.local"
    if [[ "${EXTERNAL_ACCESS_ENABLED:-false}" =~ ^(yes|true)$ ]]; then
      configure_external_access
    fi
    configure_kafka_sasl
    if [ -f /secret-config/server-secret.properties ]; then
      append_file_to_kafka_conf /secret-config/server-secret.properties $KAFKA_CONFIG_FILE
    fi
---
# Source: system/charts/redis/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: redis-configuration
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: redis
    app.kubernetes.io/version: 7.2.4
    helm.sh/chart: redis-19.1.3
data:
  redis.conf: |-
    # User-supplied common configuration:
    # Enable AOF https://redis.io/topics/persistence#append-only-file
    appendonly yes
    # Disable RDB persistence, AOF persistence already enabled.
    save ""
    # End of common configuration
  master.conf: |-
    dir /data
    # User-supplied master configuration:
    rename-command FLUSHDB ""
    rename-command FLUSHALL ""
    # End of master configuration
  replica.conf: |-
    dir /data
    # User-supplied replica configuration:
    rename-command FLUSHDB ""
    rename-command FLUSHALL ""
    # End of replica configuration
---
# Source: system/charts/redis/templates/health-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: redis-health
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: redis
    app.kubernetes.io/version: 7.2.4
    helm.sh/chart: redis-19.1.3
data:
  ping_readiness_local.sh: |-
    #!/bin/bash

    [[ -f $REDIS_PASSWORD_FILE ]] && export REDIS_PASSWORD="$(< "${REDIS_PASSWORD_FILE}")"
    [[ -n "$REDIS_PASSWORD" ]] && export REDISCLI_AUTH="$REDIS_PASSWORD"
    response=$(
      timeout -s 15 $1 \
      redis-cli \
        -h localhost \
        -p $REDIS_PORT \
        ping
    )
    if [ "$?" -eq "124" ]; then
      echo "Timed out"
      exit 1
    fi
    if [ "$response" != "PONG" ]; then
      echo "$response"
      exit 1
    fi
  ping_liveness_local.sh: |-
    #!/bin/bash

    [[ -f $REDIS_PASSWORD_FILE ]] && export REDIS_PASSWORD="$(< "${REDIS_PASSWORD_FILE}")"
    [[ -n "$REDIS_PASSWORD" ]] && export REDISCLI_AUTH="$REDIS_PASSWORD"
    response=$(
      timeout -s 15 $1 \
      redis-cli \
        -h localhost \
        -p $REDIS_PORT \
        ping
    )
    if [ "$?" -eq "124" ]; then
      echo "Timed out"
      exit 1
    fi
    responseFirstWord=$(echo $response | head -n1 | awk '{print $1;}')
    if [ "$response" != "PONG" ] && [ "$responseFirstWord" != "LOADING" ] && [ "$responseFirstWord" != "MASTERDOWN" ]; then
      echo "$response"
      exit 1
    fi
  ping_readiness_master.sh: |-
    #!/bin/bash

    [[ -f $REDIS_MASTER_PASSWORD_FILE ]] && export REDIS_MASTER_PASSWORD="$(< "${REDIS_MASTER_PASSWORD_FILE}")"
    [[ -n "$REDIS_MASTER_PASSWORD" ]] && export REDISCLI_AUTH="$REDIS_MASTER_PASSWORD"
    response=$(
      timeout -s 15 $1 \
      redis-cli \
        -h $REDIS_MASTER_HOST \
        -p $REDIS_MASTER_PORT_NUMBER \
        ping
    )
    if [ "$?" -eq "124" ]; then
      echo "Timed out"
      exit 1
    fi
    if [ "$response" != "PONG" ]; then
      echo "$response"
      exit 1
    fi
  ping_liveness_master.sh: |-
    #!/bin/bash

    [[ -f $REDIS_MASTER_PASSWORD_FILE ]] && export REDIS_MASTER_PASSWORD="$(< "${REDIS_MASTER_PASSWORD_FILE}")"
    [[ -n "$REDIS_MASTER_PASSWORD" ]] && export REDISCLI_AUTH="$REDIS_MASTER_PASSWORD"
    response=$(
      timeout -s 15 $1 \
      redis-cli \
        -h $REDIS_MASTER_HOST \
        -p $REDIS_MASTER_PORT_NUMBER \
        ping
    )
    if [ "$?" -eq "124" ]; then
      echo "Timed out"
      exit 1
    fi
    responseFirstWord=$(echo $response | head -n1 | awk '{print $1;}')
    if [ "$response" != "PONG" ] && [ "$responseFirstWord" != "LOADING" ]; then
      echo "$response"
      exit 1
    fi
  ping_readiness_local_and_master.sh: |-
    script_dir="$(dirname "$0")"
    exit_status=0
    "$script_dir/ping_readiness_local.sh" $1 || exit_status=$?
    "$script_dir/ping_readiness_master.sh" $1 || exit_status=$?
    exit $exit_status
  ping_liveness_local_and_master.sh: |-
    script_dir="$(dirname "$0")"
    exit_status=0
    "$script_dir/ping_liveness_local.sh" $1 || exit_status=$?
    "$script_dir/ping_liveness_master.sh" $1 || exit_status=$?
    exit $exit_status
---
# Source: system/charts/redis/templates/scripts-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: redis-scripts
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: redis
    app.kubernetes.io/version: 7.2.4
    helm.sh/chart: redis-19.1.3
data:
  start-master.sh: |
    #!/bin/bash

    [[ -f $REDIS_PASSWORD_FILE ]] && export REDIS_PASSWORD="$(< "${REDIS_PASSWORD_FILE}")"
    if [[ -f /opt/bitnami/redis/mounted-etc/master.conf ]];then
        cp /opt/bitnami/redis/mounted-etc/master.conf /opt/bitnami/redis/etc/master.conf
    fi
    if [[ -f /opt/bitnami/redis/mounted-etc/redis.conf ]];then
        cp /opt/bitnami/redis/mounted-etc/redis.conf /opt/bitnami/redis/etc/redis.conf
    fi
    ARGS=("--port" "${REDIS_PORT}")
    ARGS+=("--protected-mode" "no")
    ARGS+=("--include" "/opt/bitnami/redis/etc/redis.conf")
    ARGS+=("--include" "/opt/bitnami/redis/etc/master.conf")
    exec redis-server "${ARGS[@]}"
---
# Source: system/charts/rendering-srv/templates/configmap-handlebars.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: "rendering-srv-handlebars"
  labels:
    helm.sh/chart: rendering-srv-0.1.27
    app.kubernetes.io/name: rendering-srv
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.3.9"
    app.kubernetes.io/managed-by: Helm
data:
  helper-list.js: |
    module.exports = function listHandlebarsExtensions(hbs, opts) {
      hbs.registerHelper("list", function(items, options) {
        const itemsAsHtml = items.map(item => "<li>" + options.fn(item) + "</li>");
        return "<ul>\n" + itemsAsHtml.join("\n") + "\n</ul>";
      });
    };
---
# Source: system/charts/cloudserver/templates/pvc.yaml
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: cloudserver
spec:
  accessModes:
    - ReadWriteMany
  resources:
    requests:
      storage: 10Gi
---
# Source: system/templates/job-1-migrations.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: release-name-system-1-migrations
  labels:
    helm.sh/chart: system-0.1.75
    app.kubernetes.io/name: system
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
rules:
- apiGroups:
  - ""
  resources:
  - services
  - pods
  verbs:
  - get
  - list
  - watch
---
# Source: system/templates/job-1-migrations.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: release-name-system-1-migrations
  labels:
    helm.sh/chart: system-0.1.75
    app.kubernetes.io/name: system
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: release-name-system-1-migrations
subjects:
- kind: ServiceAccount
  namespace: default
  name: release-name-system-1-migrations
---
# Source: system/charts/access-control-srv/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: access-control-srv
  labels:
    helm.sh/chart: access-control-srv-0.1.29
    app.kubernetes.io/name: access-control-srv
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.4.2"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 50051
      targetPort: grpc
      protocol: TCP
      name: grpc
  selector:
    app.kubernetes.io/name: access-control-srv
    app.kubernetes.io/instance: release-name
---
# Source: system/charts/catalog-srv/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: catalog-srv
  labels:
    helm.sh/chart: catalog-srv-0.1.17
    app.kubernetes.io/name: catalog-srv
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.4.5"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 50051
      targetPort: grpc
      protocol: TCP
      name: grpc
  selector:
    app.kubernetes.io/name: catalog-srv
    app.kubernetes.io/instance: release-name
---
# Source: system/charts/cloudserver/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: cloudserver
spec:
  type: ClusterIP
  ports:
    - name: s3
      port: 8000
      protocol: TCP
      targetPort: s3
    - name: localdata
      port: 9991
      protocol: TCP
      targetPort: localdata
    - name: localmetadata
      port: 9990
      protocol: TCP
      targetPort: localmetadata
  selector:
    app: cloudserver
---
# Source: system/charts/facade-srv/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: facade-srv
  labels:
    helm.sh/chart: facade-srv-0.1.28
    app.kubernetes.io/name: facade-srv
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.5.8"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 5000
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/name: facade-srv
    app.kubernetes.io/instance: release-name
---
# Source: system/charts/fulfillment-srv/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: fulfillment-srv
  labels:
    helm.sh/chart: fulfillment-srv-0.1.18
    app.kubernetes.io/name: fulfillment-srv
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.2.6"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 50051
      targetPort: grpc
      protocol: TCP
      name: grpc
  selector:
    app.kubernetes.io/name: fulfillment-srv
    app.kubernetes.io/instance: release-name
---
# Source: system/charts/identity-srv/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: identity-srv
  labels:
    helm.sh/chart: identity-srv-0.1.30
    app.kubernetes.io/name: identity-srv
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.6.12"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 50051
      targetPort: grpc
      protocol: TCP
      name: grpc
  selector:
    app.kubernetes.io/name: identity-srv
    app.kubernetes.io/instance: release-name
---
# Source: system/charts/invoicing-srv/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: invoicing-srv
  labels:
    helm.sh/chart: invoicing-srv-0.1.18
    app.kubernetes.io/name: invoicing-srv
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.3.8"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 50051
      targetPort: grpc
      protocol: TCP
      name: grpc
  selector:
    app.kubernetes.io/name: invoicing-srv
    app.kubernetes.io/instance: release-name
---
# Source: system/charts/kafka/templates/controller-eligible/svc-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: kafka-controller-headless
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: kafka
    app.kubernetes.io/version: 3.7.0
    helm.sh/chart: kafka-28.0.4
    app.kubernetes.io/component: controller-eligible
    app.kubernetes.io/part-of: kafka
spec:
  type: ClusterIP
  clusterIP: None
  publishNotReadyAddresses: true
  ports:
    - name: tcp-interbroker
      port: 9094
      protocol: TCP
      targetPort: interbroker
    - name: tcp-client
      port: 9092
      protocol: TCP
      targetPort: client
    - name: tcp-controller
      protocol: TCP
      port: 9093
      targetPort: controller
  selector:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/name: kafka
    app.kubernetes.io/component: controller-eligible
    app.kubernetes.io/part-of: kafka
---
# Source: system/charts/kafka/templates/svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: kafka
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: kafka
    app.kubernetes.io/version: 3.7.0
    helm.sh/chart: kafka-28.0.4
    app.kubernetes.io/component: kafka
spec:
  type: ClusterIP
  sessionAffinity: None
  ports:
    - name: tcp-client
      port: 9092
      protocol: TCP
      targetPort: client
      nodePort: null
  selector:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/name: kafka
    app.kubernetes.io/part-of: kafka
---
# Source: system/charts/notification-srv/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: notification-srv
  labels:
    helm.sh/chart: notification-srv-0.1.24
    app.kubernetes.io/name: notification-srv
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.3.6"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 50051
      targetPort: grpc
      protocol: TCP
      name: grpc
  selector:
    app.kubernetes.io/name: notification-srv
    app.kubernetes.io/instance: release-name
---
# Source: system/charts/ordering-srv/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: ordering-srv
  labels:
    helm.sh/chart: ordering-srv-0.1.19
    app.kubernetes.io/name: ordering-srv
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.2.9"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 50051
      targetPort: grpc
      protocol: TCP
      name: grpc
  selector:
    app.kubernetes.io/name: ordering-srv
    app.kubernetes.io/instance: release-name
---
# Source: system/charts/ostorage-srv/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: ostorage-srv
  labels:
    helm.sh/chart: ostorage-srv-0.1.24
    app.kubernetes.io/name: ostorage-srv
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.3.7"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 50051
      targetPort: grpc
      protocol: TCP
      name: grpc
  selector:
    app.kubernetes.io/name: ostorage-srv
    app.kubernetes.io/instance: release-name
---
# Source: system/charts/payment-srv/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: payment-srv
  labels:
    helm.sh/chart: payment-srv-0.1.16
    app.kubernetes.io/name: payment-srv
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.3.3"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 50051
      targetPort: grpc
      protocol: TCP
      name: grpc
  selector:
    app.kubernetes.io/name: payment-srv
    app.kubernetes.io/instance: release-name
---
# Source: system/charts/pdf-rendering-srv/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: pdf-rendering-srv
  labels:
    helm.sh/chart: pdf-rendering-srv-0.2.4
    app.kubernetes.io/name: pdf-rendering-srv
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.0.6"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 50051
      targetPort: grpc
      protocol: TCP
      name: grpc
  selector:
    app.kubernetes.io/name: pdf-rendering-srv
    app.kubernetes.io/instance: release-name
---
# Source: system/charts/redis/templates/headless-svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: redis-headless
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: redis
    app.kubernetes.io/version: 7.2.4
    helm.sh/chart: redis-19.1.3
spec:
  type: ClusterIP
  clusterIP: None
  ports:
    - name: tcp-redis
      port: 6379
      targetPort: redis
  selector:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/name: redis
---
# Source: system/charts/redis/templates/master/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: redis-master
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: redis
    app.kubernetes.io/version: 7.2.4
    helm.sh/chart: redis-19.1.3
    app.kubernetes.io/component: master
spec:
  type: ClusterIP
  internalTrafficPolicy: Cluster
  sessionAffinity: None
  ports:
    - name: tcp-redis
      port: 6379
      targetPort: redis
      nodePort: null
  selector:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/name: redis
    app.kubernetes.io/component: master
---
# Source: system/charts/rendering-srv/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: rendering-srv
  labels:
    helm.sh/chart: rendering-srv-0.1.27
    app.kubernetes.io/name: rendering-srv
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.3.9"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 50051
      targetPort: grpc
      protocol: TCP
      name: grpc
  selector:
    app.kubernetes.io/name: rendering-srv
    app.kubernetes.io/instance: release-name
---
# Source: system/charts/resource-srv/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: resource-srv
  labels:
    helm.sh/chart: resource-srv-0.1.18
    app.kubernetes.io/name: resource-srv
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.5.6"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 50051
      targetPort: grpc
      protocol: TCP
      name: grpc
  selector:
    app.kubernetes.io/name: resource-srv
    app.kubernetes.io/instance: release-name
---
# Source: system/charts/scheduling-srv/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: scheduling-srv
  labels:
    helm.sh/chart: scheduling-srv-0.1.20
    app.kubernetes.io/name: scheduling-srv
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.2.7"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 50051
      targetPort: grpc
      protocol: TCP
      name: grpc
  selector:
    app.kubernetes.io/name: scheduling-srv
    app.kubernetes.io/instance: release-name
---
# Source: system/charts/access-control-srv/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: access-control-srv
  labels:
    helm.sh/chart: access-control-srv-0.1.29
    app.kubernetes.io/name: access-control-srv
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.4.2"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: access-control-srv
      app.kubernetes.io/instance: release-name
  template:
    metadata:
      annotations:
        checksum/config: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855
      labels:
        app.kubernetes.io/name: access-control-srv
        app.kubernetes.io/instance: release-name
    spec:
      serviceAccountName: access-control-srv
      securityContext:
        {}
      containers:
        - name: access-control-srv
          securityContext:
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
            runAsNonRoot: true
            runAsUser: 1000
          image: "ghcr.io/restorecommerce/access-control-srv:1.4.2"
          imagePullPolicy: IfNotPresent
          ports:
            - name: grpc
              containerPort: 50051
              protocol: TCP
          env:
            - name: npm_config_cache
              value: /tmp/npm/
            - name: NODE_ENV
              value: production
            - name: authorization__cache__url
              value: redis://redis-master:6379
            - name: redis__url
              value: redis://redis-master:6379
            - name: logger__elasticsearch__clientOpts__node
              value: http://restorecommerce-es-http:9200
            - name: authorization__enabled
              value: "false"
            - name: database__main__host
              value: arangodb-single-000000
          livenessProbe:
            initialDelaySeconds: 10
            periodSeconds: 30
            grpc:
              port: 50051
          readinessProbe:
            initialDelaySeconds: 10
            periodSeconds: 15
            grpc:
              port: 50051
              service: readiness
          resources:
            {}
          volumeMounts:
            - name: tmp
              mountPath: /tmp
      volumes:
        - name: tmp
          emptyDir: {}
---
# Source: system/charts/catalog-srv/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: catalog-srv
  labels:
    helm.sh/chart: catalog-srv-0.1.17
    app.kubernetes.io/name: catalog-srv
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.4.5"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: catalog-srv
      app.kubernetes.io/instance: release-name
  template:
    metadata:
      annotations:
        checksum/config: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855
      labels:
        app.kubernetes.io/name: catalog-srv
        app.kubernetes.io/instance: release-name
    spec:
      serviceAccountName: catalog-srv
      securityContext:
        {}
      containers:
        - name: catalog-srv
          securityContext:
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
            runAsNonRoot: true
            runAsUser: 1000
          image: "ghcr.io/restorecommerce/catalog-srv:1.4.5"
          imagePullPolicy: IfNotPresent
          ports:
            - name: grpc
              containerPort: 50051
              protocol: TCP
          env:
            - name: npm_config_cache
              value: /tmp/npm/
            - name: NODE_ENV
              value: production
            - name: redis__url
              value: redis://redis-master:6379
            - name: authorization__cache__url
              value: redis://redis-master:6379
            - name: logger__elasticsearch__clientOpts__node
              value: http://restorecommerce-es-http:9200
            - name: database__main__host
              value: arangodb-single-000000
          livenessProbe:
            initialDelaySeconds: 10
            periodSeconds: 30
            grpc:
              port: 50051
          readinessProbe:
            initialDelaySeconds: 10
            periodSeconds: 15
            grpc:
              port: 50051
              service: readiness
          resources:
            {}
          volumeMounts:
            - name: tmp
              mountPath: /tmp
      volumes:
        - name: tmp
          emptyDir: {}
---
# Source: system/charts/cloudserver/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: cloudserver
  labels:
    app: cloudserver
spec:
  replicas: 1
  selector:
    matchLabels:
      app: cloudserver
  template:
    metadata:
      labels:
        app: cloudserver
    spec:
      containers:
        - name: cloudserver
          image: "zenko/cloudserver:latest-7.70.10"
          imagePullPolicy: IfNotPresent
          ports:
          - name: s3
            containerPort: 8000
            protocol: TCP
          - name: localdata
            containerPort: 9991
            protocol: TCP
          - name: localmetadata
            containerPort: 9990
            protocol: TCP
          volumeMounts:
            - mountPath: /usr/src/app/localData
              name: cloudserver
              subPath: localData
            - mountPath: /usr/src/app/localMetadata
              name: cloudserver
              subPath: localMetadata
          env:
            - name: SCALITY_ACCESS_KEY_ID
              value: ZFKQGYD2P6DJO4U7N33U
            - name: SCALITY_SECRET_ACCESS_KEY
              value: fO09epo9zT6tslwhh192l0UHbtpCjCYTnE3TYtec
            - name: ENDPOINT
              value: cloudserver
      volumes:
        - name: cloudserver
          persistentVolumeClaim:
            claimName: cloudserver
---
# Source: system/charts/facade-srv/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: facade-srv
  labels:
    helm.sh/chart: facade-srv-0.1.28
    app.kubernetes.io/name: facade-srv
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.5.8"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: facade-srv
      app.kubernetes.io/instance: release-name
  template:
    metadata:
      annotations:
        checksum/config: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855
      labels:
        app.kubernetes.io/name: facade-srv
        app.kubernetes.io/instance: release-name
    spec:
      serviceAccountName: facade-srv
      securityContext:
        {}
      containers:
        - name: facade-srv
          securityContext:
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
            runAsNonRoot: true
            runAsUser: 1000
          image: "ghcr.io/restorecommerce/facade-srv:1.5.8"
          imagePullPolicy: IfNotPresent
          ports:
            - name: http
              containerPort: 5000
              protocol: TCP
          env:
            - name: npm_config_cache
              value: /tmp/npm/
            - name: NODE_ENV
              value: production
          resources:
            {}
          volumeMounts:
            - name: tmp
              mountPath: /tmp
      volumes:
        - name: tmp
          emptyDir: {}
---
# Source: system/charts/fulfillment-srv/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: fulfillment-srv
  labels:
    helm.sh/chart: fulfillment-srv-0.1.18
    app.kubernetes.io/name: fulfillment-srv
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.2.6"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: fulfillment-srv
      app.kubernetes.io/instance: release-name
  template:
    metadata:
      annotations:
        checksum/config: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855
      labels:
        app.kubernetes.io/name: fulfillment-srv
        app.kubernetes.io/instance: release-name
    spec:
      serviceAccountName: fulfillment-srv
      securityContext:
        {}
      containers:
        - name: fulfillment-srv
          securityContext:
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
            runAsNonRoot: true
            runAsUser: 1000
          image: "ghcr.io/restorecommerce/fulfillment-srv:0.2.6"
          imagePullPolicy: IfNotPresent
          ports:
            - name: grpc
              containerPort: 50051
              protocol: TCP
          env:
            - name: npm_config_cache
              value: /tmp/npm/
            - name: NODE_ENV
              value: production
            - name: redis__url
              value: redis://redis-master:6379
            - name: authorization__cache__url
              value: redis://redis-master:6379
            - name: logger__elasticsearch__clientOpts__node
              value: http://restorecommerce-es-http:9200
            - name: database__main__host
              value: arangodb-single-000000
          livenessProbe:
            initialDelaySeconds: 10
            periodSeconds: 30
            grpc:
              port: 50051
          readinessProbe:
            initialDelaySeconds: 10
            periodSeconds: 15
            grpc:
              port: 50051
              service: readiness
          resources:
            {}
          volumeMounts:
            - name: tmp
              mountPath: /tmp
      volumes:
        - name: tmp
          emptyDir: {}
---
# Source: system/charts/identity-srv/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: identity-srv
  labels:
    helm.sh/chart: identity-srv-0.1.30
    app.kubernetes.io/name: identity-srv
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.6.12"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: identity-srv
      app.kubernetes.io/instance: release-name
  template:
    metadata:
      annotations:
        checksum/config: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855
      labels:
        app.kubernetes.io/name: identity-srv
        app.kubernetes.io/instance: release-name
    spec:
      serviceAccountName: identity-srv
      securityContext:
        {}
      containers:
        - name: identity-srv
          securityContext:
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
            runAsNonRoot: true
            runAsUser: 1000
          image: "ghcr.io/restorecommerce/identity-srv:1.6.12"
          imagePullPolicy: IfNotPresent
          ports:
            - name: grpc
              containerPort: 50051
              protocol: TCP
          env:
            - name: npm_config_cache
              value: /tmp/npm/
            - name: NODE_ENV
              value: production
            - name: authorization__cache__url
              value: redis://redis-master:6379
            - name: redis__url
              value: redis://redis-master:6379
            - name: logger__elasticsearch__clientOpts__node
              value: http://restorecommerce-es-http:9200
            - name: authorization__enabled
              value: "false"
            - name: database__main__host
              value: arangodb-single-000000
          livenessProbe:
            initialDelaySeconds: 10
            periodSeconds: 30
            grpc:
              port: 50051
          readinessProbe:
            initialDelaySeconds: 10
            periodSeconds: 15
            grpc:
              port: 50051
              service: readiness
          resources:
            {}
          volumeMounts:
            - name: tmp
              mountPath: /tmp
      volumes:
        - name: tmp
          emptyDir: {}
---
# Source: system/charts/invoicing-srv/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: invoicing-srv
  labels:
    helm.sh/chart: invoicing-srv-0.1.18
    app.kubernetes.io/name: invoicing-srv
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.3.8"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: invoicing-srv
      app.kubernetes.io/instance: release-name
  template:
    metadata:
      annotations:
        checksum/config: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855
      labels:
        app.kubernetes.io/name: invoicing-srv
        app.kubernetes.io/instance: release-name
    spec:
      serviceAccountName: invoicing-srv
      securityContext:
        {}
      containers:
        - name: invoicing-srv
          securityContext:
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
            runAsNonRoot: true
            runAsUser: 1000
          image: "ghcr.io/restorecommerce/invoicing-srv:1.3.8"
          imagePullPolicy: IfNotPresent
          ports:
            - name: grpc
              containerPort: 50051
              protocol: TCP
          env:
            - name: npm_config_cache
              value: /tmp/npm/
            - name: NODE_ENV
              value: production
            - name: redis__url
              value: redis://redis-master:6379
            - name: authorization__cache__url
              value: redis://redis-master:6379
            - name: logger__elasticsearch__clientOpts__node
              value: http://restorecommerce-es-http:9200
            - name: database__main__host
              value: arangodb-single-000000
          livenessProbe:
            initialDelaySeconds: 10
            periodSeconds: 30
            grpc:
              port: 50051
          readinessProbe:
            initialDelaySeconds: 10
            periodSeconds: 15
            grpc:
                port: 50051
                service: readiness
          resources:
            {}
          volumeMounts:
            - name: tmp
              mountPath: /tmp
      volumes:
        - name: tmp
          emptyDir: {}
---
# Source: system/charts/notification-srv/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: notification-srv
  labels:
    helm.sh/chart: notification-srv-0.1.24
    app.kubernetes.io/name: notification-srv
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.3.6"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: notification-srv
      app.kubernetes.io/instance: release-name
  template:
    metadata:
      annotations:
        checksum/config: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855
      labels:
        app.kubernetes.io/name: notification-srv
        app.kubernetes.io/instance: release-name
    spec:
      serviceAccountName: notification-srv
      securityContext:
        {}
      containers:
        - name: notification-srv
          securityContext:
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
            runAsNonRoot: true
            runAsUser: 1000
          image: "ghcr.io/restorecommerce/notification-srv:1.3.6"
          imagePullPolicy: IfNotPresent
          ports:
            - name: grpc
              containerPort: 50051
              protocol: TCP
          env:
            - name: npm_config_cache
              value: /tmp/npm/
            - name: NODE_ENV
              value: production
            - name: redis__url
              value: redis://redis-master:6379
            - name: authorization__cache__url
              value: redis://redis-master:6379
            - name: logger__elasticsearch__clientOpts__node
              value: http://restorecommerce-es-http:9200
          livenessProbe:
            initialDelaySeconds: 10
            periodSeconds: 30
            grpc:
              port: 50051
          readinessProbe:
            initialDelaySeconds: 10
            periodSeconds: 15
            grpc:
              port: 50051
              service: readiness
          resources:
            {}
          volumeMounts:
            - name: tmp
              mountPath: /tmp
      volumes:
        - name: tmp
          emptyDir: {}
---
# Source: system/charts/ordering-srv/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ordering-srv
  labels:
    helm.sh/chart: ordering-srv-0.1.19
    app.kubernetes.io/name: ordering-srv
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "0.2.9"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: ordering-srv
      app.kubernetes.io/instance: release-name
  template:
    metadata:
      annotations:
        checksum/config: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855
      labels:
        app.kubernetes.io/name: ordering-srv
        app.kubernetes.io/instance: release-name
    spec:
      serviceAccountName: ordering-srv
      securityContext:
        {}
      containers:
        - name: ordering-srv
          securityContext:
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
            runAsNonRoot: true
            runAsUser: 1000
          image: "ghcr.io/restorecommerce/ordering-srv:0.2.9"
          imagePullPolicy: IfNotPresent
          ports:
            - name: grpc
              containerPort: 50051
              protocol: TCP
          env:
            - name: npm_config_cache
              value: /tmp/npm/
            - name: NODE_ENV
              value: production
            - name: redis__url
              value: redis://redis-master:6379
            - name: authorization__cache__url
              value: redis://redis-master:6379
            - name: logger__elasticsearch__clientOpts__node
              value: http://restorecommerce-es-http:9200
            - name: database__main__host
              value: arangodb-single-000000
          livenessProbe:
            initialDelaySeconds: 10
            periodSeconds: 30
            grpc:
              port: 50051
          readinessProbe:
            initialDelaySeconds: 10
            periodSeconds: 15
            grpc:
              port: 50051
              service: readiness
          resources:
            {}
          volumeMounts:
            - name: tmp
              mountPath: /tmp
      volumes:
        - name: tmp
          emptyDir: {}
---
# Source: system/charts/ostorage-srv/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ostorage-srv
  labels:
    helm.sh/chart: ostorage-srv-0.1.24
    app.kubernetes.io/name: ostorage-srv
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.3.7"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: ostorage-srv
      app.kubernetes.io/instance: release-name
  template:
    metadata:
      annotations:
        checksum/config: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855
      labels:
        app.kubernetes.io/name: ostorage-srv
        app.kubernetes.io/instance: release-name
    spec:
      serviceAccountName: ostorage-srv
      securityContext:
        {}
      containers:
        - name: ostorage-srv
          securityContext:
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
            runAsNonRoot: true
            runAsUser: 1000
          image: "ghcr.io/restorecommerce/ostorage-srv:1.3.7"
          imagePullPolicy: IfNotPresent
          ports:
            - name: grpc
              containerPort: 50051
              protocol: TCP
          env:
            - name: npm_config_cache
              value: /tmp/npm/
            - name: NODE_ENV
              value: production
            - name: authorization__cache__url
              value: redis://redis-master:6379
            - name: redis__url
              value: redis://redis-master:6379
            - name: logger__elasticsearch__clientOpts__node
              value: http://restorecommerce-es-http:9200
            - name: s3__client__accessKeyId
              value: ZFKQGYD2P6DJO4U7N33U
            - name: s3__client__secretAccessKey
              value: fO09epo9zT6tslwhh192l0UHbtpCjCYTnE3TYtec
            - name: s3__client__endpoint
              value: http://cloudserver:8000
          livenessProbe:
            initialDelaySeconds: 10
            periodSeconds: 30
            grpc:
              port: 50051
          readinessProbe:
            initialDelaySeconds: 10
            periodSeconds: 15
            grpc:
              port: 50051
              service: readiness
          resources:
            {}
          volumeMounts:
            - name: tmp
              mountPath: /tmp
      volumes:
        - name: tmp
          emptyDir: {}
---
# Source: system/charts/payment-srv/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: payment-srv
  labels:
    helm.sh/chart: payment-srv-0.1.16
    app.kubernetes.io/name: payment-srv
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.3.3"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: payment-srv
      app.kubernetes.io/instance: release-name
  template:
    metadata:
      annotations:
        checksum/config: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855
      labels:
        app.kubernetes.io/name: payment-srv
        app.kubernetes.io/instance: release-name
    spec:
      serviceAccountName: payment-srv
      securityContext:
        {}
      containers:
        - name: payment-srv
          securityContext:
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
            runAsNonRoot: true
            runAsUser: 1000
          image: "ghcr.io/restorecommerce/payment-srv:1.3.3"
          imagePullPolicy: IfNotPresent
          ports:
            - name: grpc
              containerPort: 50051
              protocol: TCP
          env:
            - name: npm_config_cache
              value: /tmp/npm/
            - name: NODE_ENV
              value: production
            - name: redis__host
              value: redis://redis-master:6379
            - name: authorization__cache__url
              value: redis://redis-master:6379
            - name: logger__elasticsearch__clientOpts__node
              value: http://restorecommerce-es-http:9200
          livenessProbe:
            initialDelaySeconds: 10
            periodSeconds: 30
            grpc:
              port: 50051
          readinessProbe:
            initialDelaySeconds: 10
            periodSeconds: 15
            grpc:
              port: 50051
              service: readiness
          resources:
            {}
          volumeMounts:
            - name: tmp
              mountPath: /tmp
      volumes:
        - name: tmp
          emptyDir: {}
---
# Source: system/charts/pdf-rendering-srv/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: pdf-rendering-srv
  labels:
    helm.sh/chart: pdf-rendering-srv-0.2.4
    app.kubernetes.io/name: pdf-rendering-srv
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.0.6"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: pdf-rendering-srv
      app.kubernetes.io/instance: release-name
  template:
    metadata:
      annotations:
        checksum/config: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855
      labels:
        app.kubernetes.io/name: pdf-rendering-srv
        app.kubernetes.io/instance: release-name
    spec:
      serviceAccountName: pdf-rendering-srv
      securityContext:
        {}
      containers:
        - name: pdf-rendering-srv
          securityContext:
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
            runAsNonRoot: true
            runAsUser: 1000
          image: "ghcr.io/restorecommerce/pdf-rendering-srv:1.0.6"
          imagePullPolicy: IfNotPresent
          ports:
            - name: grpc
              containerPort: 50051
              protocol: TCP
          env:
            - name: npm_config_cache
              value: /tmp/npm/
            - name: NODE_ENV
              value: production
          livenessProbe:
            initialDelaySeconds: 10
            periodSeconds: 30
            grpc:
              port: 50051
          readinessProbe:
            initialDelaySeconds: 10
            periodSeconds: 15
            grpc:
              port: 50051
              service: readiness
          resources:
            {}
          volumeMounts:
            - name: tmp
              mountPath: /tmp
      volumes:
        - name: tmp
          emptyDir: {}
---
# Source: system/charts/rendering-srv/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: rendering-srv
  labels:
    helm.sh/chart: rendering-srv-0.1.27
    app.kubernetes.io/name: rendering-srv
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.3.9"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: rendering-srv
      app.kubernetes.io/instance: release-name
  template:
    metadata:
      annotations:
        checksum/config: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855
        checksum/handlebars: 160e156c5899b6ed0c676c965b7ab49d8964ab62fd631aa31a63fff44dc60b76
      labels:
        app.kubernetes.io/name: rendering-srv
        app.kubernetes.io/instance: release-name
    spec:
      serviceAccountName: rendering-srv
      securityContext:
        {}
      containers:
        - name: rendering-srv
          securityContext:
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
            runAsNonRoot: true
            runAsUser: 1000
          image: "ghcr.io/restorecommerce/rendering-srv:1.3.9"
          imagePullPolicy: IfNotPresent
          ports:
            - name: grpc
              containerPort: 50051
              protocol: TCP
          env:
            - name: npm_config_cache
              value: /tmp/npm/
            - name: NODE_ENV
              value: production
            - name: redis__url
              value: redis://redis-master:6379
            - name: authorization__cache__url
              value: redis://redis-master:6379
            - name: logger__elasticsearch__clientOpts__node
              value: http://restorecommerce-es-http:9200
          livenessProbe:
            initialDelaySeconds: 10
            periodSeconds: 30
            grpc:
              port: 50051
          readinessProbe:
            initialDelaySeconds: 10
            periodSeconds: 15
            grpc:
              port: 50051
              service: readiness
          resources:
            {}
          volumeMounts:
            - name: tmp
              mountPath: /tmp
            - name: handlebars
              mountPath: "/home/node/rendering-srv/handlebars/helper-list.js"
              subPath: helper-list.js
      volumes:
        - name: tmp
          emptyDir: {}
        - name: handlebars
          configMap:
            name: "rendering-srv-handlebars"
---
# Source: system/charts/resource-srv/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: resource-srv
  labels:
    helm.sh/chart: resource-srv-0.1.18
    app.kubernetes.io/name: resource-srv
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.5.6"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: resource-srv
      app.kubernetes.io/instance: release-name
  template:
    metadata:
      annotations:
        checksum/config: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855
      labels:
        app.kubernetes.io/name: resource-srv
        app.kubernetes.io/instance: release-name
    spec:
      serviceAccountName: resource-srv
      securityContext:
        {}
      containers:
        - name: resource-srv
          securityContext:
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
            runAsNonRoot: true
            runAsUser: 1000
          image: "ghcr.io/restorecommerce/resource-srv:1.5.6"
          imagePullPolicy: IfNotPresent
          ports:
            - name: grpc
              containerPort: 50051
              protocol: TCP
          env:
            - name: npm_config_cache
              value: /tmp/npm/
            - name: NODE_ENV
              value: production
            - name: redis__url
              value: redis://redis-master:6379
            - name: authorization__cache__url
              value: redis://redis-master:6379
            - name: logger__elasticsearch__clientOpts__node
              value: http://restorecommerce-es-http:9200
            - name: authorization__enabled
              value: "false"
            - name: database__main__host
              value: arangodb-single-000000
          livenessProbe:
            initialDelaySeconds: 10
            periodSeconds: 30
            grpc:
              port: 50051
          readinessProbe:
            initialDelaySeconds: 10
            periodSeconds: 15
            grpc:
              port: 50051
              service: readiness
          resources:
            {}
          volumeMounts:
            - name: tmp
              mountPath: /tmp
      volumes:
        - name: tmp
          emptyDir: {}
---
# Source: system/charts/scheduling-srv/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: scheduling-srv
  labels:
    helm.sh/chart: scheduling-srv-0.1.20
    app.kubernetes.io/name: scheduling-srv
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "1.2.7"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: scheduling-srv
      app.kubernetes.io/instance: release-name
  template:
    metadata:
      annotations:
        checksum/config: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855
      labels:
        app.kubernetes.io/name: scheduling-srv
        app.kubernetes.io/instance: release-name
    spec:
      serviceAccountName: scheduling-srv
      securityContext:
        {}
      containers:
        - name: scheduling-srv
          securityContext:
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
            runAsNonRoot: true
            runAsUser: 1000
          image: "ghcr.io/restorecommerce/scheduling-srv:1.2.7"
          imagePullPolicy: IfNotPresent
          ports:
            - name: grpc
              containerPort: 50051
              protocol: TCP
          env:
            - name: npm_config_cache
              value: /tmp/npm/
            - name: NODE_ENV
              value: production
            - name: authorization__cache__url
              value: redis://redis-master:6379
            - name: redis__url
              value: redis://redis-master:6379
            - name: logger__elasticsearch__clientOpts__node
              value: http://restorecommerce-es-http:9200
          livenessProbe:
            initialDelaySeconds: 10
            periodSeconds: 30
            grpc:
              port: 50051
          readinessProbe:
            initialDelaySeconds: 10
            periodSeconds: 15
            grpc:
              port: 50051
              service: readiness
          resources:
            {}
          volumeMounts:
            - name: tmp
              mountPath: /tmp
      volumes:
        - name: tmp
          emptyDir: {}
---
# Source: system/charts/kafka/templates/controller-eligible/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: kafka-controller
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: kafka
    app.kubernetes.io/version: 3.7.0
    helm.sh/chart: kafka-28.0.4
    app.kubernetes.io/component: controller-eligible
    app.kubernetes.io/part-of: kafka
spec:
  podManagementPolicy: Parallel
  replicas: 3
  selector:
    matchLabels:
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/name: kafka
      app.kubernetes.io/component: controller-eligible
      app.kubernetes.io/part-of: kafka
  serviceName: kafka-controller-headless
  updateStrategy:
    type: RollingUpdate
  template:
    metadata:
      labels:
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: kafka
        app.kubernetes.io/version: 3.7.0
        helm.sh/chart: kafka-28.0.4
        app.kubernetes.io/component: controller-eligible
        app.kubernetes.io/part-of: kafka
      annotations:
        checksum/configuration: 6aca0825c523cf92c2ef3d7310d48b22e49eb6bd9aa86cd79a0a714a99a09820
        checksum/passwords-secret: 98fc6637480cd96e1b35f957905ae7a18d0f6e945996b1f14b98eb889a7a202e
    spec:
      
      automountServiceAccountToken: false
      hostNetwork: false
      hostIPC: false
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/instance: release-name
                    app.kubernetes.io/name: kafka
                    app.kubernetes.io/component: controller-eligible
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      securityContext:
        fsGroup: 1001
        fsGroupChangePolicy: Always
        seccompProfile:
          type: RuntimeDefault
        supplementalGroups: []
        sysctls: []
      serviceAccountName: kafka
      enableServiceLinks: true
      initContainers:
        - name: kafka-init
          image: docker.io/bitnami/kafka:3.7.0-debian-12-r2
          imagePullPolicy: IfNotPresent
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seLinuxOptions: {}
          resources:
            limits: {}
            requests: {} 
          command:
            - /bin/bash
          args:
            - -ec
            - |
              /scripts/kafka-init.sh
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: MY_POD_NAME
              valueFrom:
                fieldRef:
                    fieldPath: metadata.name
            - name: KAFKA_VOLUME_DIR
              value: "/bitnami/kafka"
            - name: KAFKA_MIN_ID
              value: "0"
            - name: KAFKA_CLIENT_USERS
              value: "user1"
            - name: KAFKA_CLIENT_PASSWORDS
              valueFrom:
                secretKeyRef:
                  name: kafka-user-passwords
                  key: client-passwords
            - name: KAFKA_INTER_BROKER_USER
              value: "inter_broker_user"
            - name: KAFKA_INTER_BROKER_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: kafka-user-passwords
                  key: inter-broker-password
            - name: KAFKA_CONTROLLER_USER
              value: "controller_user"
            - name: KAFKA_CONTROLLER_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: kafka-user-passwords
                  key: controller-password
          volumeMounts:
            - name: data
              mountPath: /bitnami/kafka
            - name: kafka-config
              mountPath: /config
            - name: kafka-configmaps
              mountPath: /configmaps
            - name: kafka-secret-config
              mountPath: /secret-config
            - name: scripts
              mountPath: /scripts
            - name: tmp
              mountPath: /tmp
      containers:
        - name: kafka
          image: docker.io/bitnami/kafka:3.7.0-debian-12-r2
          imagePullPolicy: "IfNotPresent"
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seLinuxOptions: {}
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: KAFKA_HEAP_OPTS
              value: "-Xmx1024m -Xms1024m"
            - name: KAFKA_KRAFT_CLUSTER_ID
              valueFrom:
                secretKeyRef:
                  name: kafka-kraft-cluster-id
                  key: kraft-cluster-id
            - name: KAFKA_KRAFT_BOOTSTRAP_SCRAM_USERS
              value: "true"
            - name: KAFKA_CLIENT_USERS
              value: "user1"
            - name: KAFKA_CLIENT_PASSWORDS
              valueFrom:
                secretKeyRef:
                  name: kafka-user-passwords
                  key: client-passwords
            - name: KAFKA_INTER_BROKER_USER
              value: "inter_broker_user"
            - name: KAFKA_INTER_BROKER_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: kafka-user-passwords
                  key: inter-broker-password
            - name: KAFKA_CONTROLLER_USER
              value: "controller_user"
            - name: KAFKA_CONTROLLER_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: kafka-user-passwords
                  key: controller-password
          ports:
            - name: controller
              containerPort: 9093
            - name: client
              containerPort: 9092
            - name: interbroker
              containerPort: 9094
          livenessProbe:
            failureThreshold: 3
            initialDelaySeconds: 10
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            tcpSocket:
              port: "controller"
          readinessProbe:
            failureThreshold: 6
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            tcpSocket:
              port: "controller"
          resources:
            limits:
              cpu: 750m
              ephemeral-storage: 1024Mi
              memory: 768Mi
            requests:
              cpu: 500m
              ephemeral-storage: 50Mi
              memory: 512Mi
          volumeMounts:
            - name: data
              mountPath: /bitnami/kafka
            - name: logs
              mountPath: /opt/bitnami/kafka/logs
            - name: kafka-config
              mountPath: /opt/bitnami/kafka/config/server.properties
              subPath: server.properties
            - name: tmp
              mountPath: /tmp
      volumes:
        - name: kafka-configmaps
          configMap:
            name: kafka-controller-configuration
        - name: kafka-secret-config
          emptyDir: {}
        - name: kafka-config
          emptyDir: {}
        - name: tmp
          emptyDir: {}
        - name: scripts
          configMap:
            name: kafka-scripts
            defaultMode: 493
        - name: logs
          emptyDir: {}
  volumeClaimTemplates:
    - apiVersion: v1
      kind: PersistentVolumeClaim
      metadata:
        name: data
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: "8Gi"
---
# Source: system/charts/redis/templates/master/application.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: redis-master
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: redis
    app.kubernetes.io/version: 7.2.4
    helm.sh/chart: redis-19.1.3
    app.kubernetes.io/component: master
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/name: redis
      app.kubernetes.io/component: master
  serviceName: redis-headless
  updateStrategy:
    type: RollingUpdate
  template:
    metadata:
      labels:
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: redis
        app.kubernetes.io/version: 7.2.4
        helm.sh/chart: redis-19.1.3
        app.kubernetes.io/component: master
      annotations:
        checksum/configmap: 86bcc953bb473748a3d3dc60b7c11f34e60c93519234d4c37f42e22ada559d47
        checksum/health: aff24913d801436ea469d8d374b2ddb3ec4c43ee7ab24663d5f8ff1a1b6991a9
        checksum/scripts: 43cdf68c28f3abe25ce017a82f74dbf2437d1900fd69df51a55a3edf6193d141
        checksum/secret: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a
    spec:
      
      securityContext:
        fsGroup: 1001
        fsGroupChangePolicy: Always
        supplementalGroups: []
        sysctls: []
      serviceAccountName: redis-master
      automountServiceAccountToken: false
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/instance: release-name
                    app.kubernetes.io/name: redis
                    app.kubernetes.io/component: master
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      enableServiceLinks: true
      terminationGracePeriodSeconds: 30
      containers:
        - name: redis
          image: docker.io/bitnami/redis:7.2.4-debian-12-r12
          imagePullPolicy: "IfNotPresent"
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seLinuxOptions: {}
            seccompProfile:
              type: RuntimeDefault
          command:
            - /bin/bash
          args:
            - -c
            - /opt/bitnami/scripts/start-scripts/start-master.sh
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: REDIS_REPLICATION_MODE
              value: master
            - name: ALLOW_EMPTY_PASSWORD
              value: "yes"
            - name: REDIS_TLS_ENABLED
              value: "no"
            - name: REDIS_PORT
              value: "6379"
          ports:
            - name: redis
              containerPort: 6379
          livenessProbe:
            initialDelaySeconds: 20
            periodSeconds: 5
            # One second longer than command timeout should prevent generation of zombie processes.
            timeoutSeconds: 6
            successThreshold: 1
            failureThreshold: 5
            exec:
              command:
                - sh
                - -c
                - /health/ping_liveness_local.sh 5
          readinessProbe:
            initialDelaySeconds: 20
            periodSeconds: 5
            timeoutSeconds: 2
            successThreshold: 1
            failureThreshold: 5
            exec:
              command:
                - sh
                - -c
                - /health/ping_readiness_local.sh 1
          resources:
            limits:
              cpu: 150m
              ephemeral-storage: 1024Mi
              memory: 192Mi
            requests:
              cpu: 100m
              ephemeral-storage: 50Mi
              memory: 128Mi
          volumeMounts:
            - name: start-scripts
              mountPath: /opt/bitnami/scripts/start-scripts
            - name: health
              mountPath: /health
            - name: redis-data
              mountPath: /data
            - name: config
              mountPath: /opt/bitnami/redis/mounted-etc
            - name: empty-dir
              mountPath: /opt/bitnami/redis/etc/
              subPath: app-conf-dir
            - name: empty-dir
              mountPath: /tmp
              subPath: tmp-dir
      volumes:
        - name: start-scripts
          configMap:
            name: redis-scripts
            defaultMode: 0755
        - name: health
          configMap:
            name: redis-health
            defaultMode: 0755
        - name: config
          configMap:
            name: redis-configuration
        - name: empty-dir
          emptyDir: {}
  volumeClaimTemplates:
    - apiVersion: v1
      kind: PersistentVolumeClaim
      metadata:
        name: redis-data
        labels:
          app.kubernetes.io/instance: release-name
          app.kubernetes.io/name: redis
          app.kubernetes.io/component: master
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: "8Gi"
---
# Source: system/templates/arangodb-deployment.yaml
apiVersion: database.arangodb.com/v1alpha
kind: ArangoDeployment
metadata:
  name: arangodb
spec:
  mode: Single
  image: 'arangodb/arangodb:3.12.0'
  auth:
    jwtSecretName: None
  externalAccess:
    type: None
  tls:
    caSecretName: None
  single:
    volumeClaimTemplate:
      metadata:
        name: arangodb
      spec:
        accessModes:
        - ReadWriteOnce
        resources:
          requests:
            storage: 8Gi
    resources:
      limits:
        memory: 1024Mi
status:
  agency:
    id:
      - SNGL-000000
    size: 1
  members:
    single:
      - id: SNGL-000000
        persistentVolumeClaim:
          name: arangodb-single-000000
        persistentVolumeClaimName: arangodb-single-000000
---
# Source: system/templates/elasticsearch.yaml
apiVersion: elasticsearch.k8s.elastic.co/v1
kind: Elasticsearch
metadata:
  name: restorecommerce
spec:
  version: 8.12.0
  http:
    tls:
      selfSignedCertificate:
        disabled: true
  nodeSets:
  - name: default
    count: 2
    config:
      node.store.allow_mmap: false
      xpack.security.authc:
        anonymous:
          username: anonymous
          roles: superuser
          authz_exception: false
    volumeClaimTemplates:
    - metadata:
        name: elasticsearch-data
      spec:
        accessModes:
        - ReadWriteOnce
        resources:
          requests:
            storage: 10Gi
---
# Source: system/templates/kibana.yaml
apiVersion: kibana.k8s.elastic.co/v1
kind: Kibana
metadata:
  name: restorecommerce
spec:
  version: 8.12.0
  count: 1
  elasticsearchRef:
    name: restorecommerce
  config:
    xpack.security.enabled: false
  http:
    tls:
      selfSignedCertificate:
        disabled: true
  podTemplate:
    spec:
      containers:
      - name: kibana
        resources:
          limits:
            memory: 4Gi
        readinessProbe:
          failureThreshold: 3
          httpGet:
            path: /
            port: 5601
            scheme: HTTP
          initialDelaySeconds: 10
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 5
---
# Source: system/templates/job-1-migrations.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: release-name-system-1-migrations
  labels:
    helm.sh/chart: system-0.1.75
    app.kubernetes.io/name: system
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
  annotations:
    "helm.sh/hook": post-install,post-upgrade
    "helm.sh/hook-delete-policy": before-hook-creation
spec:
  activeDeadlineSeconds: 3600
  backoffLimit: 6

  template:
    metadata:
      labels:
        helm.sh/chart: system-0.1.75
        app.kubernetes.io/name: system
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/managed-by: Helm
    spec:
      securityContext:
        runAsUser: 1000
        fsGroup: 1000
      restartPolicy: OnFailure
      serviceAccountName: release-name-system-1-migrations
      initContainers:
        # TODO Wait for all services
        - name: wait-for-facade
          image: groundnuty/k8s-wait-for:v1.7
          imagePullPolicy: IfNotPresent
          args:
            - "service"
            - "facade-srv"
        - name: wait-for-identity
          image: groundnuty/k8s-wait-for:v1.7
          imagePullPolicy: IfNotPresent
          args:
            - "service"
            - "identity-srv"
        - name: wait-for-resource
          image: groundnuty/k8s-wait-for:v1.7
          imagePullPolicy: IfNotPresent
          args:
            - "service"
            - "resource-srv"
        - name: wait-for-access-control
          image: groundnuty/k8s-wait-for:v1.7
          imagePullPolicy: IfNotPresent
          args:
            - "service"
            - "access-control-srv"
      containers:
        - name: migrations
          image: "busybox:latest"
          args:
            - echo
            - hello
          resources:
            requests:
              cpu: 250m
              memory: 200Mi
