---
# Source: sumo-besu-node/templates/node-statefulset.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: sumo-besu-node-release-name-sa
  namespace: default
---
# Source: sumo-besu-node/templates/besu-config-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: sumo-besu-node-release-name-besu-config
  labels:
    app: sumo-besu-node
    chart: sumo-besu-node-0.1.75
    release: release-name
    heritage: Helm
    namespace: default
    app.kubernetes.io/name: sumo-besu-node
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    helm.sh/chart: sumo-besu-node-0.1.75
  namespace: default
data:
  config.toml: |-
    # Every possible CLI should be in this file.
    #
    # Please use a plausible value, besu has to at least be able to parse it.
    # If it is a multi-valued CLI make it a TOML array.
    # If it is a number or boolean make it a number or boolean
    # All other config options are strings, and must be quoted.

    # Node Information
    data-path="/data/besu"
    genesis-file="/etc/genesis/genesis.json"
    logging="INFO"
    node-private-key-file="/keys/private.key"

    # Transaction Pool
    tx-pool-retention-hours=999
    tx-pool-max-size=4096

    # P2P network
    p2p-enabled=true
    discovery-enabled=true
    static-nodes-file="/config/static/static-nodes.json"
    p2p-host="0.0.0.0"
    p2p-port=30303
    max-peers=25
    

    
    host-allowlist=["*"]
    

    # JSON-RPC
    rpc-http-enabled=true
    rpc-http-host="0.0.0.0"
    rpc-http-port=8545
    rpc-http-api=["DEBUG","ETH","TXPOOL","ADMIN", "WEB3", "IBFT", "NET"]
    rpc-http-cors-origins=["all"]
    rpc-http-authentication-enabled=false
    rpc-http-max-active-connections=80
    

    

    

    

    

    

    # Metrics
    metrics-enabled=true
    metrics-host="0.0.0.0"
    metrics-port=9545
    

    

    # DEBUG REMOVE BEFORE ACTUAL PRODUCTION TESTING
    revert-reason-enabled=true
    min-gas-price=0
---
# Source: sumo-besu-node/templates/node-statefulset.yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: sumo-besu-node-release-name-pvc
  namespace: default
spec:
  storageClassName: gp2
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: "300Gi"
---
# Source: sumo-besu-node/templates/node-statefulset.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: sumo-besu-node-release-name-role
  namespace: default
rules:
  - apiGroups: [""]
    resources: ["secrets"]
    verbs: ["get"]
  - apiGroups: [""]
    resources: ["services"]
    verbs: ["get", "list"]
---
# Source: sumo-besu-node/templates/node-statefulset.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: sumo-besu-node-release-name-rb
  namespace: default
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: sumo-besu-node-release-name-role
subjects:
- kind: ServiceAccount
  name: sumo-besu-node-release-name-sa
  namespace: default
---
# Source: sumo-besu-node/templates/node-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: sumo-besu-node-release-name
  labels:
    app: sumo-besu-node-release-name
    chart: sumo-besu-node-0.1.75
    release: release-name
    heritage: Helm
    namespace: default
    app.kubernetes.io/name: sumo-besu-node-release-name
    helm.sh/chart: sumo-besu-node-0.1.75
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: release-name
  namespace: default
spec:
  type: ClusterIP
  selector:
    app: sumo-besu-node-release-name
    release: release-name
    component: release-name
    app.kubernetes.io/name: sumo-besu-node-release-name
    app.kubernetes.io/instance: release-name
  ports:
    - name: json-rpc
      port: 8545
      targetPort: json-rpc
      protocol: TCP
    - name: engine-rpc
      port: 5679
      targetPort: engine-rpc
      protocol: TCP
    - name: ws
      port: 8546
      targetPort: ws
      protocol: TCP
    - name: graphql
      port: 8547
      targetPort: graphql
      protocol: TCP
    - name: rlpx
      port: 30303
      targetPort: rlpx
      protocol: TCP
    - name: discovery
      port: 30303
      targetPort: discovery
      protocol: UDP
    - name: metrics
      port: 9545
      targetPort: metrics
      protocol: TCP
---
# Source: sumo-besu-node/templates/node-statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: sumo-besu-node-release-name
  labels:
    app: sumo-besu-node-release-name
    chart: sumo-besu-node-0.1.75
    release: release-name
    heritage: Helm
    namespace: default
    component: release-name
    app.kubernetes.io/name: sumo-besu-node-release-name
    helm.sh/chart: sumo-besu-node-0.1.75
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    type: "besu-node"
  namespace: default
spec:
  replicas: 1
  podManagementPolicy: OrderedReady
  selector:
    matchLabels:
      app: sumo-besu-node-release-name
      release: release-name
      component: release-name
      app.kubernetes.io/name: sumo-besu-node-release-name
      app.kubernetes.io/instance: release-name
  serviceName: sumo-besu-node-release-name
  template:
    metadata:
      labels:
        app: sumo-besu-node-release-name
        release: release-name
        component: release-name
        app.kubernetes.io/name: sumo-besu-node-release-name
        app.kubernetes.io/instance: release-name
        type: "besu-node"
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "9545"
        prometheus.io/path: "/metrics"
    spec:
      serviceAccountName: sumo-besu-node-release-name-sa
      initContainers:
      - name: init-bootnode
        image: curlimages/curl:latest
        command:
          - /bin/sh
          - -c
          - "curl -X GET --connect-timeout 30 --max-time 10 --retry 6 --retry-delay 0 --retry-max-time 300 besu-node-bootnode-1.default.svc.cluster.local:8545/liveness"

        # fix for minikube and PVC's only writable as root https://github.com/kubernetes/minikube/issues/1990
      - name: volume-permission-besu
        image: busybox
        command: ["sh", "-c", "chown -R 1000:1000 /data"]
        volumeMounts:
          - name: data
            mountPath: /data
        securityContext:
          runAsUser: 0

      containers:


      - name: release-name-besu
        image: hyperledger/besu:22.4-openjdk-latest
        imagePullPolicy: IfNotPresent
        resources:
          limits:
            cpu: 12
            memory: 64G
          requests:
            cpu: 6
            memory: 16G
        env:
          - name: POD_IP
            valueFrom:
              fieldRef:
                fieldPath: status.podIP
          - name: POD_NAME
            valueFrom:
              fieldRef:
                fieldPath: metadata.name
          - name: BOOTNODE1_PUBKEY
            valueFrom:
              secretKeyRef:
                name: besu-node-bootnode-1-keys
                key: enode
          - name: BOOTNODE2_PUBKEY
            valueFrom:
              secretKeyRef:
                name: besu-node-bootnode-2-keys
                key: enode
        volumeMounts:
          - name: besu-keys
            mountPath: /keys
            readOnly: true
          - name: genesis
            mountPath: /etc/genesis
            readOnly: true
          - name: static-nodes
            mountPath: /config/static
          - name: besu-config
            mountPath: /etc/besu
            readOnly: true
          - name: data
            mountPath: /data/besu
        ports:
          - name: json-rpc
            containerPort: 8545
            protocol: TCP
          - name: engine-rpc
            containerPort: 5679
            protocol: TCP
          - name: ws
            containerPort: 8546
            protocol: TCP
          - name: graphql
            containerPort: 8547
            protocol: TCP
          - name: rlpx
            containerPort: 30303
            protocol: TCP
          - name: discovery
            containerPort: 30303
            protocol: UDP
          - name: metrics
            containerPort: 9545
            protocol: TCP
        command:
          - /bin/sh
          - -c
        args:
          - |
            exec
            export BOOTNODE_ENODE1="enode://${BOOTNODE1_PUBKEY}@besu-node-bootnode-1-0.besu-node-bootnode-1.default.svc.cluster.local:30303" ;
            export BOOTNODE_ENODE2="enode://${BOOTNODE2_PUBKEY}@besu-node-bootnode-2-0.besu-node-bootnode-2.default.svc.cluster.local:30303" ;
            /opt/besu/bin/besu \
              --config-file=/etc/besu/config.toml \
              --Xdns-enabled=true --Xdns-update-enabled=true --Xnat-kube-service-name=sumo-besu-node-release-name \
              --bootnodes=${BOOTNODE_ENODE1},${BOOTNODE_ENODE2}
        livenessProbe:
          httpGet:
            path: /liveness
            port: 8545
          initialDelaySeconds: 180
          periodSeconds: 60
      volumes:
      - name: besu-keys
        secret:
          secretName: sumo-besu-node-release-name-keys
      - name: genesis
        configMap:
          name: sumo-besu-genesis
          items:
            - key: genesis.json
              path: genesis.json
      - name: static-nodes
        configMap:
          name: sumo-besu-enodes
          items:
            - key: static-nodes.json
              path: static-nodes.json
      - name: besu-config
        configMap:
          name: sumo-besu-node-release-name-besu-config
      - name: data
        persistentVolumeClaim:
          claimName: sumo-besu-node-release-name-pvc
---
# Source: sumo-besu-node/templates/servicemonitor.yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: sumo-besu-node-release-name
  labels:
    helm.sh/chart: sumo-besu-node-0.1.75
    app: sumo-besu-node-release-name
    chart: sumo-besu-node-0.1.75
    release: release-name
    heritage: Helm
    namespace: default
    app.kubernetes.io/name: sumo-besu-node-release-name
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/version: "latest"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: release-name

spec:
  endpoints:
    - port: metrics
  namespaceSelector:
    matchNames:
      - default
  selector:
    matchLabels:
      app.kubernetes.io/name: sumo-besu-node-release-name
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/component: release-name
---
# Source: sumo-besu-node/templates/node-hooks.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: sumo-besu-node-release-name-hooks-sa
  namespace: default
  annotations:
    "helm.sh/hook-delete-policy": before-hook-creation
    "helm.sh/hook": "pre-install,pre-delete,post-delete"
---
# Source: sumo-besu-node/templates/node-hooks.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: sumo-besu-node-release-name-hooks-role
  namespace: default
  annotations:
    "helm.sh/hook-delete-policy": before-hook-creation
    "helm.sh/hook": "pre-install,pre-delete,post-delete"
rules:
  - apiGroups: [""]
    resources: ["secrets", "configmaps"]
    verbs: ["create", "get", "list", "update", "delete" ]
  - apiGroups: [""]
    resources: ["services"]
    verbs: ["get", "list"]
---
# Source: sumo-besu-node/templates/node-hooks.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: sumo-besu-node-release-name-hooks-rb
  namespace: default
  annotations:
    "helm.sh/hook-delete-policy": before-hook-creation
    "helm.sh/hook": "pre-install,pre-delete,post-delete"
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: sumo-besu-node-release-name-hooks-role
subjects:
  - kind: ServiceAccount
    name: sumo-besu-node-release-name-hooks-sa
    namespace:  default
---
# Source: sumo-besu-node/templates/node-hooks.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: sumo-besu-node-release-name-pre-install-hook
  namespace: default
  annotations:
    "helm.sh/hook": pre-install
    "helm.sh/hook-weight": "0"
    "helm.sh/hook-delete-policy": "hook-succeeded"
spec:
  backoffLimit: 1
  completions: 1
  template:
    spec:
      serviceAccountName: sumo-besu-node-release-name-hooks-sa
      restartPolicy: "OnFailure"
      containers:
        - name: sumo-besu-node-release-name-pre-start-hook
          image: consensys/quorum-k8s-hooks:latest
          imagePullPolicy: IfNotPresent
          securityContext:
            runAsUser: 0
          command:
            - /bin/bash
            - -c
          args:
            - |

              function update_enodes_configmap {
                kubectl -n default get configmap besu-node-enodes -o json
                if [ $? -ne 0 ]; then
                echo "[]" > /tmp/static-nodes.json.raw
                fi
                # update the entries
                echo "updating besu-node-enodes..."
                pubkey=$(cat /tmp/enode )
                echo $(kubectl -n default get configmap besu-node-enodes -o jsonpath='{.data.static-nodes\.json}' ) > /tmp/static-nodes.json.raw
                NEEDLE="enode://$pubkey@sumo-besu-node-release-name-0.sumo-besu-node-release-name.default.svc.cluster.local:30303?discport=0"
                cat /tmp/static-nodes.json.raw | jq --arg NEEDLE "$NEEDLE" '. += [ $NEEDLE ] | unique ' > /tmp/static-nodes.json
                kubectl -n default create configmap besu-node-enodes --from-file=static-nodes.json=/tmp/static-nodes.json -o yaml --dry-run=client | kubectl replace -f -
              }

              function update_tessera_peers_configmap {
                kubectl -n default get configmap tessera-peers -o json
                # first time a tx node is deployed and there is no configmap
                if [ $? -ne 0 ]; then
                  echo "No tessera-peers found, creating a new one..."
                  echo "[{ \"url\": \"http://sumo-besu-node-release-name.default.svc.cluster.local:9000\" }]"  > /tmp/tessera-peers
                  kubectl --namespace default create configmap tessera-peers --from-file=tesseraPeers=/tmp/tessera-peers

                # update the entries
                else
                  echo "Tessera-peers found, updating existing..."
                  echo $(kubectl -n default get configmap tessera-peers -o jsonpath='{.data.tesseraPeers}' ) > /tmp/tessera-peers.raw
                  NEEDLE="http://sumo-besu-node-release-name.default.svc.cluster.local:9000"
                  cat /tmp/tessera-peers.raw | jq --arg NEEDLE "$NEEDLE" '. += [{"url": $NEEDLE}] | unique ' > /tmp/tessera-peers
                  kubectl -n default create configmap tessera-peers --from-file=tesseraPeers=/tmp/tessera-peers -o yaml --dry-run=client | kubectl replace -f -
                fi
              }

              echo "sumo-besu-node-release-name hook ..."

              echo "hook completed"
---
# Source: sumo-besu-node/templates/node-hooks.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: sumo-besu-node-release-name-keys-pre-delete-hook
  namespace: default
  annotations:
    helm.sh/hook-weight: "0"
    helm.sh/hook: "pre-delete"
    helm.sh/hook-delete-policy: "hook-succeeded"
spec:
  backoffLimit: 1
  completions: 1
  template:
    metadata:
      labels:
        app.kubernetes.io/name: sumo-besu-node
        app.kubernetes.io/instance: release-name
    spec:
      serviceAccountName: sumo-besu-node-release-name-hooks-sa
      restartPolicy: "OnFailure"
      containers:
        - name: delete-keys
          image: consensys/quorum-k8s-hooks:latest
          securityContext:
            runAsUser: 0
          imagePullPolicy: 
          command:
            - /bin/bash
            - -c
          args:
            - |

              function delete_node_from_tessera_peers_configmap {
                kubectl -n default get configmap tessera-peers -o json
                # if there is no configmap, do nothing
                if [ $? -ne 0 ]; then
                  echo "No tessera-peers found, nothing to do..."
                # delete the one
                else
                  echo "tessera-peers found, deleting sumo-besu-node-release-name..."
                  echo $(kubectl -n default get configmap tessera-peers -o jsonpath='{.data.tesseraPeers}' ) > /tmp/tessera-peers.raw
                  cat /tmp/tessera-peers.raw | jq --arg NEEDLE "sumo-besu-node-release-name" 'del(.[] | select( .url | contains($NEEDLE) ))' > /tmp/tessera-peers
                  kubectl -n default create configmap tessera-peers --from-file=tesseraPeers=/tmp/tessera-peers -o yaml --dry-run=client | kubectl replace -f -
                fi
              }

              function delete_node_from_enodes_configmap {
                kubectl -n default  get configmap besu-node-enodes -o json
                # if there is no configmap, do nothing
                if [ $? -ne 0 ]; then
                  echo "No peers found, nothing to do..."
                # delete the one
                else
                  echo "besu-node-enodes found, deleting sumo-besu-node-release-name..."
                  echo $(kubectl -n default get configmap besu-node-enodes -o jsonpath='{.data.static-nodes\.json}' ) > /tmp/static-nodes.json.raw
                  cat /tmp/static-nodes.json.raw | jq --arg NEEDLE "sumo-besu-node-release-name" 'del(.[] | select( . | contains($NEEDLE) ))' > /tmp/static-nodes.json
                  kubectl -n default create configmap besu-node-enodes --from-file=static-nodes.json=/tmp/static-nodes.json -o yaml --dry-run=client | kubectl replace -f -
                fi
              }

              delete_node_from_enodes_configmap
              delete_node_from_tessera_peers_configmap
              echo "Completed"
