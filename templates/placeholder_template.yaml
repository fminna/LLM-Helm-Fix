---
# Source: placeholder/templates/common.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: tc-system
  annotations:
    "helm.sh/resource-policy": keep
---
# Source: placeholder/templates/common.yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: release-name-placeholder-config
  labels:
    app: "placeholder-0.0.1"
    app.kubernetes.io/managed-by: "Helm"
    app.kubernetes.io/version: "0.20.4145"
    helm-revision: "1"
    helm.sh/chart: "placeholder-0.0.1"
    release: "release-name"
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 100Gi
---
# Source: placeholder/templates/common.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-placeholder
  labels:
    app: "placeholder-0.0.1"
    app.kubernetes.io/instance: "release-name"
    app.kubernetes.io/managed-by: "Helm"
    app.kubernetes.io/name: "placeholder"
    app.kubernetes.io/version: "0.20.4145"
    helm-revision: "1"
    helm.sh/chart: "placeholder-0.0.1"
    release: "release-name"
    service.name: "main"
spec:
  type: ClusterIP
  publishNotReadyAddresses: false
  ports:
    - name: main
      port: 9117
      protocol: TCP
      targetPort: 9117
  selector:
    pod.name: main
    app.kubernetes.io/name: placeholder
    app.kubernetes.io/instance: release-name
---
# Source: placeholder/templates/common.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-placeholder
  labels:
    app: "placeholder-0.0.1"
    app.kubernetes.io/managed-by: "Helm"
    app.kubernetes.io/version: "0.20.4145"
    helm-revision: "1"
    helm.sh/chart: "placeholder-0.0.1"
    release: "release-name"
spec:  
  replicas: 1
  revisionHistoryLimit: 3
  strategy:
    type: Recreate
  selector:
    matchLabels:
      pod.name: main
      app.kubernetes.io/name: placeholder
      app.kubernetes.io/instance: release-name
  template:
    metadata:
      labels:
        app: "placeholder-0.0.1"
        app.kubernetes.io/instance: "release-name"
        app.kubernetes.io/managed-by: "Helm"
        app.kubernetes.io/name: "placeholder"
        app.kubernetes.io/version: "0.20.4145"
        helm-revision: "1"
        helm.sh/chart: "placeholder-0.0.1"
        pod.name: "main"
        release: "release-name"
      annotations:
        rollme: "MbJei"
    spec:
      serviceAccountName: default
      automountServiceAccountToken: false
      runtimeClassName: 
      hostNetwork: false
      hostPID: false
      enableServiceLinks: false
      restartPolicy: Always
      dnsPolicy: ClusterFirst
      dnsConfig:
        options:
          - name: ndots
            value: "2"
      terminationGracePeriodSeconds: 60
      securityContext:
        fsGroup: 568
        fsGroupChangePolicy: OnRootMismatch
        supplementalGroups:
          - 568
        sysctls: []
      containers:
        - name: release-name-placeholder
          image: tccr.io/truecharts/jackett:v0.20.4145@sha256:e9e1a99651381a47b655dfe9c7eda3a86cda02cb49437fe57fc8ff1a91303ffa
          imagePullPolicy: IfNotPresent
          tty: false
          stdin: false
          ports:
            - name: main
              containerPort: 9117
              protocol: TCP
              hostPort: null
          volumeMounts:
            - name: config
              mountPath: /config
              readOnly: false
            - name: devshm
              mountPath: /dev/shm
              readOnly: false
            - name: shared
              mountPath: /shared
              readOnly: false
            - name: tmp
              mountPath: /tmp
              readOnly: false
            - name: varlogs
              mountPath: /var/logs
              readOnly: false
            - name: varrun
              mountPath: /var/run
              readOnly: false
          livenessProbe:
            httpGet:
              port: 9117
              path: /UI/Login
              scheme: HTTP
            initialDelaySeconds: 10
            failureThreshold: 5
            successThreshold: 1
            timeoutSeconds: 5
            periodSeconds: 10
          readinessProbe:
            httpGet:
              port: 9117
              path: /UI/Login
              scheme: HTTP
            initialDelaySeconds: 10
            failureThreshold: 5
            successThreshold: 2
            timeoutSeconds: 5
            periodSeconds: 10
          startupProbe:
            httpGet:
              port: 9117
              path: /UI/Login
              scheme: HTTP
            initialDelaySeconds: 10
            failureThreshold: 60
            successThreshold: 1
            timeoutSeconds: 2
            periodSeconds: 5
          resources:
            requests:
              cpu: 10m
              memory: 50Mi
            limits: 
              cpu: 4000m 
              memory: 8Gi
          securityContext:
            runAsNonRoot: true
            runAsUser: 568
            runAsGroup: 568
            readOnlyRootFilesystem: false
            allowPrivilegeEscalation: false
            privileged: false
            seccompProfile:
              type: RuntimeDefault
            capabilities:
              add: []
              drop:
                - ALL
          env:
            - name: "TZ"
              value: "UTC"
            - name: "UMASK"
              value: "0022"
            - name: "UMASK_SET"
              value: "0022"
            - name: "S6_READ_ONLY_ROOT"
              value: "1"
      volumes:
        - name: config
          persistentVolumeClaim:
            claimName: release-name-placeholder-config
        - name: devshm
          emptyDir:
            medium: Memory
        - name: shared
          emptyDir: {}
        - name: tmp
          emptyDir: {}
        - name: varlogs
          emptyDir: {}
        - name: varrun
          emptyDir:
            medium: Memory
---
# Source: placeholder/templates/common.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: release-name-placeholder-manifests
  namespace: default
  annotations:
    "helm.sh/hook": pre-install, pre-upgrade
    "helm.sh/hook-weight": "-7"
    "helm.sh/hook-delete-policy": hook-succeeded,before-hook-creation,hook-failed
automountServiceAccountToken: false
---
# Source: placeholder/templates/common.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: release-name-placeholder-manifests
  annotations:
    "helm.sh/hook": pre-install, pre-upgrade
    "helm.sh/hook-weight": "-7"
    "helm.sh/hook-delete-policy": hook-succeeded,before-hook-creation,hook-failed
rules:
  - apiGroups:  ["*"]
    resources:  ["*"]
    verbs:  ["*"]
---
# Source: placeholder/templates/common.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: release-name-placeholder-manifests
  annotations:
    "helm.sh/hook": pre-install, pre-upgrade
    "helm.sh/hook-weight": "-7"
    "helm.sh/hook-delete-policy": hook-succeeded,before-hook-creation,hook-failed
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: release-name-placeholder-manifests
subjects:
  - kind: ServiceAccount
    name: release-name-placeholder-manifests
    namespace: default
---
# Source: placeholder/templates/common.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: release-name-placeholder-manifests
  namespace: default
  annotations:
    "helm.sh/hook": pre-install, pre-upgrade
    "helm.sh/hook-weight": "-6"
    "helm.sh/hook-delete-policy": hook-succeeded,before-hook-creation,hook-failed
spec:
  template:
    spec:
      automountServiceAccountToken: true
      serviceAccountName: release-name-placeholder-manifests
      containers:
        - name: release-name-placeholder-manifests
          image: tccr.io/truecharts/kubectl:v1.26.0@sha256:323ab7aa3e7ce84c024df79d0f364282c1135499298f54be2ade46508a116c4b
          securityContext:
            runAsUser: 568
            runAsGroup: 568
            readOnlyRootFilesystem: true
            runAsNonRoot: true
            allowPrivilegeEscalation: false
            privileged: false
            seccompProfile:
              type: RuntimeDefault
            capabilities:
              add: []
              drop:
                - ALL
          resources:
            requests:
              cpu: 10m
              memory: 50Mi
            limits:
              cpu: 4000m
              memory: 8Gi
          livenessProbe:
            exec:
              command:
              - cat
              - /tmp/healthy
            initialDelaySeconds: 10
            failureThreshold: 60
            successThreshold: 1
            timeoutSeconds: 5
            periodSeconds: 10
          readinessProbe:
            exec:
              command:
              - cat
              - /tmp/healthy
            initialDelaySeconds: 10
            failureThreshold: 60
            successThreshold: 2
            timeoutSeconds: 5
            periodSeconds: 10
          startupProbe:
            exec:
              command:
              - cat
              - /tmp/healthy
            initialDelaySeconds: 10
            failureThreshold: 60
            successThreshold: 1
            timeoutSeconds: 2
            periodSeconds: 5
          command:
            - "/bin/sh"
            - "-c"
            - |
              /bin/sh <<'EOF'
              touch /tmp/healthy
              echo "Installing manifests..."

              kubectl apply --server-side --force-conflicts --grace-period 30 --v=4 -k https://github.com/truecharts/manifests/manifests || \
              kubectl apply --server-side --force-conflicts --grace-period 30 -k https://github.com/truecharts/manifests/manifests || echo 'Job succeeded...'

              echo "Install finished..."

              echo "Starting waits and checks..."
              kubectl delete pod --field-selector=status.phase==Succeeded -n cnpg-system || echo "Delete of Completed Pods failed..."
              kubectl delete pod --field-selector=status.phase==Failed -n cnpg-system || echo "Delete of Failed Pods failed..."
              kubectl wait --namespace cnpg-system --for=condition=ready pod --selector=app.kubernetes.io/name=cloudnative-pg --timeout=60s || echo "metallb-system wait failed..."

              kubectl delete pod --field-selector=status.phase==Succeeded -n metallb-system || echo "Delete of Completed Pods failed..."
              kubectl delete pod --field-selector=status.phase==Failed -n metallb-system || echo "Delete of Failed Pods failed..."
              kubectl wait --namespace metallb-system --for=condition=ready pod --selector=app=metallb --timeout=60s || echo "metallb-system wait failed..."

              kubectl delete pod --field-selector=status.phase==Succeeded -n cert-manager || echo "Delete of Completed Pods failed..."
              kubectl delete pod --field-selector=status.phase==Failed -n cert-manager || echo "Delete of Failed Pods failed..."
              kubectl wait --namespace cert-manager --for=condition=ready pod --selector=app.kubernetes.io/instance=cert-manager --timeout=60s || echo "cert-manager wait failed..."

              cmctl check api --wait=1m || echo "cmctl wait failed..."
              EOF
          volumeMounts:
            - name: release-name-placeholder-manifests-temp
              mountPath: /tmp
            - name: release-name-placeholder-manifests-home
              mountPath: /home/apps/
      restartPolicy: Never
      volumes:
        - name: release-name-placeholder-manifests-temp
          emptyDir: {}
        - name: release-name-placeholder-manifests-home
          emptyDir: {}
