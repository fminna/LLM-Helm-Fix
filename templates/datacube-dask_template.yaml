---
# Source: datacube-dask/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-datacube-dask
  labels:
    app: release-name-datacube-dask
    chart: "datacube-dask-0.4.10"
    release: "release-name"
    heritage: "Helm"
data:
  kubernetes.yaml: "kubernetes:\n  count:\n    max: 4\n    min: 2\n    start: 2\n  env: {}\n  host: 0.0.0.0\n  name: dask-{uuid}\n  namespace: null\n  port: 8786\n  worker-template:\n    kind: Pod\n    metadata:\n      annotations:\n        iam.amazonaws.com/role: kubernetes-wms\n      labels:\n        app: dask\n    spec:\n      containers:\n      - args:\n        - dask-worker\n        - --nthreads\n        - \"2\"\n        - --no-bokeh\n        - --memory-limit\n        - 6GB\n        - --death-timeout\n        - \"60\"\n        image: opendatacube/dask:latest\n        name: dask\n        resources:\n          limits:\n            cpu: \"2\"\n            memory: 6G\n          requests:\n            cpu: \"2\"\n            memory: 6G\n      restartPolicy: Never\n  worker-template-path: null"
---
# Source: datacube-dask/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-datacube-dask
  labels:
    app.kubernetes.io/name: datacube-dask
    helm.sh/chart: datacube-dask-0.4.10
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
  annotations:
    null
spec:
  type: NodePort
  ports:
    - port: 8786
      targetPort: scheduler
      protocol: TCP
      name: scheduler
    - port: 8787
      targetPort: bokeh
      protocol: TCP
      name: bokeh
  selector:
    app.kubernetes.io/name: datacube-dask
    app.kubernetes.io/instance: release-name
---
# Source: datacube-dask/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-datacube-dask-scheduler
  labels:
    app.kubernetes.io/name: datacube-dask
    helm.sh/chart: datacube-dask-0.4.10
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: datacube-dask
      app.kubernetes.io/instance: release-name
  template:
    metadata:
      labels:
        app.kubernetes.io/name: datacube-dask
        app.kubernetes.io/instance: release-name
    spec:
      # Turning single-request-reopen option on would fix issue where in two requests from the same port are
      # not handled correctly it will close the socket and open a new one before sending the second request.
      dnsConfig:
        options:
          - name: single-request-reopen
      containers:
        - name: datacube-dask-scheduler
          image: "opendatacube/dask:latest"
          imagePullPolicy: Always
          volumeMounts:
          - name: config-volume
            mountPath: /etc/config/datacube/dask/
          command: [ "dask-scheduler", ]
          args:
          - "--port"
          - "8786"
          - "--bokeh-port"
          - "8787"
          env:
          - name: "DASK_CONFIG"
            value: "/etc/config/datacube/dask/kubernetes.yaml"
          ports:
            - name: scheduler
              containerPort: 8786
              protocol: TCP
            - name: bokeh
              containerPort: 8787
          livenessProbe:
            exec:
              command:
              - dask-scheduler-health.py
              - --port
              - "8786"
            initialDelaySeconds: 30
            periodSeconds: 60
          resources:
            {}
      volumes:
      - name: config-volume
        configMap:
          name: release-name-datacube-dask
---
# Source: datacube-dask/templates/worker-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-datacube-dask-worker
  labels:
    app.kubernetes.io/name: datacube-dask
    helm.sh/chart: datacube-dask-0.4.10
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: datacube-dask-worker
      app.kubernetes.io/instance: release-name
  template:
    metadata:
      labels:
        app.kubernetes.io/name: datacube-dask-worker
        app.kubernetes.io/instance: release-name
      annotations:
        iam.amazonaws.com/role: kubernetes-wms
    spec:
      # Turning single-request-reopen option on would fix issue where in two requests from the same port are
      # not handled correctly it will close the socket and open a new one before sending the second request.
      dnsConfig:
        options:
          - name: single-request-reopen
      containers:
        - name: datacube-dask-worker
          image: "opendatacube/dask:latest"
          imagePullPolicy: Always
          command:
          - "docker-entrypoint.sh"
          args:
          - dask-worker
          - release-name-datacube-dask.default:8786
          - "--nthreads"
          - "2"
          - "--no-bokeh"
          - "--memory-limit"
          - "6GB"
          - "--death-timeout"
          - "60"
          env:
          - name: DB_HOSTNAME
            value: "localhost"
          - name: DB_PORT
            value: "5432"
          - name: DB_DATABASE
            value: "datacube"
          - name: DB_USERNAME
            valueFrom:
              secretKeyRef:
                name: datacube
                key: postgres-username
          - name: DB_PASSWORD
            valueFrom:
              secretKeyRef:
                name: datacube
                key: postgres-password
          ports:
            - name: worker
              containerPort: 8789
              protocol: TCP
          # livenessProbe:
          #   exec:
          #     command:
          #     - dask-scheduler-health.py
          #     - --port
          #     - "8786"
          #   initialDelaySeconds: 30
          #   periodSeconds: 60
          resources:
            limits:
              cpu: "2"
              memory: 6G
            requests:
              cpu: "2"
              memory: 6G
---
# Source: datacube-dask/templates/worker-hpa.yaml
apiVersion: autoscaling/v2beta1
kind: HorizontalPodAutoscaler
metadata:
  name: release-name-datacube-dask-worker
  labels:
    app.kubernetes.io/name: datacube-dask
    helm.sh/chart: datacube-dask-0.4.10
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: release-name-datacube-dask-worker
  minReplicas: 1
  maxReplicas: 10
  metrics:
    - type: Resource
      resource:
        name: cpu
        targetAverageUtilization: 75
