---
# Source: vcluster-pro-eks/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: vc-release-name
  namespace: default
  labels:
    app: vcluster
    chart: "vcluster-pro-eks-0.2.0"
    release: "release-name"
    heritage: "Helm"
---
# Source: vcluster-pro-eks/templates/workloadserviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: vc-workload-release-name
  namespace: default
  labels:
    app: vcluster
    chart: "vcluster-pro-eks-0.2.0"
    release: "release-name"
    heritage: "Helm"
---
# Source: vcluster-pro-eks/templates/coredns.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-coredns
  namespace: default  
data:
  coredns.yaml: |-
    apiVersion: v1
    kind: ServiceAccount
    metadata:
      name: coredns
      namespace: kube-system
    ---
    apiVersion: rbac.authorization.k8s.io/v1
    kind: ClusterRole
    metadata:
      labels:
        kubernetes.io/bootstrapping: rbac-defaults
      name: system:coredns
    rules:
    - apiGroups:
      - ""
      resources:
      - endpoints
      - services
      - pods
      - namespaces
      verbs:
      - list
      - watch
    - apiGroups:
      - discovery.k8s.io
      resources:
      - endpointslices
      verbs:
      - list
      - watch
    ---
    apiVersion: rbac.authorization.k8s.io/v1
    kind: ClusterRoleBinding
    metadata:
      annotations:
        rbac.authorization.kubernetes.io/autoupdate: "true"
      labels:
        kubernetes.io/bootstrapping: rbac-defaults
      name: system:coredns
    roleRef:
      apiGroup: rbac.authorization.k8s.io
      kind: ClusterRole
      name: system:coredns
    subjects:
    - kind: ServiceAccount
      name: coredns
      namespace: kube-system
    ---
    apiVersion: v1
    kind: ConfigMap
    metadata:
      name: coredns
      namespace: kube-system
    data:
      Corefile: |-
        .:1053 {
            errors {
                stacktrace
            }
            health
            ready
            rewrite name regex .*\.nodes\.vcluster\.com kubernetes.default.svc.cluster.local
            kubernetes cluster.local in-addr.arpa ip6.arpa {
                pods insecure
                fallthrough in-addr.arpa ip6.arpa
            }
            hosts /etc/NodeHosts {
                ttl 60
                reload 15s
                fallthrough
            }
            prometheus :9153
            forward . /etc/resolv.conf
            cache 30
            loop
            loadbalance
        }
      
        import /etc/coredns/custom/*.server
      NodeHosts: ""
    ---
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: coredns
      namespace: kube-system
      labels:
        k8s-app: kube-dns
        kubernetes.io/name: "CoreDNS"
    spec:
      replicas: 1
      strategy:
        type: RollingUpdate
        rollingUpdate:
          maxUnavailable: 1
      selector:
        matchLabels:
          k8s-app: kube-dns
      template:
        metadata:
          labels:
            k8s-app: kube-dns
        spec:
          priorityClassName: "system-cluster-critical"
          serviceAccountName: coredns
          tolerations:
            - key: "CriticalAddonsOnly"
              operator: "Exists"
            - key: "node-role.kubernetes.io/control-plane"
              operator: "Exists"
              effect: "NoSchedule"
            - key: "node-role.kubernetes.io/master"
              operator: "Exists"
              effect: "NoSchedule"
          nodeSelector:
            kubernetes.io/os: linux
          topologySpreadConstraints:
            - maxSkew: 1
              topologyKey: kubernetes.io/hostname
              whenUnsatisfiable: DoNotSchedule
              labelSelector:
                matchLabels:
                  k8s-app: kube-dns
          containers:
          - name: coredns
            image: "public.ecr.aws/eks-distro/coredns/coredns:v1.8.7-eks-1-24-7"
            imagePullPolicy: IfNotPresent
            resources:
              limits:
                cpu: 1000m
                memory: 512Mi
              requests:
                cpu: 20m
                memory: 64Mi
            args: [ "-conf", "/etc/coredns/Corefile" ]
            volumeMounts:
            - name: config-volume
              mountPath: /etc/coredns
              readOnly: true
            - name: custom-config-volume
              mountPath: /etc/coredns/custom
              readOnly: true
            ports:
            - containerPort: 1053
              name: dns
              protocol: UDP
            - containerPort: 1053
              name: dns-tcp
              protocol: TCP
            - containerPort: 9153
              name: metrics
              protocol: TCP
            securityContext:
              runAsNonRoot:  true
              runAsUser:  {{.RUN_AS_USER}}
              runAsGroup: {{.RUN_AS_GROUP}}
              allowPrivilegeEscalation: false
              capabilities:
                drop:
                - all
              readOnlyRootFilesystem: true
            livenessProbe:
              httpGet:
                path: /health
                port: 8080
                scheme: HTTP
              initialDelaySeconds: 60
              periodSeconds: 10
              timeoutSeconds: 1
              successThreshold: 1
              failureThreshold: 3
            readinessProbe:
              httpGet:
                path: /ready
                port: 8181
                scheme: HTTP
              initialDelaySeconds: 0
              periodSeconds: 2
              timeoutSeconds: 1
              successThreshold: 1
              failureThreshold: 3
          dnsPolicy: Default
          volumes:
            - name: config-volume
              configMap:
                name: coredns
                items:
                - key: Corefile
                  path: Corefile
                - key: NodeHosts
                  path: NodeHosts
            - name: custom-config-volume
              configMap:
                name: coredns-custom
                optional: true
    ---
    apiVersion: v1
    kind: Service
    metadata:
      name: kube-dns
      namespace: kube-system
      annotations:
        prometheus.io/port: "9153"
        prometheus.io/scrape: "true"
      labels:
        k8s-app: kube-dns
        kubernetes.io/cluster-service: "true"
        kubernetes.io/name: "CoreDNS"
    spec:
      selector:
        k8s-app: kube-dns
      ports:
      - name: dns
        port: 53
        targetPort: 1053
        protocol: UDP
      - name: dns-tcp
        port: 53
        targetPort: 1053
        protocol: TCP
      - name: metrics
        port: 9153
        protocol: TCP
---
# Source: vcluster-pro-eks/templates/init-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-init-manifests
  namespace: default
  labels:
    app: vcluster
    chart: "vcluster-pro-eks-0.2.0"
    release: "release-name"
    heritage: "Helm"
data:
  manifests: |-
    ---
---
# Source: vcluster-pro-eks/templates/rbac/clusterrole.yaml
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: vc-release-name-v-default
  labels:
    app: vcluster
    chart: "vcluster-pro-eks-0.2.0"
    release: "release-name"
    heritage: "Helm"
rules:
  - apiGroups: ["cluster.loft.sh", "storage.loft.sh"]
    resources: ["features", "virtualclusters"]
    verbs: ["get", "list", "watch"]
---
# Source: vcluster-pro-eks/templates/rbac/clusterrolebinding.yaml
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: vc-release-name-v-default
  labels:
    app: vcluster
    chart: "vcluster-pro-eks-0.2.0"
    release: "release-name"
    heritage: "Helm"
subjects:
  - kind: ServiceAccount
    name: vc-release-name
    namespace: default
roleRef:
  kind: ClusterRole
  name: vc-release-name-v-default
  apiGroup: rbac.authorization.k8s.io
---
# Source: vcluster-pro-eks/templates/rbac/role.yaml
kind: Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: release-name
  namespace: default
  labels:
    app: vcluster
    chart: "vcluster-pro-eks-0.2.0"
    release: "release-name"
    heritage: "Helm"
rules:
  - apiGroups: [""]
    resources: ["configmaps", "secrets", "services", "pods", "pods/attach", "pods/portforward", "pods/exec", "persistentvolumeclaims"]
    verbs: ["create", "delete", "patch", "update", "get", "list", "watch"]
  - apiGroups: [""]
    resources: ["endpoints"]
    verbs: ["create", "delete", "patch", "update"]
  - apiGroups: [""]
    resources: ["endpoints", "events", "pods/log"]
    verbs: ["get", "list", "watch"]
  - apiGroups: ["apps"]
    resources: ["statefulsets", "replicasets", "deployments"]
    verbs: ["get", "list", "watch"]
---
# Source: vcluster-pro-eks/templates/rbac/rolebinding.yaml
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: release-name
  namespace: default
  labels:
    app: vcluster
    chart: "vcluster-pro-eks-0.2.0"
    release: "release-name"
    heritage: "Helm"
subjects:
  - kind: ServiceAccount
    name: vc-release-name
    namespace: default
roleRef:
  kind: Role
  name: release-name
  apiGroup: rbac.authorization.k8s.io
---
# Source: vcluster-pro-eks/templates/api-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-api
  namespace: default
  labels:
    app: vcluster-api
    chart: "vcluster-pro-eks-0.2.0"
    release: "release-name"
    heritage: "Helm"
spec:
  type: ClusterIP
  ports:
    - name: https
      port: 443
      targetPort: 6443
      protocol: TCP
  selector:
    app: vcluster-api
    release: release-name
---
# Source: vcluster-pro-eks/templates/etcd-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-etcd
  namespace: default
  labels:
    app: vcluster-etcd
    chart: "vcluster-pro-eks-0.2.0"
    release: "release-name"
    heritage: "Helm"
spec:
  type: ClusterIP
  ports:
    - name: etcd
      port: 2379
      targetPort: 2379
      protocol: TCP
    - name: peer
      port: 2380
      targetPort: 2380
      protocol: TCP
  selector:
    app: vcluster-etcd
    release: release-name
---
# Source: vcluster-pro-eks/templates/etcd-statefulset-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-etcd-headless
  namespace: default
  labels:
    app: vcluster-etcd
    chart: "vcluster-pro-eks-0.2.0"
    release: "release-name"
    heritage: "Helm"
spec:
  publishNotReadyAddresses: true
  ports:
    - name: etcd
      port: 2379
      targetPort: 2379
      protocol: TCP
    - name: peer
      port: 2380
      targetPort: 2380
      protocol: TCP
  clusterIP: None
  selector:
    app: vcluster-etcd
    release: "release-name"
---
# Source: vcluster-pro-eks/templates/syncer-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name
  namespace: default
  labels:
    app: vcluster
    chart: "vcluster-pro-eks-0.2.0"
    release: "release-name"
    heritage: "Helm"
spec:
  type: ClusterIP
  ports:
    - name: https
      port: 443
      targetPort: 8443
      protocol: TCP
    - name: kubelet
      port: 10250
      targetPort: 8443
      protocol: TCP
  selector:
    app: vcluster
    release: release-name
---
# Source: vcluster-pro-eks/templates/api-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-api
  namespace: default
  labels:
    app: vcluster-api
    chart: "vcluster-pro-eks-0.2.0"
    release: "release-name"
    heritage: "Helm"
spec:
  replicas: 1
  strategy:
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
    type: RollingUpdate
  selector:
    matchLabels:
      app: vcluster-api
      release: release-name
  template:
    metadata:
      labels:
        app: vcluster-api
        release: release-name
    spec:
      terminationGracePeriodSeconds: 10
      nodeSelector:
        {}
      affinity:
        {}
      tolerations:
        []
      automountServiceAccountToken: false
      volumes:
        - name: certs
          secret:
            secretName: release-name-certs
      containers:
      - name: kube-apiserver
        image: "public.ecr.aws/eks-distro/kubernetes/kube-apiserver:v1.24.9-eks-1-24-7"
        command:
          - kube-apiserver
          - '--advertise-address=0.0.0.0'
          - '--allow-privileged=true'
          - '--audit-log-maxage=30'
          - '--audit-log-maxbackup=10'
          - '--audit-log-maxsize=512'
          - '--cloud-provider=external'
          - '--authorization-mode=Node,RBAC'
          - '--client-ca-file=/run/config/pki/ca.crt'
          - '--enable-admission-plugins=NodeRestriction'
          - '--enable-bootstrap-token-auth=true'
          - '--etcd-cafile=/run/config/pki/etcd-ca.crt'
          - '--etcd-certfile=/run/config/pki/apiserver-etcd-client.crt'
          - '--etcd-keyfile=/run/config/pki/apiserver-etcd-client.key'
          - '--etcd-servers=https://release-name-etcd:2379'
          - '--kubelet-client-certificate=/run/config/pki/apiserver-kubelet-client.crt'
          - '--kubelet-client-key=/run/config/pki/apiserver-kubelet-client.key'
          - '--kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname'
          - '--profiling=false'
          - '--proxy-client-cert-file=/run/config/pki/front-proxy-client.crt'
          - '--proxy-client-key-file=/run/config/pki/front-proxy-client.key'
          - '--requestheader-allowed-names=front-proxy-client'
          - '--requestheader-client-ca-file=/run/config/pki/front-proxy-ca.crt'
          - '--requestheader-extra-headers-prefix=X-Remote-Extra-'
          - '--requestheader-group-headers=X-Remote-Group'
          - '--requestheader-username-headers=X-Remote-User'
          - '--secure-port=6443'
          - '--service-account-issuer=https://kubernetes.default.svc.cluster.local'
          - '--service-account-key-file=/run/config/pki/sa.pub'
          - '--service-account-signing-key-file=/run/config/pki/sa.key'
          - '--service-cluster-ip-range=$(SERVICE_CIDR)'
          - '--tls-cert-file=/run/config/pki/apiserver.crt'
          - '--tls-private-key-file=/run/config/pki/apiserver.key'
          - '--watch-cache=false'
          - '--endpoint-reconciler-type=none'
        livenessProbe:
          httpGet:
            path: /livez
            port: 6443
            scheme: HTTPS
          initialDelaySeconds: 10
          timeoutSeconds: 15
          periodSeconds: 10
          successThreshold: 1
          failureThreshold: 8
        readinessProbe:
          httpGet:
            path: /readyz
            port: 6443
            scheme: HTTPS
          timeoutSeconds: 15
          periodSeconds: 1
          successThreshold: 1
          failureThreshold: 3
        securityContext:
          {}
        env:
          - name: SERVICE_CIDR
            valueFrom:
              configMapKeyRef:
                name: "vc-cidr-release-name"
                key: cidr
        volumeMounts:
          - mountPath: /run/config/pki
            name: certs
            readOnly: true
        resources:
          requests:
            cpu: 40m
            memory: 300Mi
---
# Source: vcluster-pro-eks/templates/controller-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-controller
  namespace: default
  labels:
    app: vcluster-controller
    chart: "vcluster-pro-eks-0.2.0"
    release: "release-name"
    heritage: "Helm"
spec:
  replicas: 1
  strategy:
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
    type: RollingUpdate
  selector:
    matchLabels:
      app: vcluster-controller
      release: release-name
  template:
    metadata:
      labels:
        app: vcluster-controller
        release: release-name
    spec:
      terminationGracePeriodSeconds: 10
      nodeSelector:
        {}
      affinity:
        {}
      tolerations:
        []
      automountServiceAccountToken: false
      volumes:
        - name: certs
          secret:
            secretName: release-name-certs
      containers:
      - name: kube-controller-manager
        image: "public.ecr.aws/eks-distro/kubernetes/kube-controller-manager:v1.24.9-eks-1-24-7"
        command:
          - kube-controller-manager
          - '--authentication-kubeconfig=/run/config/pki/controller-manager.conf'
          - '--authorization-kubeconfig=/run/config/pki/controller-manager.conf'
          - '--bind-address=0.0.0.0'
          - '--client-ca-file=/run/config/pki/ca.crt'
          - '--cluster-name=kubernetes'
          - '--cluster-signing-cert-file=/run/config/pki/ca.crt'
          - '--cluster-signing-key-file=/run/config/pki/ca.key'
          - '--controllers=*,-nodeipam,-nodelifecycle,-persistentvolume-binder,-attachdetach,-persistentvolume-expander,-cloud-node-lifecycle,-ttl'
          - '--horizontal-pod-autoscaler-sync-period=60s'
          - '--kubeconfig=/run/config/pki/controller-manager.conf'
          - '--profiling=false'
          - '--service-cluster-ip-range=$(SERVICE_CIDR)'
          - '--tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256'
          - '--use-service-account-credentials=true'
          - '--leader-elect=false'
          - '--node-monitor-grace-period=180s'
          - '--node-monitor-period=30s'
          - '--pvclaimbinder-sync-period=60s'
          - '--requestheader-client-ca-file=/run/config/pki/front-proxy-ca.crt'
          - '--root-ca-file=/run/config/pki/ca.crt'
          - '--service-account-private-key-file=/run/config/pki/sa.key'
          - '--use-service-account-credentials=true'
        livenessProbe:
          httpGet:
            path: /healthz
            port: 10257
            scheme: HTTPS
          initialDelaySeconds: 10
          timeoutSeconds: 15
          periodSeconds: 10
          successThreshold: 1
          failureThreshold: 8
        startupProbe:
          httpGet:
            path: /healthz
            port: 10257
            scheme: HTTPS
          initialDelaySeconds: 10
          timeoutSeconds: 15
          periodSeconds: 10
          successThreshold: 1
          failureThreshold: 24
        securityContext:
          {}
        env:
          - name: SERVICE_CIDR
            valueFrom:
              configMapKeyRef:
                name: "vc-cidr-release-name"
                key: cidr
        volumeMounts:
          - mountPath: /run/config/pki
            name: certs
            readOnly: true
        resources:
          requests:
            cpu: 15m
---
# Source: vcluster-pro-eks/templates/syncer-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name
  namespace: default
  labels:
    app: vcluster
    chart: "vcluster-pro-eks-0.2.0"
    release: "release-name"
    heritage: "Helm"
spec:
  replicas: 1
  strategy:
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
    type: RollingUpdate
  selector:
    matchLabels:
      app: vcluster
      release: release-name
  template:
    metadata:
      labels:
        app: vcluster
        release: release-name
    spec:
      terminationGracePeriodSeconds: 10
      nodeSelector:
        {}
      affinity:
        {}
      tolerations:
        []
      serviceAccountName: vc-release-name
      volumes:
        - name: certs
          secret:
            secretName: release-name-certs
        - name: coredns
          configMap:
            name: release-name-coredns
        - name: custom-config-volume
          configMap:
            name: coredns-custom
            optional: true
      containers:
      - name: syncer
        image: "ghcr.io/loft-sh/vcluster-pro:0.2.0"
        args:
          - --name=release-name
          - --request-header-ca-cert=/pki/ca.crt
          - --client-ca-cert=/pki/ca.crt
          - --server-ca-cert=/pki/ca.crt
          - --server-ca-key=/pki/ca.key
          - --kube-config=/pki/admin.conf
          - --service-account=vc-workload-release-name                    
          - --kube-config-context-name=my-vcluster
          - --leader-elect=false          
          - --sync=-ingressclasses
        livenessProbe:
          httpGet:
            path: /healthz
            port: 8443
            scheme: HTTPS
          failureThreshold: 10
          initialDelaySeconds: 60
          periodSeconds: 2
        readinessProbe:
          httpGet:
            path: /readyz
            port: 8443
            scheme: HTTPS
          failureThreshold: 30
          periodSeconds: 2
        securityContext:
          {}
        env:
          - name: VCLUSTER_NODE_NAME
            valueFrom:
              fieldRef:
                fieldPath: spec.nodeName
          - name: CONFIG
            value: |-
              ---
          - name: VCLUSTER_TELEMETRY_CONFIG
            value: "{\"disabled\":\"false\",\"instanceCreator\":\"helm\",\"instanceCreatorUID\":\"\"}"
        volumeMounts:
          - mountPath: /manifests/coredns
            name: coredns
            readOnly: true
          - mountPath: /pki
            name: certs
            readOnly: true
        resources:
          limits:
            memory: 1Gi
          requests:
            cpu: 10m
            memory: 64Mi
---
# Source: vcluster-pro-eks/templates/etcd-statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: release-name-etcd
  namespace: default
  labels:
    app: vcluster-etcd
    chart: "vcluster-pro-eks-0.2.0"
    release: "release-name"
    heritage: "Helm"
spec:
  serviceName: release-name-etcd-headless
  replicas: 1
  podManagementPolicy: Parallel
  selector:
    matchLabels:
      app: vcluster-etcd
      release: release-name
  volumeClaimTemplates:
    - metadata:
        name: data
      spec:
        accessModes: [ "ReadWriteOnce" ]
        resources:
          requests:
            storage: 5Gi
  template:
    metadata:
      labels:
        app: vcluster-etcd
        release: release-name
    spec:
      terminationGracePeriodSeconds: 10
      nodeSelector:
        {}
      affinity:
        {}
      tolerations:
        []
      automountServiceAccountToken: false
      volumes:
        - name: certs
          secret:
            secretName: release-name-certs
      containers:
      - name: etcd
        image: "public.ecr.aws/eks-distro/etcd-io/etcd:v3.5.6-eks-1-24-7"
        command:
          - etcd
          - '--cert-file=/run/config/pki/etcd-server.crt'
          - '--client-cert-auth=true'
          - '--data-dir=/var/lib/etcd'
          - '--advertise-client-urls=https://$(NAME).release-name-etcd-headless.default:2379'
          - '--initial-advertise-peer-urls=https://$(NAME).release-name-etcd-headless.default:2380'
          - '--initial-cluster=release-name-etcd-0=https://release-name-etcd-0.release-name-etcd-headless.default:2380'
          - '--initial-cluster-token=release-name'
          - '--initial-cluster-state=new'
          - '--listen-client-urls=https://0.0.0.0:2379'
          - '--listen-metrics-urls=http://0.0.0.0:2381'
          - '--listen-peer-urls=https://0.0.0.0:2380'
          - '--key-file=/run/config/pki/etcd-server.key'
          - '--name=$(NAME)'
          - '--peer-cert-file=/run/config/pki/etcd-peer.crt'
          - '--peer-client-cert-auth=true'
          - '--peer-key-file=/run/config/pki/etcd-peer.key'
          - '--peer-trusted-ca-file=/run/config/pki/etcd-ca.crt'
          - '--snapshot-count=10000'
          - '--trusted-ca-file=/run/config/pki/etcd-ca.crt'
        securityContext:
          {}
        env:
        - name: NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        volumeMounts:
          - name: data
            mountPath: /var/lib/etcd
          - mountPath: /run/config/pki
            name: certs
            readOnly: true
        resources:
          requests:
            cpu: 20m
            memory: 150Mi
        livenessProbe:
          httpGet:
            path: /health
            port: 2381
            scheme: HTTP
          initialDelaySeconds: 10
          timeoutSeconds: 15
          periodSeconds: 10
          successThreshold: 1
          failureThreshold: 8
        startupProbe:
          httpGet:
            path: /health
            port: 2381
            scheme: HTTP
          initialDelaySeconds: 10
          timeoutSeconds: 15
          periodSeconds: 10
          successThreshold: 1
          failureThreshold: 24
---
# Source: vcluster-pro-eks/templates/pre-install-hook-job-serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: release-name-job
  namespace: default
  annotations:
    "helm.sh/hook": pre-install
    "helm.sh/hook-weight": "3"
    "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded
---
# Source: vcluster-pro-eks/templates/pre-install-hook-job-role.yaml
kind: Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: release-name-job
  namespace: default
  annotations:    
    "helm.sh/hook": pre-install
    "helm.sh/hook-weight": "3"
    "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded
rules:
  - apiGroups: [""]
    resources: ["secrets", "configmaps","services"]
    verbs: ["create", "get", "list"]
---
# Source: vcluster-pro-eks/templates/pre-install-hook-job-rolebinding.yaml
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: release-name-job
  namespace: default
  annotations:
    "helm.sh/hook": pre-install
    "helm.sh/hook-weight": "3"
    "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded
subjects:
  - kind: ServiceAccount
    name: release-name-job
    namespace: default
roleRef:
  kind: Role
  name: release-name-job
  apiGroup: rbac.authorization.k8s.io
---
# Source: vcluster-pro-eks/templates/pre-install-hook-job.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: release-name-job
  namespace: default
  annotations:
    "helm.sh/hook": pre-install
    "helm.sh/hook-weight": "3"
    "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded
spec:
  backoffLimit: 3
  template:
    metadata:
      name: release-name-job
    spec:
      serviceAccountName: release-name-job
      restartPolicy: OnFailure
      nodeSelector:
        {}
      affinity:
        {}
      tolerations:
        []
      containers:
        - name: certs
          image: "ghcr.io/loft-sh/vcluster-pro:0.2.0"
          imagePullPolicy: IfNotPresent
          command:
            - /vcluster
            - certs
          args:
            - --prefix=release-name
            - --etcd-replicas=1
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
            runAsGroup: 10001
            runAsNonRoot: true
            runAsUser: 10001
          volumeMounts:
            - name: cert-storage
              mountPath: /certs
          resources:
            {}
      volumes:
        - name: cert-storage
          emptyDir: {}
