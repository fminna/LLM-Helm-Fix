---
# Source: backend/templates/api-pdb.yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: release-name-backend-api
  labels:
    app.kubernetes.io/name: backend
    helm.sh/chart: backend-2.4.24
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    component: "api"
spec:
  maxUnavailable: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: backend
      app.kubernetes.io/instance: release-name
      component: "api"
---
# Source: backend/charts/rabbitmq/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: release-name-rabbitmq
  namespace: "default"
  labels:
    app.kubernetes.io/name: rabbitmq
    helm.sh/chart: rabbitmq-11.3.1
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
automountServiceAccountToken: true
secrets:
  - name: release-name-rabbitmq
---
# Source: backend/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: release-name-backend
  labels:
    app.kubernetes.io/name: backend
    helm.sh/chart: backend-2.4.24
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
---
# Source: backend/charts/rabbitmq/templates/config-secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: release-name-rabbitmq-config
  namespace: "default"
  labels:
    app.kubernetes.io/name: rabbitmq
    helm.sh/chart: rabbitmq-11.3.1
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
type: Opaque
data:
  rabbitmq.conf: |-
    IyMgVXNlcm5hbWUgYW5kIHBhc3N3b3JkCiMjCmRlZmF1bHRfdXNlciA9IHJhYmJpdG1xCiMjIENsdXN0ZXJpbmcKIyMKY2x1c3Rlcl9mb3JtYXRpb24ucGVlcl9kaXNjb3ZlcnlfYmFja2VuZCAgPSByYWJiaXRfcGVlcl9kaXNjb3ZlcnlfazhzCmNsdXN0ZXJfZm9ybWF0aW9uLms4cy5ob3N0ID0ga3ViZXJuZXRlcy5kZWZhdWx0CmNsdXN0ZXJfZm9ybWF0aW9uLm5vZGVfY2xlYW51cC5pbnRlcnZhbCA9IDEwCmNsdXN0ZXJfZm9ybWF0aW9uLm5vZGVfY2xlYW51cC5vbmx5X2xvZ193YXJuaW5nID0gdHJ1ZQpjbHVzdGVyX3BhcnRpdGlvbl9oYW5kbGluZyA9IGF1dG9oZWFsCiMgcXVldWUgbWFzdGVyIGxvY2F0b3IKcXVldWVfbWFzdGVyX2xvY2F0b3IgPSBtaW4tbWFzdGVycwojIGVuYWJsZSBndWVzdCB1c2VyCmxvb3BiYWNrX3VzZXJzLmd1ZXN0ID0gZmFsc2UKI2RlZmF1bHRfdmhvc3QgPSBkZWZhdWx0LXZob3N0CiNkaXNrX2ZyZWVfbGltaXQuYWJzb2x1dGUgPSA1ME1C
---
# Source: backend/charts/rabbitmq/templates/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: release-name-rabbitmq
  namespace: "default"
  labels:
    app.kubernetes.io/name: rabbitmq
    helm.sh/chart: rabbitmq-11.3.1
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
type: Opaque
data:
  rabbitmq-password: "cmFiYml0bXE="
  
  rabbitmq-erlang-cookie: "eFBIbnFid3NySjMyTlBKUVUyR1pQNTRFeXhEb2s0Qks="
---
# Source: backend/templates/api-secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: release-name-backend-api
  labels:
    app.kubernetes.io/name: backend
    helm.sh/chart: backend-2.4.24
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    component: "api"
type: Opaque
data:
  ALLOWED_HOSTS: ""
  CORS_ORIGIN_WHITELIST: ""
  CORS_ALLOW_ALL_ORIGINS: "RmFsc2U="
  SKIP_RECAPTCHA_VERIFICATION: "RmFsc2U="
  RECAPTCHA_URL: "aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS9yZWNhcHRjaGEvYXBpL3NpdGV2ZXJpZnk="
  RECAPTCHA_SECRET: ""
  RECAPTCHA_HOSTNAME: ""
  RECAPTCHA_CONTACT_ACTION: "Y29udGFjdA=="
  RECAPTCHA_CONTACT_SCORE: "MC41"
  RECAPTCHA_PROFILE_ACTION: "cHJvZmlsZQ=="
  RECAPTCHA_PROFILE_SCORE: "MC41"
---
# Source: backend/templates/common-secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: release-name-backend
  labels:
    app.kubernetes.io/name: backend
    helm.sh/chart: backend-2.4.24
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
type: Opaque
data:
  SECRET_KEY: ""
  CELERY_BROKER_URL: "YW1xcDovL3JhYmJpdG1xOnJhYmJpdG1xQHJlbGVhc2UtbmFtZS1yYWJiaXRtcTo1Njcy"
  CELERY_FLOWER_PASSWORD: ""
  DATABASE_URL: "cG9zdGdyZXM6Ly8lIXMoPG5pbD4pOiUhcyg8bmlsPilAJSFzKDxuaWw+KTolIWcoPG5pbD4pLyUhcyg8bmlsPik="
  NOTIFIERS_TELEGRAM_TOKEN: ""
  NOTIFIERS_TELEGRAM_CHAT_ID: ""
  MULTISIG_OWNERS_TELEGRAM_TOKEN: ""
  MULTISIG_OWNERS_TELEGRAM_CHAT_ID: ""
  MAILGUN_API_KEY: ""
---
# Source: backend/templates/celery-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-backend-celery
  labels:
    app.kubernetes.io/name: backend
    helm.sh/chart: backend-2.4.24
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    component: "celery"
data:
  ENVIRONMENT: "staging"
  SENTRY_DSN: ""
---
# Source: backend/templates/common-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-backend
  labels:
    app.kubernetes.io/name: backend
    helm.sh/chart: backend-2.4.24
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
data:
  ENVIRONMENT: "staging"
  CELERY_FLOWER_USER: ""
  # https://github.com/notifiers/notifiers/issues/328
  USERNAME: user
  ENABLED_NETWORKS: "goerli,perm_goerli,gnosis,mainnet,harbour_goerli,harbour_mainnet"
  SENTRY_DSN: ""
  MEMCACHED_URL: ""

  POOL_PAGE: "https://app.stakewise.io"
  SOLO_PAGE: "https://app.stakewise.io/solo"

  SEND_EMAILS: "False"
  MAILGUN_SENDER_DOMAIN: "mail.stakewise.io"
  MAILGUN_API_URL: "https://api.eu.mailgun.net/v3"
  DEFAULT_FROM_EMAIL: "\"Stakewise\" <no-reply@mail.stakewise.io>"

  MANAGERS: ""
  STATIC_URL: "https://static.stakewise.io/"
  STAKING_APR_SAMPLES_COUNT: "3"

  VALIDATOR_MAX_PENALTY_COUNT: "2"

  MAINNET_SEND_TELEGRAM_NOTIFICATIONS: "False"
  GOERLI_SEND_TELEGRAM_NOTIFICATIONS: "False"
  GNOSIS_SEND_TELEGRAM_NOTIFICATIONS: "False"
  HARBOUR_GOERLI_SEND_TELEGRAM_NOTIFICATIONS: "False"
  HARBOUR_MAINNET_SEND_TELEGRAM_NOTIFICATIONS: "False"
  MAINNET_ETH1_ENDPOINTS: ""
  MAINNET_ETH2_ENDPOINTS: ""
  MAINNET_STAKEWISE_SUBGRAPH_URLS: "https://api.thegraph.com/subgraphs/name/stakewise/stakewise-mainnet"
  MAINNET_ETHEREUM_SUBGRAPH_URLS: "https://api.thegraph.com/subgraphs/name/stakewise/ethereum-mainnet"
  MAINNET_UNISWAP_V3_SUBGRAPH_URLS: "https://api.thegraph.com/subgraphs/name/stakewise/uniswap-v3-mainnet"
  GOERLI_ETH1_ENDPOINTS: ""
  GOERLI_ETH2_ENDPOINTS: ""
  GOERLI_STAKEWISE_SUBGRAPH_URLS: "https://api.thegraph.com/subgraphs/name/stakewise/stakewise-goerli"
  GOERLI_ETHEREUM_SUBGRAPH_URLS: "https://api.thegraph.com/subgraphs/name/stakewise/ethereum-goerli"
  GOERLI_UNISWAP_V3_SUBGRAPH_URLS: "https://api.thegraph.com/subgraphs/name/stakewise/uniswap-v3-goerli"
  PERM_GOERLI_ETH1_ENDPOINTS: ""
  PERM_GOERLI_ETH2_ENDPOINTS: ""
  PERM_GOERLI_STAKEWISE_SUBGRAPH_URLS: "https://api.thegraph.com/subgraphs/name/stakewise/stakewise-perm-goerli"
  PERM_GOERLI_ETHEREUM_SUBGRAPH_URLS: "https://api.thegraph.com/subgraphs/name/stakewise/ethereum-goerli"
  GNOSIS_ETH1_ENDPOINTS: ""
  GNOSIS_ETH2_ENDPOINTS: ""
  GNOSIS_STAKEWISE_SUBGRAPH_URLS: "https://api.thegraph.com/subgraphs/name/stakewise/stakewise-gnosis"
  GNOSIS_ETHEREUM_SUBGRAPH_URLS: "https://api.thegraph.com/subgraphs/name/stakewise/ethereum-gnosis"
  HARBOUR_GOERLI_ETH1_ENDPOINTS: ""
  HARBOUR_GOERLI_ETH2_ENDPOINTS: ""
  HARBOUR_GOERLI_STAKEWISE_SUBGRAPH_URLS: "https://api.thegraph.com/subgraphs/name/stakewise/stakewise-perm-goerli"
  HARBOUR_GOERLI_ETHEREUM_SUBGRAPH_URLS: "https://api.thegraph.com/subgraphs/name/stakewise/ethereum-goerli"
  HARBOUR_MAINNET_ETH1_ENDPOINTS: ""
  HARBOUR_MAINNET_ETH2_ENDPOINTS: ""
  HARBOUR_MAINNET_STAKEWISE_SUBGRAPH_URLS: "https://api.thegraph.com/subgraphs/name/stakewise/stakewise-harbour-mainnet"
  HARBOUR_MAINNET_ETHEREUM_SUBGRAPH_URLS: "https://api.thegraph.com/subgraphs/name/stakewise/ethereum-mainnet"
---
# Source: backend/charts/rabbitmq/templates/role.yaml
kind: Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: release-name-rabbitmq-endpoint-reader
  namespace: "default"
  labels:
    app.kubernetes.io/name: rabbitmq
    helm.sh/chart: rabbitmq-11.3.1
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
rules:
  - apiGroups: [""]
    resources: ["endpoints"]
    verbs: ["get"]
  - apiGroups: [""]
    resources: ["events"]
    verbs: ["create"]
---
# Source: backend/charts/rabbitmq/templates/rolebinding.yaml
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: release-name-rabbitmq-endpoint-reader
  namespace: "default"
  labels:
    app.kubernetes.io/name: rabbitmq
    helm.sh/chart: rabbitmq-11.3.1
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
subjects:
  - kind: ServiceAccount
    name: release-name-rabbitmq
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: release-name-rabbitmq-endpoint-reader
---
# Source: backend/charts/memcached/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-memcached
  namespace: default
  labels:
    app.kubernetes.io/name: memcached
    helm.sh/chart: memcached-6.3.3
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
  annotations:
spec:
  type: ClusterIP
  sessionAffinity: None
  ports:
    - name: memcache
      port: 11211
      targetPort: memcache
      nodePort: null
  selector:
    app.kubernetes.io/name: memcached
    app.kubernetes.io/instance: release-name
---
# Source: backend/charts/rabbitmq/templates/svc-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-rabbitmq-headless
  namespace: "default"
  labels:
    app.kubernetes.io/name: rabbitmq
    helm.sh/chart: rabbitmq-11.3.1
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
spec:
  clusterIP: None
  ports:
    - name: epmd
      port: 4369
      targetPort: epmd
    - name: amqp
      port: 5672
      targetPort: amqp
    - name: dist
      port: 25672
      targetPort: dist
    - name: http-stats
      port: 15672
      targetPort: stats
  selector: 
    app.kubernetes.io/name: rabbitmq
    app.kubernetes.io/instance: release-name
  publishNotReadyAddresses: true
---
# Source: backend/charts/rabbitmq/templates/svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-rabbitmq
  namespace: "default"
  labels:
    app.kubernetes.io/name: rabbitmq
    helm.sh/chart: rabbitmq-11.3.1
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  sessionAffinity: None
  ports:
    - name: amqp
      port: 5672
      targetPort: amqp
      nodePort: null
    - name: epmd
      port: 4369
      targetPort: epmd
      nodePort: null
    - name: dist
      port: 25672
      targetPort: dist
      nodePort: null
    - name: http-stats
      port: 15672
      targetPort: stats
      nodePort: null
  selector: 
    app.kubernetes.io/name: rabbitmq
    app.kubernetes.io/instance: release-name
---
# Source: backend/templates/admin-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-backend-admin
  labels:
    app.kubernetes.io/name: backend
    helm.sh/chart: backend-2.4.24
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    component: "admin"
spec:
  type: ClusterIP
  ports:
    - name: http
      port: 8000
      protocol: TCP
      targetPort: http
  selector:
    app.kubernetes.io/name: backend
    app.kubernetes.io/instance: release-name
    component: "admin"
---
# Source: backend/templates/api-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-backend-api
  labels:
    app.kubernetes.io/name: backend
    helm.sh/chart: backend-2.4.24
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    component: "api"
spec:
  type: ClusterIP
  ports:
    - name: http
      port: 8000
      protocol: TCP
      targetPort: http
  selector:
    app.kubernetes.io/name: backend
    app.kubernetes.io/instance: release-name
    component: "api"
---
# Source: backend/templates/celery-flower-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-backend-celery-flower
  labels:
    app.kubernetes.io/name: backend
    helm.sh/chart: backend-2.4.24
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    component: "celery-flower"
spec:
  type: ClusterIP
  ports:
    - name: http
      port: 5555
      protocol: TCP
      targetPort: http
  selector:
    app.kubernetes.io/name: backend
    app.kubernetes.io/instance: release-name
    component: "celery-flower"
---
# Source: backend/charts/memcached/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-memcached
  namespace: default
  labels:
    app.kubernetes.io/name: memcached
    helm.sh/chart: memcached-6.3.3
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: memcached
      app.kubernetes.io/instance: release-name
  replicas: 1
  strategy:
    rollingUpdate: {}
    type: RollingUpdate
  template:
    metadata:
      labels:
        app.kubernetes.io/name: memcached
        helm.sh/chart: memcached-6.3.3
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/managed-by: Helm
      annotations:
    spec:
      
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: memcached
                    app.kubernetes.io/instance: release-name
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      securityContext:
        fsGroup: 1001
      serviceAccountName: default
      containers:
        - name: memcached
          image: docker.io/bitnami/memcached:1.6.17-debian-11-r35
          imagePullPolicy: "IfNotPresent"
          securityContext:
            runAsNonRoot: true
            runAsUser: 1001
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: MEMCACHED_PORT_NUMBER
              value: "11211"
          ports:
            - name: memcache
              containerPort: 11211
          livenessProbe:
            failureThreshold: 6
            initialDelaySeconds: 30
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            tcpSocket:
              port: memcache
          readinessProbe:
            failureThreshold: 6
            initialDelaySeconds: 5
            periodSeconds: 5
            successThreshold: 1
            timeoutSeconds: 3
            tcpSocket:
              port: memcache
          resources:
            limits: {}
            requests:
              cpu: 250m
              memory: 256Mi
          volumeMounts:
            - name: tmp
              mountPath: /tmp
      volumes:
        - name: tmp
          emptyDir: {}
---
# Source: backend/templates/admin-deployment.yaml
kind: Deployment
apiVersion: apps/v1
metadata:
  name: release-name-backend-admin
  labels:
    app.kubernetes.io/name: backend
    helm.sh/chart: backend-2.4.24
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    component: "admin"
spec:
  replicas: 1
  minReadySeconds: 15
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  selector:
    matchLabels:
      app.kubernetes.io/name: backend
      app.kubernetes.io/instance: release-name
      component: "admin"
  template:
    metadata:
      labels:
        app.kubernetes.io/name: backend
        app.kubernetes.io/instance: release-name
        component: "admin"
      annotations:
        checksum/common-secret: 3ce1c6967b23e973236682ca11d5ea9bf7d9742bc77dba6e99c50d9e1d31b890
        checksum/common-configmap: d56074dc25dd3907436299da8c2ff105036c093723f830e923db9e3ef1582142
        checksum/admin-secret: 01ba4719c80b6fe911b091a7c05124b64eeece964e09c058ef8f9805daca546b
    spec:
      securityContext:
        
        fsGroup: 65534
        runAsUser: 65534
      serviceAccountName: release-name-backend
      priorityClassName: ""
      initContainers:
        - name: initdb
          image: "europe-west4-docker.pkg.dev/stakewiselabs/private/backend:v2.4.23"
          imagePullPolicy: IfNotPresent
          command: ["python", "manage.py", "migrate", "--no-input"]
          envFrom:
            - secretRef:
                name: release-name-backend
            - configMapRef:
                name: release-name-backend
          env:
            - name: DJANGO_SETTINGS_MODULE
              value: "config.settings.admin_settings"
            - name: ALLOWED_HOSTS
              value: ""
      containers:
        - name: backend
          image: "europe-west4-docker.pkg.dev/stakewiselabs/private/backend:v2.4.23"
          imagePullPolicy: IfNotPresent
          envFrom:
            - configMapRef:
                name: release-name-backend
            - secretRef:
                name: release-name-backend
          env:
            - name: DJANGO_SETTINGS_MODULE
              value: "config.settings.admin_settings"
            - name: ALLOWED_HOSTS
              value: ""
          ports:
            - name: http
              containerPort: 8000
              protocol: TCP
          resources:
            limits:
              cpu: 300m
              memory: 1024Mi
            requests:
              cpu: 100m
              memory: 512Mi
          livenessProbe:
            httpGet:
              path: "/admin/login/"
              port: http
            initialDelaySeconds: 15
            timeoutSeconds: 30
            failureThreshold: 5
            periodSeconds: 60
          readinessProbe:
            httpGet:
              path: "/admin/login/"
              port: http
            initialDelaySeconds: 15
            timeoutSeconds: 30
            failureThreshold: 5
            periodSeconds: 60
---
# Source: backend/templates/api-deployment.yaml
kind: Deployment
apiVersion: apps/v1
metadata:
  name: release-name-backend-api
  labels:
    app.kubernetes.io/name: backend
    helm.sh/chart: backend-2.4.24
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    component: "api"
spec:
  replicas: 2
  minReadySeconds: 15
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  selector:
    matchLabels:
      app.kubernetes.io/name: backend
      app.kubernetes.io/instance: release-name
      component: "api"
  template:
    metadata:
      labels:
        app.kubernetes.io/name: backend
        app.kubernetes.io/instance: release-name
        component: "api"
      annotations:
        checksum/common-secret: 3ce1c6967b23e973236682ca11d5ea9bf7d9742bc77dba6e99c50d9e1d31b890
        checksum/common-configmap: d56074dc25dd3907436299da8c2ff105036c093723f830e923db9e3ef1582142
        checksum/api-secret: 24bb50a4c478a1a3841476581f94f5e974913ad8ed9ae8ffe45bc6d9fcc164a6
    spec:
      securityContext:
        
        fsGroup: 65534
        runAsUser: 65534
      serviceAccountName: release-name-backend
      priorityClassName: ""
      initContainers:
        - name: migrate-db
          image: "europe-west4-docker.pkg.dev/stakewiselabs/private/backend:v2.4.23"
          imagePullPolicy: IfNotPresent
          command: ["python", "manage.py", "migrate", "--no-input"]
          envFrom:
            - secretRef:
                name: release-name-backend
            - configMapRef:
                name: release-name-backend
            - secretRef:
                name: release-name-backend-api
          env:
            - name: DJANGO_SETTINGS_MODULE
              value: "config.settings.api_settings"
      containers:
        - name: backend
          image: "europe-west4-docker.pkg.dev/stakewiselabs/private/backend:v2.4.23"
          imagePullPolicy: IfNotPresent
          envFrom:
            - secretRef:
                name: release-name-backend
            - configMapRef:
                name: release-name-backend
            - secretRef:
                name: release-name-backend-api
          env:
            - name: DJANGO_SETTINGS_MODULE
              value: "config.settings.api_settings"
          resources:
            limits:
              cpu: 1000m
              memory: 1024Mi
            requests:
              cpu: 100m
              memory: 512Mi
          ports:
            - name: http
              containerPort: 8000
              protocol: TCP
          livenessProbe:
            httpGet:
              path: /healthz/
              port: http
              httpHeaders:
                - name: Host
                  value: "api.stakewise.io"
            initialDelaySeconds: 15
            timeoutSeconds: 30
            failureThreshold: 5
            periodSeconds: 60
          readinessProbe:
            httpGet:
              path: /healthz/
              port: http
              httpHeaders:
                - name: Host
                  value: "api.stakewise.io"
            initialDelaySeconds: 15
            timeoutSeconds: 30
            failureThreshold: 5
            periodSeconds: 60
---
# Source: backend/templates/celery-beat.yaml
kind: Deployment
apiVersion: apps/v1
metadata:
  name: release-name-backend-celery-beat
  labels:
    app.kubernetes.io/name: backend
    helm.sh/chart: backend-2.4.24
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    component: "celery-beat"
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: backend
      app.kubernetes.io/instance: release-name
      component: "celery-beat"
  template:
    metadata:
      labels:
        app.kubernetes.io/name: backend
        app.kubernetes.io/instance: release-name
        component: "celery-beat"
      annotations:
        checksum/common-secret: 3ce1c6967b23e973236682ca11d5ea9bf7d9742bc77dba6e99c50d9e1d31b890
        checksum/common-configmap: d56074dc25dd3907436299da8c2ff105036c093723f830e923db9e3ef1582142
        checksum/celery-configmap: ed75fb71ee5b56eeaa77834bd6e01a94d0123171fb3f4e6aefa2fe5b52947815
    spec:
      securityContext:
        
        fsGroup: 65534
        runAsUser: 65534
      serviceAccountName: release-name-backend
      priorityClassName: ""
      containers:
        - name: backend
          image: "europe-west4-docker.pkg.dev/stakewiselabs/private/backend:v2.4.23"
          imagePullPolicy: IfNotPresent
          command: ["/start-celerybeat"]
          envFrom:
            - secretRef:
                name: release-name-backend
            - configMapRef:
                name: release-name-backend
            - configMapRef:
                name: release-name-backend-celery
          env:
            - name: DJANGO_SETTINGS_MODULE
              value: "config.settings.celery_settings"
          resources:
            limits:
              cpu: 250m
              memory: 512Mi
            requests:
              cpu: 50m
              memory: 256Mi
---
# Source: backend/templates/celery-flower.yaml
kind: Deployment
apiVersion: apps/v1
metadata:
  name: release-name-backend-celery-flower
  labels:
    app.kubernetes.io/name: backend
    helm.sh/chart: backend-2.4.24
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    component: "celery-flower"
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: backend
      app.kubernetes.io/instance: release-name
      component: "celery-flower"
  template:
    metadata:
      labels:
        app.kubernetes.io/name: backend
        app.kubernetes.io/instance: release-name
        component: "celery-flower"
      annotations:
        checksum/common-secret: 3ce1c6967b23e973236682ca11d5ea9bf7d9742bc77dba6e99c50d9e1d31b890
        checksum/common-configmap: d56074dc25dd3907436299da8c2ff105036c093723f830e923db9e3ef1582142
        checksum/celery-configmap: ed75fb71ee5b56eeaa77834bd6e01a94d0123171fb3f4e6aefa2fe5b52947815
    spec:
      securityContext:
        
        fsGroup: 65534
        runAsUser: 65534
      serviceAccountName: release-name-backend
      priorityClassName: ""
      containers:
        - name: backend
          image: "europe-west4-docker.pkg.dev/stakewiselabs/private/backend:v2.4.23"
          imagePullPolicy: IfNotPresent
          command: ["/start-flower"]
          envFrom:
            - secretRef:
                name: release-name-backend
            - configMapRef:
                name: release-name-backend
            - configMapRef:
                name: release-name-backend-celery
          ports:
            - name: http
              containerPort: 5555
              protocol: TCP
          resources:
            limits:
              cpu: 250m
              memory: 512Mi
            requests:
              cpu: 50m
              memory: 256Mi
---
# Source: backend/templates/celery-worker.yaml
kind: Deployment
apiVersion: apps/v1
metadata:
  name: release-name-backend-celery-worker
  labels:
    app.kubernetes.io/name: backend
    helm.sh/chart: backend-2.4.24
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    component: "celery-worker"
spec:
  replicas: 3
  selector:
    matchLabels:
      app.kubernetes.io/name: backend
      app.kubernetes.io/instance: release-name
      component: "celery-worker"
  template:
    metadata:
      labels:
        app.kubernetes.io/name: backend
        app.kubernetes.io/instance: release-name
        component: "celery-worker"
      annotations:
        checksum/common-secret: 3ce1c6967b23e973236682ca11d5ea9bf7d9742bc77dba6e99c50d9e1d31b890
        checksum/common-configmap: d56074dc25dd3907436299da8c2ff105036c093723f830e923db9e3ef1582142
        checksum/celery-configmap: ed75fb71ee5b56eeaa77834bd6e01a94d0123171fb3f4e6aefa2fe5b52947815
    spec:
      securityContext:
        
        fsGroup: 65534
        runAsUser: 65534
      serviceAccountName: release-name-backend
      priorityClassName: ""
      containers:
        - name: backend
          image: "europe-west4-docker.pkg.dev/stakewiselabs/private/backend:v2.4.23"
          imagePullPolicy: IfNotPresent
          command: ["/start-celeryworker"]
          envFrom:
            - secretRef:
                name: release-name-backend
            - configMapRef:
                name: release-name-backend
            - configMapRef:
                name: release-name-backend-celery
          env:
            - name: DJANGO_SETTINGS_MODULE
              value: "config.settings.celery_settings"
          resources:
            limits:
              cpu: 1000m
              memory: 1024Mi
            requests:
              cpu: 1000m
              memory: 512Mi
---
# Source: backend/charts/rabbitmq/templates/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: release-name-rabbitmq
  namespace: "default"
  labels:
    app.kubernetes.io/name: rabbitmq
    helm.sh/chart: rabbitmq-11.3.1
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
spec:
  serviceName: release-name-rabbitmq-headless
  podManagementPolicy: OrderedReady
  replicas: 1
  updateStrategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/name: rabbitmq
      app.kubernetes.io/instance: release-name
  template:
    metadata:
      labels:
        app.kubernetes.io/name: rabbitmq
        helm.sh/chart: rabbitmq-11.3.1
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/managed-by: Helm
      annotations:
        checksum/config: 8f6457b5883be5ccb22aec2f5bc8fb530a5d7a0cb4eecd70816a9ecac37b773c
        checksum/secret: bb9398020ca3248ff39c451d6705e1262398258f20b7fc03a77aa0ff29fcd038
    spec:
      
      serviceAccountName: release-name-rabbitmq
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: rabbitmq
                    app.kubernetes.io/instance: release-name
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      securityContext:
        fsGroup: 1001
      terminationGracePeriodSeconds: 120
      initContainers:
      containers:
        - name: rabbitmq
          image: docker.io/bitnami/rabbitmq:3.11.6-debian-11-r0
          imagePullPolicy: "IfNotPresent"
          securityContext:
            runAsNonRoot: true
            runAsUser: 1001
          lifecycle:
            preStop:
              exec:
                command:
                  - /bin/bash
                  - -ec
                  - |
                    if [[ -f /opt/bitnami/scripts/rabbitmq/nodeshutdown.sh ]]; then
                        /opt/bitnami/scripts/rabbitmq/nodeshutdown.sh -t "120" -d "false"
                    else
                        rabbitmqctl stop_app
                    fi
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: MY_POD_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
            - name: MY_POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: MY_POD_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: K8S_SERVICE_NAME
              value: release-name-rabbitmq-headless
            - name: K8S_ADDRESS_TYPE
              value: hostname
            - name: RABBITMQ_FORCE_BOOT
              value: "no"
            - name: RABBITMQ_NODE_NAME
              value: "rabbit@$(MY_POD_NAME).$(K8S_SERVICE_NAME).$(MY_POD_NAMESPACE).svc.cluster.local"
            - name: K8S_HOSTNAME_SUFFIX
              value: ".$(K8S_SERVICE_NAME).$(MY_POD_NAMESPACE).svc.cluster.local"
            - name: RABBITMQ_MNESIA_DIR
              value: "/bitnami/rabbitmq/mnesia/$(RABBITMQ_NODE_NAME)"
            - name: RABBITMQ_LDAP_ENABLE
              value: "no"
            - name: RABBITMQ_LOGS
              value: "-"
            - name: RABBITMQ_ULIMIT_NOFILES
              value: "65536"
            - name: RABBITMQ_USE_LONGNAME
              value: "true"
            - name: RABBITMQ_ERL_COOKIE
              valueFrom:
                secretKeyRef:
                  name: release-name-rabbitmq
                  key: rabbitmq-erlang-cookie
            - name: RABBITMQ_LOAD_DEFINITIONS
              value: "no"
            - name: RABBITMQ_DEFINITIONS_FILE
              value: "/app/load_definition.json"
            - name: RABBITMQ_SECURE_PASSWORD
              value: "yes"
            - name: RABBITMQ_USERNAME
              value: "rabbitmq"
            - name: RABBITMQ_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: release-name-rabbitmq
                  key: rabbitmq-password
            - name: RABBITMQ_PLUGINS
              value: "rabbitmq_management, rabbitmq_peer_discovery_k8s, rabbitmq_auth_backend_ldap"
          envFrom:
          ports:
            - name: amqp
              containerPort: 5672
            - name: dist
              containerPort: 25672
            - name: stats
              containerPort: 15672
            - name: epmd
              containerPort: 4369
          livenessProbe:
            failureThreshold: 6
            initialDelaySeconds: 120
            periodSeconds: 30
            successThreshold: 1
            timeoutSeconds: 20
            exec:
              command:
                - /bin/bash
                - -ec
                - rabbitmq-diagnostics -q ping
          readinessProbe:
            failureThreshold: 3
            initialDelaySeconds: 10
            periodSeconds: 30
            successThreshold: 1
            timeoutSeconds: 20
            exec:
              command:
                - /bin/bash
                - -ec
                - rabbitmq-diagnostics -q check_running && rabbitmq-diagnostics -q check_local_alarms
          resources:
            limits: {}
            requests: {}
          volumeMounts:
            - name: configuration
              mountPath: /bitnami/rabbitmq/conf
            - name: data
              mountPath: /bitnami/rabbitmq/mnesia
      volumes:
        - name: configuration
          projected:
            sources:
              - secret:
                  name: release-name-rabbitmq-config
        - name: data
          emptyDir: {}
---
# Source: backend/templates/api-ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: release-name-backend-api
  labels:
    app.kubernetes.io/name: backend
    helm.sh/chart: backend-2.4.24
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    component: "api"
spec:
  rules:
---
# Source: backend/templates/celery-flower-ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: release-name-backend-celery-flower
  labels:
    app.kubernetes.io/name: backend
    helm.sh/chart: backend-2.4.24
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    component: "celery-flower"
spec:
  rules:
