---
# Source: kube-gcp/templates/clusterrole.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: kube-gcp-chaos-admin
  labels:    
    app.kubernetes.io/component: kube-gcp
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: kube-gcp
    app.kubernetes.io/part-of: kube-gcp 
    app.kubernetes.io/version: "3.6.0"
    helm.sh/chart: kube-gcp-3.6.0 
    litmuschaos.io/version: 3.6.0
rules:
- apiGroups:
  - ""
  - "apps"
  - "batch"
  - "extensions"
  - "litmuschaos.io"
  resources:
  - "jobs"
  - "pods"
  - "pods/exec"
  - "pods/log"
  - "pods/eviction"
  - "daemonsets"
  - "replicasets"
  - "deployments"
  - "statefulsets"
  - "services"
  - "events"
  - "configmaps"
  - "secrets"
  - "chaosengines"
  - "chaosexperiments"
  - "chaosresults"
  verbs:
  - "create"
  - "delete"
  - "get"
  - "list"
  - "patch"
  - "update"
  - "deletecollection"
- apiGroups:
  - ""
  resources:
  - "nodes"
  verbs:
  - "get"
  - "list"
  - "patch"
  - "update"
---
# Source: kube-gcp/templates/clusterrolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: kube-gcp-chaos-admin 
  labels:    
    app.kubernetes.io/component: kube-gcp
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: kube-gcp
    app.kubernetes.io/part-of: kube-gcp 
    app.kubernetes.io/version: "3.6.0"
    helm.sh/chart: kube-gcp-3.6.0 
    litmuschaos.io/version: 3.6.0
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: kube-gcp-chaos-admin
subjects:
- kind: ServiceAccount
  name: kube-gcp-chaos-admin
  namespace: default
---
# Source: kube-gcp/templates/gcp-vm-disk-loss.yaml
apiVersion: litmuschaos.io/v1alpha1
description:
  message: |
    Causes loss of a non-boot storage persistent disk from a GCP VM instance for a specified duration of time 
kind: ChaosExperiment
metadata:
  name: gcp-vm-disk-loss
  labels:    
    app.kubernetes.io/component: kube-gcp
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: kube-gcp
    app.kubernetes.io/part-of: kube-gcp 
    app.kubernetes.io/version: "3.6.0"
    helm.sh/chart: kube-gcp-3.6.0 
    litmuschaos.io/version: 3.6.0
spec:
  definition:
    scope: Cluster
    permissions:
      # Create and monitor the experiment & helper pods
      - apiGroups: [""]
        resources: ["pods"]
        verbs: ["create","delete","get","list","patch","update", "deletecollection"]
      # Performs CRUD operations on the events inside chaosengine and chaosresult
      - apiGroups: [""]
        resources: ["events"]
        verbs: ["create","get","list","patch","update"]
      # Fetch configmaps & secrets details and mount it to the experiment pod (if specified)
      - apiGroups: [""]
        resources: ["secrets","configmaps"]
        verbs: ["get","list",]
      # Track and get the runner, experiment, and helper pods log 
      - apiGroups: [""]
        resources: ["pods/log"]
        verbs: ["get","list","watch"]  
      # for creating and managing to execute comands inside target container
      - apiGroups: [""]
        resources: ["pods/exec"]
        verbs: ["get","list","create"]
      # for configuring and monitor the experiment job by the chaos-runner pod
      - apiGroups: ["batch"]
        resources: ["jobs"]
        verbs: ["create","list","get","delete","deletecollection"]
      # for creation, status polling and deletion of litmus chaos resources used within a chaos workflow
      - apiGroups: ["litmuschaos.io"]
        resources: ["chaosengines","chaosexperiments","chaosresults"]
        verbs: ["create","list","get","patch","update","delete"]
    image: "litmuschaos.docker.scarf.sh/litmuschaos/go-runner:3.6.0"
    imagePullPolicy: Always
    args:
    - -c
    - ./experiments -name gcp-vm-disk-loss
    command:
    - /bin/bash
    env:

    - name: TOTAL_CHAOS_DURATION
      value: '30' 

    - name: CHAOS_INTERVAL
      value: '30'

    - name: LIB
      value: 'litmus'
    
    # Period to wait before and after injection of chaos in sec
    - name: RAMP_TIME
      value: ''

    # parallel or serial; determines how chaos is injected
    - name: SEQUENCE
      value: 'parallel'

    # set the GCP project id
    - name: GCP_PROJECT_ID
      value: ''

    # set the disk volume name(s) as comma seperated values 
    # eg. volume1,volume2,...
    - name: DISK_VOLUME_NAMES
      value: ''
              
    # set the disk zone(s) as comma seperated values in the corresponding 
    # order of DISK_VOLUME_NAME  
    # eg. zone1,zone2,...
    - name: ZONES
      value: ''
            
    # set the device name(s) as comma seperated values in the corresponding 
    # order of DISK_VOLUME_NAME 
    # eg. device1,device2,...
    - name: DEVICE_NAMES
      value: ''
      
    labels:
      name: gcp-vm-disk-loss      
      app.kubernetes.io/component: kube-gcp
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: kube-gcp
      app.kubernetes.io/part-of: kube-gcp 
      app.kubernetes.io/version: "3.6.0"
      helm.sh/chart: kube-gcp-3.6.0 
      litmuschaos.io/version: 3.6.0
    secrets:
    - name: cloud-secret
      mountPath: /tmp/
---
# Source: kube-gcp/templates/gcp-vm-instance-stop.yaml
apiVersion: litmuschaos.io/v1alpha1
description:
  message: |
    Stops GCP VM instances and GKE nodes for a specified duration of time and later restarts them
kind: ChaosExperiment
metadata:
  name: gcp-vm-instance-stop
  labels:      
      app.kubernetes.io/component: kube-gcp
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: kube-gcp
      app.kubernetes.io/part-of: kube-gcp 
      app.kubernetes.io/version: "3.6.0"
      helm.sh/chart: kube-gcp-3.6.0 
      litmuschaos.io/version: 3.6.0
spec:
  definition:
    scope: Cluster
    permissions:
      # Create and monitor the experiment & helper pods
      - apiGroups: [""]
        resources: ["pods"]
        verbs: ["create","delete","get","list","patch","update", "deletecollection"]
      # Performs CRUD operations on the events inside chaosengine and chaosresult
      - apiGroups: [""]
        resources: ["events"]
        verbs: ["create","get","list","patch","update"]
      # Fetch configmaps & secrets details and mount it to the experiment pod (if specified)
      - apiGroups: [""]
        resources: ["secrets","configmaps"]
        verbs: ["get","list",]
      # Track and get the runner, experiment, and helper pods log 
      - apiGroups: [""]
        resources: ["pods/log"]
        verbs: ["get","list","watch"]  
      # for creating and managing to execute comands inside target container
      - apiGroups: [""]
        resources: ["pods/exec"]
        verbs: ["get","list","create"]
      # for configuring and monitor the experiment job by the chaos-runner pod
      - apiGroups: ["batch"]
        resources: ["jobs"]
        verbs: ["create","list","get","delete","deletecollection"]
      # for creation, status polling and deletion of litmus chaos resources used within a chaos workflow
      - apiGroups: ["litmuschaos.io"]
        resources: ["chaosengines","chaosexperiments","chaosresults"]
        verbs: ["create","list","get","patch","update","delete"]
      # for experiment to perform node status checks
      - apiGroups: [""]
        resources: ["nodes"]
        verbs: ["get","list"]
    image: "litmuschaos.docker.scarf.sh/litmuschaos/go-runner:3.6.0"
    imagePullPolicy: Always
    args:
    - -c
    - ./experiments -name gcp-vm-instance-stop
    command:
    - /bin/bash
    env:

    - name: TOTAL_CHAOS_DURATION
      value: '30' 

    - name: CHAOS_INTERVAL
      value: '30'

    # parallel or serial; determines how the VM instances are terminated, all at once or one at a time  
    - name: SEQUENCE
      value: 'parallel'

    # provide the LIB
    # only litmus supported
    - name: LIB
      value: 'litmus'

    # period to wait before and after injection of chaos in sec
    - name: RAMP_TIME
      value: ''

    # enable or disable; shall be enabled if the target instance is a part of an auto scaling group.
    - name: AUTO_SCALING_GROUP
      value: 'disable'
    
    # Instance name of the target vm instance(s)
    # Multiple instance names can be provided as comma separated values ex: instance1,instance2
    - name: VM_INSTANCE_NAMES
      value: ''
    
    # GCP project ID to which the vm instances belong
    - name: GCP_PROJECT_ID
      value: ''

    # Instance zone(s) of the target vm instance(s)
    # If more than one instance is targetted, provide zone for each in the order of their 
    # respective instance name in VM_INSTANCE_NAME as comma separated values ex: zone1,zone2
    - name: ZONES
      value: ''
      
    labels:
      name: gcp-vm-instance-stop      
      app.kubernetes.io/component: kube-gcp
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/managed-by: Helm
      app.kubernetes.io/name: kube-gcp
      app.kubernetes.io/part-of: kube-gcp 
      app.kubernetes.io/version: "3.6.0"
      helm.sh/chart: kube-gcp-3.6.0 
      litmuschaos.io/version: 3.6.0
    secrets:
    - name: cloud-secret
      mountPath: /tmp/
