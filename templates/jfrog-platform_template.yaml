---
# Source: jfrog-platform/charts/xray/templates/xray-resourcequota.yaml
apiVersion: v1
kind: ResourceQuota
metadata:
  labels:
    app: xray
    chart: xray-103.94.6
    release: "release-name"
    heritage: "Helm"
  name: release-name-xray
spec:
  hard:
    count/jobs.batch: 100
---
# Source: jfrog-platform/charts/artifactory/templates/nginx-pdb.yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: release-name-artifactory-nginx
  labels:
    app: artifactory
    chart: artifactory-107.84.10
    component: nginx
    heritage: Helm
    release: release-name
spec:
  selector:
    matchLabels:
      component: nginx
      app: artifactory
      release: release-name
  minAvailable: 0
---
# Source: jfrog-platform/charts/rabbitmq/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: release-name-rabbitmq
  namespace: "default"
  labels:
    app.kubernetes.io/name: rabbitmq
    helm.sh/chart: rabbitmq-11.9.3
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
automountServiceAccountToken: true
secrets:
  - name: release-name-rabbitmq
---
# Source: jfrog-platform/charts/artifactory/templates/artifactory-unified-secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: artifactory-unified-secret
  labels:
    app: "artifactory"
    chart: "artifactory-107.84.10"
    component: "artifactory"
    heritage: "Helm"
    release: "release-name"
type: Opaque
stringData:
  access.config.patch.yml: |
    security:
      tls: false
  binarystore.xml: |-
    <!-- File system filestore -->
    <config version="v1">
        <chain> <!--template="file-system"-->
                <provider id="file-system" type="file-system"/>
        </chain>
    </config>
  system.yaml: |

    access:
      database:
        maxOpenConnections: 80
      tomcat:
        connector:
          extraConfig: acceptCount="100"
          maxThreads: 50
          sendReasonPhrase: false
    artifactory:
      database:
        maxOpenConnections: 80
      tomcat:
        connector:
          extraConfig: acceptCount="400"
          maxThreads: 200
          sendReasonPhrase: false
        maintenanceConnector:
          port: 8091
    federation:
      enabled: false
    frontend:
      session:
        timeMinutes: "30"
    jfconnect:
      enabled: true
    mc:
      database:
        maxOpenConnections: 10
      enabled: true
      idgenerator:
        maxOpenConnections: 2
      tomcat:
        connector:
          extraConfig: acceptCount="100"
          maxThreads: 50
          sendReasonPhrase: false
    metadata:
      database:
        maxOpenConnections: 80
    router:
      serviceRegistry:
        insecure: false
    shared:
      database:
        allowNonPostgresql: false
        driver: org.postgresql.Driver
        type: postgresql
      extraJavaOpts: |
        -Dartifactory.graceful.shutdown.max.request.duration.millis=30000 -Dartifactory.access.client.max.connections=50
      logging:
        consoleLog:
          enabled: false

data:
  db-url: "amRiYzpwb3N0Z3Jlc3FsOi8vcmVsZWFzZS1uYW1lLXBvc3RncmVzcWw6NTQzMi9hcnRpZmFjdG9yeT9zc2xtb2RlPWRpc2FibGU="
  db-user: "YXJ0aWZhY3Rvcnk="
  db-password: "YXJ0aWZhY3Rvcnk="
  master-key: "YmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYg=="
  join-key: "RUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUU="
---
# Source: jfrog-platform/charts/artifactory/templates/nginx-certificate-secret.yaml
apiVersion: v1
kind: Secret
type: kubernetes.io/tls
metadata:
  name: release-name-artifactory-nginx-certificate
  labels:
    app: artifactory
    chart: artifactory-107.84.10
    heritage: Helm
    release: release-name
data:
  tls.crt: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURmRENDQW1TZ0F3SUJBZ0lSQUxZaUo2bDc2bW45YUwyZ0xMbHlOcWd3RFFZSktvWklodmNOQVFFTEJRQXcKR1RFWE1CVUdBMVVFQXhNT1lYSjBhV1poWTNSdmNua3RZMkV3SGhjTk1qUXdOVEUxTURrMU1UTTBXaGNOTWpVdwpOVEUxTURrMU1UTTBXakFqTVNFd0h3WURWUVFERXhoeVpXeGxZWE5sTFc1aGJXVXRZWEowYVdaaFkzUnZjbmt3CmdnRWlNQTBHQ1NxR1NJYjNEUUVCQVFVQUE0SUJEd0F3Z2dFS0FvSUJBUURBeDFZbmNGbFRsZ0hGQUJQWWlRcm0KMFh6RktlWFVNdXdsMlY3ckEreWtCT1k0VVpiVWtPNUpNa2JOU0tRTXdtRUhlK2pZT3dEL1A4ZW15QnBObXZpTwp1SGMyL0pTbXhkZVpnTmFTR09SZFcxYkFuRHdHclVCeVNHS1MxUU5zaUxzbktGQzZaV1RGWmpFcVp3MXBBaWhhCnpSODJJMFUrV0ZWZ3E2a0dTODhBNVdSM05BUmRXb2t3WFJ5TTVNS3Vla2RyY0VMTHgvR09rWTRCT0ZZNEpiRW8KTUIxTEtmaldxcWZJcjRzK3NOb216WUZoZmVFNXNzcTUxK2JsZ0RRYjc1VDNJS1lTa1poTHhPZ3BxbnBIVnNsYwpQbkdzb0FXVmNKZFZ5RlhWMU9kd0habFJiaEhqVTRvd2FMaHRldENzZ0NmeTNWcm1nNk53eWJQS0hrQWovWW5SCkFnTUJBQUdqZ2JRd2diRXdEZ1lEVlIwUEFRSC9CQVFEQWdXZ01CMEdBMVVkSlFRV01CUUdDQ3NHQVFVRkJ3TUIKQmdnckJnRUZCUWNEQWpBTUJnTlZIUk1CQWY4RUFqQUFNQjhHQTFVZEl3UVlNQmFBRkREenIyYWx2QzQ0ZHhkegptUHVXc0lRVDREeHhNRkVHQTFVZEVRUktNRWlDSUhKbGJHVmhjMlV0Ym1GdFpTMWhjblJwWm1GamRHOXllUzVrClpXWmhkV3gwZ2lSeVpXeGxZWE5sTFc1aGJXVXRZWEowYVdaaFkzUnZjbmt1WkdWbVlYVnNkQzV6ZG1Nd0RRWUoKS29aSWh2Y05BUUVMQlFBRGdnRUJBR08zcmxING1yRCtKS1M4eE1ZYkJoUjQwYVM0RnBldTd3RjkrT0F5VDZmagpJeVRhM1JqNjJBTGsyZ0tjUDNBOVJKbm15MlFIS3R0UzhoTFBBdzBxYkZFZHlSTzlPYUw4OUZXUlhtN08vZHVHCkFjWWRVTDlDTFpLdUhxU1BOWmhIN05HOEd5bnpYRkVSaVIzQzB5akxmdHhsbEgxUHpGVHB3YWh4WUl3OWcxOXIKL0h2K0dQVndNRHpqUGFMeE0rWTN3ODFwa2FmTWZuaWZVZUhXWUVSemZCTUpUWUZlZkVoOGdsVFpCaUdVWjdsVgp3VDhxK3VwMjJCbzdyeXBpVTZKUWdKeEsyS2l2Ylo2T0h4cytNb3RveWF2LzRsaEY5NzhiSXIwek9BNnUrWWNJClQrQmNCdjlORDBaS0pVcEtQeDN4aDhGNm9XTGpGRHpiZzdQMEdaMDZrV1k9Ci0tLS0tRU5EIENFUlRJRklDQVRFLS0tLS0K
  tls.key: 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
---
# Source: jfrog-platform/charts/postgresql/templates/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: release-name-postgresql
  labels:
    app.kubernetes.io/name: postgresql
    helm.sh/chart: postgresql-10.3.18
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
  namespace: default
type: Opaque
data:
  postgresql-password: "cG9zdGdyZXM="
---
# Source: jfrog-platform/charts/rabbitmq/templates/config-secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: release-name-rabbitmq-config
  namespace: "default"
  labels:
    app.kubernetes.io/name: rabbitmq
    helm.sh/chart: rabbitmq-11.9.3
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
type: Opaque
data:
  rabbitmq.conf: |-
    IyMgVXNlcm5hbWUgYW5kIHBhc3N3b3JkCiMjCmRlZmF1bHRfdXNlciA9IGFkbWluCiMjIENsdXN0ZXJpbmcKIyMKY2x1c3Rlcl9mb3JtYXRpb24ucGVlcl9kaXNjb3ZlcnlfYmFja2VuZCAgPSByYWJiaXRfcGVlcl9kaXNjb3ZlcnlfazhzCmNsdXN0ZXJfZm9ybWF0aW9uLms4cy5ob3N0ID0ga3ViZXJuZXRlcy5kZWZhdWx0CmNsdXN0ZXJfZm9ybWF0aW9uLm5vZGVfY2xlYW51cC5pbnRlcnZhbCA9IDEwCmNsdXN0ZXJfZm9ybWF0aW9uLm5vZGVfY2xlYW51cC5vbmx5X2xvZ193YXJuaW5nID0gdHJ1ZQpjbHVzdGVyX3BhcnRpdGlvbl9oYW5kbGluZyA9IGF1dG9oZWFsCmxvYWRfZGVmaW5pdGlvbnMgPSAvYXBwL2xvYWRfZGVmaW5pdGlvbi5qc29uCiMgcXVldWUgbWFzdGVyIGxvY2F0b3IKcXVldWVfbWFzdGVyX2xvY2F0b3IgPSBtaW4tbWFzdGVycwojIGVuYWJsZSBsb29wYmFjayB1c2VyCmxvb3BiYWNrX3VzZXJzLmFkbWluID0gZmFsc2UKI2RlZmF1bHRfdmhvc3QgPSBkZWZhdWx0LXZob3N0CiNkaXNrX2ZyZWVfbGltaXQuYWJzb2x1dGUgPSA1ME1C
---
# Source: jfrog-platform/charts/rabbitmq/templates/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: release-name-rabbitmq
  namespace: "default"
  labels:
    app.kubernetes.io/name: rabbitmq
    helm.sh/chart: rabbitmq-11.9.3
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
type: Opaque
data:
  rabbitmq-password: "cGFzc3dvcmQ="
  
  rabbitmq-erlang-cookie: "c2VjcmV0Y29va2ll"
---
# Source: jfrog-platform/charts/rabbitmq/templates/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: release-name-load-definition
  namespace: "default"
  labels:
    app.kubernetes.io/name: rabbitmq
    helm.sh/chart: rabbitmq-11.9.3
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
type: Opaque
stringData:
  load_definition.json: |
    {
      "vhosts": [
        {
          "name": "xray"
        }
      ],
      "users": [
        {
          "name": "admin",
          "password": "password",
          "tags": "administrator"
        }
      ],
      "permissions": [
      {
        "user": "admin",
        "vhost": "xray",
        "configure": ".*",
        "write": ".*",
        "read": ".*"
      }
      ],
      "policies": [
        {
          "name": "ha-all",
          "apply-to": "all",
          "pattern": ".*",
          "vhost": "xray",
          "definition": {
            "ha-mode": "all",
            "ha-sync-mode": "automatic"
          }
        }
      ]
    }
---
# Source: jfrog-platform/charts/xray/templates/xray-unified-secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: xray-unified-secret
  labels:
    app: "xray"
    chart: "xray-103.94.6"
    component: "xray"
    heritage: "Helm"
    release: "release-name"
type: Opaque

stringData:
  system.yaml: |

    configVersion: 1
    router:
      serviceRegistry:
        insecure: false
    shared:
      logging:
        consoleLog:
          enabled: false
      jfrogUrl: "http://release-name-artifactory:8082"
      database:
        type: postgresql
        driver: org.postgresql.Driver
      rabbitMq:
        erlangCookie:
          value: "secretcookie"
        url: "amqp://release-name-rabbitmq:5672/"
        username: "admin"
        password: "password"
    contextualAnalysis:
      registry: releases-docker.jfrog.io
      image: jfrog/xray-jas-contextual-analysis
    exposures:
      container:
        registry: releases-docker.jfrog.io
        image: jfrog/xray-jas-exposures
    

data:
  master-key: "YmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYmJiYg=="
  join-key: "RUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUU="
  execution-service-aes-key: "MU41Q1FlODdleEdBMkRDRGMzRGZscmlwMUdXZG5BaHc="
  db-url: "cG9zdGdyZXM6Ly9yZWxlYXNlLW5hbWUtcG9zdGdyZXNxbDo1NDMyL3hyYXk/c3NsbW9kZT1kaXNhYmxl"
  db-user: "eHJheQ=="
  db-password: "eHJheQ=="
---
# Source: jfrog-platform/charts/artifactory/templates/artifactory-installer-info.yaml
kind: ConfigMap
apiVersion: v1
metadata:
  name: release-name-artifactory-installer-info
  labels:
    app: artifactory
    chart: artifactory-107.84.10
    heritage: Helm
    release: release-name
data:
  installer-info.json: |
    {"productId":"Helm_JFrogPlatform/10.18.0-7.84.10","features":[{"featureId":"Platform/kubernetes-v1.28.0"},{"featureId":"Database/postgresql"},{"featureId":"Nginx_Enabled/true"},{"featureId":"ArtifactoryPersistence_Type/file-system"},{"featureId":"SplitServicesToContainers_Enabled/true"},{"featureId":"Filebeat_Enabled/false"},{"featureId":"ReplicaCount/1"}]}
---
# Source: jfrog-platform/charts/artifactory/templates/nginx-artifactory-conf.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-artifactory-nginx-artifactory-conf
  labels:
    app: artifactory
    chart: artifactory-107.84.10
    heritage: Helm
    release: release-name
data:
  artifactory.conf: |
    
    ssl_protocols TLSv1 TLSv1.1 TLSv1.2 TLSv1.3;
    ssl_certificate  /var/opt/jfrog/nginx/ssl/tls.crt;
    ssl_certificate_key  /var/opt/jfrog/nginx/ssl/tls.key;
    ssl_session_cache shared:SSL:1m;
    ssl_prefer_server_ciphers   on;
    ## server configuration
    server {listen 8443 ssl;listen 8080;
      server_name ~(?<repo>.+)\.release-name-artifactory release-name-artifactory;
    
      if ($http_x_forwarded_proto = '') {
        set $http_x_forwarded_proto  $scheme;
      }
      set $host_port 443;
      if ( $scheme = "http" ) {
        set $host_port 80;
      }
      ## Application specific logs
      ## access_log /var/log/nginx/artifactory-access.log timing;
      ## error_log /var/log/nginx/artifactory-error.log;
      rewrite ^/artifactory/?$ / redirect;
      if ( $repo != "" ) {
        rewrite ^/(v1|v2)/(.*) /artifactory/api/docker/$repo/$1/$2 break;
      }
      chunked_transfer_encoding on;
      client_max_body_size 0;
    
      location / {
        proxy_read_timeout  900;
        proxy_pass_header   Server;
        proxy_cookie_path   ~*^/.* /;
        proxy_pass          http://release-name-artifactory:8082/;
        proxy_set_header    X-JFrog-Override-Base-Url $http_x_forwarded_proto://$host:$host_port;
        proxy_set_header    X-Forwarded-Port  $server_port;
        proxy_set_header    X-Forwarded-Proto $http_x_forwarded_proto;
        proxy_set_header    Host              $http_host;
        proxy_set_header    X-Forwarded-For   $proxy_add_x_forwarded_for;
        add_header Strict-Transport-Security "max-age=31536000; includeSubDomains" always;
        location /artifactory/ {
          if ( $request_uri ~ ^/artifactory/(.*)$ ) {
            proxy_pass       http://release-name-artifactory:8081/artifactory/$1;
          }
          proxy_pass         http://release-name-artifactory:8081/artifactory/;
        }
        location /pipelines/ {
          proxy_http_version 1.1;
          proxy_set_header Upgrade $http_upgrade;
          proxy_set_header Connection "upgrade";
          proxy_set_header Host $http_host;
          proxy_pass  http://release-name-artifactory:8082;
        }
      }
    }
---
# Source: jfrog-platform/charts/artifactory/templates/nginx-conf.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-artifactory-nginx-conf
  labels:
    app: artifactory
    chart: artifactory-107.84.10
    heritage: Helm
    release: release-name
data:
  nginx.conf: |
    # Main Nginx configuration file
    worker_processes  4;error_log  /var/opt/jfrog/nginx/logs/error.log warn;
    pid        /var/run/nginx.pid;
    
    events {
      worker_connections  1024;
    }
    
    http {
      include       /etc/nginx/mime.types;
      default_type  application/octet-stream;
    
      variables_hash_max_size 1024;
      variables_hash_bucket_size 64;
      server_names_hash_max_size 4096;
      server_names_hash_bucket_size 128;
      types_hash_max_size 2048;
      types_hash_bucket_size 64;
      proxy_read_timeout 2400s;
      client_header_timeout 2400s;
      client_body_timeout 2400s;
      proxy_connect_timeout 75s;
      proxy_send_timeout 2400s;
      proxy_buffer_size 128k;
      proxy_buffers 40 128k;
      proxy_busy_buffers_size 128k;
      proxy_temp_file_write_size 250m;
      proxy_http_version 1.1;
      client_body_buffer_size 128k;
    
      log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
      '$status $body_bytes_sent "$http_referer" '
      '"$http_user_agent" "$http_x_forwarded_for"';
    
      log_format timing 'ip = $remote_addr '
      'user = \"$remote_user\" '
      'local_time = \"$time_local\" '
      'host = $host '
      'request = \"$request\" '
      'status = $status '
      'bytes = $body_bytes_sent '
      'upstream = \"$upstream_addr\" '
      'upstream_time = $upstream_response_time '
      'request_time = $request_time '
      'referer = \"$http_referer\" '
      'UA = \"$http_user_agent\"';access_log /var/opt/jfrog/nginx/logs/access.log timing;
    
      sendfile        on;
      #tcp_nopush     on;
    
      keepalive_timeout  65;
    
      #gzip  on;
    
      include /etc/nginx/conf.d/*.conf;
    
    }
---
# Source: jfrog-platform/charts/artifactory/templates/nginx-scripts-conf.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-artifactory-nginx-scripts
  labels:
    app: artifactory
    chart: artifactory-107.84.10
    heritage: Helm
    release: release-name
data:
  configreloader.sh: |
    #!/bin/sh
    ####
    # A helper script to use inotifyd to reload nginx config
    # upon configmap/ssl secrets changes.
    #
    # Synopsis: setup the nginx command via the values file
    # as follows:
    #
    ####
    # nginx:
    #   customVolumes: |
    #     - name: scripts
    #       configMap:
    #         name: {{ template "artifactory.fullname" . }}-nginx-scripts
    #         defaultMode: 0550
    #   customVolumeMounts: |
    #     - name: scripts
    #       mountPath: /var/opt/jfrog/nginx/scripts/
    #   customCommand:
    #     - /bin/sh
    #     - -c
    #     - |
    #       # watch for configmap changes
    #       /sbin/inotifyd /var/opt/jfrog/nginx/scripts/configreloader.sh {{ .Values.nginx.persistence.mountPath -}}/conf.d:n &
    #       {{ if .Values.nginx.https.enabled -}}
    #       # watch for tls secret changes
    #       /sbin/inotifyd /var/opt/jfrog/nginx/scripts/configreloader.sh {{ .Values.nginx.persistence.mountPath -}}/ssl:n &
    #       {{ end -}}
    #       nginx -g 'daemon off;'
    if [[ "$3" =~ data_tmp ]] && [ "$1" = "n" ]
    then
      # a symlink has changed in one of the watched folders
      # lets verify the config
      nginx -t -q
      if [ $? -eq 0 ]
      then
        # config is valid, lets reload nginx config
        nginx -q -s reload
      fi
    fi
---
# Source: jfrog-platform/charts/postgresql/templates/extended-config-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-postgresql-extended-configuration
  labels:
    app.kubernetes.io/name: postgresql
    helm.sh/chart: postgresql-10.3.18
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
  namespace: default
data:

  override.conf: |
    max_connections = 1000
    max_wal_size = '1000MB'
---
# Source: jfrog-platform/templates/platform-ga-upgrade.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-jfrog-platform-configmap
  labels:
    app: jfrog-platform
    chart: jfrog-platform-10.18.0
    heritage: Helm
    release: release-name
data:
---
# Source: jfrog-platform/templates/postgres-setup-script.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-setup-script
  labels:
    app: postgres-init
data:
  setupPostgres.sh: |
    #!/bin/bash
    # This can be used to create user, database, schema and grant the required permissions.
    # This script can handle multiple execution and not with "already exists" error. An entity will get created only if it does not exist.
    # NOTE : 1. This expects current linux user to be admin user in postgreSQL (this is the case with 'postgres' user)
    #        2. Execute this by logging as postgres or any other user with similar privilege
    #        3. This files needs be executed from a location which postgres (or the admin user which will be used) has access to. (/opt can be used)
    #
    #        su postgres -c "POSTGRES_PATH=/path/to/postgres/bin PGPASSWORD=postgres bash ./createPostgresUsers.sh"
    POSTGRES_LABEL="Postgres"
    
    # Logging function
    log() {
        echo -e "$1"
    }
    
    # Error function
    errorExit() {
        echo; echo -e "\033[31mERROR:\033[0m $1"; echo
        exit 1
    }
    
    # Create user if it does not exist
    createUser(){
        local user=$1
        local pass=$2
        [ ! -z ${user} ] || errorExit "user is empty"
        [ ! -z ${pass} ] || errorExit "password is empty"
        ${PSQL} $POSTGRES_OPTIONS -tAc "SELECT 1 FROM pg_roles WHERE rolname='${user}'" | grep -q 1 1>/dev/null
        local rc=$?
        # Create user if doesn't exists
        if [[ ${rc} -ne 0 ]]; then
            echo "Creating user ${user}..."
            ${PSQL} $POSTGRES_OPTIONS -c "CREATE USER ${user} WITH PASSWORD '${pass}';" 1>/dev/null || errorExit "Failed creating user ${user} on PostgreSQL"
            echo "Done"
        fi
    }
    
    # Create database if it does not exist
    createDB(){
        local db=$1
        local user=$2
        [ ! -z ${db}   ] || errorExit "db is empty"
        [ ! -z ${user} ] || errorExit "user is empty"
        if ! ${PSQL} $POSTGRES_OPTIONS -lqt | cut -d \| -f 1 | grep -qw ${db} 1>/dev/null; then
            ${PSQL} $POSTGRES_OPTIONS -c "CREATE DATABASE ${db} WITH OWNER=${user} ENCODING='UTF8';" 1>/dev/null || errorExit "Failed creating db ${db} on PostgreSQL"
        fi
    }
    
    # Check if postgres db is ready
    postgresIsNotReady() {
        attempt_number=${attempt_number:-0}
        ${PSQL} $POSTGRES_OPTIONS --version > /dev/null 2>&1
        outcome1=$?
        # Execute a simple db function to verify if postgres is up and running
        ${PSQL} $POSTGRES_OPTIONS -l > /dev/null 2>&1
        outcome2=$?
        if [[ $outcome1 -eq 0 ]] && [[ $outcome2 -eq 0  ]]; then
            return 0
        else
            if [ $attempt_number -gt 10 ]; then
                errorExit "Unable to proceed. $POSTGRES_LABEL is not reachable. This can occur if the service is not running \
    or the port is not accepting requests at $DB_PORT (host : $DB_HOST). Gave up after $attempt_number attempts"
            fi
            let "attempt_number=attempt_number+1"
            return 1
        fi
    }
    
    # Wait for availability of postgres
    init(){
        if [[ -z $POSTGRES_PATH ]]; then
            hash ${PSQL} 2>/dev/null || { echo >&2 "\"${PSQL}\" is not installed or not available in path"; exit 1; }
        fi
        log "Waiting for $POSTGRES_LABEL to get ready using the commands: \"${PSQL} $POSTGRES_OPTIONS --version\" & \"${PSQL} $POSTGRES_OPTIONS -l\""
        attempt_number=0
        while ! postgresIsNotReady
        do
            sleep 5
            echo -n '.'
        done
        log "$POSTGRES_LABEL is ready. Executing commands"
    }
    
    # Create users and DB
    setupDB(){
        local user=$1
        local pass=$2
        local db=$3
        # Create user
        createUser "${user}" "${pass}"    
        createDB "${db}" "${user}"
        ${PSQL} $POSTGRES_OPTIONS -c "GRANT ALL PRIVILEGES ON DATABASE ${db} TO ${user}" 1>/dev/null;
    }
    
    # Load default and custom postgres details from below files
    [ -f setenvDefaults.sh ] && source setenvDefaults.sh || true
    [ -f setenv.sh         ] && source setenv.sh         || true
    
    # DB_NAME=$1
    # DB_USERNAME=$2
    # DB_PASSWORD=$3
    # CHART_NAME=$4
    
    : ${DB_NAME:=$1}
    : ${DB_USERNAME:=$2}
    : ${DB_PASSWORD:=$3}
    : ${CHART_NAME:=4}
    
    ### Following are the postgres details being setup for each service.
    ##  Common details
    : ${DB_PORT:=5432}
    : ${DB_SSL_MODE:="disable"}
    : ${DB_TABLESPACE:="pg_default"}
    : ${DB_HOST:="localhost"}
    
    ## Set Postgres options
    [[ -z "${POSTGRES_PATH}" ]] && PSQL=psql || PSQL=${POSTGRES_PATH}/psql
    POSTGRES_OPTIONS="sslmode=${DB_SSL_MODE} --host=${DB_HOST} -p ${DB_PORT} -U ${PGUSERNAME} -w"
    
    init
    
    log "Setting up DB $DB_NAME and user $DB_USERNAME on Postgres for $CHART_NAME chart."
    setupDB "${DB_USERNAME}" "${DB_PASSWORD}" "${DB_NAME}" || true
    
    log "$POSTGRES_LABEL setup is now complete."
    
    exit 0
---
# Source: jfrog-platform/charts/rabbitmq/templates/role.yaml
kind: Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: release-name-rabbitmq-endpoint-reader
  namespace: "default"
  labels:
    app.kubernetes.io/name: rabbitmq
    helm.sh/chart: rabbitmq-11.9.3
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
rules:
  - apiGroups: [""]
    resources: ["endpoints"]
    verbs: ["get"]
  - apiGroups: [""]
    resources: ["events"]
    verbs: ["create"]
---
# Source: jfrog-platform/charts/rabbitmq/templates/rolebinding.yaml
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: release-name-rabbitmq-endpoint-reader
  namespace: "default"
  labels:
    app.kubernetes.io/name: rabbitmq
    helm.sh/chart: rabbitmq-11.9.3
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
subjects:
  - kind: ServiceAccount
    name: release-name-rabbitmq
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: release-name-rabbitmq-endpoint-reader
---
# Source: jfrog-platform/charts/artifactory/templates/artifactory-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-artifactory
  labels:
    app: artifactory
    chart: artifactory-107.84.10
    component: artifactory
    heritage: Helm
    release: release-name
spec:
  type: ClusterIP
  ports:
  - port: 8082
    targetPort: 8082
    protocol: TCP
    name: http-router
  - port: 8025
    targetPort: 8025
    protocol: TCP
    name: http-rtfs
  - port: 8081
    targetPort: 8081
    protocol: TCP
    name: http-artifactory
  selector:
    app: artifactory
    component: "artifactory"
    release: release-name
---
# Source: jfrog-platform/charts/artifactory/templates/nginx-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-artifactory-nginx
  labels:
    app: artifactory
    chart: artifactory-107.84.10
    component: nginx
    heritage: Helm
    release: release-name
spec:
  type: LoadBalancer
  
  externalTrafficPolicy: Cluster
  ports:
  # DEPRECATION NOTE: The following is to maintain support for values pre 1.3.0 and
  # will be cleaned up in a later version
  - port: 80
    targetPort: 8080
    protocol: TCP
    name: http
  - port: 443
    targetPort: 8443
    protocol: TCP
    name: https
  selector:
    app: artifactory
    component: nginx
    release: release-name
---
# Source: jfrog-platform/charts/postgresql/templates/svc-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-postgresql-headless
  labels:
    app.kubernetes.io/name: postgresql
    helm.sh/chart: postgresql-10.3.18
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    # Use this annotation in addition to the actual publishNotReadyAddresses
    # field below because the annotation will stop being respected soon but the
    # field is broken in some versions of Kubernetes:
    # https://github.com/kubernetes/kubernetes/issues/58662
    service.alpha.kubernetes.io/tolerate-unready-endpoints: "true"
  namespace: default
spec:
  type: ClusterIP
  clusterIP: None
  # We want all pods in the StatefulSet to have their addresses published for
  # the sake of the other Postgresql pods even before they're ready, since they
  # have to be able to talk to each other in order to become ready.
  publishNotReadyAddresses: true
  ports:
    - name: tcp-postgresql
      port: 5432
      targetPort: tcp-postgresql
  selector:
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/instance: release-name
---
# Source: jfrog-platform/charts/postgresql/templates/svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-postgresql
  labels:
    app.kubernetes.io/name: postgresql
    helm.sh/chart: postgresql-10.3.18
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
  annotations:
  namespace: default
spec:
  type: ClusterIP
  ports:
    - name: tcp-postgresql
      port: 5432
      targetPort: tcp-postgresql
  selector:
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/instance: release-name
    role: primary
---
# Source: jfrog-platform/charts/rabbitmq/templates/svc-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-rabbitmq-headless
  namespace: "default"
  labels:
    app.kubernetes.io/name: rabbitmq
    helm.sh/chart: rabbitmq-11.9.3
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
spec:
  clusterIP: None
  ports:
    - name: epmd
      port: 4369
      targetPort: epmd
    - name: amqp
      port: 5672
      targetPort: amqp
    - name: dist
      port: 25672
      targetPort: dist
    - name: http-stats
      port: 15672
      targetPort: stats
  selector: 
    app.kubernetes.io/name: rabbitmq
    app.kubernetes.io/instance: release-name
  publishNotReadyAddresses: true
---
# Source: jfrog-platform/charts/rabbitmq/templates/svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-rabbitmq
  namespace: "default"
  labels:
    app.kubernetes.io/name: rabbitmq
    helm.sh/chart: rabbitmq-11.9.3
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  sessionAffinity: None
  ports:
    - name: amqp
      port: 5672
      targetPort: amqp
      nodePort: null
    - name: epmd
      port: 4369
      targetPort: epmd
      nodePort: null
    - name: dist
      port: 25672
      targetPort: dist
      nodePort: null
    - name: http-stats
      port: 15672
      targetPort: stats
      nodePort: null
  selector: 
    app.kubernetes.io/name: rabbitmq
    app.kubernetes.io/instance: release-name
---
# Source: jfrog-platform/charts/xray/templates/xray-svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-xray
  labels:
    app: xray
    chart: xray-103.94.6
    component: xray
    heritage: Helm
    release: release-name
spec:
  type: ClusterIP
  ports:
  - port: 80
    protocol: TCP
    name: http
    targetPort: 8000
  - port: 8082
    protocol: TCP
    name: http-router
    targetPort: 8082
  selector:
    app: xray
    component: xray
    release: release-name
---
# Source: jfrog-platform/charts/artifactory/templates/nginx-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-artifactory-nginx
  labels:
    app: artifactory
    chart: artifactory-107.84.10
    heritage: Helm
    release: release-name
    component: nginx
spec:
  replicas: 1
  selector:
    matchLabels:
      app: artifactory
      release: release-name
      component: nginx
  template:
    metadata:
      annotations:
        checksum/nginx-conf: 3d646ea0f9d5cf094232162dbbb24ccef5188fc1bd4af5a6a85499da6831a485
        checksum/nginx-artifactory-conf: a1d044e28e7c93556ed94e5248e3ccb4d337b05482af06bae34dadf5cc4fcdb2
      labels:
        app: artifactory
        chart: artifactory-107.84.10
        component: nginx
        heritage: Helm
        release: release-name
    spec:
      securityContext:
        fsGroup: 107
        runAsGroup: 107
        runAsUser: 104
      serviceAccountName: default
      terminationGracePeriodSeconds: 30
      initContainers:
      - name: "setup"
        image: releases-docker.jfrog.io/ubi9/ubi-minimal:9.3.1552
        imagePullPolicy: IfNotPresent
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          privileged: false
          runAsNonRoot: true
          seccompProfile:
            type: RuntimeDefault
        command:
        - '/bin/sh'
        - '-c'
        - >
          rm -rfv /var/opt/jfrog/nginx/lost+found;
          mkdir -p /var/opt/jfrog/nginx/logs;
        volumeMounts:
        - mountPath: "/var/opt/jfrog/nginx"
          name: nginx-volume
      containers:
      - name: nginx
        image: releases-docker.jfrog.io/jfrog/nginx-artifactory-pro:7.84.10
        imagePullPolicy: IfNotPresent
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          privileged: false
          readOnlyRootFilesystem: false
          runAsNonRoot: true
          seccompProfile:
            type: RuntimeDefault
        ports:

        # DEPRECATION NOTE: The following is to maintain support for values pre 1.3.1 and
        # will be cleaned up in a later version
        - containerPort: 8080
          name: http
        - containerPort: 8443
          name: https
        volumeMounts:
        - name: nginx-conf
          mountPath: /etc/nginx/nginx.conf
          subPath: nginx.conf
        - name: nginx-artifactory-conf
          mountPath: "/var/opt/jfrog/nginx/conf.d/"
        - name: nginx-volume
          mountPath: "/var/opt/jfrog/nginx"  
        - name: ssl-certificates
          mountPath: "/var/opt/jfrog/nginx/ssl"  
        resources:
          {}
        startupProbe:
          exec:
            command:
              - sh
              - -c
              - curl -s -k --fail --max-time 5 http://localhost:8080/router/api/v1/system/readiness
          initialDelaySeconds: 3
          failureThreshold: 90
          periodSeconds: 5
          timeoutSeconds: 5
          
        readinessProbe:
          exec:
            command:
              - sh
              - -c
              - curl -s -k --fail --max-time 5 http://localhost:8080/router/api/v1/system/readiness
          initialDelaySeconds: 0
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 5
          successThreshold: 1
          
        livenessProbe:
          exec:
            command:
              - sh
              - -c
              - curl -s -k --fail --max-time 5 http://localhost:8080/
          initialDelaySeconds: 0
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 5
          successThreshold: 1
          
      volumes:
      - name: nginx-conf
        configMap:
          name: release-name-artifactory-nginx-conf
      - name: nginx-artifactory-conf
        configMap:
          name: release-name-artifactory-nginx-artifactory-conf
      - name: nginx-volume
        emptyDir: {}
      - name: ssl-certificates
        secret:
          secretName: release-name-artifactory-nginx-certificate
---
# Source: jfrog-platform/charts/artifactory/templates/artifactory-statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: release-name-artifactory
  labels:
    app: artifactory
    chart: artifactory-107.84.10
    component: artifactory
    heritage: Helm
    release: release-name
spec:
  serviceName: artifactory
  replicas: 1
  updateStrategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app: artifactory
      role: artifactory
      release: release-name
  template:
    metadata:
      labels:
        app: artifactory
        chart: artifactory-107.84.10
        heritage: Helm
        role: artifactory
        component: artifactory
        release: release-name
      annotations:
        checksum/artifactory-unified-secret: f664fac0319d81bed25beb58a4fc6c3ad0281c505c59ae661a0dc924900b4845
    spec:
      serviceAccountName: default
      terminationGracePeriodSeconds: 40
      securityContext:
        fsGroup: 1030
        runAsGroup: 1030
        runAsNonRoot: true
        runAsUser: 1030
      initContainers:
      
      - name: postgres-setup-init
        image: "releases-docker.jfrog.io/postgres:15.6-alpine"
        imagePullPolicy: IfNotPresent
        resources: 
                limits:
                  cpu: 1
                  memory: 1Gi
                requests:
                  cpu: 5m
                  memory: 10Mi
        command:
          - '/bin/bash'
          - '-c'
          - >
            echo "Running init db scripts";
            bash /scripts/setupPostgres.sh
        env:
          - name: PGUSERNAME
            value: postgres
          - name: DB_HOST
            value: release-name-postgresql
          - name: DB_PORT
            value: "5432"
          - name: DB_SSL_MODE
            value: "disable"
          - name: DB_NAME
            value: artifactory
          - name: DB_USERNAME
            valueFrom:
              secretKeyRef:
                name: artifactory-unified-secret
                key: db-user
          - name: DB_PASSWORD
            valueFrom:
              secretKeyRef:
                name: artifactory-unified-secret
                key: db-password
          - name: PGPASSWORD
            value: postgres
          - name: CHART_NAME
            value: artifactory
        volumeMounts:
          - name: postgres-setup-init-vol
            mountPath: "/scripts"
      
      - name: "delete-db-properties"
        image: releases-docker.jfrog.io/ubi9/ubi-minimal:9.3.1552
        imagePullPolicy: IfNotPresent
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          privileged: false
          runAsNonRoot: true
          seccompProfile:
            type: RuntimeDefault
        resources:
          limits:
            cpu: "1"
            memory: 1Gi
          requests:
            cpu: 10m
            memory: 50Mi
        command:
          - 'bash'
          - '-c'
          - 'rm -fv /var/opt/jfrog/artifactory/etc/db.properties'
        volumeMounts:
          - name: artifactory-volume
            mountPath: "/var/opt/jfrog/artifactory"
      - name: 'copy-system-configurations'
        image: releases-docker.jfrog.io/ubi9/ubi-minimal:9.3.1552
        imagePullPolicy: IfNotPresent
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          privileged: false
          runAsNonRoot: true
          seccompProfile:
            type: RuntimeDefault
        resources:
          limits:
            cpu: "1"
            memory: 1Gi
          requests:
            cpu: 10m
            memory: 50Mi
        command:
        - '/bin/bash'
        - '-c'
        - >
          if [[ -e "/var/opt/jfrog/artifactory/etc/filebeat.yaml" ]]; then chmod 644 /var/opt/jfrog/artifactory/etc/filebeat.yaml; fi;
          echo "Copy system.yaml to /var/opt/jfrog/artifactory/etc";
          mkdir -p /var/opt/jfrog/artifactory/etc;
          mkdir -p /var/opt/jfrog/artifactory/etc/access/keys/trusted;
          cp -fv /tmp/etc/system.yaml /var/opt/jfrog/artifactory/etc/system.yaml;
          echo "Copy binarystore.xml file";
          mkdir -p /var/opt/jfrog/artifactory/etc/artifactory;
          cp -fv /tmp/etc/artifactory/binarystore.xml /var/opt/jfrog/artifactory/etc/artifactory/binarystore.xml;
          echo "Copy access.config.patch.yml to /var/opt/jfrog/artifactory/etc/access";
          mkdir -p /var/opt/jfrog/artifactory/etc/access;
          cp -fv /tmp/etc/access.config.patch.yml /var/opt/jfrog/artifactory/etc/access/access.config.patch.yml;
          echo "Copy joinKey to /var/opt/jfrog/artifactory/bootstrap/access/etc/security";
          mkdir -p /var/opt/jfrog/artifactory/bootstrap/access/etc/security;
          echo -n ${ARTIFACTORY_JOIN_KEY} > /var/opt/jfrog/artifactory/bootstrap/access/etc/security/join.key;
          echo "Copy masterKey to /var/opt/jfrog/artifactory/etc/security";
          mkdir -p /var/opt/jfrog/artifactory/etc/security;
          echo -n ${ARTIFACTORY_MASTER_KEY} > /var/opt/jfrog/artifactory/etc/security/master.key;
        env:
        - name: ARTIFACTORY_JOIN_KEY
          valueFrom:
            secretKeyRef:
              name: "artifactory-unified-secret"
              key: join-key
        - name: ARTIFACTORY_MASTER_KEY
          valueFrom:
            secretKeyRef:
              name: "artifactory-unified-secret"
              key: master-key
        volumeMounts:
        - name: artifactory-volume
          mountPath: "/var/opt/jfrog/artifactory"
        - name: artifactory-unified-secret-volume
          mountPath: "/tmp/etc/system.yaml"
          subPath: "system.yaml"

        ######################## Binarystore  ##########################
        - name: artifactory-unified-secret-volume
          mountPath: "/tmp/etc/artifactory/binarystore.xml"
          subPath: binarystore.xml

        ######################## Access config  ##########################
        - name: artifactory-unified-secret-volume
          mountPath: "/tmp/etc/access.config.patch.yml"
          subPath: "access.config.patch.yml"

        ######################## Access certs external secret  ##########################
      containers:
      - name: router
        image: releases-docker.jfrog.io/jfrog/router:7.108.0
        imagePullPolicy: IfNotPresent
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          privileged: false
          runAsNonRoot: true
          seccompProfile:
            type: RuntimeDefault
        command:
          - '/bin/bash'
          - '-c'
          - >
            exec /opt/jfrog/router/app/bin/entrypoint-router.sh
        lifecycle:
          preStop:
            exec:
              command:
              - sh
              - -c
              - while [[ $(curl --fail --silent --connect-timeout 2 http://localhost:8081/artifactory/api/v1/system/liveness)
                =~ OK ]]; do echo Artifactory is still alive; sleep 2; done
        env:
        - name: JF_ROUTER_TOPOLOGY_LOCAL_REQUIREDSERVICETYPES
          value: jfrt,jfac,jfob,jfmd,jfevt,jffe,jfcon,jfmc
        ports:
          - name: http
            containerPort: 8082
        volumeMounts:
        - name: artifactory-volume
          mountPath: "/var/opt/jfrog/router"
        resources:
          {}
        startupProbe:
          exec:
            command:
              - sh
              - -c
              - curl -s -k --fail --max-time 5 http://localhost:8082/router/api/v1/system/readiness
          initialDelaySeconds: 10
          failureThreshold: 30
          periodSeconds: 5
          timeoutSeconds: 5
          
        readinessProbe:
          exec:
            command:
              - sh
              - -c
              - curl -s -k --fail --max-time 5 http://localhost:8082/router/api/v1/system/readiness
          initialDelaySeconds: 0
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 5
          successThreshold: 1
          
        livenessProbe:
          exec:
            command:
              - sh
              - -c
              - curl -s -k --fail --max-time 5 http://localhost:8082/router/api/v1/system/liveness
          initialDelaySeconds: 0
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 5
          successThreshold: 1
          
      - name: frontend
        image: releases-docker.jfrog.io/jfrog/artifactory-pro:7.84.10
        imagePullPolicy: IfNotPresent
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          privileged: false
          runAsNonRoot: true
          seccompProfile:
            type: RuntimeDefault
        command:
          - '/bin/bash'
          - '-c'
          - >
            exec /opt/jfrog/artifactory/app/third-party/node/bin/node /opt/jfrog/artifactory/app/frontend/bin/server/dist/bundle.js /opt/jfrog/artifactory/app/frontend
        env:
        - name: JF_SHARED_NODE_ID
          valueFrom:
            fieldRef:
              fieldPath: metadata.name   
        volumeMounts:
        - name: artifactory-volume
          mountPath: "/var/opt/jfrog/artifactory"
        resources:
          {}
        startupProbe:
          exec:
            command:
              - sh
              - -c
              - curl --fail --max-time 5 http://localhost:8070/api/v1/system/readiness
          initialDelaySeconds: 30
          failureThreshold: 90
          periodSeconds: 5
          timeoutSeconds: 5
          
        livenessProbe:
          exec:
            command:
              - sh
              - -c
              - curl --fail --max-time 5 http://localhost:8070/api/v1/system/liveness
          initialDelaySeconds: 0
          failureThreshold: 5
          timeoutSeconds: 5
          periodSeconds: 10
          successThreshold: 1
          
      - name: metadata
        image: releases-docker.jfrog.io/jfrog/artifactory-pro:7.84.10
        imagePullPolicy: IfNotPresent
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          privileged: false
          runAsNonRoot: true
          seccompProfile:
            type: RuntimeDefault
        command:
          - '/bin/bash'
          - '-c'
          - >
            exec /opt/jfrog/artifactory/app/metadata/bin/jf-metadata start
        env:
        - name: JF_SHARED_NODE_ID
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: JF_SHARED_DATABASE_USERNAME
          valueFrom:
            secretKeyRef:
              name: "artifactory-unified-secret"
              key: db-user
      
        - name: JF_SHARED_DATABASE_PASSWORD
          valueFrom:
            secretKeyRef:
              name: "artifactory-unified-secret"
              key: db-password
        - name: JF_SHARED_DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: "artifactory-unified-secret"
              key: db-url
        volumeMounts:
        - name: artifactory-volume
          mountPath: "/var/opt/jfrog/artifactory"
        resources:
          {}
        startupProbe:
          exec:
            command:
              - sh
              - -c
              - curl --fail --max-time 5 http://localhost:8086/api/v1/system/readiness
          initialDelaySeconds: 30
          failureThreshold: 90
          periodSeconds: 5
          timeoutSeconds: 5
          
        livenessProbe:
          exec:
            command:
              - sh
              - -c
              - curl --fail --max-time 5 http://localhost:8086/api/v1/system/liveness
          initialDelaySeconds: 0
          failureThreshold: 5
          timeoutSeconds: 5
          periodSeconds: 10
          successThreshold: 1
          
      - name: event
        image: releases-docker.jfrog.io/jfrog/artifactory-pro:7.84.10
        imagePullPolicy: IfNotPresent
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          privileged: false
          runAsNonRoot: true
          seccompProfile:
            type: RuntimeDefault
        command:
          - '/bin/bash'
          - '-c'
          - >
            exec /opt/jfrog/artifactory/app/event/bin/jf-event start
        env:
        - name: JF_SHARED_NODE_ID
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        volumeMounts:
        - name: artifactory-volume
          mountPath: "/var/opt/jfrog/artifactory"
        resources:
          {}
        startupProbe:
          exec:
            command:
              - sh
              - -c
              - curl --fail --max-time 5 http://localhost:8061/api/v1/system/readiness
          initialDelaySeconds: 30
          failureThreshold: 90
          periodSeconds: 5
          timeoutSeconds: 5
          
        livenessProbe:
          exec:
            command:
              - sh
              - -c
              - curl --fail --max-time 5 http://localhost:8061/api/v1/system/liveness
          initialDelaySeconds: 0
          failureThreshold: 5
          timeoutSeconds: 5
          periodSeconds: 10
          successThreshold: 1
          
      - name: jfconnect
        image: releases-docker.jfrog.io/jfrog/artifactory-pro:7.84.10
        imagePullPolicy: IfNotPresent
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          privileged: false
          runAsNonRoot: true
          seccompProfile:
            type: RuntimeDefault
        command:
          - '/bin/bash'
          - '-c'
          - >
            exec /opt/jfrog/artifactory/app/jfconnect/bin/jf-connect start
        env:
        - name: JF_SHARED_NODE_ID
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        volumeMounts:
        - name: artifactory-volume
          mountPath: "/var/opt/jfrog/artifactory"
        resources:
          {}
        startupProbe:
          exec:
            command:
              - sh
              - -c
              - curl --fail --max-time 5 http://localhost:8030/api/v1/system/readiness
          initialDelaySeconds: 30
          failureThreshold: 90
          periodSeconds: 5
          timeoutSeconds: 5
          
        livenessProbe:
          exec:
            command:
              - sh
              - -c
              - curl --fail --max-time 5 http://localhost:8030/api/v1/system/liveness
          initialDelaySeconds: 0
          failureThreshold: 5
          timeoutSeconds: 5
          periodSeconds: 10
          successThreshold: 1
          
      - name: observability
        image: releases-docker.jfrog.io/jfrog/artifactory-pro:7.84.10
        imagePullPolicy: IfNotPresent
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          privileged: false
          runAsNonRoot: true
          seccompProfile:
            type: RuntimeDefault
        command:
          - '/bin/bash'
          - '-c'
          - >
            exec /opt/jfrog/artifactory/app/observability/bin/jf-observability start
        env:
        - name: JF_SHARED_NODE_ID
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        volumeMounts:
        - name: artifactory-volume
          mountPath: "/var/opt/jfrog/artifactory"
        resources:
          {}
        startupProbe:
          exec:
            command:
              - sh
              - -c
              - curl --fail --max-time 5 http://localhost:8036/api/v1/system/readiness
          initialDelaySeconds: 30
          failureThreshold: 90
          periodSeconds: 5
          timeoutSeconds: 5
          
        livenessProbe:
          exec:
            command:
              - sh
              - -c
              - curl --fail --max-time 5 http://localhost:8036/api/v1/system/liveness
          initialDelaySeconds: 0
          failureThreshold: 5
          timeoutSeconds: 5
          periodSeconds: 10
          successThreshold: 1
          
      - name: artifactory
        image: releases-docker.jfrog.io/jfrog/artifactory-pro:7.84.10
        imagePullPolicy: IfNotPresent
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          privileged: false
          runAsNonRoot: true
          seccompProfile:
            type: RuntimeDefault
        command:
        - '/bin/bash'
        - '-c'
        - >
          set -e;
          if [ -d /artifactory_extra_conf ] && [ -d /artifactory_bootstrap ]; then
            echo "Copying bootstrap config from /artifactory_extra_conf to /artifactory_bootstrap";
            cp -Lrfv /artifactory_extra_conf/ /artifactory_bootstrap/;
          fi;
          exec /entrypoint-artifactory.sh
        env:
        - name : JF_ROUTER_ENABLED
          value: "true"
        - name : JF_ROUTER_SERVICE_ENABLED
          value: "false"
        - name : JF_EVENT_ENABLED
          value: "false"
        - name : JF_METADATA_ENABLED
          value: "false"
        - name : JF_FRONTEND_ENABLED
          value: "false"
        - name: JF_FEDERATION_ENABLED
          value: "false"
        - name : JF_OBSERVABILITY_ENABLED
          value: "false"
        - name : JF_JFCONNECT_SERVICE_ENABLED
          value: "false"
        - name: SKIP_WAIT_FOR_EXTERNAL_DB
          value: "true"
        - name: JF_SHARED_DATABASE_USERNAME
          valueFrom:
            secretKeyRef:
              name: "artifactory-unified-secret"
              key: db-user
      
        - name: JF_SHARED_DATABASE_PASSWORD
          valueFrom:
            secretKeyRef:
              name: "artifactory-unified-secret"
              key: db-password
        - name: JF_SHARED_DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: "artifactory-unified-secret"
              key: db-url
        ports:
        - containerPort: 8082
          name: http
        - containerPort: 8081
          name: http-internal
        - containerPort: 8025
          name: http-rtfs
        volumeMounts:
        - name: artifactory-volume
          mountPath: "/var/opt/jfrog/artifactory"

      ######################## Artifactory config map ##########################

      ######################## Artifactory persistence nfs ##########################

      ######################## Artifactory persistence binarystoreXml ##########################
        - name: artifactory-unified-secret-volume
          mountPath: "/tmp/etc/artifactory/binarystore.xml"
          subPath: binarystore.xml

      ######################## Artifactory persistence googleStorage ##########################

      ######################## Artifactory license ##########################

        - name: installer-info
          mountPath: "/artifactory_bootstrap/info/installer-info.json"
          subPath: installer-info.json
        startupProbe:
          exec:
            command:
              - sh
              - -c
              - curl -s -k --fail --max-time 5 http://localhost:8091/artifactory/api/v1/system/readiness
          initialDelaySeconds: 10
          failureThreshold: 90
          periodSeconds: 5
          timeoutSeconds: 5
          
        livenessProbe:
          exec:
            command:
              - sh
              - -c
              - curl -s -k --fail --max-time 5 http://localhost:8091/artifactory/api/v1/system/liveness
          initialDelaySeconds: 0
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 5
          successThreshold: 1
          
      
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - weight: 100
              podAffinityTerm:
                topologyKey: kubernetes.io/hostname
                labelSelector:
                  matchLabels:
                    app: artifactory
                    release: release-name
      volumes:
      ########## External secrets ###########
      # ca-certs secret

      # aws licence

      # binarystore-xml secret

      # access-certs secrets

      # system yaml

      # artifactory license secrets
      
      # user Plugin Secrets

      # access bootstarp

      # gcpcreds secret

      ############ Config map, Volumes and Custom Volumes ##############
      
      - name: postgres-setup-init-vol
        configMap:
          name: release-name-setup-script
      
      - name: installer-info
        configMap:
          name: release-name-artifactory-installer-info

    #########  unifiedSecretInstallation ###########
      - name: artifactory-unified-secret-volume
        secret:
          secretName: artifactory-unified-secret
    ########## volumeClaimTemplates #######
  volumeClaimTemplates:
  - metadata:
      name: artifactory-volume
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: 200Gi
---
# Source: jfrog-platform/charts/postgresql/templates/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: release-name-postgresql
  labels:
    app.kubernetes.io/name: postgresql
    helm.sh/chart: postgresql-10.3.18
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: primary
  annotations:
  namespace: default
spec:
  serviceName: release-name-postgresql-headless
  replicas: 1
  updateStrategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/name: postgresql
      app.kubernetes.io/instance: release-name
      role: primary
  template:
    metadata:
      name: release-name-postgresql
      labels:
        app.kubernetes.io/name: postgresql
        helm.sh/chart: postgresql-10.3.18
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/managed-by: Helm
        role: primary
        app.kubernetes.io/component: primary
    spec:      
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: postgresql
                    app.kubernetes.io/instance: release-name
                    app.kubernetes.io/component: primary
                namespaces:
                  - "default"
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      securityContext:
        fsGroup: 1001
      containers:
        - name: release-name-postgresql
          image: releases-docker.jfrog.io/bitnami/postgresql:15.6.0-debian-11-r16
          imagePullPolicy: "IfNotPresent"
          resources:
            requests:
              cpu: 250m
              memory: 256Mi
          securityContext:
            runAsUser: 1001
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: POSTGRESQL_PORT_NUMBER
              value: "5432"
            - name: POSTGRESQL_VOLUME_DIR
              value: "/bitnami/postgresql"
            - name: PGDATA
              value: "/bitnami/postgresql/data"
            - name: POSTGRES_USER
              value: "postgres"
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: release-name-postgresql
                  key: postgresql-password
            - name: POSTGRESQL_ENABLE_LDAP
              value: "no"
            - name: POSTGRESQL_ENABLE_TLS
              value: "no"
            - name: POSTGRESQL_LOG_HOSTNAME
              value: "false"
            - name: POSTGRESQL_LOG_CONNECTIONS
              value: "false"
            - name: POSTGRESQL_LOG_DISCONNECTIONS
              value: "false"
            - name: POSTGRESQL_PGAUDIT_LOG_CATALOG
              value: "off"
            - name: POSTGRESQL_CLIENT_MIN_MESSAGES
              value: "error"
            - name: POSTGRESQL_SHARED_PRELOAD_LIBRARIES
              value: "pgaudit"
          ports:
            - name: tcp-postgresql
              containerPort: 5432
          livenessProbe:
            exec:
              command:
                - /bin/sh
                - -c
                - exec pg_isready -U "postgres" -h 127.0.0.1 -p 5432
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 6
          readinessProbe:
            exec:
              command:
                - /bin/sh
                - -c
                - -e
                - |
                  exec pg_isready -U "postgres" -h 127.0.0.1 -p 5432
                  [ -f /opt/bitnami/postgresql/tmp/.initialized ] || [ -f /bitnami/postgresql/.initialized ]
            initialDelaySeconds: 5
            periodSeconds: 10
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 6
          volumeMounts:
            - name: postgresql-extended-config
              mountPath: /bitnami/postgresql/conf/conf.d/
            - name: dshm
              mountPath: /dev/shm
            - name: data
              mountPath: /bitnami/postgresql
              subPath: 
      volumes:
        - name: postgresql-extended-config
          configMap:
            name: release-name-postgresql-extended-configuration
        - name: dshm
          emptyDir:
            medium: Memory
            sizeLimit: 1Gi
  volumeClaimTemplates:
    - metadata:
        name: data
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: "500Gi"
---
# Source: jfrog-platform/charts/rabbitmq/templates/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: release-name-rabbitmq
  namespace: "default"
  labels:
    app.kubernetes.io/name: rabbitmq
    helm.sh/chart: rabbitmq-11.9.3
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
spec:
  serviceName: release-name-rabbitmq-headless
  podManagementPolicy: OrderedReady
  replicas: 1
  updateStrategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/name: rabbitmq
      app.kubernetes.io/instance: release-name
  template:
    metadata:
      labels:
        app.kubernetes.io/name: rabbitmq
        helm.sh/chart: rabbitmq-11.9.3
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/managed-by: Helm
      annotations:
        checksum/config: 098d6f7753d8b93f797d86ffb7051b937cfc01244f4a9df0bc58e375d9eb398c
        checksum/secret: fbb41d69d53a0751660c7970fb5996ded7d9279137f28eae7affe432f9fcbb5a
    spec:
      
      serviceAccountName: release-name-rabbitmq
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: rabbitmq
                    app.kubernetes.io/instance: release-name
                namespaces:
                  - "default"
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      securityContext:
        fsGroup: 1001
      terminationGracePeriodSeconds: 120
      initContainers:
      containers:
        - name: rabbitmq
          image: releases-docker.jfrog.io/bitnami/rabbitmq:3.12.10-debian-11-r1
          imagePullPolicy: "IfNotPresent"
          securityContext:
            runAsNonRoot: true
            runAsUser: 1001
          lifecycle:
            preStop:
              exec:
                command:
                  - /bin/bash
                  - -ec
                  - |
                    if [[ -f /opt/bitnami/scripts/rabbitmq/nodeshutdown.sh ]]; then
                        /opt/bitnami/scripts/rabbitmq/nodeshutdown.sh -t "120" -d "false"
                    else
                        rabbitmqctl stop_app
                    fi
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: MY_POD_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
            - name: MY_POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: MY_POD_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: K8S_SERVICE_NAME
              value: release-name-rabbitmq-headless
            - name: K8S_ADDRESS_TYPE
              value: hostname
            - name: RABBITMQ_FEATURE_FLAGS
              value: drop_unroutable_metric,empty_basic_get_metric,implicit_default_bindings,maintenance_mode_status,quorum_queue,stream_queue,user_limits,virtual_host_metadata
            - name: RABBITMQ_FORCE_BOOT
              value: "no"
            - name: RABBITMQ_NODE_NAME
              value: "rabbit@$(MY_POD_NAME).$(K8S_SERVICE_NAME).$(MY_POD_NAMESPACE).svc.cluster.local"
            - name: K8S_HOSTNAME_SUFFIX
              value: ".$(K8S_SERVICE_NAME).$(MY_POD_NAMESPACE).svc.cluster.local"
            - name: RABBITMQ_MNESIA_DIR
              value: "/bitnami/rabbitmq/mnesia/$(RABBITMQ_NODE_NAME)"
            - name: RABBITMQ_LDAP_ENABLE
              value: "no"
            - name: RABBITMQ_LOGS
              value: "-"
            - name: RABBITMQ_ULIMIT_NOFILES
              value: "65536"
            - name: RABBITMQ_USE_LONGNAME
              value: "true"
            - name: RABBITMQ_ERL_COOKIE
              valueFrom:
                secretKeyRef:
                  name: release-name-rabbitmq
                  key: rabbitmq-erlang-cookie
            - name: RABBITMQ_LOAD_DEFINITIONS
              value: "yes"
            - name: RABBITMQ_DEFINITIONS_FILE
              value: "/app/load_definition.json"
            - name: RABBITMQ_SECURE_PASSWORD
              value: "yes"
            - name: RABBITMQ_USERNAME
              value: "admin"
            - name: RABBITMQ_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: release-name-rabbitmq
                  key: rabbitmq-password
            - name: RABBITMQ_PLUGINS
              value: "rabbitmq_management, rabbitmq_peer_discovery_k8s, rabbitmq_auth_backend_ldap"
            - name: RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS
              value: +S 2:2 +sbwt none +sbwtdcpu none +sbwtdio none
          envFrom:
          ports:
            - name: amqp
              containerPort: 5672
            - name: dist
              containerPort: 25672
            - name: stats
              containerPort: 15672
            - name: epmd
              containerPort: 4369
          livenessProbe:
            failureThreshold: 6
            initialDelaySeconds: 120
            periodSeconds: 30
            successThreshold: 1
            timeoutSeconds: 20
            exec:
              command:
                - /bin/bash
                - -ec
                - rabbitmq-diagnostics -q ping
          readinessProbe:
            failureThreshold: 3
            initialDelaySeconds: 10
            periodSeconds: 30
            successThreshold: 1
            timeoutSeconds: 20
            exec:
              command:
                - /bin/bash
                - -ec
                - rabbitmq-diagnostics -q check_running && rabbitmq-diagnostics -q check_local_alarms
          resources:
            limits: {}
            requests: {}
          volumeMounts:
            - name: configuration
              mountPath: /bitnami/rabbitmq/conf
            - name: data
              mountPath: /bitnami/rabbitmq/mnesia
            - name: load-definition-volume
              mountPath: /app
              readOnly: true
      volumes:
        - name: configuration
          projected:
            sources:
              - secret:
                  name: release-name-rabbitmq-config
        - name: load-definition-volume
          secret:
            secretName: "release-name-load-definition"
  volumeClaimTemplates:
    - metadata:
        name: data
        labels:
          app.kubernetes.io/name: rabbitmq
          app.kubernetes.io/instance: release-name
      spec:
        accessModes:
            - "ReadWriteOnce"
        resources:
          requests:
            storage: "50Gi"
---
# Source: jfrog-platform/charts/xray/templates/xray-statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: release-name-xray
  labels:
    app: xray
    chart: xray-103.94.6
    heritage: Helm
    release: release-name
    component: xray
spec:
  serviceName: "release-name-xray"
  replicas: 1
  updateStrategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app: xray
      release: release-name
      component: xray
  template:
    metadata:
      labels:
        app: xray
        release: release-name
        component: xray
      annotations:
        checksum/xray-unified-secret: 9c4c8765d0a3311974dc438b7dadcad6a8ac0040d88c425e042173460758718a
    spec:
      serviceAccountName: default
      securityContext:
        fsGroup: 1035
        runAsGroup: 1035
        runAsNonRoot: true
        runAsUser: 1035
      initContainers:
      
      - name: postgres-setup-init
        image: "releases-docker.jfrog.io/postgres:15.6-alpine"
        imagePullPolicy: IfNotPresent
        resources: 
                limits:
                  cpu: 1
                  memory: 1Gi
                requests:
                  cpu: 5m
                  memory: 10Mi
        command:
          - '/bin/bash'
          - '-c'
          - >
            echo "Running init db scripts";
            bash /scripts/setupPostgres.sh
        env:
          - name: PGUSERNAME
            value: postgres
          - name: DB_HOST
            value: release-name-postgresql
          - name: DB_PORT
            value: "5432"
          - name: DB_SSL_MODE
            value: "disable"
          - name: DB_NAME
            value: xray
          - name: DB_USERNAME
            valueFrom:
              secretKeyRef:
                name: xray-unified-secret
                key: db-user
          - name: DB_PASSWORD
            valueFrom:
              secretKeyRef:
                name: xray-unified-secret
                key: db-password
          - name: PGPASSWORD
            value: postgres
          - name: CHART_NAME
            value: xray
        volumeMounts:
          - name: postgres-setup-init-vol
            mountPath: "/scripts"
      
      - name: 'copy-system-yaml'
        image: releases-docker.jfrog.io/ubi9/ubi-minimal:9.3.1552
        imagePullPolicy: IfNotPresent
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - NET_RAW
          runAsNonRoot: true
        resources:
          limits:
            cpu: "1"
            memory: 1Gi
          requests:
            cpu: 10m
            memory: 50Mi
        command:
        - 'bash'
        - '-c'
        - >
          if [[ -e "/var/opt/jfrog/xray/etc/filebeat.yaml" ]]; then chmod 644 /var/opt/jfrog/xray/etc/filebeat.yaml; fi;
          echo "Copy system.yaml to /var/opt/jfrog/xray/etc";
          mkdir -p /var/opt/jfrog/xray/etc;
          cp -fv /tmp/etc/system.yaml /var/opt/jfrog/xray/etc/system.yaml;
          echo "Remove /var/opt/jfrog/xray/lost+found folder if exists";
          rm -rfv /var/opt/jfrog/xray/lost+found;
          echo "Copy joinKey to /var/opt/jfrog/xray/etc/security";
          mkdir -p /var/opt/jfrog/xray/etc/security;
          echo ${XRAY_JOIN_KEY} > /var/opt/jfrog/xray/etc/security/join.key;
          echo "Copy masterKey to /var/opt/jfrog/xray/etc/security";
          mkdir -p /var/opt/jfrog/xray/etc/security;
          echo ${XRAY_MASTER_KEY} > /var/opt/jfrog/xray/etc/security/master.key;
        env:
        - name: XRAY_JOIN_KEY
          valueFrom:
            secretKeyRef:
              name: "xray-unified-secret"
              key: join-key
        - name: XRAY_MASTER_KEY
          valueFrom:
            secretKeyRef:
              name: "xray-unified-secret"
              key: master-key
        volumeMounts:
        - name: data-volume
          mountPath: "/var/opt/jfrog/xray"
        - name: xray-unified-secret-volume
          mountPath: "/tmp/etc/system.yaml"
          subPath: system.yaml
      containers:
      - name: router
        image: releases-docker.jfrog.io/jfrog/router:7.108.0
        imagePullPolicy: IfNotPresent
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - NET_RAW
          runAsNonRoot: true
        command:
          - '/bin/sh'
          - '-c'
          - >
            exec /opt/jfrog/router/app/bin/entrypoint-router.sh;
        env:
        - name: JF_ROUTER_TOPOLOGY_LOCAL_REQUIREDSERVICETYPES
          value: jfxr,jfxana,jfxidx,jfxpst,jfob
        ports:
          - name: http-router
            containerPort: 8082
        volumeMounts:
        - name: data-volume
          mountPath: "/var/opt/jfrog/router"
        resources:
          {}
        startupProbe:
          exec:
            command:
              - sh
              - -c
              - curl -s -k --fail --max-time 5 http://localhost:8082/router/api/v1/system/readiness
          initialDelaySeconds: 30
          failureThreshold: 30
          periodSeconds: 5
          timeoutSeconds: 5
          
        livenessProbe:
          exec:
            command:
              - sh
              - -c
              - curl -s -k --fail --max-time 5 http://localhost:8082/router/api/v1/system/liveness
          initialDelaySeconds: 0
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 5
          successThreshold: 1
          
        readinessProbe:
          exec:
            command:
              - sh
              - -c
              - curl -s -k --fail --max-time 5 http://localhost:8082/router/api/v1/system/readiness
          initialDelaySeconds: 0
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 5
          successThreshold: 1
          
      - name: observability
        image: releases-docker.jfrog.io/jfrog/observability:1.25.0
        imagePullPolicy: IfNotPresent
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - NET_RAW
          runAsNonRoot: true
        command:
          - '/bin/sh'
          - '-c'
          - >
            exec /opt/jfrog/observability/app/bin/entrypoint-observability.sh;
        env:
        volumeMounts:
        - name: data-volume
          mountPath: "/var/opt/jfrog/observability"
        resources:
          {}
        startupProbe:
          exec:
            command:
              - sh
              - -c
              - curl --fail --max-time 5 http://localhost:8036/api/v1/system/readiness
          initialDelaySeconds: 30
          failureThreshold: 90
          periodSeconds: 5
          timeoutSeconds: 5
          
        livenessProbe:
          exec:
            command:
              - sh
              - -c
              - curl --fail --max-time 5 http://localhost:8036/api/v1/system/liveness
          initialDelaySeconds: 0
          failureThreshold: 5
          timeoutSeconds: 5
          periodSeconds: 10
          successThreshold: 1
          
      - name: xray-server
        image: releases-docker.jfrog.io/jfrog/xray-server:3.94.6
        imagePullPolicy: IfNotPresent
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - NET_RAW
          runAsNonRoot: true
        command:
          - '/bin/bash'
          - '-c'
          - >
            exec /opt/jfrog/xray/app/bin/wrapper.sh;
        env:
              
        - name: XRAY_CHART_FULL_NAME
          value: 'release-name-xray'
        - name: XRAY_CHART_NAME
          value: 'xray'
        - name: XRAY_CHART_UNIFIED_SECRET_INSTALLATION
          value: "true"
        - name: XRAY_CHART_SYSTEM_YAML_OVERRIDE_EXISTING_SECRET
          value: ""
        - name: XRAY_CHART_SYSTEM_YAML_OVERRIDE_DATA_KEY
          value: ""
              
        - name: JF_SHARED_DATABASE_USERNAME
          valueFrom:
            secretKeyRef:
              name: "xray-unified-secret"
              key: db-user
      
        - name: JF_SHARED_DATABASE_PASSWORD
          valueFrom:
            secretKeyRef:
              name: "xray-unified-secret"
              key: db-password
        - name: JF_SHARED_DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: "xray-unified-secret"
              key: db-url
        - name: XRAY_K8S_ENV
          value: "true"
        - name: EXECUTION_JOB_AES_KEY
          valueFrom:
            secretKeyRef:
              name: "xray-unified-secret"
              key: execution-service-aes-key
        - name: "JF_SHARED_RABBITMQ_VHOST"
          value: "xray"
        
        ports:
        - containerPort: 8000
          name: http-server
        volumeMounts:
        - name: data-volume
          mountPath: "/var/opt/jfrog/xray"
        resources:
          {}
        startupProbe:
          exec:
            command:
              - sh
              - -c
              - curl -s -k --fail --max-time 5 http://localhost:8000/api/v1/system/readiness
          initialDelaySeconds: 30
          failureThreshold: 30
          periodSeconds: 5
          timeoutSeconds: 5
          
        livenessProbe:
          exec:
            command:
              - sh
              - -c
              - curl -s -k --fail --max-time 5 http://localhost:8000/api/v1/system/liveness
          initialDelaySeconds: 0
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
          successThreshold: 1
          
      - name: xray-analysis
        image: releases-docker.jfrog.io/jfrog/xray-analysis:3.94.6
        imagePullPolicy: IfNotPresent
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - NET_RAW
          runAsNonRoot: true
        command:
          - '/bin/bash'
          - '-c'
          - >
            exec /opt/jfrog/xray/app/bin/wrapper.sh;
        env:
              
        - name: XRAY_CHART_FULL_NAME
          value: 'release-name-xray'
        - name: XRAY_CHART_NAME
          value: 'xray'
        - name: XRAY_CHART_UNIFIED_SECRET_INSTALLATION
          value: "true"
        - name: XRAY_CHART_SYSTEM_YAML_OVERRIDE_EXISTING_SECRET
          value: ""
        - name: XRAY_CHART_SYSTEM_YAML_OVERRIDE_DATA_KEY
          value: ""
              
        - name: JF_SHARED_DATABASE_USERNAME
          valueFrom:
            secretKeyRef:
              name: "xray-unified-secret"
              key: db-user
      
        - name: JF_SHARED_DATABASE_PASSWORD
          valueFrom:
            secretKeyRef:
              name: "xray-unified-secret"
              key: db-password
        - name: JF_SHARED_DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: "xray-unified-secret"
              key: db-url
        - name: XRAY_HA_NODE_ID
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: XRAY_K8S_ENV
          value: "true"
        - name: EXECUTION_JOB_AES_KEY
          valueFrom:
            secretKeyRef:
              name: "xray-unified-secret"
              key: execution-service-aes-key
        - name: "JF_SHARED_RABBITMQ_VHOST"
          value: "xray"
        
        ports:
        - containerPort: 7000
          name: http-analysis
        volumeMounts:
        - name: data-volume
          mountPath: "/var/opt/jfrog/xray"
        resources:
          {}
        startupProbe:
          exec:
            command:
              - sh
              - -c
              - curl -s -k --fail --max-time 5 http://localhost:7000/api/v1/system/readiness
          initialDelaySeconds: 30
          failureThreshold: 30
          periodSeconds: 5
          timeoutSeconds: 5
          
        livenessProbe:
          exec:
            command:
              - sh
              - -c
              - curl -s -k --fail --max-time 5 http://localhost:7000/api/v1/system/liveness
          initialDelaySeconds: 0
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
          successThreshold: 1
          
      - name: xray-indexer
        image: releases-docker.jfrog.io/jfrog/xray-indexer:3.94.6
        imagePullPolicy: IfNotPresent
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - NET_RAW
          runAsNonRoot: true
        command:
          - '/bin/bash'
          - '-c'
          - >
            exec /opt/jfrog/xray/app/bin/wrapper.sh;
        env:
              
        - name: XRAY_CHART_FULL_NAME
          value: 'release-name-xray'
        - name: XRAY_CHART_NAME
          value: 'xray'
        - name: XRAY_CHART_UNIFIED_SECRET_INSTALLATION
          value: "true"
        - name: XRAY_CHART_SYSTEM_YAML_OVERRIDE_EXISTING_SECRET
          value: ""
        - name: XRAY_CHART_SYSTEM_YAML_OVERRIDE_DATA_KEY
          value: ""
              
        - name: JF_SHARED_DATABASE_USERNAME
          valueFrom:
            secretKeyRef:
              name: "xray-unified-secret"
              key: db-user
      
        - name: JF_SHARED_DATABASE_PASSWORD
          valueFrom:
            secretKeyRef:
              name: "xray-unified-secret"
              key: db-password
        - name: JF_SHARED_DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: "xray-unified-secret"
              key: db-url
        - name: XRAY_HA_NODE_ID
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: XRAY_K8S_ENV
          value: "true"
        - name: "JF_SHARED_RABBITMQ_VHOST"
          value: "xray"
        
        ports:
        - containerPort: 7002
          name: http-indexer
        volumeMounts:
        - name: data-volume
          mountPath: "/var/opt/jfrog/xray"
        resources:
          {}
        startupProbe:
          exec:
            command:
              - sh
              - -c
              - curl -s -k --fail --max-time 5 http://localhost:7002/api/v1/system/readiness
          initialDelaySeconds: 30
          failureThreshold: 30
          periodSeconds: 5
          timeoutSeconds: 5
          
        livenessProbe:
          exec:
            command:
              - sh
              - -c
              - curl -s -k --fail --max-time 5 http://localhost:7002/api/v1/system/liveness
          initialDelaySeconds: 0
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
          successThreshold: 1
          
      - name: xray-persist
        image: releases-docker.jfrog.io/jfrog/xray-persist:3.94.6
        imagePullPolicy: IfNotPresent
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - NET_RAW
          runAsNonRoot: true
        command:
          - '/bin/bash'
          - '-c'
          - >
            exec /opt/jfrog/xray/app/bin/wrapper.sh;
        env:
              
        - name: XRAY_CHART_FULL_NAME
          value: 'release-name-xray'
        - name: XRAY_CHART_NAME
          value: 'xray'
        - name: XRAY_CHART_UNIFIED_SECRET_INSTALLATION
          value: "true"
        - name: XRAY_CHART_SYSTEM_YAML_OVERRIDE_EXISTING_SECRET
          value: ""
        - name: XRAY_CHART_SYSTEM_YAML_OVERRIDE_DATA_KEY
          value: ""
              
        - name: JF_SHARED_DATABASE_USERNAME
          valueFrom:
            secretKeyRef:
              name: "xray-unified-secret"
              key: db-user
      
        - name: JF_SHARED_DATABASE_PASSWORD
          valueFrom:
            secretKeyRef:
              name: "xray-unified-secret"
              key: db-password
        - name: JF_SHARED_DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: "xray-unified-secret"
              key: db-url
        - name: XRAY_K8S_ENV
          value: "true"
        - name: "JF_SHARED_RABBITMQ_VHOST"
          value: "xray"
        
        ports:
        - containerPort: 7003
          name: http-persist
        volumeMounts:
        - name: data-volume
          mountPath: "/var/opt/jfrog/xray"
        resources:
          {}
        startupProbe:
          exec:
            command:
              - sh
              - -c
              - curl -s -k --fail --max-time 5 http://localhost:7003/api/v1/system/readiness
          initialDelaySeconds: 30
          failureThreshold: 30
          periodSeconds: 5
          timeoutSeconds: 5
          
        livenessProbe:
          exec:
            command:
              - sh
              - -c
              - curl -s -k --fail --max-time 5 http://localhost:7003/api/v1/system/liveness
          initialDelaySeconds: 0
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
          successThreshold: 1
          
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - weight: 100
              podAffinityTerm:
                topologyKey: kubernetes.io/hostname
                labelSelector:
                  matchLabels:
                    app: xray
                    release: release-name
      volumes:
      ########## External secrets ###########
      ############ Config map, Volumes and Custom Volumes ##############
      #########  unifiedSecretInstallation ###########
      - name: xray-unified-secret-volume
        secret:
          secretName: xray-unified-secret
      
      - name: postgres-setup-init-vol
        configMap:
          name: release-name-setup-script
      
  volumeClaimTemplates:
  - metadata:
      name: data-volume
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: 200Gi
---
# Source: jfrog-platform/charts/xray/templates/migration-hook.yaml
---
---
# Source: jfrog-platform/templates/migration-hook.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
    labels:
        app: jfrog-platform
        chart: jfrog-platform-10.18.0
        release: "release-name"
        heritage: "Helm"
    name: release-name-rabbitmq-migration
    annotations:
        helm.sh/hook: "pre-upgrade"
        helm.sh/hook-weight: "-10"
automountServiceAccountToken: true
---
# Source: jfrog-platform/templates/upgrade-hook.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
    labels:
        app: jfrog-platform
        chart: jfrog-platform-10.18.0
        release: "release-name"
        heritage: "Helm"
    name: release-name-jfrog-platform
    annotations:
        helm.sh/hook: "pre-upgrade"
        helm.sh/hook-weight: "-10"
automountServiceAccountToken: true
---
# Source: jfrog-platform/templates/migration-hook.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
    labels:
        app: jfrog-platform
        chart: jfrog-platform-10.18.0
        release: "release-name"
        heritage: "Helm"
    name: release-name-rabbitmq-migration
    annotations:
        helm.sh/hook: "pre-upgrade"
        helm.sh/hook-weight: "-10"
rules:
- apiGroups:
  - ""
  resources:
  - pods/exec
  - pods
  verbs:
  - create
  - get
  - list
---
# Source: jfrog-platform/templates/upgrade-hook.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
    labels:
        app: jfrog-platform
        chart: jfrog-platform-10.18.0
        release: "release-name"
        heritage: "Helm"
    name: release-name-jfrog-platform
    annotations:
        helm.sh/hook: "pre-upgrade"
        helm.sh/hook-weight: "-10"
rules:
- apiGroups:
    - ""
  resources:
    - pods/exec
    - pods
  verbs:
    - create
    - get
    - list
---
# Source: jfrog-platform/templates/migration-hook.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
    labels:
        app: jfrog-platform
        chart: jfrog-platform-10.18.0
        release: "release-name"
        heritage: "Helm"
    name: release-name-rabbitmq-migration
    annotations:
        helm.sh/hook: "pre-upgrade"
        helm.sh/hook-weight: "-10"
subjects:
    - kind: ServiceAccount
      name: release-name-rabbitmq-migration
roleRef:
    kind: Role
    apiGroup: rbac.authorization.k8s.io
    name: release-name-rabbitmq-migration
---
# Source: jfrog-platform/templates/upgrade-hook.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
    labels:
        app: jfrog-platform
        chart: jfrog-platform-10.18.0
        release: "release-name"
        heritage: "Helm"
    name: release-name-jfrog-platform
    annotations:
        helm.sh/hook: "pre-upgrade"
        helm.sh/hook-weight: "-10"
subjects:
    - kind: ServiceAccount
      name: release-name-jfrog-platform
roleRef:
    kind: Role
    apiGroup: rbac.authorization.k8s.io
    name: release-name-jfrog-platform
---
# Source: jfrog-platform/templates/migration-hook.yaml
apiVersion: batch/v1
kind: Job
metadata:
  labels:
    app: jfrog-platform
    chart: jfrog-platform-10.18.0
    heritage: Helm
    release: release-name
  name: release-name-jfrog-platform-pre-upgrade-hook
  annotations:
    "helm.sh/hook": "pre-upgrade"
    "helm.sh/hook-delete-policy": before-hook-creation,hook-succeeded
spec:
  template:
    metadata:
      labels:
        app: jfrog-platform
        chart: jfrog-platform-10.18.0
        heritage: Helm
        release: release-name
    spec:
      serviceAccountName: release-name-rabbitmq-migration
      securityContext:
        fsGroup: 1001
      containers:
        - name: pre-upgrade-container
          image: "releases-docker.jfrog.io/bitnami/kubectl:1.24.12"
          imagePullPolicy: IfNotPresent
          resources:
            limits:
              cpu: 1
              memory: 1Gi
            requests:
              cpu: 5m
              memory: 10Mi
          securityContext:
            runAsNonRoot: true
            runAsUser: 1001
          command:
            - sh
            - -c
            - |
                #!/bin/sh
                if [ "$(kubectl get pods -l "app.kubernetes.io/name=rabbitmq" -o jsonpath='{..status.conditions[?(@.type=="Ready")].status}')" = "True" ]; then
                    kubectl exec -it release-name-rabbitmq-0 -- rabbitmqctl enable_feature_flag all
                    if [ "$?" -ne 0 ]; then
                      echo "Failed to perform the migration. Please make sure to enable the feature flag in rabbitmq manually [rabbitmqctl enable_feature_flag all] "
                      exit 1
                    else
                      echo Feature flags executed successfully!
                    fi
                else
                    echo "Rabbitmq pod is not in running state. Ignoring feature flag migration for rabbitmq"
                fi
      restartPolicy: Never
      terminationGracePeriodSeconds: 0
---
# Source: jfrog-platform/templates/upgrade-hook.yaml
apiVersion: batch/v1
kind: Job
metadata:
  labels:
    app: jfrog-platform
    chart: jfrog-platform-10.18.0
    heritage: Helm
    release: release-name
  name: release-name-jfrog-platform-pre-upgrade-check
  annotations:
    "helm.sh/hook": "pre-upgrade"
    "helm.sh/hook-delete-policy": "before-hook-creation,hook-succeeded"
spec:
  backoffLimit: 0
  template:
    metadata:
      labels:
        app: jfrog-platform
        chart: jfrog-platform-10.18.0
        heritage: Helm
        release: release-name
    spec:
      serviceAccountName: release-name-jfrog-platform
      containers:
        - name: pre-upgrade-check
          image: "releases-docker.jfrog.io/bitnami/kubectl:1.24.12"
          imagePullPolicy: IfNotPresent
          resources:
            limits:
              cpu: 1
              memory: 1Gi
            requests:
              cpu: 5m
              memory: 10Mi
          command:
            - sh
            - -c
            - |
                #!/bin/sh
                if [ "$(kubectl get pods -l "statefulset.kubernetes.io/pod-name=release-name-distribution-0" -o jsonpath='{..status.conditions[?(@.type=="Ready")].status}')" = "True" ]; then
                    if [ "$?" -eq 0 ]; then
                      echo "Failed to perform the upgrade. Refer to https://github.com/jfrog/charts/blob/master/stable/jfrog-platform/CHANGELOG.md#10180"
                      echo "From chart verison 10.18.x, Products - Distribution, Insight and Pipelines are disabled. If you are using these products in the previous release(s)."
                      echo "Enable them using your custom-values.yaml file "
                      exit 1
                    fi
                else
                    echo "Distribution pod(s) don't exist. Allowing upgrade"
                fi
                if [ "$(kubectl get pods -l "statefulset.kubernetes.io/pod-name=release-name-insight-0" -o jsonpath='{..status.conditions[?(@.type=="Ready")].status}')" = "True" ]; then
                    if [ "$?" -eq 0 ]; then
                      echo "Failed to perform the upgrade. Refer to https://github.com/jfrog/charts/blob/master/stable/jfrog-platform/CHANGELOG.md#10180"
                      echo "From chart verison 10.18.x, Products - Distribution, Insight and Pipelines are disabled. If you are using these products in the previous release(s)."
                      echo "Enable them using your custom-values.yaml file "
                      exit 1
                    fi
                else
                    echo "Insight pod(s) don't exist. Allowing upgrade"
                fi
                if [ "$(kubectl get pods -l "statefulset.kubernetes.io/pod-name=release-name-pipelines-0" -o jsonpath='{..status.conditions[?(@.type=="Ready")].status}')" = "True" ]; then
                    if [ "$?" -eq 0 ]; then
                      echo "Failed to perform the upgrade. Refer to https://github.com/jfrog/charts/blob/master/stable/jfrog-platform/CHANGELOG.md#10180"
                      echo "From chart verison 10.18.x, Products - Distribution, Insight and Pipelines are disabled. If you are using these products in the previous release(s)."
                      echo "Enable them using your custom-values.yaml file "
                      exit 1
                    fi
                else
                    echo "Pipelines pod(s) don't exist. Allowing upgrade"
                fi
      restartPolicy: Never
      terminationGracePeriodSeconds: 10
