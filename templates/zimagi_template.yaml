---
# Source: zimagi/charts/redis/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
automountServiceAccountToken: true
metadata:
  name: redis
  namespace: "default"
  labels:
    app.kubernetes.io/name: redis
    helm.sh/chart: redis-17.11.3
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
---
# Source: zimagi/templates/app.yaml
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: "worker"
  namespace: "default"
  labels:
    helm.sh/chart: "zimagi-2.5.32"
    app.kubernetes.io/version: "0.13.32"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: "zimagi"
    app.kubernetes.io/instance: "release-name"
    app.kubernetes.io/component: "worker"
    
  annotations:
    nginx.ingress.kubernetes.io/proxy-connect-timeout: "30"
---
# Source: zimagi/templates/app.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: "command-api"
  namespace: "default"
  labels:
    helm.sh/chart: "zimagi-2.5.32"
    app.kubernetes.io/version: "0.13.32"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: "zimagi"
    app.kubernetes.io/instance: "release-name"
    app.kubernetes.io/component: "command-api"
    
  annotations:
    nginx.ingress.kubernetes.io/proxy-connect-timeout: "30"
    nginx.ingress.kubernetes.io/proxy-read-timeout: "86400"
---
# Source: zimagi/templates/app.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: "controller"
  namespace: "default"
  labels:
    helm.sh/chart: "zimagi-2.5.32"
    app.kubernetes.io/version: "0.13.32"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: "zimagi"
    app.kubernetes.io/instance: "release-name"
    app.kubernetes.io/component: "controller"
    
  annotations:
    nginx.ingress.kubernetes.io/proxy-connect-timeout: "30"
---
# Source: zimagi/templates/app.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: "data-api"
  namespace: "default"
  labels:
    helm.sh/chart: "zimagi-2.5.32"
    app.kubernetes.io/version: "0.13.32"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: "zimagi"
    app.kubernetes.io/instance: "release-name"
    app.kubernetes.io/component: "data-api"
    
  annotations:
    nginx.ingress.kubernetes.io/proxy-connect-timeout: "30"
    nginx.ingress.kubernetes.io/proxy-read-timeout: "600"
---
# Source: zimagi/templates/app.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: "scheduler"
  namespace: "default"
  labels:
    helm.sh/chart: "zimagi-2.5.32"
    app.kubernetes.io/version: "0.13.32"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: "zimagi"
    app.kubernetes.io/instance: "release-name"
    app.kubernetes.io/component: "scheduler"
    
  annotations:
    nginx.ingress.kubernetes.io/proxy-connect-timeout: "30"
---
# Source: zimagi/templates/app.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: "tasks"
  namespace: "default"
  labels:
    helm.sh/chart: "zimagi-2.5.32"
    app.kubernetes.io/version: "0.13.32"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: "zimagi"
    app.kubernetes.io/instance: "release-name"
    app.kubernetes.io/component: "tasks"
    
  annotations:
    nginx.ingress.kubernetes.io/proxy-connect-timeout: "30"
---
# Source: zimagi/charts/redis/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: redis-configuration
  namespace: "default"
  labels:
    app.kubernetes.io/name: redis
    helm.sh/chart: redis-17.11.3
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
data:
  redis.conf: |-
    # User-supplied common configuration:
    # Enable AOF https://redis.io/topics/persistence#append-only-file
    appendonly yes
    # Disable RDB persistence, AOF persistence already enabled.
    save ""
    # End of common configuration
  master.conf: |-
    dir /data
    # User-supplied master configuration:
    rename-command FLUSHDB ""
    rename-command FLUSHALL ""
    # End of master configuration
  replica.conf: |-
    dir /data
    # User-supplied replica configuration:
    rename-command FLUSHDB ""
    rename-command FLUSHALL ""
    # End of replica configuration
---
# Source: zimagi/charts/redis/templates/health-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: redis-health
  namespace: "default"
  labels:
    app.kubernetes.io/name: redis
    helm.sh/chart: redis-17.11.3
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
data:
  ping_readiness_local.sh: |-
    #!/bin/bash

    [[ -f $REDIS_PASSWORD_FILE ]] && export REDIS_PASSWORD="$(< "${REDIS_PASSWORD_FILE}")"
    [[ -n "$REDIS_PASSWORD" ]] && export REDISCLI_AUTH="$REDIS_PASSWORD"
    response=$(
      timeout -s 15 $1 \
      redis-cli \
        -h localhost \
        -p $REDIS_PORT \
        ping
    )
    if [ "$?" -eq "124" ]; then
      echo "Timed out"
      exit 1
    fi
    if [ "$response" != "PONG" ]; then
      echo "$response"
      exit 1
    fi
  ping_liveness_local.sh: |-
    #!/bin/bash

    [[ -f $REDIS_PASSWORD_FILE ]] && export REDIS_PASSWORD="$(< "${REDIS_PASSWORD_FILE}")"
    [[ -n "$REDIS_PASSWORD" ]] && export REDISCLI_AUTH="$REDIS_PASSWORD"
    response=$(
      timeout -s 15 $1 \
      redis-cli \
        -h localhost \
        -p $REDIS_PORT \
        ping
    )
    if [ "$?" -eq "124" ]; then
      echo "Timed out"
      exit 1
    fi
    responseFirstWord=$(echo $response | head -n1 | awk '{print $1;}')
    if [ "$response" != "PONG" ] && [ "$responseFirstWord" != "LOADING" ] && [ "$responseFirstWord" != "MASTERDOWN" ]; then
      echo "$response"
      exit 1
    fi
  ping_readiness_master.sh: |-
    #!/bin/bash

    [[ -f $REDIS_MASTER_PASSWORD_FILE ]] && export REDIS_MASTER_PASSWORD="$(< "${REDIS_MASTER_PASSWORD_FILE}")"
    [[ -n "$REDIS_MASTER_PASSWORD" ]] && export REDISCLI_AUTH="$REDIS_MASTER_PASSWORD"
    response=$(
      timeout -s 15 $1 \
      redis-cli \
        -h $REDIS_MASTER_HOST \
        -p $REDIS_MASTER_PORT_NUMBER \
        ping
    )
    if [ "$?" -eq "124" ]; then
      echo "Timed out"
      exit 1
    fi
    if [ "$response" != "PONG" ]; then
      echo "$response"
      exit 1
    fi
  ping_liveness_master.sh: |-
    #!/bin/bash

    [[ -f $REDIS_MASTER_PASSWORD_FILE ]] && export REDIS_MASTER_PASSWORD="$(< "${REDIS_MASTER_PASSWORD_FILE}")"
    [[ -n "$REDIS_MASTER_PASSWORD" ]] && export REDISCLI_AUTH="$REDIS_MASTER_PASSWORD"
    response=$(
      timeout -s 15 $1 \
      redis-cli \
        -h $REDIS_MASTER_HOST \
        -p $REDIS_MASTER_PORT_NUMBER \
        ping
    )
    if [ "$?" -eq "124" ]; then
      echo "Timed out"
      exit 1
    fi
    responseFirstWord=$(echo $response | head -n1 | awk '{print $1;}')
    if [ "$response" != "PONG" ] && [ "$responseFirstWord" != "LOADING" ]; then
      echo "$response"
      exit 1
    fi
  ping_readiness_local_and_master.sh: |-
    script_dir="$(dirname "$0")"
    exit_status=0
    "$script_dir/ping_readiness_local.sh" $1 || exit_status=$?
    "$script_dir/ping_readiness_master.sh" $1 || exit_status=$?
    exit $exit_status
  ping_liveness_local_and_master.sh: |-
    script_dir="$(dirname "$0")"
    exit_status=0
    "$script_dir/ping_liveness_local.sh" $1 || exit_status=$?
    "$script_dir/ping_liveness_master.sh" $1 || exit_status=$?
    exit $exit_status
---
# Source: zimagi/charts/redis/templates/scripts-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: redis-scripts
  namespace: "default"
  labels:
    app.kubernetes.io/name: redis
    helm.sh/chart: redis-17.11.3
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
data:
  start-master.sh: |
    #!/bin/bash

    [[ -f $REDIS_PASSWORD_FILE ]] && export REDIS_PASSWORD="$(< "${REDIS_PASSWORD_FILE}")"
    if [[ -f /opt/bitnami/redis/mounted-etc/master.conf ]];then
        cp /opt/bitnami/redis/mounted-etc/master.conf /opt/bitnami/redis/etc/master.conf
    fi
    if [[ -f /opt/bitnami/redis/mounted-etc/redis.conf ]];then
        cp /opt/bitnami/redis/mounted-etc/redis.conf /opt/bitnami/redis/etc/redis.conf
    fi
    ARGS=("--port" "${REDIS_PORT}")
    ARGS+=("--requirepass" "${REDIS_PASSWORD}")
    ARGS+=("--masterauth" "${REDIS_PASSWORD}")
    ARGS+=("--include" "/opt/bitnami/redis/etc/redis.conf")
    ARGS+=("--include" "/opt/bitnami/redis/etc/master.conf")
    exec redis-server "${ARGS[@]}"
---
# Source: zimagi/templates/app.yaml
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: "files"
  namespace: "default"
  labels:
    helm.sh/chart: "zimagi-2.5.32"
    app.kubernetes.io/version: "0.13.32"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: "zimagi"
    app.kubernetes.io/instance: "release-name"
    app.kubernetes.io/component: "files"
    
  annotations:
    nginx.ingress.kubernetes.io/proxy-connect-timeout: "30"
    
spec:
  storageClassName: "nfs"
  accessModes:
    - "ReadWriteMany"
  resources:
    requests:
      storage: "10Gi"
---
# Source: zimagi/templates/app.yaml
kind: Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: "agent-executor"
  namespace: "default"
  labels:
    helm.sh/chart: "zimagi-2.5.32"
    app.kubernetes.io/version: "0.13.32"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: "zimagi"
    app.kubernetes.io/instance: "release-name"
    app.kubernetes.io/component: "agent-executor"
    
  annotations:
    nginx.ingress.kubernetes.io/proxy-connect-timeout: "30"
    
rules:
  - apiGroups: 
      - apps
    nonResourceURLs: 
      []
    resourceNames: 
      []
    resources: 
      - deployments
    verbs: 
      - get
      - list
      - create
      - delete
---
# Source: zimagi/templates/app.yaml
kind: Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: "job-executor"
  namespace: "default"
  labels:
    helm.sh/chart: "zimagi-2.5.32"
    app.kubernetes.io/version: "0.13.32"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: "zimagi"
    app.kubernetes.io/instance: "release-name"
    app.kubernetes.io/component: "job-executor"
    
  annotations:
    nginx.ingress.kubernetes.io/proxy-connect-timeout: "30"
    
rules:
  - apiGroups: 
      - batch
    nonResourceURLs: 
      []
    resourceNames: 
      []
    resources: 
      - jobs
    verbs: 
      - get
      - list
      - create
      - delete
---
# Source: zimagi/templates/app.yaml
kind: Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: "pod-accessor"
  namespace: "default"
  labels:
    helm.sh/chart: "zimagi-2.5.32"
    app.kubernetes.io/version: "0.13.32"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: "zimagi"
    app.kubernetes.io/instance: "release-name"
    app.kubernetes.io/component: "pod-accessor"
    
  annotations:
    nginx.ingress.kubernetes.io/proxy-connect-timeout: "30"
    
rules:
  - apiGroups: 
      - ""
    nonResourceURLs: 
      []
    resourceNames: 
      []
    resources: 
      - pods
    verbs: 
      - get
---
# Source: zimagi/templates/app.yaml
kind: Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: "scheduler-config-updater"
  namespace: "default"
  labels:
    helm.sh/chart: "zimagi-2.5.32"
    app.kubernetes.io/version: "0.13.32"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: "zimagi"
    app.kubernetes.io/instance: "release-name"
    app.kubernetes.io/component: "scheduler-config-updater"
    
  annotations:
    nginx.ingress.kubernetes.io/proxy-connect-timeout: "30"
    
rules:
  - apiGroups: 
      - ""
    nonResourceURLs: 
      []
    resourceNames: 
      - scheduler
    resources: 
      - configmaps
    verbs: 
      - get
      - patch
---
# Source: zimagi/templates/app.yaml
kind: Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: "service-config-updater"
  namespace: "default"
  labels:
    helm.sh/chart: "zimagi-2.5.32"
    app.kubernetes.io/version: "0.13.32"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: "zimagi"
    app.kubernetes.io/instance: "release-name"
    app.kubernetes.io/component: "service-config-updater"
    
  annotations:
    nginx.ingress.kubernetes.io/proxy-connect-timeout: "30"
    
rules:
  - apiGroups: 
      - ""
    nonResourceURLs: 
      []
    resourceNames: 
      - command-api
      - data-api
    resources: 
      - configmaps
    verbs: 
      - get
      - patch
---
# Source: zimagi/templates/app.yaml
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: "worker-scheduler-config-updater"
  namespace: "default"
  labels:
    helm.sh/chart: "zimagi-2.5.32"
    app.kubernetes.io/version: "0.13.32"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: "zimagi"
    app.kubernetes.io/instance: "release-name"
    app.kubernetes.io/component: "worker-scheduler-config-updater"
    
  annotations:
    nginx.ingress.kubernetes.io/proxy-connect-timeout: "30"
    
subjects:
  - kind: ServiceAccount
    namespace: "default"
    name: "worker"
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: "scheduler-config-updater"
---
# Source: zimagi/templates/app.yaml
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: "command-api-scheduler-config-updater"
  namespace: "default"
  labels:
    helm.sh/chart: "zimagi-2.5.32"
    app.kubernetes.io/version: "0.13.32"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: "zimagi"
    app.kubernetes.io/instance: "release-name"
    app.kubernetes.io/component: "command-api-scheduler-config-updater"
    
  annotations:
    nginx.ingress.kubernetes.io/proxy-connect-timeout: "30"
    nginx.ingress.kubernetes.io/proxy-read-timeout: "86400"
    
subjects:
  - kind: ServiceAccount
    namespace: "default"
    name: "command-api"
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: "scheduler-config-updater"
---
# Source: zimagi/templates/app.yaml
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: "controller-pod-accessor"
  namespace: "default"
  labels:
    helm.sh/chart: "zimagi-2.5.32"
    app.kubernetes.io/version: "0.13.32"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: "zimagi"
    app.kubernetes.io/instance: "release-name"
    app.kubernetes.io/component: "controller-pod-accessor"
    
  annotations:
    nginx.ingress.kubernetes.io/proxy-connect-timeout: "30"
    
subjects:
  - kind: ServiceAccount
    namespace: "default"
    name: "controller"
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: "pod-accessor"
---
# Source: zimagi/templates/app.yaml
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: "controller-agent-executor"
  namespace: "default"
  labels:
    helm.sh/chart: "zimagi-2.5.32"
    app.kubernetes.io/version: "0.13.32"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: "zimagi"
    app.kubernetes.io/instance: "release-name"
    app.kubernetes.io/component: "controller-agent-executor"
    
  annotations:
    nginx.ingress.kubernetes.io/proxy-connect-timeout: "30"
    
subjects:
  - kind: ServiceAccount
    namespace: "default"
    name: "controller"
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: "agent-executor"
---
# Source: zimagi/templates/app.yaml
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: "scheduler-service-config-updater"
  namespace: "default"
  labels:
    helm.sh/chart: "zimagi-2.5.32"
    app.kubernetes.io/version: "0.13.32"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: "zimagi"
    app.kubernetes.io/instance: "release-name"
    app.kubernetes.io/component: "scheduler-service-config-updater"
    
  annotations:
    nginx.ingress.kubernetes.io/proxy-connect-timeout: "30"
    
subjects:
  - kind: ServiceAccount
    namespace: "default"
    name: "scheduler"
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: "service-config-updater"
---
# Source: zimagi/charts/postgresql/templates/primary/svc-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: postgresql-hl
  namespace: "default"
  labels:
    app.kubernetes.io/name: postgresql
    helm.sh/chart: postgresql-12.5.6
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: primary
    # Use this annotation in addition to the actual publishNotReadyAddresses
    # field below because the annotation will stop being respected soon but the
    # field is broken in some versions of Kubernetes:
    # https://github.com/kubernetes/kubernetes/issues/58662
    service.alpha.kubernetes.io/tolerate-unready-endpoints: "true"
spec:
  type: ClusterIP
  clusterIP: None
  # We want all pods in the StatefulSet to have their addresses published for
  # the sake of the other Postgresql pods even before they're ready, since they
  # have to be able to talk to each other in order to become ready.
  publishNotReadyAddresses: true
  ports:
    - name: tcp-postgresql
      port: 5432
      targetPort: tcp-postgresql
  selector:
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/component: primary
---
# Source: zimagi/charts/postgresql/templates/primary/svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: postgresql
  namespace: "default"
  labels:
    app.kubernetes.io/name: postgresql
    helm.sh/chart: postgresql-12.5.6
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: primary
spec:
  type: ClusterIP
  sessionAffinity: None
  ports:
    - name: tcp-postgresql
      port: 5432
      targetPort: tcp-postgresql
      nodePort: null
  selector:
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/component: primary
---
# Source: zimagi/charts/redis/templates/headless-svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: redis-headless
  namespace: "default"
  labels:
    app.kubernetes.io/name: redis
    helm.sh/chart: redis-17.11.3
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
  annotations:
    
spec:
  type: ClusterIP
  clusterIP: None
  ports:
    - name: tcp-redis
      port: 6379
      targetPort: redis
  selector:
    app.kubernetes.io/name: redis
    app.kubernetes.io/instance: release-name
---
# Source: zimagi/charts/redis/templates/master/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: redis-master
  namespace: "default"
  labels:
    app.kubernetes.io/name: redis
    helm.sh/chart: redis-17.11.3
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: master
spec:
  type: ClusterIP
  internalTrafficPolicy: Cluster
  sessionAffinity: None
  ports:
    - name: tcp-redis
      port: 6379
      targetPort: redis
      nodePort: null
  selector:
    app.kubernetes.io/name: redis
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/component: master
---
# Source: zimagi/templates/app.yaml
apiVersion: v1
kind: Service
metadata:
  name: "command-api"
  namespace: "default"
  labels:
    helm.sh/chart: "zimagi-2.5.32"
    app.kubernetes.io/version: "0.13.32"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: "zimagi"
    app.kubernetes.io/instance: "release-name"
    app.kubernetes.io/component: "command-api"
    
  annotations:
    nginx.ingress.kubernetes.io/proxy-connect-timeout: "30"
    nginx.ingress.kubernetes.io/proxy-read-timeout: "86400"
    
spec:
  type: ClusterIP
  ports:
    - name: "command-api"
      protocol: TCP
      targetPort: 5000
      port: 80
  selector:
    app.kubernetes.io/name: "zimagi"
    app.kubernetes.io/instance: "release-name"
    app.kubernetes.io/component: "command-api"
---
# Source: zimagi/templates/app.yaml
apiVersion: v1
kind: Service
metadata:
  name: "data-api"
  namespace: "default"
  labels:
    helm.sh/chart: "zimagi-2.5.32"
    app.kubernetes.io/version: "0.13.32"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: "zimagi"
    app.kubernetes.io/instance: "release-name"
    app.kubernetes.io/component: "data-api"
    
  annotations:
    nginx.ingress.kubernetes.io/proxy-connect-timeout: "30"
    nginx.ingress.kubernetes.io/proxy-read-timeout: "600"
    
spec:
  type: ClusterIP
  ports:
    - name: "data-api"
      protocol: TCP
      targetPort: 5000
      port: 80
  selector:
    app.kubernetes.io/name: "zimagi"
    app.kubernetes.io/instance: "release-name"
    app.kubernetes.io/component: "data-api"
---
# Source: zimagi/templates/app.yaml
apiVersion: v1
kind: Service
metadata:
  name: "tasks"
  namespace: "default"
  labels:
    helm.sh/chart: "zimagi-2.5.32"
    app.kubernetes.io/version: "0.13.32"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: "zimagi"
    app.kubernetes.io/instance: "release-name"
    app.kubernetes.io/component: "tasks"
    
  annotations:
    nginx.ingress.kubernetes.io/proxy-connect-timeout: "30"
    
spec:
  type: ClusterIP
  ports:
    - name: "tasks"
      protocol: TCP
      targetPort: 5000
      port: 80
  selector:
    app.kubernetes.io/name: "zimagi"
    app.kubernetes.io/instance: "release-name"
    app.kubernetes.io/component: "tasks"
---
# Source: zimagi/templates/app.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: "command-api"
  namespace: "default"
  labels:
    helm.sh/chart: "zimagi-2.5.32"
    app.kubernetes.io/version: "0.13.32"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: "zimagi"
    app.kubernetes.io/instance: "release-name"
    app.kubernetes.io/component: "command-api"
    
  annotations:
    nginx.ingress.kubernetes.io/proxy-connect-timeout: "30"
    nginx.ingress.kubernetes.io/proxy-read-timeout: "86400"
    
spec:
  replicas: 1
  revisionHistoryLimit: 1
  strategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/name: "zimagi"
      app.kubernetes.io/instance: "release-name"
      app.kubernetes.io/component: "command-api"
  template:
    metadata:
      labels:
        helm.sh/chart: "zimagi-2.5.32"
        app.kubernetes.io/version: "0.13.32"
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: "zimagi"
        app.kubernetes.io/instance: "release-name"
        app.kubernetes.io/component: "command-api"
        
    spec:
      serviceAccountName: "command-api"
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: zimagi
                    app.kubernetes.io/instance: release-name
                    app.kubernetes.io/component: command-api
                topologyKey: kubernetes.io/hostname
              weight: 1
      containers:
        - name: command-api
          image: "registry.hub.docker.com/zimagi/zimagi:0.13.32"
          imagePullPolicy: IfNotPresent
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          command:
            - zimagi-command
          env:
            - name: KUBERNETES_POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: KUBERNETES_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: KUBERNETES_POD_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
            - name: KUBERNETES_NODE_NAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
            - name: KUBERNETES_SERVICE_ACCOUNT
              valueFrom:
                fieldRef:
                  fieldPath: spec.serviceAccountName
            - name: KUBERNETES_CONTAINER_CPU_REQUEST_MILLICORES
              valueFrom:
                resourceFieldRef:
                  resource: requests.cpu
                  divisor: 1m
            - name: KUBERNETES_CONTAINER_MEMORY_LIMIT_KILOBYTES
              valueFrom:
                resourceFieldRef:
                  resource: limits.memory
                  divisor: 1Ki
            - name: KUBERNETES_WORKER_SERVICE_ACCOUNT
              value: "worker"
            - name: ZIMAGI_POSTGRES_DB
              value: "zimagi"
            - name: ZIMAGI_POSTGRES_HOST
              value: "postgresql"
            - name: ZIMAGI_POSTGRES_PORT
              value: "5432"
            - name: ZIMAGI_POSTGRES_USER
              value: "zimagi"
            - name: ZIMAGI_REDIS_HOST
              value: "redis-master"
            - name: ZIMAGI_REDIS_PORT
              value: "6379"
            - name: ZIMAGI_WORKER_PROVIDER
              value: "kubernetes"
          envFrom:
            - configMapRef:
                name: global
            - configMapRef:
                name: command-api
            - secretRef:
                name: global
            
          ports:
            - name: gateway
              containerPort: 5000
          readinessProbe:
            failureThreshold: 3
            initialDelaySeconds: 10
            periodSeconds: 5
            successThreshold: 3
            timeoutSeconds: 5
            httpGet:
              scheme: HTTP
              port: 5000
              path: /status
          livenessProbe:
            failureThreshold: 20
            initialDelaySeconds: 5
            periodSeconds: 6
            successThreshold: 1
            timeoutSeconds: 5
            httpGet:
              scheme: HTTP
              port: 5000
              path: /status
          volumeMounts:
            - mountPath: /usr/local/lib/zimagi/files
              name: files
      volumes:
        - name: files
          persistentVolumeClaim:
            claimName: files
---
# Source: zimagi/templates/app.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: "controller"
  namespace: "default"
  labels:
    helm.sh/chart: "zimagi-2.5.32"
    app.kubernetes.io/version: "0.13.32"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: "zimagi"
    app.kubernetes.io/instance: "release-name"
    app.kubernetes.io/component: "controller"
    
  annotations:
    nginx.ingress.kubernetes.io/proxy-connect-timeout: "30"
    
spec:
  replicas: 1
  revisionHistoryLimit: 1
  strategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/name: "zimagi"
      app.kubernetes.io/instance: "release-name"
      app.kubernetes.io/component: "controller"
  template:
    metadata:
      labels:
        helm.sh/chart: "zimagi-2.5.32"
        app.kubernetes.io/version: "0.13.32"
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: "zimagi"
        app.kubernetes.io/instance: "release-name"
        app.kubernetes.io/component: "controller"
        
    spec:
      serviceAccountName: "controller"
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: zimagi
                    app.kubernetes.io/instance: release-name
                    app.kubernetes.io/component: controller
                topologyKey: kubernetes.io/hostname
              weight: 1
      containers:
        - name: controller
          image: "registry.hub.docker.com/zimagi/zimagi:0.13.32"
          imagePullPolicy: IfNotPresent
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          command:
            - zimagi-controller
          env:
            - name: KUBERNETES_POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: KUBERNETES_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: KUBERNETES_POD_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
            - name: KUBERNETES_NODE_NAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
            - name: KUBERNETES_SERVICE_ACCOUNT
              valueFrom:
                fieldRef:
                  fieldPath: spec.serviceAccountName
            - name: KUBERNETES_CONTAINER_CPU_REQUEST_MILLICORES
              valueFrom:
                resourceFieldRef:
                  resource: requests.cpu
                  divisor: 1m
            - name: KUBERNETES_CONTAINER_MEMORY_LIMIT_KILOBYTES
              valueFrom:
                resourceFieldRef:
                  resource: limits.memory
                  divisor: 1Ki
            - name: KUBERNETES_WORKER_SERVICE_ACCOUNT
              value: "worker"
            - name: ZIMAGI_POSTGRES_DB
              value: "zimagi"
            - name: ZIMAGI_POSTGRES_HOST
              value: "postgresql"
            - name: ZIMAGI_POSTGRES_PORT
              value: "5432"
            - name: ZIMAGI_POSTGRES_USER
              value: "zimagi"
            - name: ZIMAGI_REDIS_HOST
              value: "redis-master"
            - name: ZIMAGI_REDIS_PORT
              value: "6379"
            - name: ZIMAGI_WORKER_PROVIDER
              value: "kubernetes"
          envFrom:
            - configMapRef:
                name: global
            - configMapRef:
                name: controller
            - secretRef:
                name: global
            
          volumeMounts:
            - mountPath: /usr/local/lib/zimagi/files
              name: files
      volumes:
        - name: files
          persistentVolumeClaim:
            claimName: files
---
# Source: zimagi/templates/app.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: "data-api"
  namespace: "default"
  labels:
    helm.sh/chart: "zimagi-2.5.32"
    app.kubernetes.io/version: "0.13.32"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: "zimagi"
    app.kubernetes.io/instance: "release-name"
    app.kubernetes.io/component: "data-api"
    
  annotations:
    nginx.ingress.kubernetes.io/proxy-connect-timeout: "30"
    nginx.ingress.kubernetes.io/proxy-read-timeout: "600"
    
spec:
  replicas: 1
  revisionHistoryLimit: 1
  strategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/name: "zimagi"
      app.kubernetes.io/instance: "release-name"
      app.kubernetes.io/component: "data-api"
  template:
    metadata:
      labels:
        helm.sh/chart: "zimagi-2.5.32"
        app.kubernetes.io/version: "0.13.32"
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: "zimagi"
        app.kubernetes.io/instance: "release-name"
        app.kubernetes.io/component: "data-api"
        
    spec:
      serviceAccountName: "data-api"
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: zimagi
                    app.kubernetes.io/instance: release-name
                    app.kubernetes.io/component: data-api
                topologyKey: kubernetes.io/hostname
              weight: 1
      containers:
        - name: data-api
          image: "registry.hub.docker.com/zimagi/zimagi:0.13.32"
          imagePullPolicy: IfNotPresent
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          command:
            - zimagi-data
          env:
            - name: KUBERNETES_POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: KUBERNETES_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: KUBERNETES_POD_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
            - name: KUBERNETES_NODE_NAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
            - name: KUBERNETES_SERVICE_ACCOUNT
              valueFrom:
                fieldRef:
                  fieldPath: spec.serviceAccountName
            - name: KUBERNETES_CONTAINER_CPU_REQUEST_MILLICORES
              valueFrom:
                resourceFieldRef:
                  resource: requests.cpu
                  divisor: 1m
            - name: KUBERNETES_CONTAINER_MEMORY_LIMIT_KILOBYTES
              valueFrom:
                resourceFieldRef:
                  resource: limits.memory
                  divisor: 1Ki
            - name: KUBERNETES_WORKER_SERVICE_ACCOUNT
              value: "worker"
            - name: ZIMAGI_POSTGRES_DB
              value: "zimagi"
            - name: ZIMAGI_POSTGRES_HOST
              value: "postgresql"
            - name: ZIMAGI_POSTGRES_PORT
              value: "5432"
            - name: ZIMAGI_POSTGRES_USER
              value: "zimagi"
            - name: ZIMAGI_REDIS_HOST
              value: "redis-master"
            - name: ZIMAGI_REDIS_PORT
              value: "6379"
            - name: ZIMAGI_WORKER_PROVIDER
              value: "kubernetes"
          envFrom:
            - configMapRef:
                name: global
            - configMapRef:
                name: data-api
            - secretRef:
                name: global
            
          ports:
            - name: gateway
              containerPort: 5000
          readinessProbe:
            failureThreshold: 3
            initialDelaySeconds: 10
            periodSeconds: 5
            successThreshold: 3
            timeoutSeconds: 5
            httpGet:
              scheme: HTTP
              port: 5000
              path: /status
          livenessProbe:
            failureThreshold: 20
            initialDelaySeconds: 5
            periodSeconds: 6
            successThreshold: 1
            timeoutSeconds: 5
            httpGet:
              scheme: HTTP
              port: 5000
              path: /status
          volumeMounts:
            - mountPath: /usr/local/lib/zimagi/files
              name: files
      volumes:
        - name: files
          persistentVolumeClaim:
            claimName: files
---
# Source: zimagi/templates/app.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: "scheduler"
  namespace: "default"
  labels:
    helm.sh/chart: "zimagi-2.5.32"
    app.kubernetes.io/version: "0.13.32"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: "zimagi"
    app.kubernetes.io/instance: "release-name"
    app.kubernetes.io/component: "scheduler"
    
  annotations:
    nginx.ingress.kubernetes.io/proxy-connect-timeout: "30"
    
spec:
  replicas: 1
  revisionHistoryLimit: 1
  strategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/name: "zimagi"
      app.kubernetes.io/instance: "release-name"
      app.kubernetes.io/component: "scheduler"
  template:
    metadata:
      labels:
        helm.sh/chart: "zimagi-2.5.32"
        app.kubernetes.io/version: "0.13.32"
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: "zimagi"
        app.kubernetes.io/instance: "release-name"
        app.kubernetes.io/component: "scheduler"
        
    spec:
      serviceAccountName: "scheduler"
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: zimagi
                    app.kubernetes.io/instance: release-name
                    app.kubernetes.io/component: scheduler
                topologyKey: kubernetes.io/hostname
              weight: 1
      containers:
        - name: scheduler
          image: "registry.hub.docker.com/zimagi/zimagi:0.13.32"
          imagePullPolicy: IfNotPresent
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          command:
            - zimagi-scheduler
          env:
            - name: KUBERNETES_POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: KUBERNETES_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: KUBERNETES_POD_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
            - name: KUBERNETES_NODE_NAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
            - name: KUBERNETES_SERVICE_ACCOUNT
              valueFrom:
                fieldRef:
                  fieldPath: spec.serviceAccountName
            - name: KUBERNETES_CONTAINER_CPU_REQUEST_MILLICORES
              valueFrom:
                resourceFieldRef:
                  resource: requests.cpu
                  divisor: 1m
            - name: KUBERNETES_CONTAINER_MEMORY_LIMIT_KILOBYTES
              valueFrom:
                resourceFieldRef:
                  resource: limits.memory
                  divisor: 1Ki
            - name: KUBERNETES_WORKER_SERVICE_ACCOUNT
              value: "worker"
            - name: ZIMAGI_POSTGRES_DB
              value: "zimagi"
            - name: ZIMAGI_POSTGRES_HOST
              value: "postgresql"
            - name: ZIMAGI_POSTGRES_PORT
              value: "5432"
            - name: ZIMAGI_POSTGRES_USER
              value: "zimagi"
            - name: ZIMAGI_REDIS_HOST
              value: "redis-master"
            - name: ZIMAGI_REDIS_PORT
              value: "6379"
            - name: ZIMAGI_WORKER_PROVIDER
              value: "kubernetes"
          envFrom:
            - configMapRef:
                name: global
            - configMapRef:
                name: scheduler
            - secretRef:
                name: global
            
          volumeMounts:
            - mountPath: /usr/local/lib/zimagi/files
              name: files
      volumes:
        - name: files
          persistentVolumeClaim:
            claimName: files
---
# Source: zimagi/templates/app.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: "tasks"
  namespace: "default"
  labels:
    helm.sh/chart: "zimagi-2.5.32"
    app.kubernetes.io/version: "0.13.32"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: "zimagi"
    app.kubernetes.io/instance: "release-name"
    app.kubernetes.io/component: "tasks"
    
  annotations:
    nginx.ingress.kubernetes.io/proxy-connect-timeout: "30"
    
spec:
  replicas: 1
  revisionHistoryLimit: 1
  strategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/name: "zimagi"
      app.kubernetes.io/instance: "release-name"
      app.kubernetes.io/component: "tasks"
  template:
    metadata:
      labels:
        helm.sh/chart: "zimagi-2.5.32"
        app.kubernetes.io/version: "0.13.32"
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: "zimagi"
        app.kubernetes.io/instance: "release-name"
        app.kubernetes.io/component: "tasks"
        
    spec:
      serviceAccountName: "tasks"
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: zimagi
                    app.kubernetes.io/instance: release-name
                    app.kubernetes.io/component: tasks
                topologyKey: kubernetes.io/hostname
              weight: 1
      containers:
        - name: tasks
          image: "registry.hub.docker.com/zimagi/zimagi:0.13.32"
          imagePullPolicy: IfNotPresent
          resources:
            requests:
              cpu: 20m
              memory: 50Mi
          command:
            - celery-flower
          env:
            - name: KUBERNETES_POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: KUBERNETES_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: KUBERNETES_POD_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
            - name: KUBERNETES_NODE_NAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
            - name: KUBERNETES_SERVICE_ACCOUNT
              valueFrom:
                fieldRef:
                  fieldPath: spec.serviceAccountName
            - name: KUBERNETES_CONTAINER_CPU_REQUEST_MILLICORES
              valueFrom:
                resourceFieldRef:
                  resource: requests.cpu
                  divisor: 1m
            - name: KUBERNETES_CONTAINER_MEMORY_LIMIT_KILOBYTES
              valueFrom:
                resourceFieldRef:
                  resource: limits.memory
                  divisor: 1Ki
            - name: KUBERNETES_WORKER_SERVICE_ACCOUNT
              value: "worker"
            - name: ZIMAGI_POSTGRES_DB
              value: "zimagi"
            - name: ZIMAGI_POSTGRES_HOST
              value: "postgresql"
            - name: ZIMAGI_POSTGRES_PORT
              value: "5432"
            - name: ZIMAGI_POSTGRES_USER
              value: "zimagi"
            - name: ZIMAGI_REDIS_HOST
              value: "redis-master"
            - name: ZIMAGI_REDIS_PORT
              value: "6379"
            - name: ZIMAGI_WORKER_PROVIDER
              value: "kubernetes"
          envFrom:
            - configMapRef:
                name: global
            - configMapRef:
                name: flower
            - secretRef:
                name: global
            
          ports:
            - name: gateway
              containerPort: 5000
          readinessProbe:
            failureThreshold: 3
            initialDelaySeconds: 10
            periodSeconds: 5
            successThreshold: 3
            timeoutSeconds: 5
            httpGet:
              scheme: HTTP
              port: 5000
              path: /
          livenessProbe:
            failureThreshold: 20
            initialDelaySeconds: 5
            periodSeconds: 6
            successThreshold: 1
            timeoutSeconds: 5
            httpGet:
              scheme: HTTP
              port: 5000
              path: /
          volumeMounts:
      volumes:
---
# Source: zimagi/charts/postgresql/templates/primary/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: postgresql
  namespace: "default"
  labels:
    app.kubernetes.io/name: postgresql
    helm.sh/chart: postgresql-12.5.6
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: primary
spec:
  replicas: 1
  serviceName: postgresql-hl
  updateStrategy:
    rollingUpdate: {}
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/name: postgresql
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/component: primary
  template:
    metadata:
      name: postgresql
      labels:
        app.kubernetes.io/name: postgresql
        helm.sh/chart: postgresql-12.5.6
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/component: primary
    spec:
      serviceAccountName: default
      
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: postgresql
                    app.kubernetes.io/instance: release-name
                    app.kubernetes.io/component: primary
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      securityContext:
        fsGroup: 1001
      hostNetwork: false
      hostIPC: false
      initContainers:
        - name: init-chmod-data
          image: docker.io/bitnami/bitnami-shell:11-debian-11-r120
          imagePullPolicy: "IfNotPresent"
          resources:
            limits: {}
            requests: {}
          command:
            - /bin/sh
            - -ec
            - |
              chown 1001:1001 /bitnami/postgresql
              mkdir -p /bitnami/postgresql/data
              chmod 700 /bitnami/postgresql/data
              find /bitnami/postgresql -mindepth 1 -maxdepth 1 -not -name "conf" -not -name ".snapshot" -not -name "lost+found" | \
                xargs -r chown -R 1001:1001
              chmod -R 777 /dev/shm
          securityContext:
            runAsUser: 0
          volumeMounts:
            - name: data
              mountPath: /bitnami/postgresql
            - name: dshm
              mountPath: /dev/shm
      containers:
        - name: postgresql
          image: docker.io/bitnami/postgresql:15.3.0-debian-11-r7
          imagePullPolicy: "IfNotPresent"
          securityContext:
            runAsUser: 1001
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: POSTGRESQL_PORT_NUMBER
              value: "5432"
            - name: POSTGRESQL_VOLUME_DIR
              value: "/bitnami/postgresql"
            - name: PGDATA
              value: "/bitnami/postgresql/data"
            # Authentication
            - name: POSTGRES_USER
              value: "zimagi"
            - name: POSTGRES_POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: zimagi-db
                  key: postgres-password
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: zimagi-db
                  key: password
            - name: POSTGRES_DB
              value: "zimagi"
            # Replication
            # Initdb
            # Standby
            # LDAP
            - name: POSTGRESQL_ENABLE_LDAP
              value: "no"
            # TLS
            - name: POSTGRESQL_ENABLE_TLS
              value: "no"
            # Audit
            - name: POSTGRESQL_LOG_HOSTNAME
              value: "false"
            - name: POSTGRESQL_LOG_CONNECTIONS
              value: "false"
            - name: POSTGRESQL_LOG_DISCONNECTIONS
              value: "false"
            - name: POSTGRESQL_PGAUDIT_LOG_CATALOG
              value: "off"
            # Others
            - name: POSTGRESQL_CLIENT_MIN_MESSAGES
              value: "error"
            - name: POSTGRESQL_SHARED_PRELOAD_LIBRARIES
              value: "pgaudit"
          ports:
            - name: tcp-postgresql
              containerPort: 5432
          livenessProbe:
            failureThreshold: 6
            initialDelaySeconds: 30
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            exec:
              command:
                - /bin/sh
                - -c
                - exec pg_isready -U "zimagi" -d "dbname=zimagi" -h 127.0.0.1 -p 5432
          readinessProbe:
            failureThreshold: 6
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            exec:
              command:
                - /bin/sh
                - -c
                - -e
                
                - |
                  exec pg_isready -U "zimagi" -d "dbname=zimagi" -h 127.0.0.1 -p 5432
                  [ -f /opt/bitnami/postgresql/tmp/.initialized ] || [ -f /bitnami/postgresql/.initialized ]
          resources:
            limits: {}
            requests:
              cpu: 250m
              memory: 256Mi
          volumeMounts:
            - name: dshm
              mountPath: /dev/shm
            - name: data
              mountPath: /bitnami/postgresql
      volumes:
        - name: dshm
          emptyDir:
            medium: Memory
  volumeClaimTemplates:
    - metadata:
        name: data
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: "10Gi"
---
# Source: zimagi/charts/redis/templates/master/application.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: redis-master
  namespace: "default"
  labels:
    app.kubernetes.io/name: redis
    helm.sh/chart: redis-17.11.3
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: master
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: redis
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/component: master
  serviceName: redis-headless
  updateStrategy:
    type: RollingUpdate
  template:
    metadata:
      labels:
        app.kubernetes.io/name: redis
        helm.sh/chart: redis-17.11.3
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/component: master
      annotations:
        checksum/configmap: ac70cc23a75cecfa12bc1bd82ee44beb56800d67859df6d45f642d2fc56a050b
        checksum/health: 1e6fdd8b4dfac87adca52d4a90664548b85217a5550003b248c8f549b48f135c
        checksum/scripts: e2a92550b168d76bb8ac5dc7d2de095bf1b70dd82fde2c9a00542fc134ef8cc9
        checksum/secret: 01ba4719c80b6fe911b091a7c05124b64eeece964e09c058ef8f9805daca546b
    spec:
      
      securityContext:
        fsGroup: 1001
      serviceAccountName: redis
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: redis
                    app.kubernetes.io/instance: release-name
                    app.kubernetes.io/component: master
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      terminationGracePeriodSeconds: 30
      containers:
        - name: redis
          image: docker.io/bitnami/redis:7.0.11-debian-11-r12
          imagePullPolicy: "IfNotPresent"
          securityContext:
            runAsUser: 1001
          command:
            - /bin/bash
          args:
            - -c
            - /opt/bitnami/scripts/start-scripts/start-master.sh
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: REDIS_REPLICATION_MODE
              value: master
            - name: ALLOW_EMPTY_PASSWORD
              value: "no"
            - name: REDIS_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: zimagi-db
                  key: redis-password
            - name: REDIS_TLS_ENABLED
              value: "no"
            - name: REDIS_PORT
              value: "6379"
          ports:
            - name: redis
              containerPort: 6379
          livenessProbe:
            initialDelaySeconds: 20
            periodSeconds: 5
            # One second longer than command timeout should prevent generation of zombie processes.
            timeoutSeconds: 6
            successThreshold: 1
            failureThreshold: 5
            exec:
              command:
                - sh
                - -c
                - /health/ping_liveness_local.sh 5
          readinessProbe:
            initialDelaySeconds: 20
            periodSeconds: 5
            timeoutSeconds: 2
            successThreshold: 1
            failureThreshold: 5
            exec:
              command:
                - sh
                - -c
                - /health/ping_readiness_local.sh 1
          resources:
            limits: {}
            requests: {}
          volumeMounts:
            - name: start-scripts
              mountPath: /opt/bitnami/scripts/start-scripts
            - name: health
              mountPath: /health
            - name: redis-data
              mountPath: /data
            - name: config
              mountPath: /opt/bitnami/redis/mounted-etc
            - name: redis-tmp-conf
              mountPath: /opt/bitnami/redis/etc/
            - name: tmp
              mountPath: /tmp
      initContainers:
        - name: volume-permissions
          image: docker.io/bitnami/bitnami-shell:11-debian-11-r118
          imagePullPolicy: "IfNotPresent"
          command:
            - /bin/bash
            - -ec
            - |
              chown -R 1001:1001 /data
          securityContext:
            runAsUser: 0
          resources:
            limits: {}
            requests: {}
          volumeMounts:
            - name: redis-data
              mountPath: /data
      volumes:
        - name: start-scripts
          configMap:
            name: redis-scripts
            defaultMode: 0755
        - name: health
          configMap:
            name: redis-health
            defaultMode: 0755
        - name: config
          configMap:
            name: redis-configuration
        - name: redis-tmp-conf
          emptyDir: {}
        - name: tmp
          emptyDir: {}
  volumeClaimTemplates:
    - metadata:
        name: redis-data
        labels:
          app.kubernetes.io/name: redis
          app.kubernetes.io/instance: release-name
          app.kubernetes.io/component: master
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: "5Gi"
