---
# Source: vechr-monitoring/templates/alert-manager/network-policy.yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  labels:
    app.kubernetes.io/component: vechr-alertmanager
    app.kubernetes.io/instance: alertmanager-release-name
    app.kubernetes.io/name: alertmanager
    app.kubernetes.io/part-of: vechr-monitoring
    app.kubernetes.io/version: 0.25.0
  name: alertmanager-release-name
  namespace: default
spec:
  egress:
  - {}
  ingress:
  - from:
    - podSelector:
        matchLabels:
          app.kubernetes.io/name: prometheus
    ports:
    - port: 9093
      protocol: TCP
    - port: 8080
      protocol: TCP
  - from:
    - podSelector:
        matchLabels:
          app.kubernetes.io/name: alertmanager
    ports:
    - port: 9094
      protocol: TCP
    - port: 9094
      protocol: UDP
  podSelector:
    matchLabels:
      app.kubernetes.io/component: vechr-alertmanager
      app.kubernetes.io/instance: alertmanager-release-name
      app.kubernetes.io/name: alertmanager
      app.kubernetes.io/part-of: vechr-monitoring
  policyTypes:
  - Egress
  - Ingress
---
# Source: vechr-monitoring/templates/kube-state-metrics/network-policy.yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  labels:
    app.kubernetes.io/component: vechr-exporter
    app.kubernetes.io/name: kube-state-metrics
    app.kubernetes.io/part-of: vechr-monitoring
    app.kubernetes.io/version: 2.9.2
  name: kube-state-metrics-release-name
  namespace: default
spec:
  egress:
  - {}
  ingress:
  - from:
    - podSelector:
        matchLabels:
          app.kubernetes.io/name: prometheus
    ports:
    - port: 8443
      protocol: TCP
    - port: 9443
      protocol: TCP
  podSelector:
    matchLabels:
      app.kubernetes.io/component: vechr-exporter
      app.kubernetes.io/name: kube-state-metrics
      app.kubernetes.io/part-of: vechr-monitoring
  policyTypes:
  - Egress
  - Ingress
---
# Source: vechr-monitoring/templates/node-exporter/network-policy.yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  labels:
    app.kubernetes.io/component: vechr-exporter
    app.kubernetes.io/name: node-exporter
    app.kubernetes.io/part-of: vechr-monitoring
    app.kubernetes.io/version: 1.6.1
  name: node-exporter-release-name
  namespace: default
spec:
  egress:
  - {}
  ingress:
  - from:
    - podSelector:
        matchLabels:
          app.kubernetes.io/name: prometheus
    ports:
    - port: 9100
      protocol: TCP
  podSelector:
    matchLabels:
      app.kubernetes.io/component: vechr-exporter
      app.kubernetes.io/name: node-exporter
      app.kubernetes.io/part-of: vechr-monitoring
  policyTypes:
  - Egress
  - Ingress
---
# Source: vechr-monitoring/templates/prometheus/network-policy.yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  labels:
    app.kubernetes.io/component: vechr-prometheus
    app.kubernetes.io/instance: prometheus-release-name
    app.kubernetes.io/name: prometheus
    app.kubernetes.io/part-of: vechr-monitoring
    app.kubernetes.io/version: 2.45.0
  name: prometheus-release-name
  namespace: default
spec:
  egress:
  - {}
  ingress:
  - from:
    - podSelector:
        matchLabels:
          app.kubernetes.io/name: prometheus
    ports:
    - port: 9090
      protocol: TCP
    - port: 8080
      protocol: TCP
    ports:
    - port: 9090
      protocol: TCP
  - from:
    - podSelector:
        matchLabels:
          app: grafana-release-name-app
    ports:
    - port: 9090
      protocol: TCP
  podSelector:
    matchLabels:
      app.kubernetes.io/component: vechr-prometheus
      app.kubernetes.io/instance: prometheus-release-name
      app.kubernetes.io/name: prometheus
      app.kubernetes.io/part-of: vechr-monitoring
  policyTypes:
  - Egress
  - Ingress
---
# Source: vechr-monitoring/templates/prometheus/operator/network-policy.yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  labels:
    app.kubernetes.io/component: vechr-prometheus-operator
    app.kubernetes.io/name: vechr-prometheus-operator
    app.kubernetes.io/part-of: vechr-monitoring
    app.kubernetes.io/version: 0.66.0
  name: prometheus-operator-release-name
  namespace: default
spec:
  egress:
  - {}
  ingress:
  - from:
    - podSelector:
        matchLabels:
          app.kubernetes.io/name: vechr-prometheus
    ports:
    - port: 8443
      protocol: TCP
  podSelector:
    matchLabels:
      app.kubernetes.io/component: vechr-prometheus-operator
      app.kubernetes.io/name: vechr-prometheus-operator
      app.kubernetes.io/part-of: vechr-monitoring
  policyTypes:
  - Egress
  - Ingress
---
# Source: vechr-monitoring/templates/alert-manager/pod-distruption-budget.yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  labels:
    app.kubernetes.io/component: vechr-alertmanager
    app.kubernetes.io/instance: alertmanager-release-name
    app.kubernetes.io/name: alertmanager
    app.kubernetes.io/part-of: vechr-monitoring
    app.kubernetes.io/version: 0.25.0
  name: alertmanager-release-name
  namespace: default
spec:
  maxUnavailable: 1
  selector:
    matchLabels:
      app.kubernetes.io/component: vechr-alertmanager
      app.kubernetes.io/instance: alertmanager-release-name
      app.kubernetes.io/name: alertmanager
      app.kubernetes.io/part-of: vechr-monitoring
---
# Source: vechr-monitoring/templates/prometheus/pod-distruption-budget.yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  labels:
    app.kubernetes.io/component: vechr-prometheus
    app.kubernetes.io/instance: prometheus-release-name
    app.kubernetes.io/name: prometheus
    app.kubernetes.io/part-of: vechr-monitoring
    app.kubernetes.io/version: 2.45.0
  name: prometheus-release-name
  namespace: default
spec:
  minAvailable: 1
  selector:
    matchLabels:
      app.kubernetes.io/component: vechr-prometheus
      app.kubernetes.io/instance: prometheus-release-name
      app.kubernetes.io/name: prometheus
      app.kubernetes.io/part-of: vechr-monitoring
---
# Source: vechr-monitoring/templates/alert-manager/service-account.yaml
apiVersion: v1
automountServiceAccountToken: false
kind: ServiceAccount
metadata:
  labels:
    app.kubernetes.io/component: vechr-alertmanager
    app.kubernetes.io/instance: alertmanager-release-name
    app.kubernetes.io/name: alertmanager
    app.kubernetes.io/part-of: vechr-monitoring
    app.kubernetes.io/version: 0.25.0
  name: alertmanager-release-name
  namespace: default
---
# Source: vechr-monitoring/templates/kube-state-metrics/service-account.yaml
apiVersion: v1
automountServiceAccountToken: false
kind: ServiceAccount
metadata:
  labels:
    app.kubernetes.io/component: vechr-exporter
    app.kubernetes.io/name: kube-state-metrics
    app.kubernetes.io/part-of: vechr-monitoring
    app.kubernetes.io/version: 2.9.2
  name: kube-state-metrics-release-name
  namespace: default
---
# Source: vechr-monitoring/templates/node-exporter/service-account.yaml
apiVersion: v1
automountServiceAccountToken: false
kind: ServiceAccount
metadata:
  labels:
    app.kubernetes.io/component: vechr-exporter
    app.kubernetes.io/name: node-exporter
    app.kubernetes.io/part-of: vechr-monitoring
    app.kubernetes.io/version: 1.6.1
  name: node-exporter-release-name
  namespace: default
---
# Source: vechr-monitoring/templates/prometheus/operator/service-account.yaml
apiVersion: v1
automountServiceAccountToken: false
kind: ServiceAccount
metadata:
  labels:
    app.kubernetes.io/component: vechr-prometheus-operator
    app.kubernetes.io/name: vechr-prometheus-operator
    app.kubernetes.io/part-of: vechr-monitoring
    app.kubernetes.io/version: 0.66.0
  name: prometheus-operator-release-name
  namespace: default
---
# Source: vechr-monitoring/templates/prometheus/service-account.yaml
apiVersion: v1
automountServiceAccountToken: true
kind: ServiceAccount
metadata:
  labels:
    app.kubernetes.io/component: vechr-prometheus
    app.kubernetes.io/instance: prometheus-release-name
    app.kubernetes.io/name: prometheus
    app.kubernetes.io/part-of: vechr-monitoring
    app.kubernetes.io/version: 2.45.0
  name: vechr-prometheus
  namespace: default
---
# Source: vechr-monitoring/templates/alert-manager/secret.yaml
apiVersion: v1
kind: Secret
metadata:
  labels:
    app.kubernetes.io/component: vechr-alertmanager
    app.kubernetes.io/instance: alertmanager-release-name
    app.kubernetes.io/name: alertmanager
    app.kubernetes.io/part-of: vechr-monitoring
    app.kubernetes.io/version: 0.25.0
  name: alertmanager-release-name
  namespace: default
stringData:
  alertmanager.yaml: |-
    "global":
      "resolve_timeout": "5m"
    "inhibit_rules":
    - "equal":
      - "namespace"
      - "alertname"
      "source_matchers":
      - "severity = critical"
      "target_matchers":
      - "severity =~ warning|info"
    - "equal":
      - "namespace"
      - "alertname"
      "source_matchers":
      - "severity = warning"
      "target_matchers":
      - "severity = info"
    - "equal":
      - "namespace"
      "source_matchers":
      - "alertname = InfoInhibitor"
      "target_matchers":
      - "severity = info"
    "receivers":
    - "name": "Default"
    - "name": "Watchdog"
    - "name": "Critical"
    - "name": "null"
    "route":
      "group_by":
      - "namespace"
      "group_interval": "5m"
      "group_wait": "30s"
      "receiver": "Default"
      "repeat_interval": "12h"
      "routes":
      - "matchers":
        - "alertname = Watchdog"
        "receiver": "Watchdog"
      - "matchers":
        - "alertname = InfoInhibitor"
        "receiver": "null"
      - "matchers":
        - "severity = critical"
        "receiver": "Critical"
type: Opaque
---
# Source: vechr-monitoring/templates/grafana/config-map.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: datasource-grafana
  namespace: default
data:
  datasource.yaml: |
      apiVersion: 1
      datasources:
      - access: proxy
        basicAuth: false
        editable: false
        isDefault: false
        name: Prometheus
        orgId: 1
        type: prometheus
        uid: prometheus
        url: http://prometheus-service.monitoring.svc.cluster.local:9090
        version: 1
      - access: proxy
        apiVersion: 1
        basicAuth: false
        editable: true
        isDefault: false
        jsonData:
          lokiSearch:
            datasourceUid: loki
          nodeGraph:
            enabled: true
          search:
            hide: false
          serviceMap:
            datasourceUid: prometheus
          traceQuery:
            spanEndTimeShift: 1h
            spanStartTimeShift: -1h
            timeShiftEnabled: true
          tracesToLogsV2:
            datasourceUid: loki
            filterBySpanID: true
            filterByTraceID: true
            spanEndTimeShift: 1h
            spanStartTimeShift: -1h
            tags:
            - key: service.name
              value: application
        name: Tempo
        orgId: 1
        type: tempo
        uid: tempo
        url: http://tempo-service.monitoring.svc.cluster.local:3200
        version: 1
      - access: proxy
        apiVersion: 1
        basicAuth: false
        editable: false
        isDefault: false
        jsonData:
          derivedFields:
          - datasourceUid: tempo
            matcherRegex: '"traceId":"([A-Za-z0-9]+)"'
            name: TraceID
            url: $${__value.raw}
        name: Loki
        orgId: 1
        type: loki
        uid: loki
        url: http://loki-service.monitoring.svc.cluster.local:3100
        version: 1
      deleteDatasources:
      - name: Prometheus
      - name: Tempo
      - name: Loki
---
# Source: vechr-monitoring/templates/loki/config-map.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: config-loki
  namespace: default
data:
  config.yaml: |
      auth_enabled: false
      common:
        instance_addr: 127.0.0.1
        path_prefix: /tmp/loki
        replication_factor: 1
        ring:
          kvstore:
            store: inmemory
        storage:
          filesystem:
            chunks_directory: /tmp/loki/chunks
            rules_directory: /tmp/loki/rules
      query_range:
        results_cache:
          cache:
            embedded_cache:
              enabled: true
              max_size_mb: 100
      ruler:
        alertmanager_url: http://localhost:9093
      schema_config:
        configs:
        - from: "2020-10-24"
          index:
            period: 24h
            prefix: index_
          object_store: filesystem
          schema: v11
          store: boltdb-shipper
      server:
        grpc_listen_port: 9096
        http_listen_port: 3100
---
# Source: vechr-monitoring/templates/tempo/config-map.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: config-tempo
  namespace: default
data:
  config.yaml: |
      compactor:
        compaction:
          block_retention: 1h
      distributor:
        receivers:
          jaeger:
            protocols:
              grpc: null
              thrift_binary: null
              thrift_compact: null
              thrift_http: null
          opencensus: null
          otlp:
            protocols:
              grpc: null
              http: null
          zipkin: null
      ingester:
        max_block_duration: 5m
      metrics_generator:
        registry:
          external_labels:
            cluster: docker-compose
            source: tempo
        storage:
          path: /tmp/tempo/generator/wal
          remote_write:
          - send_exemplars: true
            url: http://prometheus:9090/api/v1/write
      overrides:
        metrics_generator_processors:
        - service-graphs
        - span-metrics
      server:
        http_listen_port: 3200
      storage:
        trace:
          backend: local
          local:
            path: /tmp/tempo/blocks
          wal:
            path: /tmp/tempo/wal
---
# Source: vechr-monitoring/templates/kube-state-metrics/cluster-role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    app.kubernetes.io/component: vechr-exporter
    app.kubernetes.io/name: kube-state-metrics
    app.kubernetes.io/part-of: vechr-monitoring
    app.kubernetes.io/version: 2.9.2
  name: kube-state-metrics-release-name
rules:
- apiGroups:
  - ""
  resources:
  - configmaps
  - secrets
  - nodes
  - pods
  - services
  - serviceaccounts
  - resourcequotas
  - replicationcontrollers
  - limitranges
  - persistentvolumeclaims
  - persistentvolumes
  - namespaces
  - endpoints
  verbs:
  - list
  - watch
- apiGroups:
  - apps
  resources:
  - statefulsets
  - daemonsets
  - deployments
  - replicasets
  verbs:
  - list
  - watch
- apiGroups:
  - batch
  resources:
  - cronjobs
  - jobs
  verbs:
  - list
  - watch
- apiGroups:
  - autoscaling
  resources:
  - horizontalpodautoscalers
  verbs:
  - list
  - watch
- apiGroups:
  - authentication.k8s.io
  resources:
  - tokenreviews
  verbs:
  - create
- apiGroups:
  - authorization.k8s.io
  resources:
  - subjectaccessreviews
  verbs:
  - create
- apiGroups:
  - policy
  resources:
  - poddisruptionbudgets
  verbs:
  - list
  - watch
- apiGroups:
  - certificates.k8s.io
  resources:
  - certificatesigningrequests
  verbs:
  - list
  - watch
- apiGroups:
  - discovery.k8s.io
  resources:
  - endpointslices
  verbs:
  - list
  - watch
- apiGroups:
  - storage.k8s.io
  resources:
  - storageclasses
  - volumeattachments
  verbs:
  - list
  - watch
- apiGroups:
  - admissionregistration.k8s.io
  resources:
  - mutatingwebhookconfigurations
  - validatingwebhookconfigurations
  verbs:
  - list
  - watch
- apiGroups:
  - networking.k8s.io
  resources:
  - networkpolicies
  - ingressclasses
  - ingresses
  verbs:
  - list
  - watch
- apiGroups:
  - coordination.k8s.io
  resources:
  - leases
  verbs:
  - list
  - watch
- apiGroups:
  - rbac.authorization.k8s.io
  resources:
  - clusterrolebindings
  - clusterroles
  - rolebindings
  - roles
  verbs:
  - list
  - watch
---
# Source: vechr-monitoring/templates/node-exporter/cluster-role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    app.kubernetes.io/component: vechr-exporter
    app.kubernetes.io/name: node-exporter
    app.kubernetes.io/part-of: vechr-monitoring
    app.kubernetes.io/version: 1.6.1
  name: node-exporter-release-name
rules:
- apiGroups:
  - authentication.k8s.io
  resources:
  - tokenreviews
  verbs:
  - create
- apiGroups:
  - authorization.k8s.io
  resources:
  - subjectaccessreviews
  verbs:
  - create
---
# Source: vechr-monitoring/templates/prometheus/cluster-role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    app.kubernetes.io/component: vechr-prometheus
    app.kubernetes.io/instance: prometheus-release-name
    app.kubernetes.io/name: prometheus
    app.kubernetes.io/part-of: vechr-monitoring
    app.kubernetes.io/version: 2.45.0
  name: prometheus-release-name
rules:
- apiGroups:
  - ""
  resources:
  - nodes/metrics
  - nodes
  - services
  - endpoints
  - pods
  - configmaps
  verbs:
  - get
  - list
  - watch
- nonResourceURLs:
  - /metrics
  verbs:
  - get
---
# Source: vechr-monitoring/templates/prometheus/operator/cluster-role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    app.kubernetes.io/component: vechr-prometheus-operator
    app.kubernetes.io/name: vechr-prometheus-operator
    app.kubernetes.io/part-of: vechr-monitoring
    app.kubernetes.io/version: 0.66.0
  name: prometheus-operator-release-name
rules:
- apiGroups:
  - monitoring.coreos.com
  resources:
  - alertmanagers
  - alertmanagers/finalizers
  - alertmanagers/status
  - alertmanagerconfigs
  - prometheuses
  - prometheuses/finalizers
  - prometheuses/status
  - prometheusagents
  - prometheusagents/finalizers
  - prometheusagents/status
  - thanosrulers
  - thanosrulers/finalizers
  - thanosrulers/status
  - scrapeconfigs
  - servicemonitors
  - podmonitors
  - probes
  - prometheusrules
  verbs:
  - '*'
- apiGroups:
  - apps
  resources:
  - statefulsets
  verbs:
  - '*'
- apiGroups:
  - ""
  resources:
  - configmaps
  - secrets
  verbs:
  - '*'
- apiGroups:
  - ""
  resources:
  - pods
  verbs:
  - list
  - delete
- apiGroups:
  - ""
  resources:
  - services
  - services/finalizers
  - endpoints
  verbs:
  - get
  - create
  - update
  - delete
- apiGroups:
  - ""
  resources:
  - nodes
  verbs:
  - list
  - watch
- apiGroups:
  - ""
  resources:
  - namespaces
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - networking.k8s.io
  resources:
  - ingresses
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - authentication.k8s.io
  resources:
  - tokenreviews
  verbs:
  - create
- apiGroups:
  - authorization.k8s.io
  resources:
  - subjectaccessreviews
  verbs:
  - create
---
# Source: vechr-monitoring/templates/kube-state-metrics/cluster-role-binding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  labels:
    app.kubernetes.io/component: vechr-exporter
    app.kubernetes.io/name: kube-state-metrics
    app.kubernetes.io/part-of: vechr-monitoring
    app.kubernetes.io/version: 2.9.2
  name: kube-state-metrics-release-name
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: kube-state-metrics-release-name
subjects:
- kind: ServiceAccount
  name: kube-state-metrics-release-name
  namespace: default
---
# Source: vechr-monitoring/templates/node-exporter/cluster-role-binding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  labels:
    app.kubernetes.io/component: vechr-exporter
    app.kubernetes.io/name: node-exporter
    app.kubernetes.io/part-of: vechr-monitoring
    app.kubernetes.io/version: 1.6.1
  name: node-exporter-release-name
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: node-exporter-release-name
subjects:
- kind: ServiceAccount
  name: node-exporter-release-name
  namespace: default
---
# Source: vechr-monitoring/templates/prometheus/cluster-role-binding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  labels:
    app.kubernetes.io/component: vechr-prometheus
    app.kubernetes.io/instance: prometheus-release-name
    app.kubernetes.io/name: prometheus
    app.kubernetes.io/part-of: vechr-monitoring
    app.kubernetes.io/version: 2.45.0
  name: prometheus-release-name
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: prometheus-release-name
subjects:
- kind: ServiceAccount
  name: vechr-prometheus
  namespace: default
---
# Source: vechr-monitoring/templates/prometheus/operator/cluster-role-binding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  labels:
    app.kubernetes.io/component: vechr-prometheus-operator
    app.kubernetes.io/name: vechr-prometheus-operator
    app.kubernetes.io/part-of: vechr-monitoring
    app.kubernetes.io/version: 0.66.0
  name: prometheus-operator-release-name
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: prometheus-operator-release-name
subjects:
- kind: ServiceAccount
  name: prometheus-operator-release-name
  namespace: default
---
# Source: vechr-monitoring/templates/prometheus/role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  labels:
    app.kubernetes.io/component: vechr-prometheus
    app.kubernetes.io/instance: prometheus-release-name
    app.kubernetes.io/name: prometheus
    app.kubernetes.io/part-of: vechr-monitoring
    app.kubernetes.io/version: 2.45.0
  name: prometheus-release-name
  namespace: default
rules:
- apiGroups:
  - ""
  resources:
  - services
  - endpoints
  - pods
  - configmaps
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - extensions
  resources:
  - ingresses
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - networking.k8s.io
  resources:
  - ingresses
  verbs:
  - get
  - list
  - watch
---
# Source: vechr-monitoring/templates/prometheus/role-binding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  labels:
    app.kubernetes.io/component: vechr-prometheus
    app.kubernetes.io/instance: prometheus-release-name
    app.kubernetes.io/name: prometheus
    app.kubernetes.io/part-of: vechr-monitoring
    app.kubernetes.io/version: 2.45.0
  name: prometheus-release-name
  namespace: default
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: prometheus-release-name
subjects:
- kind: ServiceAccount
  name: vechr-prometheus
  namespace: default
---
# Source: vechr-monitoring/templates/alert-manager/service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: vechr-alertmanager
    app.kubernetes.io/instance: alertmanager-release-name
    app.kubernetes.io/name: alertmanager
    app.kubernetes.io/part-of: vechr-monitoring
    app.kubernetes.io/version: 0.25.0
  name: alertmanager-release-name
  namespace: default
spec:
  ports:
  - name: web
    port: 9093
    targetPort: web
  - name: reloader-web
    port: 8080
    targetPort: reloader-web
  selector:
    app.kubernetes.io/component: vechr-alertmanager
    app.kubernetes.io/instance: alertmanager-release-name
    app.kubernetes.io/name: alertmanager
    app.kubernetes.io/part-of: vechr-monitoring
  sessionAffinity: ClientIP
---
# Source: vechr-monitoring/templates/grafana/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: grafana-service
  namespace: default
  labels:
    app.kubernetes.io/component: vechr-grafana
    app.kubernetes.io/name: grafana
    app.kubernetes.io/part-of: vechr-monitoring
    app.kubernetes.io/version: 10.0.3
spec:
  type: ClusterIP
  selector:
    app.kubernetes.io/component: vechr-grafana
    app.kubernetes.io/name: grafana
    app.kubernetes.io/part-of: vechr-monitoring
  ports:
    - port: 3000
      name: grafana-dashboard
      targetPort: 3000
---
# Source: vechr-monitoring/templates/kube-state-metrics/service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: vechr-exporter
    app.kubernetes.io/name: kube-state-metrics
    app.kubernetes.io/part-of: vechr-monitoring
    app.kubernetes.io/version: 2.9.2
  name: kube-state-metrics-release-name
  namespace: default
spec:
  clusterIP: None
  ports:
  - name: https-main
    port: 8443
    targetPort: https-main
  - name: https-self
    port: 9443
    targetPort: https-self
  selector:
    app.kubernetes.io/component: vechr-exporter
    app.kubernetes.io/name: kube-state-metrics
    app.kubernetes.io/part-of: vechr-monitoring
---
# Source: vechr-monitoring/templates/loki/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: loki-service
  namespace: default
  labels:
    app.kubernetes.io/component: vechr-loki
    app.kubernetes.io/name: loki
    app.kubernetes.io/part-of: vechr-monitoring
    app.kubernetes.io/version: 2.8.0
spec:
  type: ClusterIP
  selector:
    app.kubernetes.io/component: vechr-loki
    app.kubernetes.io/name: loki
    app.kubernetes.io/part-of: vechr-monitoring
  ports:
    - port: 3100
      name: loki-port
      targetPort: 3100
---
# Source: vechr-monitoring/templates/node-exporter/service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: vechr-exporter
    app.kubernetes.io/name: node-exporter
    app.kubernetes.io/part-of: vechr-monitoring
    app.kubernetes.io/version: 1.6.1
  name: node-exporter-service
  namespace: default
spec:
  clusterIP: None
  ports:
  - name: https
    port: 9100
    targetPort: https
  selector:
    app.kubernetes.io/component: vechr-exporter
    app.kubernetes.io/name: node-exporter
    app.kubernetes.io/part-of: vechr-monitoring
---
# Source: vechr-monitoring/templates/prometheus/operator/service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: vechr-prometheus-operator
    app.kubernetes.io/name: vechr-prometheus-operator
    app.kubernetes.io/part-of: vechr-monitoring
    app.kubernetes.io/version: 0.66.0
  name: prometheus-operator-release-name
  namespace: default
spec:
  clusterIP: None
  ports:
  - name: https
    port: 8443
    targetPort: https
  selector:
    app.kubernetes.io/component: vechr-prometheus-operator
    app.kubernetes.io/name: vechr-prometheus-operator
    app.kubernetes.io/part-of: vechr-monitoring
---
# Source: vechr-monitoring/templates/prometheus/service.yaml
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: vechr-prometheus
    app.kubernetes.io/instance: prometheus-release-name
    app.kubernetes.io/name: prometheus
    app.kubernetes.io/part-of: vechr-monitoring
    app.kubernetes.io/version: 2.45.0
  name: prometheus-service
  namespace: default
spec:
  ports:
  - name: web
    port: 9090
    targetPort: web
  - name: reloader-web
    port: 8080
    targetPort: reloader-web
  selector:
    app.kubernetes.io/component: vechr-prometheus
    app.kubernetes.io/instance: prometheus-vechr-monitoring
    app.kubernetes.io/name: prometheus
    app.kubernetes.io/part-of: vechr-monitoring
  sessionAffinity: ClientIP
---
# Source: vechr-monitoring/templates/tempo/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: tempo-service
  namespace: default
  labels:
    app.kubernetes.io/component: vechr-tempo
    app.kubernetes.io/name: tempo
    app.kubernetes.io/part-of: vechr-monitoring
    app.kubernetes.io/version: latest
spec:
  type: ClusterIP
  selector:
    app.kubernetes.io/component: vechr-tempo
    app.kubernetes.io/name: tempo
    app.kubernetes.io/part-of: vechr-monitoring
  ports:
    - name: tempo-port
      port: 3200
      targetPort: 3200
    
    - name: jaeger-ingest
      port: 14268
      targetPort: 14268
    
    - name: jaeger-grpc
      port: 14250
      targetPort: 14250
    
    - name: tempo-grpc
      port: 9095
      targetPort: 9095
    
    - name: otlp-grpc
      port: 4317
      targetPort: 4317
    
    - name: otlp-http
      port: 4318
      targetPort: 4318
    
    - name: zipkin
      port: 9411
      targetPort: 9411
---
# Source: vechr-monitoring/templates/node-exporter/daemonset.yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  labels:
    app.kubernetes.io/component: vechr-exporter
    app.kubernetes.io/name: node-exporter
    app.kubernetes.io/part-of: vechr-monitoring
    app.kubernetes.io/version: 1.6.1
  name: node-exporter-release-name
  namespace: default
spec:
  selector:
    matchLabels:
      app.kubernetes.io/component: vechr-exporter
      app.kubernetes.io/name: node-exporter
      app.kubernetes.io/part-of: vechr-monitoring
  template:
    metadata:
      annotations:
        kubectl.kubernetes.io/default-container: node-exporter
      labels:
        app.kubernetes.io/component: vechr-exporter
        app.kubernetes.io/name: node-exporter
        app.kubernetes.io/part-of: vechr-monitoring
        app.kubernetes.io/version: 1.6.1
    spec:
      automountServiceAccountToken: true
      containers:
      - args:
        - --web.listen-address=127.0.0.1:9100
        
        - --path.sysfs=/host/sys
        
        
        - --path.rootfs=/host/root
        - --path.udev.data=/host/root/run/udev/data
        
        - --no-collector.wifi
        - --no-collector.hwmon
        - --no-collector.btrfs
        - --collector.filesystem.mount-points-exclude=^/(dev|proc|sys|run/k3s/containerd/.+|var/lib/docker/.+|var/lib/kubelet/pods/.+)($|/)
        - --collector.netclass.ignored-devices=^(veth.*|[a-f0-9]{15})$
        - --collector.netdev.device-exclude=^(veth.*|[a-f0-9]{15})$
        image: quay.io/prometheus/node-exporter:v1.6.1
        name: node-exporter-release-name
        resources:
          limits:
            cpu: 250m
            memory: 180Mi
          requests:
            cpu: 102m
            memory: 180Mi
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            add:
            - SYS_TIME
            drop:
            - ALL
          readOnlyRootFilesystem: false
        volumeMounts:
        
        - mountPath: /host/sys
          mountPropagation: None
          name: sys
          readOnly: true
        
        - mountPath: /host/root
          mountPropagation:  None
          name: root
          readOnly: true
      - args:
        - --logtostderr
        - --secure-listen-address=[$(IP)]:9100
        - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305
        - --upstream=http://127.0.0.1:9100/
        env:
        - name: IP
          valueFrom:
            fieldRef:
              fieldPath: status.podIP
        image: quay.io/brancz/kube-rbac-proxy:v0.14.2
        name: kube-rbac-proxy
        ports:
        - containerPort: 9100
          hostPort: 9100
          name: https
        resources:
          limits:
            cpu: 20m
            memory: 40Mi
          requests:
            cpu: 10m
            memory: 20Mi
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          readOnlyRootFilesystem: true
          runAsGroup: 65532
          runAsNonRoot: true
          runAsUser: 65532
      hostNetwork: true
      hostPID: true
      nodeSelector:
        kubernetes.io/os: linux
      priorityClassName: system-cluster-critical
      securityContext:
        runAsNonRoot: true
        runAsUser: 65534
      serviceAccountName: node-exporter-release-name
      tolerations:
      - operator: Exists
      volumes:
      
      - hostPath:
          path: /sys
        name: sys
      
      
      - hostPath:
          path: /
        name: root
      
  updateStrategy:
    rollingUpdate:
      maxUnavailable: 10%
    type: RollingUpdate
---
# Source: vechr-monitoring/templates/grafana/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: grafana-release-name
  namespace: default
  labels:
    app.kubernetes.io/component: vechr-grafana
    app.kubernetes.io/name: grafana
    app.kubernetes.io/part-of: vechr-monitoring
    app.kubernetes.io/version: 10.0.3
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/component: vechr-grafana
      app.kubernetes.io/name: grafana
      app.kubernetes.io/part-of: vechr-monitoring
  template:
    metadata:
      name: grafana-release-name
      labels:
        app.kubernetes.io/component: vechr-grafana
        app.kubernetes.io/name: grafana
        app.kubernetes.io/part-of: vechr-monitoring
    spec:
      restartPolicy: Always
      containers:
        - name: grafana-release-name
          image: grafana/grafana:10.0.3
          ports:
            - name: http
              containerPort: 3000
              protocol: TCP
          imagePullPolicy: Always
          env:
            
            - name: GF_PATHS_PROVISIONING
              value: "/etc/grafana/provisioning"
            
            - name: GF_AUTH_ANONYMOUS_ENABLED
              value: "true"
            
            - name: GF_AUTH_ANONYMOUS_ORG_ROLE
              value: "Admin"
            
          volumeMounts:
          - name: datasource-config-volume
            mountPath: /etc/grafana/provisioning/datasources/datasource.yaml
            subPath: datasource.yaml

      volumes:
        - name: datasource-config-volume
          configMap:
            name: datasource-grafana
---
# Source: vechr-monitoring/templates/kube-state-metrics/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/component: vechr-exporter
    app.kubernetes.io/name: kube-state-metrics
    app.kubernetes.io/part-of: vechr-monitoring
    app.kubernetes.io/version: 2.9.2
  name: kube-state-metrics-release-name
  namespace: default
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/component: vechr-exporter
      app.kubernetes.io/name: kube-state-metrics
      app.kubernetes.io/part-of: vechr-monitoring
  template:
    metadata:
      annotations:
        kubectl.kubernetes.io/default-container: kube-state-metrics
      labels:
        app.kubernetes.io/component: vechr-exporter
        app.kubernetes.io/name: kube-state-metrics
        app.kubernetes.io/part-of: vechr-monitoring
        app.kubernetes.io/version: 2.9.2
    spec:
      automountServiceAccountToken: true
      containers:
      - args:
        - --host=127.0.0.1
        - --port=8081
        - --telemetry-host=127.0.0.1
        - --telemetry-port=8082
        image: registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.9.2
        name: kube-state-metrics
        resources:
          limits:
            cpu: 100m
            memory: 250Mi
          requests:
            cpu: 10m
            memory: 190Mi
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          readOnlyRootFilesystem: true
          runAsNonRoot: true
          runAsUser: 65534
          seccompProfile:
            type: RuntimeDefault
      - args:
        - --logtostderr
        - --secure-listen-address=:8443
        - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305
        - --upstream=http://127.0.0.1:8081/
        image: quay.io/brancz/kube-rbac-proxy:v0.14.2
        name: kube-rbac-proxy-main
        ports:
        - containerPort: 8443
          name: https-main
        resources:
          limits:
            cpu: 40m
            memory: 40Mi
          requests:
            cpu: 20m
            memory: 20Mi
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          readOnlyRootFilesystem: true
          runAsGroup: 65532
          runAsNonRoot: true
          runAsUser: 65532
      - args:
        - --logtostderr
        - --secure-listen-address=:9443
        - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305
        - --upstream=http://127.0.0.1:8082/
        image: quay.io/brancz/kube-rbac-proxy:v0.14.2
        name: kube-rbac-proxy-self
        ports:
        - containerPort: 9443
          name: https-self
        resources:
          limits:
            cpu: 20m
            memory: 40Mi
          requests:
            cpu: 10m
            memory: 20Mi
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          readOnlyRootFilesystem: true
          runAsGroup: 65532
          runAsNonRoot: true
          runAsUser: 65532
      nodeSelector:
        kubernetes.io/os: linux
      serviceAccountName: kube-state-metrics-release-name
---
# Source: vechr-monitoring/templates/loki/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: loki-release-name
  namespace: default
  labels:
    app.kubernetes.io/component: vechr-loki
    app.kubernetes.io/name: loki
    app.kubernetes.io/part-of: vechr-monitoring
    app.kubernetes.io/version: 2.8.0
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/component: vechr-loki
      app.kubernetes.io/name: loki
      app.kubernetes.io/part-of: vechr-monitoring
  template:
    metadata:
      name: loki-release-name
      labels:
        app.kubernetes.io/component: vechr-loki
        app.kubernetes.io/name: loki
        app.kubernetes.io/part-of: vechr-monitoring
    spec:
      restartPolicy: Always
      containers:
        - name: loki-release-name
          image: grafana/loki:2.8.0
          args: ["-config.file=/etc/loki/config.yaml"]
          ports:
            - name: http
              containerPort: 3100
              protocol: TCP
          imagePullPolicy: Always
          env:
            
            - name: JAEGER_AGENT_HOST
              value: "tempo"
            
            - name: JAEGER_ENDPOINT
              value: "http://tempo:14268/api/traces"
            
            - name: JAEGER_SAMPLER_TYPE
              value: "const"
            
            - name: JAEGER_SAMPLER_PARAM
              value: "1"
            
          volumeMounts:
          - name: config-loki-volume
            mountPath: /etc/loki/config.yaml
            subPath: config.yaml

      volumes:
        - name: config-loki-volume
          configMap:
            name: config-loki
---
# Source: vechr-monitoring/templates/prometheus/operator/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app.kubernetes.io/component: vechr-prometheus-operator
    app.kubernetes.io/name: vechr-prometheus-operator
    app.kubernetes.io/part-of: vechr-monitoring
    app.kubernetes.io/version: 0.66.0
  name: prometheus-operator-release-name
  namespace: default
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/component: vechr-prometheus-operator
      app.kubernetes.io/name: vechr-prometheus-operator
      app.kubernetes.io/part-of: vechr-monitoring
  template:
    metadata:
      annotations:
        kubectl.kubernetes.io/default-container: prometheus-operator
      labels:
        app.kubernetes.io/component: vechr-prometheus-operator
        app.kubernetes.io/name: vechr-prometheus-operator
        app.kubernetes.io/part-of: vechr-monitoring
        app.kubernetes.io/version: 0.66.0
    spec:
      automountServiceAccountToken: true
      containers:
      - args:
        - --kubelet-service=kube-system/kubelet
        - --prometheus-config-reloader=quay.io/prometheus-operator/prometheus-config-reloader:v0.66.0
        image: quay.io/prometheus-operator/prometheus-operator:v0.66.0
        name: prometheus-operator-release-name
        ports:
        - containerPort: 8080
          name: http
        resources:
          limits:
            cpu: 200m
            memory: 200Mi
          requests:
            cpu: 100m
            memory: 100Mi
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          readOnlyRootFilesystem: true
      - args:
        - --logtostderr
        - --secure-listen-address=:8443
        - --tls-cipher-suites=TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305
        - --upstream=http://127.0.0.1:8080/
        image: quay.io/brancz/kube-rbac-proxy:v0.14.2
        name: kube-rbac-proxy
        ports:
        - containerPort: 8443
          name: https
        resources:
          limits:
            cpu: 20m
            memory: 40Mi
          requests:
            cpu: 10m
            memory: 20Mi
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          readOnlyRootFilesystem: true
          runAsGroup: 65532
          runAsNonRoot: true
          runAsUser: 65532
      nodeSelector:
        kubernetes.io/os: linux
      securityContext:
        runAsNonRoot: true
        runAsUser: 65534
        seccompProfile:
          type: RuntimeDefault
      serviceAccountName: prometheus-operator-release-name
---
# Source: vechr-monitoring/templates/tempo/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: tempo-release-name
  namespace: default
  labels:
    app.kubernetes.io/component: vechr-tempo
    app.kubernetes.io/name: tempo
    app.kubernetes.io/part-of: vechr-monitoring
    app.kubernetes.io/version: latest
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/component: vechr-tempo
      app.kubernetes.io/name: tempo
      app.kubernetes.io/part-of: vechr-monitoring
  template:
    metadata:
      name: tempo-release-name
      labels:
        app.kubernetes.io/component: vechr-tempo
        app.kubernetes.io/name: tempo
        app.kubernetes.io/part-of: vechr-monitoring
    spec:
      restartPolicy: Always
      containers:
        - name: tempo-release-name
          image: grafana/tempo:latest
          args: ["-config.file=/etc/config.yaml"]
          ports:
            
            - name: jaeger-ingest
              containerPort: 14268
              protocol: TCP
            
            - name: jaeger-grpc
              containerPort: 14250
              protocol: TCP
            
            - name: tempo-grpc
              containerPort: 9095
              protocol: TCP
            
            - name: otlp-grpc
              containerPort: 4317
              protocol: TCP
            
            - name: otlp-http
              containerPort: 4318
              protocol: TCP
            
            - name: zipkin
              containerPort: 9411
              protocol: TCP
            
          imagePullPolicy: Always
          env:
            
          volumeMounts:
          - name: config-tempo-volume
            mountPath: /etc/config.yaml
            subPath: config.yaml

      volumes:
        - name: config-tempo-volume
          configMap:
            name: config-tempo
---
# Source: vechr-monitoring/templates/alert-manager/alert-manager.yaml
apiVersion: monitoring.coreos.com/v1
kind: Alertmanager
metadata:
  labels:
    app.kubernetes.io/component: vechr-alertmanager
    app.kubernetes.io/instance: alertmanager-release-name
    app.kubernetes.io/name: alertmanager
    app.kubernetes.io/part-of: vechr-monitoring
    app.kubernetes.io/version: 0.25.0
  name: alertmanager-release-name
  namespace: default
spec:
  image: quay.io/prometheus/alertmanager:v0.25.0
  nodeSelector:
    kubernetes.io/os: linux
  podMetadata:
    labels:
      app.kubernetes.io/component: vechr-alertmanager
      app.kubernetes.io/instance: alertmanager-release-name
      app.kubernetes.io/name: alertmanager
      app.kubernetes.io/part-of: vechr-monitoring
      app.kubernetes.io/version: 0.25.0
  replicas: 2
  resources:
    limits:
      cpu: 100m
      memory: 100Mi
    requests:
      cpu: 4m
      memory: 100Mi
  securityContext:
    fsGroup: 2000
    runAsNonRoot: true
    runAsUser: 1000
  serviceAccountName: alertmanager-release-name
  version: 0.25.0
---
# Source: vechr-monitoring/templates/prometheus/prometheus.yaml
apiVersion: monitoring.coreos.com/v1
kind: Prometheus
metadata:
  labels:
    app.kubernetes.io/component: vechr-prometheus
    app.kubernetes.io/instance: prometheus-release-name
    app.kubernetes.io/name: prometheus
    app.kubernetes.io/part-of: vechr-monitoring
    app.kubernetes.io/version: 2.45.0
  name: prometheus-release-name
  namespace: default
spec:
  alerting:
    alertmanagers:
    - apiVersion: v2
      name: alertmanager-release-name
      namespace: default
      port: web
  enableFeatures: [remote-write-receiver]
  externalLabels: {}
  image: quay.io/prometheus/prometheus:v2.45.0
  nodeSelector:
    kubernetes.io/os: linux
  podMetadata:
    labels:
      app.kubernetes.io/component: vechr-prometheus
      app.kubernetes.io/instance: prometheus-release-name
      app.kubernetes.io/name: prometheus
      app.kubernetes.io/part-of: vechr-monitoring
      app.kubernetes.io/version: 2.45.0
  podMonitorSelector:     {}
  probeNamespaceSelector:     {}
  probeSelector:     {}
  replicas: 3
  resources:
    requests:
      memory: 400Mi
  ruleNamespaceSelector:      {}
  ruleSelector:     {}
  securityContext:
    fsGroup: 2000
    runAsNonRoot: true
    runAsUser: 1000
  serviceAccountName: vechr-prometheus
  serviceMonitorNamespaceSelector:     {}
  serviceMonitorSelector:     {}
  version: 2.45.0
---
# Source: vechr-monitoring/templates/alert-manager/service-monitor.yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  labels:
    app.kubernetes.io/component: vechr-alertmanager
    app.kubernetes.io/instance: alertmanager-release-name
    app.kubernetes.io/name: alertmanager
    app.kubernetes.io/part-of: vechr-monitoring
    app.kubernetes.io/version: 0.25.0
  name: alertmanager-release-name
  namespace: default
spec:
  endpoints:
  - interval: 30s
    port: web
  - interval: 30s
    port: reloader-web
  selector:
    matchLabels:
      app.kubernetes.io/component: vechr-alertmanager
      app.kubernetes.io/instance: alertmanager-release-name
      app.kubernetes.io/name: alertmanager
      app.kubernetes.io/part-of: vechr-monitoring
---
# Source: vechr-monitoring/templates/grafana/service-monitor.yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  labels:
    app.kubernetes.io/component: vechr-grafana
    app.kubernetes.io/name: grafana
    app.kubernetes.io/part-of: vechr-monitoring
    app.kubernetes.io/version: 10.0.3
  name: grafana-release-name
  namespace: default
spec:
  endpoints:
  - interval: 15s
    port: grafana-dashboard
  selector:
    matchLabels:
      app.kubernetes.io/component: vechr-grafana
      app.kubernetes.io/name: grafana
      app.kubernetes.io/part-of: vechr-monitoring
---
# Source: vechr-monitoring/templates/kube-state-metrics/service-monitor.yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  labels:
    app.kubernetes.io/component: vechr-exporter
    app.kubernetes.io/name: kube-state-metrics
    app.kubernetes.io/part-of: vechr-monitoring
    app.kubernetes.io/version: 2.9.2
  name: kube-state-metrics-release-name
  namespace: default
spec:
  endpoints:
  - bearerTokenFile: /var/run/secrets/kubernetes.io/serviceaccount/token
    honorLabels: true
    interval: 30s
    metricRelabelings:
    - action: drop
      regex: kube_endpoint_address_not_ready|kube_endpoint_address_available
      sourceLabels:
      - __name__
    port: https-main
    relabelings:
    - action: labeldrop
      regex: (pod|service|endpoint|namespace)
    scheme: https
    scrapeTimeout: 30s
    tlsConfig:
      insecureSkipVerify: true
  - bearerTokenFile: /var/run/secrets/kubernetes.io/serviceaccount/token
    interval: 30s
    port: https-self
    scheme: https
    tlsConfig:
      insecureSkipVerify: true
  jobLabel: app.kubernetes.io/name
  selector:
    matchLabels:
      app.kubernetes.io/component: vechr-exporter
      app.kubernetes.io/name: kube-state-metrics
      app.kubernetes.io/part-of: vechr-monitoring
---
# Source: vechr-monitoring/templates/loki/service-monitor.yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  labels:
    app.kubernetes.io/component: vechr-loki
    app.kubernetes.io/name: loki
    app.kubernetes.io/part-of: vechr-monitoring
    app.kubernetes.io/version: 2.8.0
  name: loki-release-name
  namespace: default
spec:
  endpoints:
  - interval: 15s
    port: loki-port
  selector:
    matchLabels:
      app.kubernetes.io/component: vechr-loki
      app.kubernetes.io/name: loki
      app.kubernetes.io/part-of: vechr-monitoring
---
# Source: vechr-monitoring/templates/node-exporter/service-monitor.yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  labels:
    app.kubernetes.io/component: vechr-exporter
    app.kubernetes.io/name: node-exporter
    app.kubernetes.io/part-of: vechr-monitoring
    app.kubernetes.io/version: 1.6.1
  name: node-exporter-release-name
  namespace: default
spec:
  endpoints:
  - bearerTokenFile: /var/run/secrets/kubernetes.io/serviceaccount/token
    interval: 15s
    port: https
    relabelings:
    - action: replace
      regex: (.*)
      replacement: $1
      sourceLabels:
      - __meta_kubernetes_pod_node_name
      targetLabel: instance
    scheme: https
    tlsConfig:
      insecureSkipVerify: true
  jobLabel: app.kubernetes.io/name
  selector:
    matchLabels:
      app.kubernetes.io/component: vechr-exporter
      app.kubernetes.io/name: node-exporter
      app.kubernetes.io/part-of: vechr-monitoring
---
# Source: vechr-monitoring/templates/prometheus/operator/service-monitor.yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  labels:
    app.kubernetes.io/component: vechr-prometheus-operator
    app.kubernetes.io/name: vechr-prometheus-operator
    app.kubernetes.io/part-of: vechr-monitoring
    app.kubernetes.io/version: 0.66.0
  name: prometheus-operator-release-name
  namespace: default
spec:
  endpoints:
  - bearerTokenFile: /var/run/secrets/kubernetes.io/serviceaccount/token
    honorLabels: true
    port: https
    scheme: https
    tlsConfig:
      insecureSkipVerify: true
  selector:
    matchLabels:
      app.kubernetes.io/component: vechr-prometheus-operator
      app.kubernetes.io/name: vechr-prometheus-operator
      app.kubernetes.io/part-of: vechr-monitoring
      app.kubernetes.io/version: 0.66.0
---
# Source: vechr-monitoring/templates/prometheus/service-monitor.yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  labels:
    app.kubernetes.io/component: vechr-prometheus
    app.kubernetes.io/instance: prometheus-release-name
    app.kubernetes.io/name: prometheus
    app.kubernetes.io/part-of: vechr-monitoring
    app.kubernetes.io/version: 2.45.0
  name: vechr-prometheus
  namespace: default
spec:
  endpoints:
  - interval: 30s
    port: web
  - interval: 30s
    port: reloader-web
  selector:
    matchLabels:
      app.kubernetes.io/component: vechr-prometheus
      app.kubernetes.io/instance: prometheus-release-name
      app.kubernetes.io/name: prometheus
      app.kubernetes.io/part-of: vechr-monitoring
---
# Source: vechr-monitoring/templates/tempo/service-monitor.yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  labels:
    app.kubernetes.io/component: vechr-tempo
    app.kubernetes.io/name: tempo
    app.kubernetes.io/part-of: vechr-monitoring
    app.kubernetes.io/version: latest
  name: tempo-release-name
  namespace: default
spec:
  endpoints:
  - interval: 15s
    port: tempo-port
  selector:
    matchLabels:
      app.kubernetes.io/component: vechr-tempo
      app.kubernetes.io/name: tempo
      app.kubernetes.io/part-of: vechr-monitoring
